{"ver":"0.1","info":{"id":"lfSXRz","date":"1705971425","viewed":146,"name":"Importance Sampled Gaussian Fit","username":"chronos","description":"Optimizing/fitting 2D Gaussian Splats. Implements a momentum based minibatch SGD optimization method.\nChange the parameters  (defines) in the Common tab if this sets your computer on fire.","likes":8,"published":1,"flags":32,"usePreview":0,"tags":["2d","gradient","gradient","numbers","optimization","gaussian","dual","splat","automatic","differentiation","descent","splatting","momentum"],"hasliked":0,"parentid":"ddGBDV","parentname":"Momentum Forward Gaussian Fit"},"renderpass":[{"inputs":[{"id":"XdX3Rn","filepath":"/media/a/52d2a8f514c4fd2d9866587f4d7b2a5bfa1a11a0e772077d7682deb8b3b517e5.jpg","previewfilepath":"/media/ap/52d2a8f514c4fd2d9866587f4d7b2a5bfa1a11a0e772077d7682deb8b3b517e5.jpg","type":"texture","channel":3,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\n/*\n\n    Fork of my previous shader \"FMomentum Forward Gaussian Fit\"\n    \n    I've been meaning to make this slight improvement to the Gaussian Fit shader to\n    try to correct what I think is bias in the gradient estimator:\n    It didn't uniformly sample, but also did not take into account the sampling probability in\n    the monte carlo estimator. So I think it was kindof like doing biased importance sampling.\n    hopefully that is fixed now.\n    \n    I also switched the sampling pattern to use the Box Muller transform to importance sample with the shape\n    of a normal distribution with the same parameters as the gaussian, i.e proportional to it.\n    A potential problem here (in theory) is that it will never sample too far from the mean, due to\n    limits to numerical precision. So some regions of the image may end up never being sampled if we are unlucky.\n    \n    I think this should improve the gradient estimation, unless I made a mistake somwhere,\n    but this is still a gradient descent method (albeit with momentum) so it can still get stuck in local minima.\n    \n    Also added a new buffer, buffer B that can be used to visualize samples from the normal distributions.\n    \n    ----------------------------------------------------------------------------------------------\n\n    Momentum Forward Gaussian Fit description:\n\n    Fork of my previous shader \"Fwrd Grad Gaussian Optimization\"\n    Modified to use the momentum stochastic (minibatch) gradient descent method\n    for optimization in addition to the previous forward gradient method for estimating gradients.\n    \n    It looks like this version is a little better at escaping local minima :)\n    \n    ----------------------------------------------------------------------------------------------\n    \n    Fwrd Grad Gaussian Optimization description:\n\n    Fork of my previous shader \"Gaussian Splat Optimization\"\n    Modified to use the \"Forward Gradient Method\" from the paper\n    \"Gradients without Backpropagation\" by Baydin, Pearlmutter, Syme, Wood, Torr\n    \n    In essence it uses an unbiased estimator of the gradient based on\n    forward mode automatic differentiation via dual numbers\n    with random (zero mean and unit variance) perturbations / weights.\n\n    This allows the shader to just sample a random number per parameter per iteration\n    instead of having to do a full render pass per parameter per iteration.\n    \n    Also tried to fix the sRGB color encode / decode ( aka gamma correction )\n    which was not done in my previous shader ( ...to my great shame :O  )\n\n    ----------------------------------------------------------------------------------------------\n\n    Some issues remain:\n     - Gaussians overlapping / overwriting others kills the gradients of the lower layers, preventing optimization\n     - There is no alpha parameter currently, so splats cannot \"relinquish\" their space / influence without moving / shrinking\n     - The optimization can/will get trapped in local minima   (Seems to have improved by using momentum)\n     - Splats that end up outside the optimization target region will not be optimized as much, since those samples are rejected\n     - There is no adaptivity / splitting / cloning of gaussians, like e.g in the paper \"3D Gaussian Splatting for Real-Time Radiance Field Rendering\"\n     \n    TODOs: \n    - Momentum based optimizer                                                       DONE!\n    - Better learning rate decay\n    - Second order / Hessian approximation (?)\n    - Split gaussian parameters among more pixels to allow better parallelization?\n        ( seems like the compiler handles this already though)\n    - Intra-frame optimization substepping\n    - Iteratively optimize multiple layers of splats\n    - Go 3D\n    - importance sampling                                                            DONE!\n    \n*/\n\nGaussian get_gaussian(int j)\n{\n    ivec2 jia = ivec2(j*2, 0);\n    ivec2 jib = ivec2(j*2+1, 0);\n    vec4 a = texelFetch(iChannel0, jia, 0);\n    vec4 b = texelFetch(iChannel0, jib, 0);\n    Gaussian G;\n    G.pos = a.xy;\n    G.scale = a.zw;\n    G.color = b.rgb;\n    G.angle = b.w;\n    return G;\n}\n\nGaussian get_gradient(int j)\n{\n    ivec2 jia = ivec2(j*2, 1);\n    ivec2 jib = ivec2(j*2+1, 1);\n    vec4 a = texelFetch(iChannel0, jia, 0);\n    vec4 b = texelFetch(iChannel0, jib, 0);\n    Gaussian G;\n    G.pos = a.xy;\n    G.scale = a.zw;\n    G.color = b.rgb;\n    G.angle = b.w;\n    return G;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = (2.*fragCoord-iResolution.xy)/iResolution.y;\n    vec2 mouse = (2.*iMouse.xy-iResolution.xy)/iResolution.y;\n    \n    if(length(iMouse.xy) < 10.) mouse = vec2(min(iTime-2., 1.), 0);\n    \n    vec3 color = vec3(0);\n    \n    bool bIsBorder = any(greaterThan(abs(uv),vec2(1.)));\n    if(mouse.x > uv.x || bIsBorder)\n    {\n    \n#if DEBUG_IMPORTANCE_SAMPLING\n        if(mouse.y > uv.y)  // if above the mouse pointer, display the randomly drawn samples (histogram)\n        {\n            \n            const int samples_per_frame = 500;\n        \n            // Normalize to average number of samples per frame scaled by screen area in UV coordinate units.\n            float width  = 2. * iResolution.x/iResolution.y;\n            float height = 2.;\n\n            float screen_area = (iResolution.x / width) * (iResolution.y / height);\n            float total_sample_count = float((iFrame+1) * samples_per_frame);\n\n            vec4 bufB = texture(iChannel1, fragCoord.xy/iResolution.xy);            \n            \n            color.rgb = bufB.rgb;\n            color.rgb *= screen_area / float(samples_per_frame);\n            //color.rgb *= screen_area / total_sample_count;\n            \n        }\n        else\n#endif\n        {\n            for(int j = 0; j < NUM_GAUSSIANS; j++)\n            {\n                Gaussian G = get_gaussian(j);\n                color = draw_gaussian(color, uv, G);\n            }\n        }\n    }\n    else\n    {\n        color = sRGBdecode(texture(iChannel3, uv*.5 + .5).rgb);\n    }\n    \n    // Show gaussian centers\n    #if 1\n    float pix_size = 2. / iResolution.y;\n    for(int j = 0; j < NUM_GAUSSIANS; j++)\n    {\n        Gaussian G = get_gaussian(j);\n        float d = distance(uv, G.pos);\n        color = mix(color, vec3(0), smoothstep(0.0125 + pix_size, 0.0125, d));\n        color = mix(color, vec3(1), smoothstep(0.0075 + pix_size, 0.0075, d));\n\n    }\n    #endif\n    \n    // Darken borders\n    #if 1\n    if(bIsBorder) color*=0.1;\n    #endif\n    \n    // Testcode for random samping in gaussian\n    #if 0\n    if(true)\n    {\n        float rhash = hash(vec3(uv, iTime));\n        float ahash = hash(vec3(uv, float(iFrame)));\n        float angle = 0.;\n        vec2 scale  = vec2(.25, .125);\n        vec2 center  = vec2(0.25);\n\n        Gaussian G;\n        G.pos = center;\n        G.color = vec3(1);\n        G.angle = angle;\n        G.scale = scale;\n\n        vec2 p = BoxMullerTrasform(rhash, ahash, G);\n        if(distance(p, uv) < 0.01) color += 1.;\n\n        color += draw_gaussian(vec3(0), uv, G) * 0.1;\n    }\n    #endif\n    color = sRGBencode(color);\n    \n    fragColor = vec4(color, 1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"#define NUM_GAUSSIANS 32\n#define SAMPLES_PER_FRAME 2500\n#define ALPHA .98\n\n#define DEBUG_IMPORTANCE_SAMPLING 0\n\nconst float learning_rate = 0.003;\n\nconst float PI = 3.14159265;\n\nfloat sRGBencode(float C_linear)\n{\n    return C_linear > 0.0031308 ? (1.055 * pow(C_linear, 1./2.4) - 0.055) : (12.92 * C_linear);\n}\n\nvec3 sRGBencode(vec3 C_linear)\n{\n    C_linear = clamp(C_linear, 0., 1.);\n    return vec3(sRGBencode(C_linear.x), sRGBencode(C_linear.y), sRGBencode(C_linear.z));\n}\n\nfloat sRGBdecode(float C_sRGB)\n{\n    return C_sRGB > 0.04045 ? (pow((C_sRGB + 0.055)/1.055, 2.4) ) : (C_sRGB / 12.92);\n}\n\nvec3 sRGBdecode(vec3 C_sRGB)\n{\n    return vec3(sRGBdecode(C_sRGB.x), sRGBdecode(C_sRGB.y), sRGBdecode(C_sRGB.z));\n}\n\nvec2 real = vec2(1, 0);\nvec2 dual = vec2(0, 1);\nvec2 dualize(float a) { return vec2(a, 0.); }\nvec2 Dual(float a) { return vec2(a, 0.); }\nfloat get_derivative(vec2 dualnum) { return dualnum.y; }\n\nvec2 dexp(vec2 a) // derive from taylor series of exp(x) and that dual^2 = 0\n{\n    return exp(a.x) * vec2(1, a.y);   \n}\n\nvec2 dsin(vec2 a)\n{\n    return vec2(sin(a.x), a.y * cos(a.x));\n}\n\nvec2 dcos(vec2 a)\n{\n    return vec2(cos(a.x), -a.y * sin(a.x));\n}\n\nvec2 dmul(vec2 a, vec2 b)\n{\n    return vec2(a.x * b.x, a.x * b.y + b.x * a.y);\n}\n\nvec2 ddiv(vec2 a, vec2 b)\n{\n    return vec2(a.x / b.x, (a.y * b.x - a.x * b.y) / (b.x * b.x));\n}\n\nvec2 dsqrt(vec2 a)\n{\n    if(a.x == 0.) return vec2(0);\n    return vec2(sqrt(a.x), 0.5 * a.y / sqrt(a.x));\n}\n\n\nstruct Gaussian\n{\n    vec2 pos;\n    vec2 scale;\n    vec3 color;\n    float angle;\n};\n\nstruct DualColor\n{\n    vec2 red;\n    vec2 green;\n    vec2 blue;\n};\n\nstruct DualGaussian\n{\n    vec2 posx;\n    vec2 posy;\n    vec2 scalex;\n    vec2 scaley;\n    \n    DualColor color;\n    \n    vec2 angle;\n};\n\n\nDualColor dualize(vec3 color)\n{\n    DualColor dualcolor;\n    dualcolor.red = dualize(color.r);\n    dualcolor.green = dualize(color.g);\n    dualcolor.blue = dualize(color.b);\n    return dualcolor;\n}\n\nvec3 Real(DualColor dualcolor)\n{\n    return vec3(\n        dualcolor.red.x,\n        dualcolor.green.x,\n        dualcolor.blue.x\n    );\n    \n}\n\nGaussian Real(DualGaussian DG)\n{\n    Gaussian G;\n    \n    G.pos = vec2(DG.posx.x, DG.posy.x);\n    G.scale = vec2(DG.scalex.x, DG.scaley.x);;\n    G.color = Real(DG.color);\n    G.angle = DG.angle.x;\n    \n    return G;\n    \n}\n\nDualGaussian dualize(Gaussian G)\n{\n    DualGaussian DG;\n    \n    DG.posx = dualize(G.pos.x);\n    DG.posy = dualize(G.pos.y);\n    \n    DG.scalex = dualize(G.scale.x);\n    DG.scaley = dualize(G.scale.y);\n    \n    DG.color = dualize(G.color);\n    \n    DG.angle = dualize(G.angle);\n    return DG;\n}\n\n\nDualColor dmix(DualColor a, DualColor b, vec2 alpha)\n{\n    DualColor c;\n    c.red =   dmul((vec2(1,0) - alpha), a.red)   + dmul(alpha, b.red);\n    c.green = dmul((vec2(1,0) - alpha), a.green) + dmul(alpha, b.green);\n    c.blue =  dmul((vec2(1,0) - alpha), a.blue)  + dmul(alpha, b.blue);\n    return c;\n}\n\nfloat gaussian(float x)\n{\n    return exp(- x * x * .5);// / sqrt(2. * PI);\n}\n\nfloat gaussian(vec2 x)\n{\n    return exp(- dot(x, x) * .5);// / sqrt(2. * PI);\n}\n\nvec3 draw_gaussian(vec3 color, vec2 p, Gaussian G)\n{\n    float c = cos(G.angle);\n    float s = sin(G.angle);\n\n    // Inverse of (Scale, Rotate, Translate) = \n    // (Inverse of Translate, Inverse of Rotate, Inverse of Scale)\n    mat2 invRot = mat2(c, -s, s, c);\n    vec2 x = (invRot * (p - G.pos)) / G.scale;\n\n    return  mix(color, G.color, ALPHA * gaussian(x));\n}\n\nDualColor draw_dual_gaussian(DualColor color, vec2 p, DualGaussian DG)\n{\n    vec2 c = dcos(DG.angle);\n    vec2 s = dsin(DG.angle);\n\n    // Inverse of (Scale, Rotate, Translate) = \n    // (Inverse of Translate, Inverse of Rotate, Inverse of Scale)\n    \n    vec2 posx = dualize(p.x) - DG.posx;\n    vec2 posy = dualize(p.y) - DG.posy;\n    \n    vec2 px =  dmul(c, posx)  + dmul(s, posy);\n    vec2 py =  dmul(-s, posx) + dmul(c, posy);\n    \n    px = ddiv(px, DG.scalex);\n    py = ddiv(py, DG.scaley);\n\n    vec2 ddot = dmul(px, px) + dmul(py, py);\n\n    vec2 gaussian = dexp( -ddot * .5);\n    \n    vec2 alpha = gaussian;\n\n    return dmix(color, DG.color, ALPHA * alpha);\n}\n\nvec2 dColorDistSquared(DualColor a, DualColor b)\n{\n    return\n       dmul(a.red   - b.red,   a.red   - b.red) +\n       dmul(a.green - b.green, a.green - b.green) +\n       dmul(a.blue  - b.blue,  a.blue -  b.blue);\n}\n\nconst uint signmask = 0x80000000u;\nconst uint expmask  = 0xEF800000u;\nconst uint mantissamask  = 0x00EFFFFFu;\n\nfloat pack_in_float(uint bits_24)\n{\n    uint bits = bits_24 & 0x00FFFFFFu;\n    uint signbit = (bits & 0x00800000u) << 8u;\n    uint mantissabits = (bits & mantissamask);\n    uint exponentbits = floatBitsToUint(1.) & expmask;\n    return uintBitsToFloat(signbit | exponentbits | mantissabits);\n}\n\nuint unpack_from_float(float encoded)\n{\n    uint bits = floatBitsToUint(encoded);\n    uint a = (bits & signmask) >> 8;\n    uint b = (bits & mantissamask);\n    return a | b;\n}\n\nfloat hash(vec3 uv)\n{\n    uint x = floatBitsToUint(uv.x) | 1u; // 0 is a fixed point so we remove it. although this introduces duplicate 1\n    uint y = floatBitsToUint(uv.y);\n    uint z = floatBitsToUint(uv.z);\n    \n    y ^= y >> 13;\n    y ^= y << 17;\n    y ^= y >> 5;\n    y *= 0x2545F491u;\n\n    x ^= y;\n    x ^= x >> 13;\n    x ^= x << 17;\n    x ^= x >> 5;\n    x *= 0x4F6CDD1Du;\n    \n    z ^= x;\n    z ^= z >> 13;\n    z ^= z << 17;\n    z ^= z >> 5;\n    z *= 0x1D6C45F4u;\n    \n    // Shift down by 9 to use top 23 bits in mantissa\n    // Use exponent and sign bits from 0.5\n    // floatBitsToUint(.5) is a constant so that part can be pre-computed. (0x3f000000)\n    // Since the top 23 bits are shifted right, the rest (top bits) are zero and do not need to be masked out\n    // uint w = ((z>>9) & 0x007FFFFFu) | (0xFF800000u & floatBitsToUint(.5));\n    \n    uint w = (z>>9) | 0x3f000000u; // simplified version of the above commented out line\n    \n    // re-normalize from [0.5, 1) to [0, 1)\n    // This probably loses some bits, but should still be ok\n    return 2. * uintBitsToFloat(w) - 1.;\n}\n\nvec2 BoxMullerTrasform(float U0, float U1, Gaussian G)\n{    \n    vec2 smp = sqrt(\n            -2. * log(U0)\n        ) * vec2(cos(2. * PI * U1), sin(2.*PI*U1));\n    float c = cos(G.angle), s = sin(G.angle);\n    return (mat2(c, s, -s, c) * mat2(G.scale.x, 0., 0., G.scale.y)) * smp + G.pos;\n}\n\nfloat normal_dist(vec2 x, vec2 mean, mat2 covariance)\n{\n    return exp(-.5 * dot(x-mean,inverse(covariance)*(x-mean))) / sqrt(determinant(covariance) * pow(2. * PI, 2.));\n}\n\nfloat normal_dist(vec2 x, Gaussian G)\n{\n    vec2 mean = G.pos;\n\n    float angle = G.angle;\n    float c = cos(angle);\n    float s = sin(angle);\n    mat2 Rotate = mat2(c, s, -s, c);\n    mat2 Scale  = mat2(G.scale.x, 0., 0., G.scale.y);\n\n    mat2 RS = Rotate * Scale;\n\n    mat2 covariance = RS * transpose(RS);\n    \n    return normal_dist(x, mean, covariance);\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"XdX3Rn","filepath":"/media/a/52d2a8f514c4fd2d9866587f4d7b2a5bfa1a11a0e772077d7682deb8b3b517e5.jpg","previewfilepath":"/media/ap/52d2a8f514c4fd2d9866587f4d7b2a5bfa1a11a0e772077d7682deb8b3b517e5.jpg","type":"texture","channel":3,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"Xsf3zn","filepath":"/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"/media/ap/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsBSR3","filepath":"/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","previewfilepath":"/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","type":"texture","channel":2,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"Gaussian get_gaussian(int j)\n{\n    ivec2 jia = ivec2(j*2, 0);\n    ivec2 jib = ivec2(j*2+1, 0);\n    vec4 a = texelFetch(iChannel0, jia, 0);\n    vec4 b = texelFetch(iChannel0, jib, 0);\n    Gaussian G;\n    G.pos = a.xy;\n    G.scale = a.zw;\n    G.color = b.rgb;\n    G.angle = b.w;\n    return G;\n}\n\nGaussian get_gradient(int j)\n{\n    ivec2 jia = ivec2(j*2, 1);\n    ivec2 jib = ivec2(j*2+1, 1);\n    vec4 a = texelFetch(iChannel0, jia, 0);\n    vec4 b = texelFetch(iChannel0, jib, 0);\n    Gaussian G;\n    G.pos = a.xy;\n    G.scale = a.zw;\n    G.color = b.rgb;\n    G.angle = b.w;\n    return G;\n}\n\n// https://en.wikipedia.org/wiki/Continuous_uniform_distribution#Cumulative_distribution_function\nfloat continuous_uniform_distribution(float mean, float standard_deviation, float hash)\n{\n    return standard_deviation  * sqrt(3.) * ( 2. * hash - 1.) + mean;\n}\n\n// https://www.wolframalpha.com/input?i=uniform+distribution++with+minimum+-sqrt%283%29+and+maximum+sqrt%283%29\nfloat continuous_uniform_distribution(float hash)\n{\n    return sqrt(3.) * ( 2. * hash - 1.);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec2 ji = ivec2(fragCoord.xy);\n    \n    int j = (ji.x / 2);\n    int i = ji.y;\n    \n    Gaussian Output;\n    Gaussian Gradient;\n    \n    if(iFrame <= 10) // Initialize parameters to random values in somewhat sensible ranges.\n    {\n        Output.pos = (texelFetch(iChannel2, ivec2(fragCoord), 0).yz * 2. - 1.) * .98;\n        Output.scale = sqrt(texelFetch(iChannel1, ivec2(fragCoord), 0).xy) / 2. + 0.1;\n        Output.color = texelFetch(iChannel1, ivec2(fragCoord), 0).rgb * .8 + .1;\n        Output.angle = texelFetch(iChannel2, ivec2(fragCoord), 0).z * 2. * PI;\n    }\n    else\n    {\n        // Only run once for each Gaussian\n        if(j > NUM_GAUSSIANS || i >= 2) return;    \n        \n        Gaussian G = get_gaussian(j);\n        Gaussian Grad = get_gradient(j);\n        \n        Grad.pos   *= 0.;\n        Grad.scale *= 0.;\n        Grad.color *= 0.;\n        Grad.angle *= 0.;\n        \n        const int samples_per_frame = SAMPLES_PER_FRAME;\n        float schedule = mix(4., .25, smoothstep(30., 600., iTime));\n        float stepsize = schedule * learning_rate / float(samples_per_frame);\n        \n        for(int smp = 0; smp < samples_per_frame; smp++)\n        {\n            // Sample random pixel p in the gaussian.\n            // Have to be a bit careful with the random numbers,\n            // so that each sample becomes different\n            // and the samples are the same for each gaussian\n            // since they are stored in 2 pixels (probably not strictly required)\n            float U0 = hash(vec3(vec2(j,j), float(iFrame*SAMPLES_PER_FRAME + smp)));\n            float U1 = hash(vec3(float(iFrame*SAMPLES_PER_FRAME + smp), vec2(j,U0)));\n            \n            Gaussian ImportanceSampleGaussian = G;\n            \n            // Importance sampling is unbiased regardless, \n            // And using the exact same size gaussian would probably reduce variance further\n            // But under-sampling in parts of the image would likely make it more likely to get stuck in\n            // Local minima, so as a tradeoff we make the impotance sampling a bit less sharp\n            // to combat this, at the 'cost' of increased variance in the gradient estimator.\n            #if 1\n            ImportanceSampleGaussian.scale *= 1.20;\n            ImportanceSampleGaussian.scale += 0.05;\n            #endif\n            \n            vec2 p = BoxMullerTrasform(U0, U1, ImportanceSampleGaussian);\n            float importance_sample_weight = max(normal_dist(p, ImportanceSampleGaussian), 1e-7);\n\n            // Handle samples outside the target area\n            #if 1\n                if(any(greaterThan(abs(p),vec2(1.)))) continue;\n            #else\n                // This doesn't quite work, since the skinny, rotated gaussians\n                // outside the target area will not project onto the gaussian again.\n                p = clamp(p, -1., 1.); \n            #endif\n            \n            DualColor TargetColor = dualize(sRGBdecode(texture(iChannel3, p*.5 + .5).rgb));    \n        \n            Gaussian Perturbations;\n            \n            float hsh = hash(vec3(iFrame*SAMPLES_PER_FRAME + smp, j, U1));\n            Perturbations.pos.x = continuous_uniform_distribution(hsh);\n            hsh = hash(vec3(iFrame*SAMPLES_PER_FRAME + smp, j, hsh));\n            Perturbations.pos.y = continuous_uniform_distribution(hsh);\n            hsh = hash(vec3(iFrame*SAMPLES_PER_FRAME + smp, j, hsh));\n            Perturbations.scale.x = continuous_uniform_distribution(hsh);\n            hsh = hash(vec3(iFrame*SAMPLES_PER_FRAME + smp, j, hsh));\n            Perturbations.scale.y = continuous_uniform_distribution(hsh);\n            hsh = hash(vec3(iFrame*SAMPLES_PER_FRAME + smp, j, hsh));\n            Perturbations.color.r = continuous_uniform_distribution(hsh);\n            hsh = hash(vec3(iFrame*SAMPLES_PER_FRAME + smp, j, hsh));\n            Perturbations.color.g = continuous_uniform_distribution(hsh);\n            hsh = hash(vec3(iFrame*SAMPLES_PER_FRAME + smp, j, hsh));\n            Perturbations.color.b = continuous_uniform_distribution(hsh);\n            hsh = hash(vec3(iFrame*SAMPLES_PER_FRAME + smp, j, hsh));\n            Perturbations.angle = continuous_uniform_distribution(hsh);\n            \n            DualColor Color = dualize(vec3(0));\n            for(int i = 0; i < NUM_GAUSSIANS; i++)\n            {\n                DualGaussian DG = dualize(get_gaussian(i));\n\n                if(i == j) // Compute derivative only for the Gaussian we store the parameters for in the pixel(s)\n                {\n                    DG.posx.y += Perturbations.pos.x;\n                    DG.posy.y += Perturbations.pos.y;\n                    DG.scalex.y += Perturbations.scale.x;\n                    DG.scaley.y += Perturbations.scale.y;\n                    DG.color.red.y += Perturbations.color.r;\n                    DG.color.green.y += Perturbations.color.g;\n                    DG.color.blue.y += Perturbations.color.b;\n                    DG.angle.y += Perturbations.angle;\n                }\n\n                Color = draw_dual_gaussian(Color, p, DG);\n            }\n\n            // Compute Mean Squared Error (MSE)\n            vec2 loss = dColorDistSquared(Color, TargetColor);\n\n            #if 0\n            loss = dsqrt(loss); // Enable to use Mean Absolute Error (MAE)\n            #endif\n\n            float partial = get_derivative(loss);\n    \n            float weighted_partial = partial / importance_sample_weight;\n    \n            Grad.pos   += weighted_partial * Perturbations.pos;\n            Grad.scale += weighted_partial * Perturbations.scale;\n            Grad.color += weighted_partial * Perturbations.color;\n            Grad.angle += weighted_partial * Perturbations.angle;\n        }\n        \n       \n         // Update momentum\n        Gaussian PrevGrad = get_gradient(j);\n        float dampening = 0.9;\n        Gradient.pos   = dampening * PrevGrad.pos   - stepsize * Grad.pos;\n        Gradient.scale = dampening * PrevGrad.scale - stepsize * Grad.scale;\n        Gradient.color = dampening * PrevGrad.color - stepsize * Grad.color;\n        Gradient.angle = dampening * PrevGrad.angle - stepsize * Grad.angle; // should be slerp?\n        \n        \n         // Update weights \n        #if 1\n            G.pos   += Gradient.pos;\n            G.scale += Gradient.scale;\n            G.color += Gradient.color;\n            G.angle += Gradient.angle;\n\n            G.pos   = clamp(G.pos, -1.1, 1.1);\n            G.scale = clamp(G.scale, 0.033, 5.);\n            G.color = clamp(G.color, 0., 1.);\n            G.angle = mod(G.angle, 2. * PI);\n        #endif\n            Output = G;\n        \n    }\n    \n    if((ji.y & 1) == 0)\n    {\n        if((ji.x & 1) == 0)\n        {\n            fragColor = vec4(Output.pos, Output.scale);\n        }\n        else\n        {\n            fragColor = vec4(Output.color, Output.angle);\n        }\n    }\n    else\n    {\n        if((ji.x & 1) == 0)\n        {\n            fragColor = vec4(Gradient.pos, Gradient.scale);\n        }\n        else\n        {\n            fragColor = vec4(Gradient.color, Gradient.angle);\n        }\n    }\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"/*\n\n    Buffer B\n    \n    ----------------------------------------------------------------------\n    \n    This buffer draws a predetermined number of random samples from a uniformly randomly\n    picked Gaussian (normal distribution), which makes the resulting distribution a valid\n    probability distribution as well.\n    I believe this is a Mixture of Gaussians (as in Gaussian Mixture Model) of sorts.\n\n    The parameters of the randomly picked Gaussians are retrieved from Buffer A.\n    \n    The drawn samples are bucketed into pixels and added to their counts, like a histogram.\n    \n    One idea could be to splat more than one pixel (e.g. based on a a Gaussian distribution with std ~ pixel radius)\n    where a sample lands, so that the sub-pixel position is taken into account, giving a form of\n    'anti-aliasing'.\n    \n*/\n\nGaussian get_gaussian(int j)\n{\n    ivec2 jia = ivec2(j*2, 0);\n    ivec2 jib = ivec2(j*2+1, 0);\n    vec4 a = texelFetch(iChannel0, jia, 0);\n    vec4 b = texelFetch(iChannel0, jib, 0);\n    Gaussian G;\n    G.pos = a.xy;\n    G.scale = a.zw;\n    G.color = b.rgb;\n    G.angle = b.w;\n    return G;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = (2.*fragCoord-iResolution.xy)/iResolution.y;\n    \n    // Just to bucket values in each pixel\n    vec2 uv_lower = (2. * floor(fragCoord) - iResolution.xy) / iResolution.y;\n    vec2 uv_upper = (2. *  ceil(fragCoord) - iResolution.xy) / iResolution.y;\n\n    vec3 color = vec3(0);\n\n    vec4 prev_color = texelFetch(iChannel1, ivec2(fragCoord), 0);\n   \n    const int samples_per_frame = 500;\n    const int num_gaussians = NUM_GAUSSIANS;\n    \n    float cnt = 0.;\n    \n    for(int i = 0; i < samples_per_frame; i++)\n    {\n        vec2 smp = vec2(0); // sample \n        \n        // Using Box-Muller transform\n        float U0 = hash(vec3(0., float(i), iFrame));\n        float U1 = hash(vec3(1., float(i), iFrame));\n\n        // Pick random gaussian uniformly\n        Gaussian G = get_gaussian(\n            clamp(\n                int(float(num_gaussians) * hash(vec3(2., float(i), iFrame))),\n                0,\n                num_gaussians-1\n                )\n            );\n        \n        // TODO: Need to account for importance sampling shape modification here (e.g. increased scale),\n        // if visualizing impotance sampling and if not just straight gaussian is used.\n        #if DEBUG_IMPORTANCE_SAMPLING\n        \n        \n        #endif\n        //////////\n            \n        smp = BoxMullerTrasform(U0, U1, G);\n\n         // Put the sample in its bucket\n        if(\n            uv_lower.x <= smp.x\n            &&\n            smp.x < uv_upper.x\n            &&\n            uv_lower.y <= smp.y\n            &&\n            smp.y < uv_upper.y\n        )\n        {\n            color.rgb += G.color;\n            cnt++;\n        }\n    }\n\n    float exp_moving_avg_param = 0.01;\n    fragColor = vec4(mix(prev_color.rgb, color, exp_moving_avg_param), mix(prev_color.a, cnt, exp_moving_avg_param));\n}\n","name":"Buffer B","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"NdlfRf","date":"1645147728","viewed":175,"name":"Unbiased sRGB Quantization","username":"ttg","description":"Dithering should happen in sRGB, but quantization should do rounding in linear intensity intervals.\n\nPlots (center): error in resulting physical intensity averaged over the dithering.\nRed: naive quantization\nGreen: sRGB-aware quantization\n","likes":5,"published":1,"flags":32,"usePreview":0,"tags":["2d","rgb","dithering","srgb"],"hasliked":0,"parentid":"NssBRX","parentname":"Dithering should happen in sRGB"},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Display and plot the averaged result\n\nvoid mainImage (out vec4 srgb, vec2 f) {\n  vec3 v = texelFetch(iChannel0,ivec2(f),0).rgb/float(iFrame+1);\n\n  // Dim display to make plot easier to read\n  v *= .2;\n\n  vec2 R = iResolution.xy;\n  vec2 uv = f/R;\n  vec2 m = iMouse.xy/R;\n  if (iMouse.x<1.) m=vec2(0,.5);\n  float x=uv.x;\n  float y=uv.y;\n  float vref = texture(iChannel1,vec2(x,m.y)).w;\n  vec3 vtest = texture(iChannel0,vec2(x,m.y)).rgb/float(iFrame+1);\n  vec2 a=vtest.rg;\n  vec2 b= (a-vref)*100.+.5;\n  if (abs(a.x-y)<.002) v=vec3(1,0,0);\n  if (abs(a.y-y)<.002) v=vec3(0,.3,0);\n  if (abs(b.x-y)<.004) v=vec3(0,0,0);\n  if (abs(b.x-y)<.002) v=vec3(1,0,0);\n  if (abs(b.y-y)<.004) v=vec3(0,0,0);\n  if (abs(b.y-y)<.002) v=vec3(0,1,0);\n\n  srgb.xyz = srgb_encode(v);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// The displays expects colors in sRGB space, so we'll be converting colors\n// from linear space to sRGB. But also, the display has a limted number of\n// bits (usually 8, but say 3 for today's test - change line 11 to emulate\n// other bit counts). So we'll want to dither the results to prevent banding.\n// So now the question arises - should we convert to sRGB before or after\n// dithering. The answer is _before_, since dithering aids quantization, and\n// that happens in sRGB, or in the display if you want. Comment the #define\n// in line 12 to see the consequences of doing the sRGB conversion _after_ \n// dithering - darkest colors are wrong, and the noise no longer feels uniform.\n\n#define BITS 4\n#define SHOW_CORRECT\n\n//------------------------------------------------------------------\n// rand()\n//------------------------------------------------------------------\nint   seed = 1;\nint   rand(void) { seed = seed*0x343fd+0x269ec3; return (seed>>16)&32767; }\nfloat frand(void) { return float(rand())/32767.0; }\nvoid  srand( ivec2 p, int frame )\n{\n    int n = frame;\n    n = (n<<13)^n; n=n*(n*n*15731+789221)+1376312589; // hash by Hugo Elias\n    n += p.y;\n    n = (n<<13)^n; n=n*(n*n*15731+789221)+1376312589;\n    n += p.x;\n    n = (n<<13)^n; n=n*(n*n*15731+789221)+1376312589;\n    seed = n;\n}\n\n//------------------------------------------------------------------\n// color display functions\n//------------------------------------------------------------------\n\nfloat lrgb2srgb( float color )\n{\n\treturn (color<0.0031308) ? color*12.92:1.055*pow(color,(1.0/2.4))-0.055;\n}\n\nfloat dither( float color )\n{\n    float n = frand()+frand()-1.0;  // triangular noise\n    return color + n/(exp2(float(BITS))-1.);\n}\n\nfloat quantize( float color )\n{\n    const float levelrange = exp2(float(BITS))-1.;\n    return round(color*levelrange)/levelrange;\n}\n\nfloat quantize_srgb( float color )\n{\n    const float levelrange = exp2(float(BITS))-1.;\n    float qvalf = floor(color*levelrange)/levelrange;\n    float qvalc = qvalf+1./levelrange; // ceiling\n    \n    // same as simple quantize\n    //   (round = test against middle of encoded range):\n    // return (color>.5*(qvalf+qvalc)) ? qvalc : qvalf;\n    \n    // rounding in linear intensity range\n    //   (round = test against middle of represented range):\n    return (srgb_decode(color)>.5*(srgb_decode(qvalf)+srgb_decode(qvalc)))\n            ? qvalc : qvalf;\n}\n\n//------------------------------------------------------------------\n// main\n//------------------------------------------------------------------\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    // Init randoms\n    srand( ivec2(fragCoord), iFrame );\n\n    // Coordinates\n    float x = 1.0*fragCoord.x/iResolution.x;\n    float y = 3.0*fragCoord.y/iResolution.y;\n\n    // Create an energy linear color ramp. Note that darks will feel\n    // compressed to your eye. Do col=pow(x,2.2) to make it more\n    // perceptually linear if you want\n    float col = x;\n    \n    // Important!  Make headroom for perceptually uniform dithering of whites\n    // ( else clamping to 1 will cause saturation problem,\n    //   or dithering must be adjusted )\n    col*=srgb_decode(1.-.5*exp2(-float(BITS)));\n    \n    // Reference value\n    fragColor.w = col;\n\n    // CORRECT: convert to sRGB BEFORE dithering\n    #ifdef SHOW_CORRECT\n        col = lrgb2srgb( col ); \n\n        if( y>1.0 && y<2.0 )\n        col = dither( col );\n\n    // INCORRECT: converting to sRGB AFTER dithering\n    #else\n        if( y>1.0 && y<2.0 )\n        col = dither(col);\n        \n        col = lrgb2srgb( col ); \n    #endif\n\n    fragColor.xyz = vec3(col);\n    \n    // simulate 2^BITS color level display screen\n    if( y>1.0 )\n    {\n        // Slightly incorrect: simple rounding quantizer\n        fragColor.r = quantize(col);\n        \n        // Correct: nonlinearity-aware quantizer\n        fragColor.g = quantize_srgb(col);\n        fragColor.b = fragColor.g;\n    }\n    fragColor = clamp(fragColor,0.,1.);\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"vec3 srgb_decode (vec3 e) {\n  return mix(e/12.92,pow((e+.055)/1.055,vec3(2.4)),lessThan(vec3(.04045),e));\n}\nfloat srgb_decode (float e) { return srgb_decode(vec3(e)).x; }\n\nvec3 srgb_encode (vec3 v) {\n  return mix(12.92*v,1.055*pow(v,vec3(.41666))-.055,lessThan(vec3(.0031308),v));\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// Buffer B: simulate the monitor's rendering of sRGB triplets into light intensities\n\nvoid mainImage (out vec4 v, vec2 f) {\n  vec3 srgb = texelFetch(iChannel0, ivec2(f), 0).xyz;\n  v.rgb = srgb_decode(srgb);\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// Buffer C: sum light intensities over time and average over vertical\n\nvoid mainImage (out vec4 v, vec2 f) {\n  v.rgb = vec3(0.);\n  for (int i=0; i<20; i++)\n    v.rgb+= texelFetch(iChannel1, ivec2(f)+ivec2(0,i-10), 0).rgb / 20.;\n  v.rgb+= texelFetch(iChannel0, ivec2(f), 0).rgb;\n}\n","name":"Buffer C","description":"","type":"buffer"}]}
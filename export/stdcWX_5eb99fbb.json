{"ver":"0.1","info":{"id":"stdcWX","date":"1660779790","viewed":130,"name":"Analytic intersect, dist, text","username":"pyrite","description":"demo of analytic sphere, triangle, intersections including texture scales, sums of inverse distances. \n\nyou can pause and use the mouse to rotate the camera","likes":4,"published":1,"flags":0,"usePreview":0,"tags":["dof","camera","aa","ssaa","ca"],"hasliked":0,"parentid":"Nl3yDj","parentname":"discrete optical camera"},"renderpass":[{"inputs":[{"id":"XdXGzn","filepath":"/media/a/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","previewfilepath":"/media/ap/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","type":"texture","channel":0,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"vec4 asphere(in vec3 ro, in vec3 rd, in vec3 sp, in float sr){ \n    // geometric solution for analytic ray-sphere intersection\n    vec3 e0 = sp - ro; //vector from ray origin to center of sphere\n    float e1 = dot(e0,rd); //distance from origin of ray to closest point on ray to center of sphere\n    float cr2 = dot(e0,e0) - e1*e1; //square of radius of closest point on ray to center of sphere\n    float cr = sqrt(cr2); //radius of closest point on ray to center of sphere\n    float sr2 = sr*sr; //square of sphere radius\n    float e2 = sqrt(sr2 - cr2); //distance from closest point of ray to center of sphere to edge of sphere.\n    float t = e1-e2; //shortest distance from ray origin to intersection of ray and sphere\n    float id = 1.0/(cr-sr);\n    vec2 text = (t*rd+ro-sp).rg;\n    if(cr<sr){return vec4(t, text, id);}//distance to surface, inverse distance\n    return vec4(999.9, vec2(0.0), id);\n}\n\nvec4 atriangle( in vec3 ro, in vec3 rd, in vec3 v0, in vec3 v1, in vec3 v2 )\n{\n    vec3 v1v0 = v1 - v0;\n    vec3 v2v0 = v2 - v0;\n    vec3 rov0 = ro - v0;\n\n    // Cramer's rule for solving p(t) = ro+t·rd = p(u,v) = vo + u·(v1-v0) + v·(v2-v1)\n    float d = 1.0/determinant(mat3(v1v0, v2v0, -rd ));\n    float u =   d*determinant(mat3(rov0, v2v0, -rd ));\n    float v =   d*determinant(mat3(v1v0, rov0, -rd ));\n    float t =   d*determinant(mat3(v1v0, v2v0, rov0));\n    \n    //t = min(t, min(1.0-(u+v), min(u, v)));\n    if( u<0.0 || v<0.0 || (u+v)>1.0 ) t = 999.0;\n    float id = max(1.0/sqrt(u*u+(v-1.0)*(v-1.0)),\n               max(1.0/sqrt((u-1.0)*(u-1.0)+v*v),\n               max(1.0/sqrt(u*u+v*v),\n               (v>=0.0 && v<1.0 && (u+v)<1.0)?(1.0/(-u)):\n               (u>=0.0 && u<1.0 && (u+v)<1.0)?(1.0/(-v)):\n               (u>=0.0 && u<v+1.0 && v>=0.0 && v<u+1.0 && (u+v)>=1.0)?(1.4142136/(u+v-1.0)):\n               0.0)));\n               \n    float du = 1.0/(-u);\n    float dv = 1.0/(-v);\n    float dt = du+dv;\n    return vec4( t, u, v, id );\n}\n\nvec4 amins(in vec4 s1, in vec4 s2){ //returns vec3 with smallest first element, and sum of inverse distance\n    return (abs(s1.s)<abs(s2.s))?\n    vec4(s1.rgb, s1.a+s2.a):\n    vec4(s2.rgb, s1.a+s2.a);\n}\n\nvec3 ascene(in vec3 ro, in vec3 rd){\n    //*/\n    vec4 t = vec4(999.9,vec3(0.0));\n    vec3 move = vec3(sin(iTime)-0.75, sin(iTime)-0.75,0.0);\n    \n        t = amins(t,\n            amins(\n                asphere(ro,rd,vec3(-0.5,-0.5,0.0)-move*0.5,0.5),\n                atriangle(ro,rd,vec3(0.0)+move,vec3(1.0,0.0,0.0)+move,vec3(0.0,1.0,0.0)+move)\n                ));\n    \n    /*/\n    vec2 t = \n        amins(asphere(ro,rd,vec3(0.0,0.0,0.0),1.5),\n        amins(asphere(ro,rd,vec3(-2,0.0,0.0),1.0), \n        amins(asphere(ro,rd,vec3(0.0,-2,0.0),1.0),\n        amins(asphere(ro,rd,vec3(1.15,1.15,1.15),1.0),\n        amins(asphere(ro,rd,vec3(0.0,0.0,-2),1.0),\n        asphere(ro,rd,vec3(3.,3.,3.),0.2)\n        ))))); //length along ray to intersection, material, sum of inverse distance\n    //*/\n    vec3 col = vec3(0.0);\n    /*/\n    \n        col = clamp(col+vec3(t.z/(5.0+abs(t.z))),0.0,1.0); //add sigmoid of sum of inverse distances\n        }\n    //*/\n        \n    if (t.r<999.0){\n        vec3 loc = t.r*rd+ro; //ray information to location\n        if (t.gb == vec2(0.0)){col = texture(iChannel0,loc.rg*0.2,0.0).rgb;}\n        else{col = texture(iChannel0,t.gb*0.2,0.0).rgb;}//clamp((vec3(loc.x,loc.y,loc.z)+vec3(1.0))*0.5,0.0,1.0);\n        //col = clamp(col+vec3(t.y/(5.0+abs(t.y)),0.0,0.0),0.0,1.0); //add sigmoid of sum of inverse distances\n    }\n    else \n    col = clamp(col + vec3(t.w/(10.0+abs(t.w))),0.0,1.0);\n    \n\n    return col;\n}\n\nvec3 acamera( in vec3 cameraPos, in vec3 cameraDir, in vec2 fragCoord){\n    //THIS v\n    const int lensResolution = 5; //THIS <\n    const int superSample = 2; //THIS <\n    float lensDistance = 2.0; //THIS <\n    float lensDiameter = 0.5; //THIS <\n    float focalDis = 20.0; //THIS <\n    float chromaticAberration = 0.1; //THIS <\n    //THIS ^\n    \n    //fragcoord is the center of the pixel\n\tvec2 sensorLoc = \n        vec2(0.5,0.5*(iResolution.y/iResolution.x))//sets x limits from 0->1, y at same scale, center at (0.5,0.?)\n        - fragCoord.xy / iResolution.x; //reverse sensor and center on (0,0)\n        \n    vec3 trueY = vec3(0.0,1.0,0.0); //useful later could be hardcoded later instead\n    vec3 cameraX = normalize(cross(cameraDir,trueY)); //right dir for camera\n    vec3 cameraY = normalize(cross(cameraX,cameraDir)); //up dir for camera\n    \n    vec3 colorTotal = vec3(0.0);//for each pixel reset the accumulated color\n    float colorCount = 0.0; //keep track of how many color samples are in final sum\n        \n    float sscale = 1.0/(iResolution.x); //size of a pixel\n    float sstep = 1.0/float(superSample); //step for Super Sample Anti Aliasing\n    float sstart = sstep/2.0 - 0.5; //location of first SSAA step\n    \n    float lstep = 1.0/(float(lensResolution)); //step for lens\n    float lstart = lstep/2.0 - 0.5; //location of first lens step\n    \n    //Red Channel\n    float rFocalDis = focalDis*(1.0+chromaticAberration); //adjust focal lenth for red channel based on aberration\n    float rFocal = 1.0+lensDistance/rFocalDis; //adjust focal lenth for red channel based on lens position\n    \n    //Green Channel \n    float gFocalDis = focalDis; //adjust focal lenth for green channel based on aberration\n    float gFocal = 1.0+lensDistance/gFocalDis; //adjust focal lenth for green channel based on lens position\n\n    //Blue Channel\n    float bFocalDis = focalDis*(1.0-chromaticAberration); //adjust focal lenth for blue channel based on aberration\n    float bFocal = 1.0+lensDistance/bFocalDis; //adjust focal lenth for blue channel based on lens position\n    \n    \n    for (float sx = sstart; sx < 0.5; sx += sstep){ //SSAA x direction\n    \tfor (float sy = sstart; sy < 0.5; sy += sstep){ //SSAA y direction\n            \n        \tvec2 ss = vec2(sx,sy)*sscale; //sub pixel offset for SSAA\n            vec3 sensorRel = cameraX*(sensorLoc.x+ss.x) + cameraY*(sensorLoc.y+ss.y); //position on sensor relative to center of sensor. Used once\n            vec3 sensorPos = cameraPos - lensDistance*cameraDir + sensorRel; //3d position of ray1 origin on sensor\n            \t\n            for (float lx = lstart; lx <0.5; lx+=lstep){\n        \t\tfor (float ly = lstart; ly <0.5; ly+=lstep){\n                    \n            \t\tvec2 lensCoord = vec2(lx,ly); //fragCoord analog for lens array. lens is square\n        \t\t\tvec2 lensLoc = (lensCoord)*lensDiameter; //location on 2d lens plane\n            \t\t\n                    if (length(lensCoord)<0.5){ //trim lens to circle\n                        \n                \t\tvec3 lensRel = cameraX*(lensLoc.x) + cameraY*(lensLoc.y); //position on lens relative to lens center. Used twice\n            \t\t\tvec3 lensPos = cameraPos + lensRel; // 3d position of ray1 end and ray2 origin on lens\n            \t\t\tvec3 senlenRay = lensPos - sensorPos; //direction of ray from sensor to lens\n                        \n                        //Red channel\n                        vec3 rRay = senlenRay - rFocal*(lensRel); //direction of ray afer being focused by lens\n                        rRay = normalize(rRay); //normalize after focus\n                        \n                        vec3 red = ascene(lensPos,rRay); //scene returns red\n                        \n                        if(chromaticAberration!=0.0){\n                            //Green channel\n                            vec3 gRay = senlenRay - gFocal*(lensRel); //direction of ray afer being focused by lens\n                            gRay = normalize(gRay); //normalize after focus\n\n                            //Blue channel\n                            vec3 bRay = senlenRay - bFocal*(lensRel); //direction of ray afer being focused by lens\n                            bRay = normalize(bRay); //normalize after focus\n                            \n                            vec3 green = ascene(lensPos,gRay); //scene returns green\n                            vec3 blue = ascene(lensPos,bRay); //scene returns blue\n\n                            colorTotal = colorTotal+vec3(red.r, green.g, blue.b); //sum color over all points from lens\n                        }else{\n                            colorTotal = colorTotal+red;\n                        }\n                        \n                        colorCount += 1.0; //total number of colors added.\n                    }\n                }\n            }\n        }\n    }\n    \n    return colorTotal/colorCount; //return average color value after all rays have been summed. \n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n\n    float tau = 0.2*iTime - 5.0*iMouse.x/iResolution.x; //tau used to determine camera position\n    \n    vec3 cameraPos = 20.0*vec3(1.0*sin(3.0*tau),0.0*sin(2.0*tau),1.0*cos(3.0*tau)); //this is not normalized\n    vec3 cameraDir = normalize(-cameraPos); //normalized ray from cameraPos to 0,0,0\n    \n    \n    fragColor = vec4(acamera(cameraPos,cameraDir,fragCoord),0.0); //return the color of the pixel on the camera sensor. \n}","name":"Image","description":"","type":"image"}]}
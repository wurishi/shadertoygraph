{"ver":"0.1","info":{"id":"sdy3zc","date":"1651431121","viewed":101,"name":"Review Path Tracing","username":"YUIT","description":"Review Path tracing, not complete yet!","likes":5,"published":1,"flags":32,"usePreview":0,"tags":["pathtracer"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec4 col = texelFetch(iChannel0, ivec2(fragCoord),0);\n    col.rgb = LinearToGamma(col.rgb);\n    fragColor = col;\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"\n// Path Tracer Review\n// Use right hand coordinate system\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Macro and constants\n#define EPS_float 1e-08                  // Epsilon for float\n#define PLANE_BIAS 0.000090               // Plane bias\n#define RAY(t, r) ((r.o)+(r.d)*(t))      // Ray formular\n#define PI 3.1415926\n#define TWO_PI 6.2831853\n#define ONE_OVER_PI 0.31830989\n#define ONE_BY_SQRT_TWO 0.7071067811\n\n#define TMIN 0.0001\n#define TMAX 100.\n#define INFINITE 1e9\n#define DEPTH 2u\n#define CONVERGE_FRAMECOUNT 20000\n\n// The compile time when use 3 SPP is about 3 seconds (when DEPTH is 2), \n// but with 4 SPP or 5 SPP, that is even lower about 1 seconds \n// Question: why happen this?\n#define SPP 5u \n#define USE_PROGRESSIVE 1\n#define USE_JITTERED_NROOT 0\n#define USE_WORLDSPACE_RAY 1\n#define USE_POISSON 0                    // Use Poisson disk distribution \n#define USE_GOLDNOISE 0\n\n#define PLACE_OBJ_SPHERE 1\n#define PLACE_OBJ_PLANE  0\n#define PLACE_OBJ_BOX    0\n#define PLACE_OBJ_REC    1\n\n#define IMPORTANCE_SAMPLING 0\n#define SIMPLE_UNIFORM_HEMISPHERE 1\n\nconst mat3 IDENTITY_COORD = mat3(1.);\nuint global_seed = 5841U;\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Utility functions\n\n// Construct a orthogonal basis from a unit vector\n// This algorithm is the Hughes-M¨oller method\nvoid ONB(in vec3 u, inout vec3 v, inout vec3 w)\n{\n    if (u.z < -0.999999){\n         v = vec3(0., -1., 0.);\n         w = vec3(-1., 0., 0.);\n         return;\n    }else{\n        float a = 1./(1.+u.z);\n        float b = -u.x*u.y*a;\n        v = vec3(1.-u.x*u.x*a,b,-u.x);\n        w = vec3(b,1.-u.y*u.y*a,-u.y);\n    }\n}\n\nvoid hughes_moeller(vec3 n, out vec3 b1, out vec3 b2 )\n{\n    // Choose a vector orthogonal to n as the direction of b2.\n    if( abs (n.x ) > abs (n. z )) b2 = vec3 (-n.y , n .x , 0.0);\n    else b2 = vec3 (0.0, -n.z , n.y );\n    b2 *= inversesqrt(dot (b2 , b2 )); // Normalize b2\n    b1 = cross(b2, n); // Construct b1 using a cross product\n}\n\nvoid naive( vec3 n , out vec3 b1 , out vec3 b2 )\n{\n    // If n is near the x-axis , use the y- axis . Otherwise use the x- axis .\n    if(n.x > 0.9 ) b1 = vec3(0.0, 1.0, 0.0);\n    else b1 = vec3(1.0, 0.0, 0.0);\n    b1 -= n* dot (b1 , n ); // Make b1 orthogonal to n\n    b1 *= inversesqrt(dot (b1 , b1 )); // Normalize b1\n    b2 = cross (n , b1 ); // Construct b2 using a cross product\n}\n\nvoid NormalTransformToWorld(inout vec3 n, vec3 u, vec3 v, vec3 w)\n{\n    n = normalize(u*n.x + v*n.y + w*n.z);\n}\n\nmat4 RotateY(float angle)\n{\n    float sinc = sin(radians(angle));\n    float cosc = cos(radians(angle));\n    return mat4(\n        vec4(cosc,0.,sinc,0.),\n        vec4(0.,1.,0.,0.),\n        vec4(-sinc,0,cosc,0.),\n        vec4(0.,0.,0.,1.)\n    );\n}\n\nvec2 Rotate2d( vec2 p, float a ) \n{\n\tvec2 sc = vec2(sin(a),cos(a));\n\treturn vec2( dot( p, vec2(sc.y, -sc.x) ), dot( p, sc.xy ) );\n}\n\nfloat pow2(float a){ return a*a; }\nfloat pow4(float a){ return a*a*a*a; }\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Random number generator\n// From https://www.shadertoy.com/view/Xt3cDn\n\nvoid InitSeed(uint offset)\n{\n    global_seed += offset;\n}\n\nuint baseHash(uvec3 p)\n{\n    p = 1103515245U*((p.xyz >> 1U)^(p.yzx));\n    uint h32 = 1103515245U*((p.x^p.z)^(p.y>>3U));\n    return h32^(h32 >> 16);\n}\n\nuint baseHash(uint p)\n{\n    p = 1103515245U*((p >> 1U)^(p));\n    uint h32 = 1103515245U*((p)^(p>>3U));\n    return h32^(h32 >> 16);\n}\n\nvec2 hash21(uint x)\n{\n    uint n = baseHash(x);\n    uvec2 rz = uvec2(n, n*48271U); //see: http://random.mat.sbg.ac.at/results/karl/server/node4.html\n    return vec2((rz.xy >> 1) & uvec2(0x7fffffffU))/float(0x7fffffff);\n}\n\nvec3 hash31(uint x)\n{\n    uint n = baseHash(x);\n    uvec3 rz = uvec3(n, n*16807U, n*48271U); //see: http://random.mat.sbg.ac.at/results/karl/server/node4.html\n    return vec3((rz >> 1) & uvec3(0x7fffffffU))/float(0x7fffffff);\n}\n\nfloat PHI = 1.61803398874989484820459 * 00000.1; // Golden Ratio   \nfloat PI_  = 3.14159265358979323846264 * 00000.1; // PI\nfloat SQ2 = 1.41421356237309504880169 * 10000.0; // Square Root of Two\n\n// https://www.shadertoy.com/view/ltB3zD\nfloat gold_noise(in vec2 coordinate, in float seed){\n    return fract(tan(distance(coordinate*(seed+PHI), vec2(PHI, PI_)))*SQ2);\n}\n\n\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Sampling Strategy\n\n\n// The sample point per pixel\n#if !USE_PROGRESSIVE\nvec2 sampledPoints[SPP*SPP];\n#else\nvec2 sampledPoints[1];\n#endif\n\n// Poisson Disc Sampling\n// Fast Poisson Disc Sampling in Arbitrary Dimensions\n// It's a sequential method just run in CPU\n// Need another method fitted to these situation\n// 2-dimensinal nxn grid \n// 1. define the basic \n// cell size = r / sqrt(2)\nvoid Poisson(float radius, uint seed)\n{\n    \n}\n\nvoid LUTPoisson()\n{\n\n}\n\n// Stochastic Sampling in Computer Graphics \n// Author: ROBERT L. COOK\n// Stochastic sampling is a Monte Carlo technique \n\n// Generate per pixel jitter points\nvoid Jittered_RegularGrid(uint seed, float pixelSize)\n{\n    // Iterate a nxn grid\n#if !USE_PROGRESSIVE\n    uint n = SPP;\n#else \n    uint n = 1u;\n#endif\n    for(uint i=0u;i < n*n;i++){\n        sampledPoints[i] = \n            hash21(i+seed)*           // uniformly random number in (0,1)\n            vec2(1./float(n))*        // cell size\n            vec2(i%n+1u,i/n+1u);      // match to each cell\n        sampledPoints[i] -= vec2(.5);\n        sampledPoints[i] *= pixelSize;\n    }\n}\n\n#if !USE_PROGRESSIVE && USE_JITTERED_NROOT\nvoid Jittered_NROOT(uint seed, float pixelSize)\n{\n    uint sqrt_samples=SPP;\n    float sub_cell_width=pixelSize/float(SPP);\n    for(uint i=0u;i<sqrt_samples;i++)\n        for(uint j=0u;j<sqrt_samples;j++){\n            vec2 rand=vec2(-.5)+hash21(i+seed);\n            sampledPoints[i*sqrt_samples+j]=vec2(\n                float(i)*sub_cell_width*float(sqrt_samples)+float(j)*sub_cell_width+rand.x*sub_cell_width,\n                float(j)*sub_cell_width*float(sqrt_samples)+float(i)*sub_cell_width+rand.y*sub_cell_width\n            );\n        }\n    // shuffle the xy coordinates\n    for(uint i=0u;i<sqrt_samples;i++)\n        for(uint j=0u;j<sqrt_samples;j++){\n            uvec2 k=uvec2(j)+uvec2(\n                baseHash(j*50054430u)%(1u+uint(sqrt_samples-j-1u)),\n                baseHash(j*30352430u)%(1u+uint(sqrt_samples-j-1u))\n            );\n            float t=sampledPoints[i*sqrt_samples+j].x;\n            sampledPoints[i*sqrt_samples+j].x=sampledPoints[i*sqrt_samples+k.x].x;\n            sampledPoints[i*sqrt_samples+k.x].x=t;\n\n            t=sampledPoints[j*sqrt_samples+i].y;\n            sampledPoints[j*sqrt_samples+i].y=sampledPoints[k.y*sqrt_samples+i].y;\n            sampledPoints[k.y*sqrt_samples+i].y=t;\n        }\n    for(uint i=0u;i < SPP*SPP;i++)\n        sampledPoints[i] *= pixelSize;\n}\n#endif\n\nvec3 HemisphereRandomSample(uint seed)\n{\n    vec3 sampleVec=vec3(0.);\n    // reference: https://mathworld.wolfram.com/SpherePointPicking.html\n#if SIMPLE_UNIFORM_HEMISPHERE\n    vec2 rand = hash21(global_seed+seed)*vec2(1., PI);\n    rand.x = rand.x*2.-1.; // range[0, 2*PI]\n    vec2 theta = vec2(sin(rand.y), cos(rand.y)); // range[0, PI]\n    vec2 phi = vec2(sin(acos(rand.x)), rand.x);\n    sampleVec = vec3(phi.y*theta.x,phi.x*theta.x,theta.y);\n    \n#elif IMPORTANCE_SAMPLING\n    vec2 rand=hash21(global_seed+seed)*vec2(PI,TWO_PI);\n    float r = sqrt(rand.x);\n    float theta = TWO_PI*rand.y;\n \n    float x = r*cos(theta);\n    float y = r*sin(theta);\n    sampleVec=vec3(x,y,sqrt(max(0.f,1.-rand.x*rand.x-rand.y*rand.y)));\n#else\n\n#endif\n    return sampleVec;\n}\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Camera and Ray models\n\n\n// Define Ray Model\nstruct Ray\n{\n    vec3 o;\n    vec3 d;\n};\n\n// Define The Pinhole Camera Model\nstruct Camera \n{\n    // fov in y direction\n    float fovy; \n    vec3 t;\n    vec3 e;\n};\n\n// Get pinhole camera view matrix\nmat4 GetPinholeCameraViewMatrix(in Camera cam)\n{   \n    vec3 forward = -normalize(cam.t - cam.e);\n    vec3 right, up;\n    \n    naive(forward, right, up);\n    /*right = normalize(cross(IDENTITY_COORD[1], forward));\n    up = cross(forward, right);*/\n    mat3 m = transpose(mat3(right,up,forward));\n    \n    mat4 viewMatrix = mat4(\n        vec4(m[0],0.),\n        vec4(m[1],0.),\n        vec4(m[2],0.),\n        vec4(-m*cam.e, 1.)\n    );\n    return viewMatrix;\n}\n\n// aspect = Height/Width\nfloat focalLengthToFovY(float f, float h)\n{\n    return 2.*atan(.5*h/f);\n}\n\n// Calculate focal length from fovy\nfloat fovYToFocalLength(float fovy, float h)\n{\n    return h/(2.*tan(radians(.5*fovy)));\n}\n\nfloat GetFilmWidth(float fovy, float f, float aspect)\n{\n    return 2.*f*tan(radians(fovy*.5))/aspect;\n}\n\nvoid GetPinholeCameraRay(\n    inout Ray ray, in vec2 pixel, in vec2 offset, in vec2 vp,\n    in vec3 u, in vec3 v, in vec3 w, in float aspect)\n{   \n    vec2 pi = (pixel+offset)/vp-.5;\n    pi.y *= aspect;\n    // Transform pixel coordinate into film plane based frame\n    ray.d = normalize(pi.x*u+pi.y*v+w);\n}\n\n\n// Distributed ray tracing\n#if !USE_PROGRESSIVE\nRay distributed_camera_rays[SPP*SPP];\n#else \nRay distributed_camera_rays[1];\n#endif\n\nvoid DistributedCameraRay(\n    vec2 pixel, vec2 vp, float fovy,\n#if USE_WORLDSPACE_RAY\n    vec3 rayOrigin, \n    vec3 cam_u, vec3 cam_v, vec3 cam_w,\n#endif\n    float aspect)\n{\n    // Generate the jitterd points\n#if USE_POISSON\n    Poisson();\n#elif !USE_PROGRESSIVE && USE_JITTERED_NROOT\n    Jittered_NROOT(uint(dot(pixel,pixel))+global_seed, 0.7);\n#else\n    Jittered_RegularGrid(uint(dot(pixel,pixel))+global_seed, 1.);\n#endif\n    float f = fovYToFocalLength(fovy,1.);\n    Ray r = Ray(vec3(0.),vec3(0.));\n    vec3 u,v,w;\n#if USE_WORLDSPACE_RAY\n    r.o = rayOrigin;\n    u = cam_u;\n    v = cam_v;\n    w = cam_w*-f;\n#else\n    u = IDENTITY_COORD[0];\n    v = IDENTITY_COORD[1];\n    w = IDENTITY_COORD[2]*-f;\n#endif\n    \n    \n#if !USE_PROGRESSIVE\n    for (uint i=0u;i < SPP*SPP;i++)\n#else \n    for (uint i=0u;i < 1u;i++)\n#endif\n    {   \n        GetPinholeCameraRay(r, pixel, sampledPoints[i], vp,\n            u, v, w, aspect);\n        distributed_camera_rays[i] = r;\n    }\n}\n\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Color operations\n// This pathtracer is based on RGB color space\n// so I do not consider the wave length related radiance\n// Due to the input data such as material reflectance is in RGB color space,\n// The data need to convert to spectral\n\n// CIE 1931 2° observer XYZ color model\nconst mat3 xyz_to_sRGB = mat3(\n    vec3( 3.2410, -1.5374, -0.4986), \n    vec3(-0.9692,  1.8760,  0.0416), \n    vec3( 0.0556, -0.2040,  1.0570)\n);\n\nconst mat3 sRGB_to_xyz = mat3(\n    vec3(0.41238, 0.35757, 0.18045),\n    vec3(0.21261, 0.71513, 0.07214),\n    vec3(0.01934, 0.11921, 0.95050)\n);\n\n// CIE xyz to sRGB\nvec3 CIEXYZ_to_sRGB(vec3 xyz)\n{\n    return xyz_to_sRGB * xyz;\n}\n\n// sRGB to CIE xyz\nvec3 SRGB_to_CIEXYZ(vec3 srgb)\n{\n    return sRGB_to_xyz*srgb;\n}\n\n// viewing_gamma = display_gamma * camera_gamma\n// 1.125 = 2.2 * 1./1.925\n// we assume we have a camera gamma as 0.51~=1./1.925\n// This formular is a proximation for the Linear to sRGB\nvec3 LinearToGamma(vec3 col)\n{\n    return sqrt(col);\n}\n\n// Use sRGB color space defined OETF(optical-electrical transfer function)\n// this is the most correct version include two part\n// a linear part + a nonlinear part\nvec3 EOTF_SRGB(vec3 col)\n{\n    bvec3 result = lessThan(col, vec3(0.00304));\n    vec3 linearPart = 12.92 * col;\n    vec3 nonLinearPart = 1.055*pow(col,vec3(0.41))-vec3(0.055);\n    vec3 color = col;\n    for(int i = 0;i < 3;i++)\n        color[i] = result[i] ? linearPart[i] : nonLinearPart[i];\n    return color;\n}\n\n// Tone mappers\n\n// Simple logrithm tone mapper\nvec3 LogriTone(vec3 col)\n{\n    return col/(vec3(1.)+col);\n}\n\n// TODO:\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Surface Intersection Test\n// From https://iquilezles.org/articles/intersectors/ \n\nstruct ShapeSphere\n{\n    vec3 ce;\n    float ra;\n    uint materialId;\n};\n\n\n// sphere of size ra centered at point ce\nvec2 sphIntersect( in vec3 ro, in vec3 rd, in vec3 ce, float ra )\n{\n    vec3 oc = ro - ce;\n    float b = dot( oc, rd );\n    float c = dot( oc, oc ) - ra*ra;\n    float h = b*b - c;\n    if( h<0.0 ) return vec2(-1.0); // no intersection\n    h = sqrt( h );\n    return vec2( -b-h, -b+h );\n}\n\nstruct ShapeBox\n{\n    vec3 boxSize;\n    uint materialId;\n};\n\n// axis aligned box centered at the origin, with size boxSize\nvec2 boxIntersection( in vec3 ro, in vec3 rd, vec3 boxSize, out vec3 outNormal ) \n{\n    vec3 m = 1.0/rd; // can precompute if traversing a set of aligned boxes\n    vec3 n = m*ro;   // can precompute if traversing a set of aligned boxes\n    vec3 k = abs(m)*boxSize;\n    vec3 t1 = -n - k;\n    vec3 t2 = -n + k;\n    float tN = max( max( t1.x, t1.y ), t1.z );\n    float tF = min( min( t2.x, t2.y ), t2.z );\n    if( tN>tF || tF<0.0) return vec2(-1.0); // no intersection\n    outNormal = -sign(rd)*step(t1.yzx,t1.xyz)*step(t1.zxy,t1.xyz);\n    return vec2( tN, tF );\n}\n\nstruct ShapePlane\n{\n    vec4 pp;\n    uint materialId;\n};\n\n// plane degined by p (p.xyz must be normalized)\nfloat plaIntersect( in vec3 ro, in vec3 rd, in vec4 p )\n{\n    return (p.w-dot(ro,p.xyz))/dot(rd,p.xyz);\n}\n\n// My implementation for rectangle intersection\nstruct ShapeRectangle\n{\n    vec4 p;\n    vec2 size;\n    uint materialId;\n};\n\nvec3 IntersectWithRectangle(in Ray r, in ShapeRectangle rec)\n{\n    float hit_t=plaIntersect(r.o, r.d, rec.p);\n    if (isnan(hit_t)) return vec3(-1.);\n    // Test if the t is in the range (TMIN,TMAX)\n    if(hit_t>TMAX||hit_t<TMIN) return vec3(-1.);\n    vec3 ray_hit=RAY(hit_t, r);\n    vec3 y=rec.p.xyz, x, z;\n    naive(y, x, z);\n    mat3 basis = transpose(mat3(x, y, z));\n    mat4 transform=mat4(\n        vec4(basis[0],0.),\n        vec4(basis[1],0.),\n        vec4(basis[2],0.),\n        vec4(-basis*(rec.p.xyz*rec.p.w),1.));\n    vec3 rhit=(transform*vec4(ray_hit,1.)).xyz;\n    return vec3(abs(rhit.xz),hit_t);\n}\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Material Representation\n\n// Shading model\n#define LAMBERTIAN           0u\n#define BLINN_PHONG          1u\n#define TORRANCE             2u\n#define COOK_TORRANCE        3u\n#define OREN_NAYER           4u\n#define PHONG                5u\n#define MODIFIED_BLINNPHONG  6u\n\nstruct Material\n{\n    uint type;\n    vec3 reflectance;\n    \n    vec4 specularReflectance;\n};\n\nconst uint MATERIAL_CNT = 6u;\nMaterial g_materials[MATERIAL_CNT] = Material[](\n    Material(MODIFIED_BLINNPHONG, vec3(1.0,0.6,0.1),vec4(vec3(0.2),120.)),\n    Material(BLINN_PHONG, vec3(0.1,0.2,0.9),vec4(vec3(0.1),200.)),\n    Material(LAMBERTIAN, vec3(1.,0.,0.),vec4(vec3(0.1),200.)),\n    Material(LAMBERTIAN, vec3(0.,1.,0.),vec4(vec3(0.1),200.)),\n    Material(LAMBERTIAN, vec3(0.,0.,1.),vec4(vec3(0.1),1000.)),\n    Material(LAMBERTIAN, vec3(1.,1.,1.),vec4(vec3(0.1),200.))\n);\n\nMaterial GetMaterial(uint id)\n{\n    return g_materials[id];\n}\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Scene Init\n\nstruct HitRecord\n{\n    float t;  // parameter t\n    vec3 n,p; // normal and position\n    \n    // TODO: shader information\n    uint surfaceMaterialId;\n};\n\nvoid InitHitRecord(inout HitRecord hit)\n{\n    hit.t = TMAX;\n    hit.n = hit.p = vec3(0.);\n    hit.surfaceMaterialId = 0u;\n}\n\n// Init scene data here\n#if PLACE_OBJ_SPHERE\nconst uint sphereCnt = 3u;          \nShapeSphere spheres[sphereCnt] = ShapeSphere[](\n    ShapeSphere(vec3(0.,0.9,1.),0.5,1u)\n   ,ShapeSphere(vec3(0.,-1.6,1.),0.4,0u)\n   ,ShapeSphere(vec3(-0.83,-1.7,-1.0),0.3,1u)\n);\n#endif\n\n#if PLACE_OBJ_PLANE\nconst uint planeCnt = 1u;\nShapePlane planes[planeCnt] = ShapePlane[](\n    ShapePlane(vec4(0.,1.,0.,-2.),1u)\n);\n#endif\n\n#if PLACE_OBJ_BOX\nconst uint boxCnt = 1u;\nShapeBox boxes[boxCnt] = ShapeBox[](\n    ShapeBox(vec3(2.),0u)\n);\n#endif\n\n#if PLACE_OBJ_REC\nconst uint recCnt = 4u;\nShapeRectangle rectangles[recCnt] = ShapeRectangle[](\n     ShapeRectangle(vec4(1.,0.,0.,-1.3),vec2(2.,2.),2u)                  // Left\n    //,ShapeRectangle(vec4(-1.,0.1,0.,-1.6),vec2(1.6,2.),4u)                 // Right\n    ,ShapeRectangle(vec4(0.,1.,0.,-2.),vec2(1.3,2.),3u)        // Bottom\n    ,ShapeRectangle(vec4(0.,-1.,0.,-2.),vec2(1.3,2.),4u)      // Upper\n    ,ShapeRectangle(vec4(0.,0.,1.,-2.),vec2(1.3,2.),5u)            // Back\n);\n#endif\n\n\n#if !USE_WORLDSPACE_RAY\nvoid WorldToView(mat4 viewMat)\n{\n#if PLACE_OBJ_SPHERE\n    for(uint i=0u;i<sphereCnt;i++){\n        spheres[i].ce = (viewMat * vec4(spheres[i].ce,1.)).xyz;\n    }\n#endif\n\n#if PLACE_OBJ_PLANE\n    for(uint i=0u;i<planeCnt;i++){\n        vec3 p = normalize(planes[i].pp.xyz);\n        p = (viewMat * vec4(p, 0.)).xyz;\n        planes[i].pp.xyz = p;\n    }\n#endif\n}\n#endif\n\nbool IntersectScene(Ray r, float tmin, float tmax, inout HitRecord hit)\n{\n    bool hitted = false;\n#if PLACE_OBJ_SPHERE\n    for(uint i=0u;i<sphereCnt;i++){\n        vec2 sph = sphIntersect(r.o, r.d, spheres[i].ce, spheres[i].ra);\n        if (sph.x == -1.) continue;\n        else \n        {\n            float t = sph.x;\n            if (t<tmin) t=sph.y;\n            if (t<tmin || t>tmax) continue;\n            if (hit.t>t){\n                hit.t = t;\n                hit.p = RAY(hit.t,r);\n                hit.n = normalize(hit.p-spheres[i].ce);\n                hit.surfaceMaterialId = spheres[i].materialId;\n                hitted = true;\n            }\n        }\n    }\n#endif\n\n#if PLACE_OBJ_PLANE\n    for(uint i=0u;i<planeCnt;i++){\n        vec4 plane = vec4(normalize(planes[i].pp.xyz), planes[i].pp.w);\n        float pla = plaIntersect(r.o, r.d, plane);\n        if (isnan(pla)) continue;\n        pla -= PLAN_BIAS;\n        if (pla>tmin && pla<tmax && pla<hit.t)\n        {\n            hit.t = pla;\n            hit.p = RAY(hit.t-PLANE_BIAS,r);\n            hit.n = plane.xyz;\n            hit.surfaceMaterialId = planes[i].materialId;\n            hitted = true;\n        }\n    }\n#endif\n\n#if PLACE_OBJ_REC\n    for(uint i=0u;i<recCnt;i++){\n        vec3 rec = IntersectWithRectangle(r, rectangles[i]);\\\n        if (rec.x < 0.) continue;\n        rec.z -= PLANE_BIAS;\n        bvec2 re = lessThan(rec.xy, rectangles[i].size);\n        if (hit.t > rec.z && re.x && re.y){\n            hit.p = RAY(rec.z, r);\n            hit.n = rectangles[i].p.xyz;\n            hit.t = rec.z;\n            hit.surfaceMaterialId = rectangles[i].materialId;\n            hitted = true;\n        }\n    }\n#endif\n    return hitted;\n}\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Light sources\n\n// direction\n// Illuminance E_v -> unit is lumen*m^-2\n// TODO: may be use blackbody radiation as source\n// TODO: angular dependence, we need to consider the sun disk size as we seen from the earth \nstruct DirectionalLight\n{\n    vec3 dir;\n    vec3 color;           // Perceptral color response\n    float illuminance;\n};\n\nstruct AmbientLight\n{\n    vec3 color;\n    float illuminance;\n};\n\nconst DirectionalLight directionalLight = DirectionalLight(\n    vec3(2.4,1.,1.), \n    vec3(0.9,0.3,0.1), \n    23.11 \n);\n\nconst AmbientLight ambientLight = AmbientLight(\n    vec3(0.3,0.55,0.9), 0.5\n);\n\nvec3 GetAmbientLightColor() { return ambientLight.color; }\nfloat GetAmbientLightIlluminance() { return ambientLight.illuminance; }\n\nvec3 GetDirectionalLightDir() { return normalize(directionalLight.dir); }\nvec3 GetDirectionalLightColor() { return directionalLight.color; }\nfloat GetDirectionalLightIlluminance() { return directionalLight.illuminance; }\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Bidirectional Surface Scattering Refelction Distribution Function\n\nstruct BRDFParams\n{\n    vec3 position;\n    float VdotL;\n    float NdotL;\n    float RdotV;\n    float NdotH;\n    float NdotV;\n};\n\nBRDFParams GetBRDFParams(vec3 lightDir, Ray ray, HitRecord hit)\n{\n    BRDFParams param = BRDFParams(vec3(0.),0.,0.,0.,0.,0.);\n    param.position = hit.p;\n    param.NdotL = dot(hit.n, lightDir);\n    param.VdotL = dot(-ray.d, lightDir);\n    param.RdotV = max(0.,dot(reflect(lightDir, hit.n), ray.d));\n    param.NdotH = max(0.,dot(hit.n,normalize((lightDir-ray.d)*.5)));\n    param.NdotV = max(0.,dot(hit.n,-ray.d));\n    return param;\n}\n\n// Material component\n// Body reflection : scattering\n// Surface reflection: specularly reflection\n\n\n// Simple empirical models\n// Basic Lambertian Model\nvec3 brdfLambertian(Material material){\n    return material.reflectance*ONE_OVER_PI;\n}\n\n// Basic Phong Model\n// Just used for nonmetals\nvec3 brdfPhong(Material material, BRDFParams param){\n    float shinness = material.specularReflectance.w;\n    vec3 d = (vec3(1.)-material.specularReflectance.xyz);\n    return brdfLambertian(material)*d+\n           material.specularReflectance.xyz*\n           pow(param.RdotV,shinness)/param.NdotL;\n}\n\n// Blinn Phong Model\n// Just used for nonmetals\nvec3 brdfBlinnPhong(Material material, BRDFParams param){\n    float shinness = material.specularReflectance.w;\n    vec3 d = (vec3(1.)-material.specularReflectance.xyz);\n    return brdfLambertian(material)*d+\n           material.specularReflectance.xyz*\n           pow(param.NdotH,shinness)/param.NdotL;\n}\n\n// Modified Blinn Phong Model\n// Just used for nonmetals\nvec3 brdfMBlinnPhong(Material material, BRDFParams param){\n    float shinness = material.specularReflectance.w;\n    vec3 d = (vec3(1.)-material.specularReflectance.xyz);\n    return brdfLambertian(material)*d+\n           material.specularReflectance.xyz*\n           pow(param.NdotH,shinness);\n}\n\n// Physically based shading model\n// microfacet Cook-Torrance BRDF\n\n// Define the fresnel equation: \n// Fresnel equation define the how many \n// reflected radiant flux in total incident flux\n// Current assume the light is unpolarized\n\n// m is the roughness parameter\n// alpha is the angle between the facet normal with the mean surface normal\nfloat COOKTORRANCE_NDF(float m, vec2 alpha)\n{\n    float tanAlpha = alpha.x/alpha.y;\n    return exp(-pow2(tanAlpha/m))/(m*m*pow4(alpha.x));\n}\n\nfloat F0ToN(float f0)\n{\n    f0 = sqrt(f0);\n    return (1.+f0)/(1.-f0);\n}\n\n// Assume don't know the k\nfloat Fresnel(vec2 angle, float n1, float n2){\n    \n    return 0.;\n}\n\nvec3 brdfCookTorrance(Material material ,BRDFParams param){\n    return vec3(0.);\n}\n\n\n// uniformly sampled pdf for lambertian surface\n// probability dentsity function\n\nvec3 pdfLambertian(){\n    //TODO:\n    return vec3(0.);\n}\n\n\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n// Trace related data and function\n\nvec3 GetMaterialBRDF(uint materialId, BRDFParams param){\n    Material material = GetMaterial(materialId);\n    uint type = material.type;\n    if (type == LAMBERTIAN)\n        return brdfLambertian(material);\n    if (type == PHONG)\n        return brdfPhong(material, param);\n    if (type == BLINN_PHONG)\n        return brdfBlinnPhong(material, param);\n    if (type == MODIFIED_BLINNPHONG)\n        return brdfMBlinnPhong(material, param);\n    return vec3(1.,0.,1.);\n}\n\n// Lambertian reflection\nvoid GetBouncedRayInHemisphere(out Ray r, in HitRecord hit)\n{\n    vec3 t, b;\n    naive(hit.n, b, t);\n    r.d = HemisphereRandomSample(baseHash(uint(fract(dot(r.d,r.d)*hit.t)*418574.875)));\n    NormalTransformToWorld(r.d, t, b, hit.n);\n    r.o = hit.p;\n}\n\n// Trace a shadow from current r\nbool ShadowTrace(HitRecord hit)\n{\n    // TODO: Distributed shadow ray\n    Ray r;\n    r.o = hit.p;\n    r.d = GetDirectionalLightDir();\n    InitHitRecord(hit);\n    if (IntersectScene(r, TMIN, TMAX, hit))\n        return true;\n    return false;\n}\n\n// Deep trace with ray bounce\n// Integerate with hemisphere\nbool RandomBounce(inout vec3 radiance, inout Ray ray, inout HitRecord hit)\n{\n    bool terminate = false;\n    if (IntersectScene(ray, TMIN, TMAX, hit)){\n        // Check current ray whether a shadow ray\n        if(ShadowTrace(hit)){\n            // Current point in shadow so not add direct illumination\n        }else{\n            if (hit.surfaceMaterialId == 100u){\n                // Grid shading\n                vec2 val = step(abs(sin(hit.p.xz)),vec2(0.05));\n                vec3 grid = val.x>0.||val.y>0. ? vec3(val.y,0.,val.y>0.?0.:val.x) : vec3(0.);\n                grid *= (TMAX-hit.t)/TMAX;\n                radiance += grid;\n            }else{\n                BRDFParams param = GetBRDFParams(GetDirectionalLightDir(), ray, hit);\n                radiance += \n                    GetMaterialBRDF(hit.surfaceMaterialId, param)*\n                    max(0.,param.NdotL)*\n                    GetDirectionalLightColor()*GetDirectionalLightIlluminance();\n            }\n        }\n        GetBouncedRayInHemisphere(ray, hit);\n    }else{\n        radiance += GetAmbientLightColor()*\n                    GetAmbientLightIlluminance()*ONE_OVER_PI;\n        terminate = true;\n    }\n    return terminate;\n}\n\n// From camera trace\nvec3 EyeTrace()\n{\n    vec3 radiance = vec3(0.0);\n    HitRecord hit; \n    InitHitRecord(hit);\n\n#if USE_PROGRESSIVE\n    Ray ray = distributed_camera_rays[0];\n#else\n    const uint n=SPP*SPP;\n    for (uint i=0u;i<n;i++){\n        Ray ray = distributed_camera_rays[i];\n        InitHitRecord(hit);\n#endif\n        for (uint i=0u;i<DEPTH;i++)\n            if(RandomBounce(radiance, ray, hit)) break;\n        \n#if !USE_PROGRESSIVE\n    }\n    return radiance/vec3(n);\n#else\n    return radiance;\n#endif\n}\n\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////\n//////////////////////////////////////////////////////","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    if( ivec2(fragCoord) == ivec2(0)){\n        fragColor = iResolution.xyxy;\n    } else {\n    \n        vec2 screenCoord = fragCoord;\n        Camera cam = Camera(60., vec3(0.), vec3(1.01,0.,11.+\n            (iMouse.y-iResolution.y*.5)/iResolution.y*15.));\n        mat4 viewMat = GetPinholeCameraViewMatrix(cam);\n        viewMat = RotateY((iMouse.x-iResolution.x*.5)/iResolution.x*30.) * viewMat;\n        \n#if USE_PROGRESSIVE\n        InitSeed(uint(iFrame%CONVERGE_FRAMECOUNT));\n#endif\n\n#if USE_WORLDSPACE_RAY\n        DistributedCameraRay(\n            screenCoord, iResolution.xy, cam.fovy, cam.e,\n            viewMat[0].xyz, viewMat[1].xyz, viewMat[2].xyz,\n            iResolution.y/iResolution.x\n        );\n#else\n        WorldToView(viewMat);\n        DistributedCameraRay(\n            screenCoord, iResolution.xy, cam.fovy,\n            iResolution.y/iResolution.x\n        );\n#endif\n        vec3 col = EyeTrace();\n        \n#if USE_PROGRESSIVE\n        if(texelFetch(iChannel0,ivec2(0),0).xy == iResolution.xy){\n            fragColor=vec4(col,1)+texelFetch(iChannel0,ivec2(fragCoord),0);\n        }else{\n            fragColor=vec4(col,1);\n        }\n#else\n        fragColor = vec4(col, 1.);\n#endif\n    }\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec4 col = texelFetch(iChannel0, ivec2(fragCoord),0);\n    // Simple tonemapping\n    col.rgb = LogriTone(col.rgb/col.w);\n    \n    fragColor = col;\n}","name":"Buffer B","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"slByWV","date":"1650233790","viewed":222,"name":"Raytracing 2 - Reprojection","username":"KylBlz","description":"Diffuse only with geometric reprojection. Moved the first surface properties to the end instead of the beginning to reduce motion blur.\nSome weird reprojection effects at the edges of the screen persist....","likes":6,"published":1,"flags":32,"usePreview":0,"tags":["ray","buffer","trace","reprojection"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\n// Thanks Paniq\nvec3 linear_srgb(vec3 x) {\n    return mix(1.055*pow(x, vec3(1./2.4)) - 0.055, 12.92*x, step(x, vec3(0.0031308)));\n}\n\nvec3 srgb_linear(vec3 x) {\n    return mix(pow((x + 0.055)/1.055,vec3(2.4)), x / 12.92, step(x, vec3(0.04045)));\n}\n\n// Paniq's ACES fitted from https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl\nvec3 ACESFitted(vec3 color) {\n\t// ODT_SAT => XYZ => D60_2_D65 => sRGB\n    color = color * mat3(\n        0.59719, 0.35458, 0.04823,\n        0.07600, 0.90834, 0.01566,\n        0.02840, 0.13383, 0.83777\n    );\n    // Apply RRT and ODT\n    vec3 a = color * (color + 0.0245786) - 0.000090537;\n    vec3 b = color * (0.983729 * color + 0.4329510) + 0.238081;\n    color = a / b;\n\t// Back to color space\n    color = color * mat3(\n         1.60475, -0.53108, -0.07367,\n        -0.10208,  1.10813, -0.00605,\n        -0.00327, -0.07276,  1.07602\n    );\n    // Clamp to [0, 1]\n    return clamp(color, 0.0, 1.0);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    \n    int ho;\n    float asp, vv, ht;\n    vec2 ro = INIT_ROT.xy, lo = INIT_ROT.xy;\n    vec3 rl = INIT_POS.xyz, rd, ll = INIT_POS.xyz, ld, hn, hl;\n    decodeAll(fragCoord, iResolution.xy, iFrame, iChannel0, iChannel1, asp, rl, ro, rd, ll, lo, ld, vv, hn, ho, ht, hl);\n    mat3 surf = getSurface(ho, hl);\n\n    // sample D buffer\n    vec4 dBuffer = texelFetch(iChannel1, ivec2(fragCoord.xy), 0);\n    \n    // apply first surface properties\n    dBuffer.rgb *= surf[0];\n    \n    // tonemap\n    fragColor = 10.0 * dBuffer / floor(dBuffer.a);\n    fragColor.rgb = linear_srgb(ACESFitted(fragColor.rgb));\n    \n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"//////////////////////////////// Rendering Configuration ////////////////////////////////\n\n// always use biased sampling (fallback to unbiased ground truth)\n#define BIASED\n// raymarching steps\n#define STEPS 255\n// number of direct light samples\n#define SMP_DIRECT 1\n// number of frames to smooth over time\n#define TEMPORALSMOOTHING 16\n\nconst float\teps = 0.001,     ieps = 0.999,   zfar = 50.0,       FOV = 2.0,\n            HPI = 1.5707963, PI = 3.1415926, TWOPI = 6.2831853, SQRT2 = 1.4142136, SC45 = 0.7071068;\nconst vec4 INIT_POS = vec4(-3.5, 2.5, -4.0, 0.),\n    \t   INIT_ROT = vec4(.1, 1.8, 0., 0.);\n\n//////////////////////////////// Random tools ////////////////////////////////\n\n// generate a unique value for each pixel/sample/frame\nivec3 genSeed(in int iFrame, in int smp, in ivec2 fragCoord) {\n    ivec2 s = 1 + iFrame + smp + fragCoord;\n    return ivec3(s, s.x ^ s.y);\n}\n\n// Thanks Epic games\nvec3 pcg3(in ivec3 v) {\n    uvec3 w = uvec3(v) * 1664525u + 1013904223u;\n    w.x += w.y*w.z;\n    w.y += w.z*w.x;\n    w.z += w.x*w.y;\n    w ^= w >> 16u;\n    w.x += w.y*w.z;\n    w.y += w.z*w.x;\n    w.z += w.x*w.y;\n    return vec3(w) / exp2(32.0);\n}\n\n// thanks hornet https://www.shadertoy.com/view/4ssXRX\nvec3 boxmuller(in vec3 u, in vec3 v) {\n\treturn 0.23 * sqrt(-log(u + 0.00001))*cos(TWOPI * v) + 0.5;\n}\n\nvoid basis(in vec3 n, out vec3 f, out vec3 r) {\n    float s = (n.z >= 0.0)? 1.0: -1.0;\n    float a = 1.0 / (s + n.z);\n    float b = -n.x*n.y*a;\n    f = vec3(1.0 - n.x*n.x*a*s, b*s, -n.x*s);\n    r = vec3(b, s - n.y*n.y*a, -n.y);\n}\n\nvec3 rotateXY(in vec3 p, in vec2 angle) {\n\tvec2 c = cos(angle), s = sin(angle);\n    vec3 o = p;\n\to.yz *= mat2(c.x, s.x, -s.x, c.x); \n    o.xz *= mat2(c.y, s.y, -s.y, c.y);\n\treturn o;\n}\n\n//////////////////////////////// Sampling tools ////////////////////////////////\n\n// linear angle of sphere at distance D with radius R\nfloat linearAngle(float d, float r) {\n    return asin(clamp(r/d, eps, ieps));\n}\n\n// solid angle of sphere given distance squared and radius squared\nfloat solidAngle(float d2, float r2) {\n    return (1.0 - sqrt(1.0 - clamp(r2/d2, 0.0, 1.0))) * TWOPI;\n}\n\nfloat Lambertian(in vec3 hn, in vec3 nlv) {\n    return max(eps, dot(nlv, hn));\n}\n\n// using gaussian distribution\nvec3 uniformSphere(in ivec3 seed) {\n    vec3 rnd = boxmuller(pcg3(seed), pcg3(~seed.zxy));\n    return rnd * 2.0 - 1.0;\n}\n\n// using normalized gaussian distribution\nvec3 uniformDir(in ivec3 seed) {\n    return normalize(uniformSphere(seed));\n}\n\n// only one hemisphere\nvec3 uniformHemiDir(in vec3 hn, in ivec3 seed) {\n    vec3 rnd = uniformDir(seed);\n    return rnd * sign(dot(hn, rnd));\n}\n\n// cosine distribution (unbiased sampling)\nvec3 cosHemiDir(vec3 hn, ivec3 seed) {\n    vec3 rnd = uniformDir(seed);\n    return normalize(hn + rnd * ieps);\n}\n\n// uniform sample cone (biased sampling)\nvec3 uniformConeDir(vec3 lv, float lr, in ivec3 seed) {\n    vec3 rnd = pcg3(seed);\n    float sa = linearAngle(length(lv), lr);\n    float rad = sqrt(rnd.x) * tan(sa);\n    float tha = rnd.y * TWOPI;\n    vec3 r, u, nlv = normalize(lv);\n    basis(nlv, r, u);\n    return normalize(nlv + rad * (r * cos(tha) + u * sin(tha)));\n}\n\n//////////////////////////////// Scene Modeling ////////////////////////////////\n\nvec2 sdMin(in vec2 a, in vec2 b) {\n    if (a.x < b.x)\n        return a;\n    return b;\n}\n\nfloat sdBox(in vec3 p, in mat3 o, in vec3 s) {\n    vec3 d = abs(p * o) - s;\n    return min(max(d.x, max(d.y, d.z)), 0.0) + length(max(d, 0.0));\n}\n\nconst int\n    LIGHT = 1,\n    FLOOR = 2,\n    WALL1 = 3,\n    BOX = 4,\n    WALL2 = 6,\n    CEIL = 7;\n    \n// light parameters\nvec3 lightLoc = vec3(5.5, 5.0, -4.0);\nfloat lightRadius = 1.0;\nvec3 lightColor = vec3(10.0);\n\n// scene geometry, returns distance X and object Y\nvec2 sdf(in vec3 l, in int o) {\n    vec2 d = vec2(zfar, 0.);\n    if (o != FLOOR) d = sdMin(d, vec2(l.y - 0.0, FLOOR));\n    if (o != CEIL)  d = sdMin(d, vec2(-l.y + 10.0, CEIL));\n    if (o != WALL1) d = sdMin(d, vec2(-l.x + 10.0, WALL1));\n    if (o != WALL2) d = sdMin(d, vec2(l.z + 10.0, WALL2));\n    if (o != LIGHT) d = sdMin(d, vec2(length(l - lightLoc) - lightRadius, LIGHT));\n    if (o != BOX)   d = sdMin(d, vec2(sdBox(l - vec3(7.5, 0.93, -7.5), mat3(1.0), vec3(0.8)) - 0.1, BOX));\n    return d;\n}\n\n// scene color, returns reflection [0], emission [1], and transmission [2] colors RGB\nmat3 getSurface(in int ho, in vec3 hl) {\n    mat3 ret;\n    if (ho == LIGHT) {\n        ret[0] = vec3(1.0);\n        ret[1] = lightColor;\n    } else if (ho == BOX) {\n        ret[0] = vec3(0.025 + 0.1 * float(int(floor(hl.x * 4.0) + floor(hl.y * 4.0) + floor(hl.z * 4.0)) & 1));\n        ret[1] = vec3(0.0);\n    } else if (ho < 1) {\n        ret[0] = vec3(0.0);\n        ret[1] = vec3(0.0);\n    } else {\n        // checker pattern\n        float refl = float(int(ho == FLOOR || ho == CEIL)) * (0.5 + float(int(floor(hl.x) + floor(hl.y) + floor(hl.z)) & 1)) * 0.25 + 0.75;\n        float cm = cos(float(ho)) * 0.025;\n        float sm = sin(float(ho)) * 0.025;\n        ret[0] = vec3(0.05 + cm, 0.05 + sm, 0.05 - (cm + sm) * 0.25) * refl;\n        ret[1] = vec3(0.0);\n    }\n    return ret;\n}\n\nvec3 norm(in vec3 p, in float ep) {\n    vec3 n = vec3(0.0);\n    for (int i = 0; i < 4; ++i) {\n        vec3 e = 0.5773*(2.0*vec3((((i+3)>>1)&1), ((i>>1)&1), (i&1))-1.0);\n        n += e * sdf(p + e*ep, -1).x;\n    }\n    return normalize(n);\n}\n\nvec2 march(in vec3 l, in vec3 rd, in int o) {\n    float t = 0.0;\n    vec2 sdSmp;\n    for (int i = 0; i < STEPS; ++i) {\n        sdSmp = sdf(l + rd * t, o);\n        t += sdSmp.x;\n        if (sdSmp.x < eps)\n            break;\n        if (t > zfar)\n            return vec2(zfar, 0.0);\n    }\n    return vec2(min(t, zfar), sdSmp.y);\n}\n\n//////////////////////////////// Buffers ////////////////////////////////\n\n// diffuse light buffer\nfloat encodeDbuffer(in int o) {\n    return float(o) * 0.1;\n}\n\nint decodeDbuffer(in float a) {\n    return int(fract(a) * 10.1);\n}\n\n// geometry buffer\nvoid encodeGbuffer(out vec4 val, in vec3 n, in int o, in float t) {\n    val = vec4(n * float(o), t);\n}\n\nvoid decodeGbuffer(in vec4 val, out vec3 n, out int o, out float t) {\n    t = val.w;\n    o = int(length(val.xyz)+eps);\n    n = val.xyz / float(o);\n}\n\n// last loc, last orient, hit loc, hit object, 1/aspect, channel, resolution\nvec4 reprojectDbuffer(in vec3 ll, in vec2 lo, in vec3 hl, in int ho, in float asp, sampler2D iChannel, in vec2 iChanRes) {\n    // last camera basis\n    vec3 lf = rotateXY(vec3(0.0, 0.0, 1.0), lo);\n    vec3 r = normalize(cross(lf, vec3(0.0, 1.0, 0.0)));\n    vec3 u = normalize(cross(lf, r));\n    // dir to point\n    vec3 nhl = normalize(ll - hl);\n    // project into last cam basis\n    vec2 luv = vec2(dot(nhl, r), dot(nhl, u));\n    // project onto imaging plane NDC coords\n    luv = (luv * FOV) / (dot(nhl, lf) * vec2(asp, 1.0));\n    // ndc to image pixel coords (minus half pixel, glsl uses 'pixel centers')\n    vec2 fuv = (luv * -0.5 + 0.5) * iChanRes - 0.5;\n    ivec2 iuv = ivec2(fuv);\n    // bounds check\n    if (any(greaterThan(iuv, ivec2(iChanRes)-1)) || any(lessThan(iuv, ivec2(0))))\n        return vec4(0.0);\n    vec2 a = clamp(fuv - vec2(iuv), vec2(0.0), vec2(1.0));\n    // samples with matching materials are considered\n    vec4 col   = texelFetch(iChannel, iuv, 0);\n    vec4 colx  = texelFetch(iChannel, iuv + ivec2(1, 0), 0);\n    vec4 coly  = texelFetch(iChannel, iuv + ivec2(0, 1), 0);\n    vec4 colxy = texelFetch(iChannel, iuv + ivec2(1, 1), 0);\n    float c1 = float(int(decodeDbuffer(col.a) == ho));\n    float c2 = float(int(decodeDbuffer(colx.a) == ho));\n    float c3 = float(int(decodeDbuffer(coly.a) == ho));\n    float c4 = float(int(decodeDbuffer(colxy.a) == ho));\n    // get number of samples that matched\n    float n = c1 + c2 + c3 + c4;\n    // fanciest mixing\n    if (n > 3.0)\n        return mix(mix(col/col.a, colx/colx.a, a.x), mix(coly/coly.a, colxy/colxy.a, a.x), a.y) * min(col.a, min(colx.a, min(coly.a, colxy.a)));\n    if (n < 1.0)\n        return vec4(0.0);\n    // fallback mixing\n    return (c1*col + c2*colx + c3*coly + c4*colxy);\n}\n\n// just a big 'ol helper function that gets all the values\nvoid decodeAll(in vec2 fragCoord, in vec2 iResolution, in int iFrame, in sampler2D gBuffer, in sampler2D lastFrame, out float asp, out vec3 rl, out vec2 ro, out vec3 rd, out vec3 ll, out vec2 lo, out vec3 ld, out float vv, out vec3 hn, out int ho, out float ht, out vec3 hl) {\n    asp = iResolution.x / iResolution.y;\n    vec2 ndca = (2.0 * fragCoord.xy / iResolution.xy - 1.0) * vec2(asp, 1.0);\n    // get current cam\n    if (iFrame > 1) {\n        rl = texelFetch(gBuffer, ivec2(0, int(iResolution.y) - 1), 0).xyz;\n        ro = texelFetch(gBuffer, ivec2(1, int(iResolution.y) - 1), 0).xy;\n        ll = texelFetch(lastFrame, ivec2(0, int(iResolution.y) - 1), 0).xyz;\n        lo = texelFetch(lastFrame, ivec2(1, int(iResolution.y) - 1), 0).xy;\n    }\n    rd = rotateXY(normalize(vec3(ndca, FOV)), ro);\n    ld = rotateXY(normalize(vec3(ndca, FOV)), lo);\n\tvv = length(rl - ll);\n    // get last trace\n    decodeGbuffer(texelFetch(gBuffer, ivec2(fragCoord.xy), 0), hn, ho, ht);\n    hl = rl + rd * ht;\n}\n","name":"Common","description":"","type":"common"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// first trace G buffer (normal, material, distance)\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n\n    float asp = iResolution.x / iResolution.y;\n    vec2 ndca = (2.0 * fragCoord.xy / iResolution.xy - 1.0) * vec2(asp, 1.0);\n    \n    // get current cam\n\tvec3 l = INIT_POS.xyz,\n         o = INIT_ROT.xyz;\n    vec3 d = rotateXY(normalize(vec3(ndca, FOV)), o.xy);\n    \n    // move the camera\n    if (iFrame > 1) {\n        l = INIT_POS.xyz + vec3(sin(iTime * 0.5), 0.0, cos(iTime * 0.5));\n    }\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(l, 0.0);\n            return;\n        } else if (x == 1) {\n            fragColor = vec4(o, 0.0);\n            return;\n        }\n    }\n    \n    // initial scene march\n    vec2 h = march(l, d, -1);\n    // encode normal, object ID, and depth\n    fragColor = vec4(0.0);\n    encodeGbuffer(fragColor, norm(l + d * h.x, eps), int(h.y), h.x);\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"\n//////////////////////////////// Scene Sampling ////////////////////////////////\n\n// marches the light and returns contribution RGB\nvec3 lightContribution(in vec3 hl, in int ho, in vec3 lv, in float density) {\n    vec2 lm = march(hl, lv, ho);\n    if (int(lm.y) == LIGHT)\n        return lightColor * density;\n    return vec3(0.0);\n}\n\n// returns sample direction XYZ, pdf W\nvec4 LambertianSphereLightPDF(in vec3 hl, in vec3 hn, in vec3 ll, in float lr, in ivec3 seed) {\n    vec3 lv = ll - hl;\n    vec3 directDir = uniformConeDir(lv, lr, seed);\n    float lpdf = solidAngle(dot(lv, lv), lr*lr);\n    float gpdf = Lambertian(hn, directDir);\n    return vec4(directDir, lpdf * gpdf);\n}\n\n// do biased sampling (direct light on lambertian surface)\nvec3 DirectOnly(in vec3 hl, in vec3 hn, in int ho, in ivec3 seed) {\n    // take direct light samples only\n    vec3 smpDirect = vec3(0.0);\n    for (int i = 0; i < SMP_DIRECT; ++i) {\n        ivec3 si = seed + i;\n        // get PDF\n        vec4 dlpdf = LambertianSphereLightPDF(hl, hn, lightLoc, lightRadius, si);\n        // sample light\n        smpDirect += lightContribution(hl, ho, dlpdf.xyz, dlpdf.w);\n    }\n    return smpDirect / float(SMP_DIRECT);\n}\n\n// do unbiased sampling (diffuse BRDF)\nvec3 Unbiased(in vec3 hl, in vec3 hn, in int ho, in ivec3 seed) {\n    // unbiased sampling (GT)\n    vec3 smpUnbias = vec3(0.0);\n    for (int i = 0; i < SMP_DIRECT; ++i) {\n        ivec3 si = seed + i;\n        vec3 udir = cosHemiDir(hn, si);\n        // sample light\n        smpUnbias += lightContribution(hl, ho, udir, PI);\n    }\n    return smpUnbias /= float(SMP_DIRECT);\n}\n\n//////////////////////////////// Main Image ////////////////////////////////\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n\n    bool biased = false;\n    int ho;\n    float asp, vv, ht;\n    vec2 ro = INIT_ROT.xy, lo = INIT_ROT.xy;\n    vec3 rl = INIT_POS.xyz, rd, ll = INIT_POS.xyz, ld, hn, hl;\n    decodeAll(fragCoord.xy, iResolution.xy, iFrame, iChannel0, iChannel1, asp, rl, ro, rd, ll, lo, ld, vv, hn, ho, ht, hl);\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(rl, 0.0);\n            return;\n        } else if (x == 1) {\n            fragColor = vec4(ro, 0.0, 0.0);\n            return;\n        }\n    }\n    \n    // reproject last frame onto this one\n    fragColor = reprojectDbuffer(ll, lo, hl, ho, asp, iChannel1, iChannelResolution[1].xy);\n    fragColor.a = floor(fragColor.a);\n    if (fragColor.a < eps) {\n        // if sample failed, start with biased sampling to minimize variance\n        biased = true;\n    }\n\n#ifdef BIASED\n    // force biased rendering\n    biased = true;\n#endif\n    \n    // accumulate a maximum of TEMPORALSMOOTHING frames\n    if (fragColor.a > float(TEMPORALSMOOTHING)) {\n        fragColor *= float(TEMPORALSMOOTHING) / fragColor.a;\n    }\n\n    mat3 surf = getSurface(ho, hl);\n    // surface color\n    vec3 rc = vec3(1.0); // do later\n    // surface emissive\n    fragColor.rgb += rc * surf[1];\n\n    // ignore light\n    if (ho != LIGHT) {\n        ivec3 seed = genSeed(iFrame, 1, ivec2(fragCoord.xy*iResolution.xy));\n        if (biased) {\n            // direct sample lights\n            fragColor.rgb += rc * DirectOnly(hl, hn, ho, seed);\n        } else {\n            // unbiased sampling (GT)\n            fragColor.rgb += rc * Unbiased(hl, hn, ho, seed);\n        }\n    }\n    fragColor.a += 1.0 + encodeDbuffer(ho);\n}\n","name":"Buffer B","description":"","type":"buffer"}]}
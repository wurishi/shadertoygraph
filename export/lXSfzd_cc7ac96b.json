{"ver":"0.1","info":{"id":"lXSfzd","date":"1729990874","viewed":132,"name":"Voxel Cone Tracing FR","username":"capslpop","description":"finally doin this","likes":3,"published":1,"flags":32,"usePreview":1,"tags":["conetrace"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XsfGzn","filepath":"/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","previewfilepath":"/media/ap/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","type":"cubemap","channel":2,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"vec4 trilinearFetch(vec3 pos, int LOD) {\n    ivec3 basePos = ivec3(floor(pos));\n    vec3 frac = fract(pos);\n\n    vec4 c000 = getLight(iChannel1, basePos, LOD);\n    vec4 c100 = getLight(iChannel1, basePos + ivec3(1, 0, 0), LOD);\n    vec4 c010 = getLight(iChannel1, basePos + ivec3(0, 1, 0), LOD);\n    vec4 c110 = getLight(iChannel1, basePos + ivec3(1, 1, 0), LOD);\n    vec4 c001 = getLight(iChannel1, basePos + ivec3(0, 0, 1), LOD);\n    vec4 c101 = getLight(iChannel1, basePos + ivec3(1, 0, 1), LOD);\n    vec4 c011 = getLight(iChannel1, basePos + ivec3(0, 1, 1), LOD);\n    vec4 c111 = getLight(iChannel1, basePos + ivec3(1, 1, 1), LOD);\n\n    vec4 c00 = mix(c000, c100, frac.x);\n    vec4 c01 = mix(c001, c101, frac.x);\n    vec4 c10 = mix(c010, c110, frac.x);\n    vec4 c11 = mix(c011, c111, frac.x);\n\n    vec4 c0 = mix(c00, c10, frac.y);\n    vec4 c1 = mix(c01, c11, frac.y);\n\n    return mix(c0, c1, frac.z);\n}\n\nvec4 cone(vec3 point, vec3 direction) {\n    vec4 light = vec4(0.0);\n\n    for (int i = 1; i < maxLODs; i++) {\n        point += direction;\n        vec4 sampledLight = trilinearFetch(point, i); // Fetch interpolated light value\n        \n        light += sampledLight / float(i); // Adjust weight per LOD level\n        if (light.w >= 1.0) break;\n\n        point /= 2.0; // Move to next LODâ€™s coordinate system\n    }\n\n    return light;\n}\n\nvec4 cones(vec3 point, vec3 normal) {\n    float theta = pi / 8.0;\n    float phi = pi / 4.0; // Different angle for varied cone direction\n\n    // Accumulate light from several rotated directions\n    vec4 light = vec4(0.0);\n    light += cone(point, normal);\n    light += cone(point, vec3(cos(theta) * normal.x, sin(theta) * normal.y, normal.z));\n    light += cone(point, vec3(normal.x, cos(phi) * normal.y, sin(phi) * normal.z));\n    light += cone(point, vec3(sin(theta) * normal.x, cos(theta) * normal.y, normal.z));\n    light += cone(point, vec3(normal.x, sin(phi) * normal.y, cos(phi) * normal.z));\n\n    return light / 5.0;\n}\n\nvec3 rayCast(vec3 rayPos, vec3 rayDir)\n{\n    vec3 mapPos = floor(rayPos);\n\tvec3 deltaDist = abs(vec3(length(rayDir)) / rayDir);\n\tvec3 rayStep = sign(rayDir);\n\tvec3 sideDist = (sign(rayDir) * (vec3(mapPos) - rayPos) + (sign(rayDir) * 0.5) + 0.5) * deltaDist; \n\tvec3 mask;\n\tvec3 color;\n\n    voxel v;\n    \n    // step out of yourself\n    mask = vec3(lessThanEqual(sideDist.xyz, min(sideDist.yzx, sideDist.zxy)));\n    sideDist += vec3(mask) * deltaDist;\n    mapPos += mask * rayStep;\n    mask = vec3(lessThanEqual(sideDist.xyz, min(sideDist.yzx, sideDist.zxy)));\n    sideDist += vec3(mask) * deltaDist;\n    mapPos += mask * rayStep;\n    mask = vec3(lessThanEqual(sideDist.xyz, min(sideDist.yzx, sideDist.zxy)));\n    sideDist += vec3(mask) * deltaDist;\n    mapPos += mask * rayStep;\n    \n\tfor (int i = 0; i < MAX_RAY_STEPS; i++) \n    {\n        v = getVoxel(iChannel0, ivec3(mapPos), 0);\n        if (any(lessThan(mapPos, vec3(0.0))) || any(greaterThan(mapPos, vec3(volumeSize)))) break;\n\n        if (v.color.a > 0.1)\n        {\n            return v.color.rgb * cones((mapPos + 0.5) / 2.0, v.normal).rgb * 3.5 + v.color.rgb * 0.5;\n        }\n\n        mask = vec3(lessThanEqual(sideDist.xyz, min(sideDist.yzx, sideDist.zxy)));\t\t\n\t\tsideDist += mask * deltaDist;\n\t\tmapPos += mask * rayStep;\n\t}\n    \n    return clamp(texture(iChannel2, rayDir).rgb + color, 0.0, 1.0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\t//fragColor = getVoxelDebug(iChannel0, fragCoord.xy).color;\n    //fragColor = getLightDebug(iChannel1, fragCoord.xy); \n    //return;\n    \n    //vec2 uv = fragCoord.xy / iResolution.xy;\n    //fragColor = texture(iChannel3, uv) / 80.0;\n    //return;\n\n\tvec2 screenPos = (fragCoord.xy / iResolution.xy) * 2.0 - 1.0;\n\tvec3 cameraDir = vec3(0.0, 0.0, 0.8);\n\tvec3 cameraPlaneU = vec3(1.0, 0.0, 0.0);\n\tvec3 cameraPlaneV = vec3(0.0, 1.0, 0.0) * iResolution.y / iResolution.x;\n\tvec3 rayDir = cameraDir + screenPos.x * cameraPlaneU + screenPos.y * cameraPlaneV;\n\tvec3 rayPos = vec3(0.0, 0.0, -volumeSize);\n    \n\trayPos.xz = rotate2d(rayPos.xz, (iMouse.x/iResolution.x)*14.0);\n\trayDir.xz = rotate2d(rayDir.xz, (iMouse.x/iResolution.x)*14.0);\n\trayPos += vec3(volumeSize)/2.0;\n    \n\tvec3 mapPos = floor(rayPos);\n\tvec3 deltaDist = abs(vec3(length(rayDir)) / rayDir);\n\tvec3 rayStep = sign(rayDir);\n\tvec3 sideDist = (sign(rayDir) * (vec3(mapPos) - rayPos) + (sign(rayDir) * 0.5) + 0.5) * deltaDist; \n\tvec3 mask;\n\n    voxel v;\n    \n\tfor (int i = 0; i < MAX_RAY_STEPS; i++) \n    {\n        if (all(lessThan(mapPos, vec3(volumeSize))) && all(greaterThan(mapPos, vec3(0.0))))\n        {\n            v = getVoxel(iChannel0, ivec3(mapPos), 0);\n        \n            if (v.color.a > 0.1)\n            {\n                if (v.material == MIRROR_MAT)\n                {\n                    fragColor.rgb = rayCast(mapPos + 0.5, reflect(rayDir, v.normal));\n                    return;\n                }\n            \n                vec4 light = cones((mapPos + 0.5) / 2.0, v.normal);\n                fragColor = v.color * light * 3.5 + v.color * 0.25; //getLight(iChannel1, ivec3(mapPos) / 2, 1);  \n                return;\n            }\n        }\n\n        mask = vec3(lessThanEqual(sideDist.xyz, min(sideDist.yzx, sideDist.zxy)));\t\t\n\t\tsideDist += mask * deltaDist;\n\t\tmapPos += mask * rayStep;\n\t}\n    \n    fragColor = texture(iChannel2, rayDir);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"const int MAX_RAY_STEPS = 128*2*4;\n\nconst int volumeSize = 64;\nconst int maxLODs = int(floor(log2(float(volumeSize)))) + 1;\n\n// for ortho camera: ðŸŒž\nconst float cameraSize = float(volumeSize);\n\nconst float pi = 3.1415926535897932384626;\n\n// packing helper\nuint helperPackUnorm32x4(uvec4 a) {return uint( (a.x << 24) | (a.y << 16) | (a.z << 8 )| (a.w << 0 ) ); }\nuvec4 helperUnpackUnorm32x4(uint a) {return uvec4( (a & 0xFF000000u) >> 24, (a & 0x00FF0000u) >> 16, (a & 0x0000FF00u) >> 8, (a & 0x000000FFu) >> 0   ); }\nfloat packUnorm32x4(  vec4  a) { return uintBitsToFloat(helperPackUnorm32x4(uvec4(round(clamp(a, 0., 1.)*255.)))); }\nvec4  unpackUnorm32x4(float a) { return vec4(helperUnpackUnorm32x4(floatBitsToUint(a))) / 255.; }\nfloat packSnorm32x4(  vec4  a) { return uintBitsToFloat(helperPackUnorm32x4(uvec4(round(clamp(a, -1., 1.)*127.5+127.5)))); }\nvec4  unpackSnorm32x4(float a) { return clamp((vec4(helperUnpackUnorm32x4(floatBitsToUint(a))) - 127.5) / 127.5, -1., 1.); }\n\nint getSizeLOD(int LOD)\n{\n    return volumeSize / (1 << LOD);\n}\n\nvec4 getPos(sampler2D buffer, ivec3 pos, int LOD)\n{\n    ivec2 res = textureSize(buffer, 0);\n    \n    int size = getSizeLOD(LOD);\n    int offsetSize = 0;\n    for (int i = 0; i < LOD; i++)\n    {\n        int oSize = getSizeLOD(i);\n        offsetSize += oSize * oSize * oSize;\n    }\n    \n    int c = pos.x + pos.y * size + pos.z * size * size;\n    \n    if (c > size * size * size) return vec4(0.0); // boundry conditions\n    \n    c += offsetSize;\n    \n    ivec2 d = ivec2(c%res.x, c/res.x);\n    return texelFetch(buffer, d, 0);\n}\n\n// this intakes the fragment position and outputs the correct voxel coord\nivec4 getPos(vec2 fragCoord, ivec2 res)\n{\n    int c = int(fragCoord.x) + int(fragCoord.y) * res.x;\n    \n    // calculate the LOD of the fragment:\n    int lod = 0;\n    int size = volumeSize;\n    int index = c;\n    while (index >= size * size * size && lod < maxLODs) {\n        index -= size * size * size;\n        size /= 2;\n        lod++;\n    }\n    \n    ivec3 pos = ivec3(index%size, (index/size)%size, index/(size*size));\n    return ivec4(pos, lod);\n}\n\n/////////////\n// Materials\n/////////////\n\n// Diffusion\nconst uint DIFFUSE_MAT = 0u;\n// Mirror\nconst uint MIRROR_MAT = 1u;\n// Emissive\nconst uint EMISSIVE_MAT = 2u;\n// ect.\n\nstruct voxel\n{\n    vec4 color;\n    vec3 normal;\n    uint material;\n};\n\nvoxel getVoxel(sampler2D buffer, ivec3 pos, int LOD)\n{\n    vec4 info = getPos(buffer, pos, LOD);\n    voxel v;\n    v.color = unpackUnorm32x4(info.r);\n    v.normal = unpackSnorm32x4(info.b).xyz;\n    v.material = helperUnpackUnorm32x4(floatBitsToUint(info.a)).x;\n    return v;\n}\n\nvoxel getVoxelDebug(sampler2D buffer, vec2 fragCoord)\n{\n    voxel v;\n    vec4 info = texelFetch(buffer, ivec2(fragCoord), 0);\n    v.color = unpackUnorm32x4(info.r);\n    v.normal = unpackSnorm32x4(info.b).xyz;\n    v.material = helperUnpackUnorm32x4(floatBitsToUint(info.a)).x;\n    return v;\n}\n\nvec4 saveVoxel(voxel v)\n{\n    vec4 info;\n    info.r = packUnorm32x4(v.color);\n    info.b = packSnorm32x4(vec4(v.normal, 0.0));\n    info.a = uintBitsToFloat(helperPackUnorm32x4(uvec4(v.material, 0, 0, 0)));\n    return info;\n}\n\n\n// TODO: handle boundry conditions here:\nvec4 getLight(sampler2D buffer, ivec3 pos, int LOD)\n{\n    vec4 info = getPos(buffer, pos, LOD);\n    return unpackUnorm32x4(info.r);\n}\n\nvec4 getLightDebug(sampler2D buffer, vec2 fragCoord)\n{\n    vec4 info = texelFetch(buffer, ivec2(fragCoord), 0);\n    return unpackUnorm32x4(info.r);\n}\n\nvec4 saveLight(vec4 l)\n{\n    return vec4(packUnorm32x4(l), 0.0, 0.0, 0.0);\n}\n\nvec2 rotate2d(vec2 v, float a) {\n\tfloat sinA = sin(a);\n\tfloat cosA = cos(a);\n\treturn vec2(v.x * cosA - v.y * sinA, v.y * cosA + v.x * sinA);\t\n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// This is just the geometry of the scene\n// no lighting calcluations done here\n\n// this does not need to be stored as voxels\n// this could be any geometry and or data structure\n// but here I am for simplicity and art style\n\nfloat hash12(vec2 p)\n{\n\tvec3 p3  = fract(vec3(p.xyx) * .1031);\n    p3 += dot(p3, p3.yzx + 33.33);\n    return fract((p3.x + p3.y) * p3.z);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    if (iTime > 0.1)\n    {\n        discard; // once geometry is drawn you dont have to draw anymore\n    }\n\n    ivec4 posLOD = getPos(fragCoord, ivec2(iResolution.xy));\n    ivec3 pos = posLOD.xyz;\n    int LOD = posLOD.w;\n    \n    voxel v;\n\n    // pergola\n    if (pos.y > volumeSize - 6)\n    {\n        if (pos.z % 8 == 0)\n        {\n            v.color = vec4(0.875,0.682,0.345,1.0);\n            v.normal = normalize(vec3(0.0, 1.0, 0.0));\n            v.color.rgb -= hash12(fragCoord)*0.1;\n            v.material = DIFFUSE_MAT;\n        }\n    }\n    // ground\n    if (pos.y < 6)\n    {\n        v.color = vec4(0.706,0.714,0.835,1.0);\n        v.normal = normalize(vec3(0.0, -1.0, 0.0));\n        v.color.rgb -= hash12(fragCoord)*0.1;\n        v.material = DIFFUSE_MAT;\n    }\n    // sphere\n    else if (distance(vec3(pos), vec3(volumeSize/2) - vec3(0.0, 10.0, 0.0)) < 10.0)\n    {\n        v.color = vec4(0.545,0.635,0.835,1.0);\n        v.normal = normalize(vec3(pos) - vec3(volumeSize/2));\n        //v.color.rgb -= hash12(fragCoord)*0.1;\n        v.material = DIFFUSE_MAT; // EMISSIVE_MAT\n    }\n    // wall 1\n    else if (pos.z >= volumeSize - 4)\n    {\n        v.color = vec4(0.925,0.871,0.675,1.0);\n        v.normal = normalize(vec3(0.0, 0.0, -1.0));\n        v.material = DIFFUSE_MAT;\n    }     \n    // wall 2\n    else if (pos.x <= 4)\n    {\n        v.color = vec4(0.925,0.871,0.675,1.0);\n        v.normal = normalize(vec3(1.0, 0.0, 0.0));\n        v.material = MIRROR_MAT;\n    }\n    \n    fragColor = saveVoxel(v);\n    return;\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// this is rendering the camera in the orthogonal view point of the sun's perspective\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = (fragCoord.xy / iResolution.xy) * 2.0 - 1.0;\n    vec3 rayPos = vec3(uv * cameraSize, volumeSize);   // Orthographic origin based on screen space\n    vec3 rayDir = vec3(0.0, 0.0, -1.0); // Fixed direction for orthographic projection\n\n    rayPos.yz = rotate2d(rayPos.yz, (iMouse.y/iResolution.y)*14.0);\n\trayDir.yz = rotate2d(rayDir.yz, (iMouse.y/iResolution.y)*14.0);\n\trayPos += vec3(volumeSize)/2.0;\n    \n\tvec3 mapPos = floor(rayPos);\n\tvec3 deltaDist = abs(vec3(length(rayDir)) / rayDir);\n\tvec3 rayStep = sign(rayDir);\n\tvec3 sideDist = (sign(rayDir) * (vec3(mapPos) - rayPos) + (sign(rayDir) * 0.5) + 0.5) * deltaDist; \n\tvec3 mask;\n\n    voxel vox;\n    \n\tfor (int i = 0; i < MAX_RAY_STEPS; i++) \n    {\n        if (all(lessThan(mapPos, vec3(volumeSize))) && all(greaterThan(mapPos, vec3(0.0))))\n        {\n            vox = getVoxel(iChannel0, ivec3(mapPos), 0);\n        \n            if (vox.color.a > 0.1)\n            {\n                float len = min(sideDist.x, min(sideDist.y, sideDist.z));\n                fragColor = vec4(len);\n                return;\n            }\n        }\n\n        mask = vec3(lessThanEqual(sideDist.xyz, min(sideDist.yzx, sideDist.zxy)));\t\t\n\t\tsideDist += mask * deltaDist;\n\t\tmapPos += mask * rayStep;\n\t}\n    \n    fragColor = vec4(1.0);\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// Here is the mipmaped 3D texture for lighting\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec4 posLOD = getPos(fragCoord, ivec2(iResolution.xy));\n    ivec3 pos = posLOD.xyz;\n    int LOD = posLOD.w;\n    \n    vec4 light = vec4(0.0);\n\n\n    // START SAMERA\n    vec3 camPos = vec3(0.0, 0.0, volumeSize);   // Orthographic origin based on screen space\n    vec3 camRight = vec3(1.0, 0.0, 0.0); // Fixed direction for orthographic projection\n    vec3 camUp = vec3(0.0, 1.0, 0.0);\n    vec3 camForward = vec3(0.0, 0.0, -1.0);\n\n    camPos.yz = rotate2d(camPos.yz, (iMouse.y/iResolution.y)*14.0);\n\tcamRight.yz = rotate2d(camRight.yz, (iMouse.y/iResolution.y)*14.0);\n    camUp.yz = rotate2d(camUp.yz, (iMouse.y/iResolution.y)*14.0);\n    camForward.yz = rotate2d(camForward.yz, (iMouse.y/iResolution.y)*14.0);\n\tcamPos += vec3(volumeSize)/2.0;\n    // END CAMERA\n\n\n    // dont use LOD 0\n    if (LOD == 0)\n    {\n        light = vec4(0.0);\n        // discard;\n    }\n    else if (LOD == 1)\n    { \n        // base layer:\n        // Here blur the lower level to add to current level\n        \n        // emissive contribution\n        vec3 emissive = vec3(0.0);\n        \n        for (int i = 0; i < 2; i++) for (int j = 0; j < 2; j++) for (int k = 0; k < 2; k++)\n        {\n            voxel v = getVoxel(iChannel0, pos * 2 + ivec3(i, j, k), 0);\n            \n            light += v.color / 8.0; // divide by 8 voxels\n            \n            if (v.material == EMISSIVE_MAT)\n            {\n                emissive += v.color.rgb / 8.0;\n            }\n        }\n        \n        // if the sun touches here then it is illuminated!\n        vec3 truePos = vec3(pos) * 2.0;\n        \n        vec3 v = truePos - camPos;\n        \n        vec2 screenCoord = vec2(dot(v, camRight), dot(v, camUp));\n        \n        float depth = texture(iChannel1, (screenCoord / cameraSize) * 0.5 + 0.5).x;\n        \n        float trueDepth = abs(dot(camPos - truePos, camForward));\n        \n        // step slightly out + 3\n        if (depth + 2.0 >= trueDepth)\n        {\n             light.rgb *= 1.0;\n        } else\n        {\n            light.rgb *= 0.0;\n        }\n        \n        light.rgb += emissive;\n    } else if (LOD <= maxLODs)\n    {\n        // higher layer:\n        // Here just blurr the lighting upwards\n        for (int i = 0; i < 2; i++) for (int j = 0; j < 2; j++) for (int k = 0; k < 2; k++)\n        {\n            light += getLight(iChannel2, pos * 2 + ivec3(i, j, k), LOD - 1) / 8.0;\n        }\n        \n    }\n    \n    fragColor = saveLight(light);\n}","name":"Buffer C","description":"","type":"buffer"}]}
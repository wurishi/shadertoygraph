{"ver":"0.1","info":{"id":"sl3yWf","date":"1660659002","viewed":209,"name":"AwareStubMan's Bloom","username":"AwareStubMan","description":"terribly slow because this is half-lazily done","likes":0,"published":1,"flags":32,"usePreview":1,"tags":["bloom"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsBSR3","filepath":"/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","previewfilepath":"/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","type":"texture","channel":1,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"#define SAMPLES 10 // samples to do for blurring per layer\n#define LAYERS 7 // how many blurred image \n#define RADIUS 0.01 // Initial radius for the first layer\n#define DITHER // dither the blur or not\n\nfloat Max_Res;\nvec2 Correct_Aspect;\nvec4 Dither;\n\nvec3 blur(vec2 co, float radius)\n{\n    // Blur using mipmaps to improve quality\n    vec4 sum = vec4(0);\n    float lod = log2(Max_Res*radius / sqrt(float(SAMPLES))); // lod is dependent on radius and sample count and sampling shape\n    for (int i = 0; i < SAMPLES; i++)\n    {\n        #ifdef DITHER\n            vec2 dither_i = animR2(Dither.xy);\n            float ang = 2.4 * float(i) + dither_i.x*2.0*PI; // vogel disk\n            float radius_i = sqrt((float(i)+dither_i.y) / float(SAMPLES));\n        #else\n            float ang = 2.4 * float(i);\n            float radius_i = sqrt((float(i)+0.5) / float(SAMPLES));\n        #endif\n        vec2 offset = vec2(cos(ang), sin(ang));\n        offset *= radius_i;\n        offset *= radius; // scale by radius in screen space\n        offset /= Correct_Aspect; // correct for aspect ratio\n        \n        float weight = smoothstep(0.0, 1.0, 1.0-radius_i) + 1e-5; // gaussian is too long so i use something else\n\n        sum.rgb += textureLod(iChannel0, co+offset, lod*1.).rgb*weight;\n        sum.a += weight;\n    }\n    sum /= sum.a;\n    \n    return sum.rgb;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Initialize the global variables\n    Rng_Seed = float(iFrame);\n    Max_Res = max(iResolution.x, iResolution.y);\n    Correct_Aspect = vec2(iResolution.x/iResolution.y, iResolution.y/iResolution.x); // stretch the smallest axis\n    Correct_Aspect = iResolution.x > iResolution.y ? vec2(1.0, Correct_Aspect.y) : vec2(Correct_Aspect.x, 1.0);\n    Dither = texture(iChannel1, fragCoord/1024.0);\n    \n    \n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    // Layer multiple blurred image with a base-2 exponential radius\n    vec3 blurred = vec3(0);\n    for (int i = 0; i < LAYERS; i++)\n    {\n        blurred += blur(uv, float(1 << i) * RADIUS);\n    }\n    blurred /= float(LAYERS);\n    \n    vec3 col = mix(texture(iChannel0, uv).rgb, blurred, 0.25); // doing mix so it's \"energy conserving\"\n    col *= ACES_INPUT_MATRIX;\n    col = mix(vec3(getLuminance(col)), col, 1.1);\n    col = piecewiseTonemap(col, 0.25, 5.0);\n    col *= ACES_OUTPUT_MATRIX;\n    col = lin2sRGB(col);\n\n    // Output to screen\n    fragColor = vec4(col,1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"XdfGRr","filepath":"/media/a/35c87bcb8d7af24c54d41122dadb619dd920646a0bd0e477e7bdc6d12876df17.webm","previewfilepath":"/media/ap/35c87bcb8d7af24c54d41122dadb619dd920646a0bd0e477e7bdc6d12876df17.webm","type":"video","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = sRGB2lin(textureLod(iChannel0, fragCoord/iResolution.xy, 0.0));\n    fragColor *= fragColor.a;\n    \n    float mask = smoothstep(\n        0.025,\n        0.1,\n        dot(fragColor.rgb-vec3(0.008,0.373,0.020), fragColor.rgb-vec3(0.008,0.373,0.020))\n    );\n    \n    // Apply green screening, go ahead and comment the line if you want\n    fragColor.rgb = mix(vec3(0.0), fragColor.rgb, mask);\n    \n    fragColor.rgb = mix(fragColor.rgb, fragColor.rgb * 100.0, pow(getLuminance(fragColor.rgb), 6.6));\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"#define GAMMA 2.2\n\n// Mathematical constants\n#define PI 3.14159265359\n\n// Misc\nfloat getLuminance(vec3 v) { return dot(v, vec3(0.2126, 0.7152, 0.0722)); }\n\n// Color space conversions\nvec3 lin2sRGB(vec3 v) { return pow(v, vec3(1.0/GAMMA)); }\nvec4 lin2sRGB(vec4 v) { return vec4(pow(v.rgb, vec3(1.0/GAMMA)), v.a); }\nvec3 sRGB2lin(vec3 v) { return pow(v, vec3(GAMMA)); }\nvec4 sRGB2lin(vec4 v) { return vec4(pow(v.rgb, vec3(GAMMA)), v.a); }\n\n// RNG\n// http://extremelearning.com.au/unreasonable-effectiveness-of-quasirandom-sequences/\nfloat Rng_Seed = 0.0;\nfloat animR1(float x)\n{\n    const float g = 1.61803398875;\n    const float a = 1.0 / g;\n    return fract(x + a*(++Rng_Seed));\n}\nvec2 animR2(vec2 x)\n{\n    const float g = 1.32471795724;\n    const vec2 a = 1.0 / vec2(g, g*g);\n    return fract(x + a*(++Rng_Seed));\n}\n\n// ACES Tonemapping\nmat3 ACES_INPUT_MATRIX = mat3(\n    0.59719, 0.35458, 0.04823,\n    0.07600, 0.90834, 0.01566,\n    0.02840, 0.13383, 0.83777\n);\nmat3 ACES_OUTPUT_MATRIX = mat3(\n    1.60475, -0.53108, -0.07367,\n    -0.10208,  1.10813, -0.00605,\n    -0.00327, -0.07276,  1.07602\n);\nvec3 RTT_ODT_FIT(vec3 v)\n{\n    vec3 a = v * (v + 0.0245786) - 0.000090537;\n    vec3 b = v * (0.983729 * v + 0.4329510) + 0.238081;\n    return a / b;\n}\nvec3 ACES_fitted(vec3 v)\n{\n    v = v * ACES_INPUT_MATRIX;\n    v = RTT_ODT_FIT(v);\n    return v * ACES_OUTPUT_MATRIX;\n}\n// Tonemap\nvec3 piecewiseTonemap(vec3 v, float shoulderStart, float whitePoint)\n{\n    float x0 = whitePoint - shoulderStart, y0 = 1.0 - shoulderStart;\n    \n    float b = x0 / y0;\n    float a = x0 / (pow(x0, b) * b);\n    \n    v = clamp(v, 0.0, whitePoint);\n    return mix(\n        v,\n        1.0 - a*pow(whitePoint - v, vec3(b)),\n        vec3(greaterThanEqual(v, vec3(shoulderStart)))\n    );\n}","name":"Common","description":"","type":"common"}]}
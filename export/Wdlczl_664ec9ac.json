{"ver":"0.1","info":{"id":"Wdlczl","date":"1586365955","viewed":307,"name":"Bonsai Sculpture","username":"Slime0","description":"A bonsai-like blob sculpture using Perlin noise and raymarching. Press L to turn off the lights, R to auto rotate.","likes":14,"published":1,"flags":48,"usePreview":1,"tags":["noise","reflection","raymarch","sdf","blur","shadow","perlin","blob","sculpture","bonsai"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// This scene uses raymarching through a signed distance function\n// with random sampling of soft lighting and blurred reflections.\n// You can see the contents of the buffers by enabling the defines below.\n// Read the comments in each buffer to see what's going on.\n// Buffer A contains initial intersection information.\n// Buffer B calculates low res lighting and reflection information.\n// Buffer C blurs buffer B.\n// The image samples from the above and does some final reflection rays.\n\n\n// Try out these defines to see what's going on in the intermediate buffers!\n#define DEBUG_INTERSECTION_BUFFER 0\n#define DEBUG_LIGHTING_BUFFER_RAW 0\n#define DEBUG_REFLECTION_BUFFER 0\n#define DEBUG_SHADOW_BUFFER 0\n#define DEBUG_BLURRED_LIGHTING_BUFFER_RAW 0\n#define DEBUG_BLURRED_REFLECTION_BUFFER 0\n#define DEBUG_BLURRED_SHADOW_BUFFER 0\n\n// Sampling from the lighting buffer weights each sample\n// to only get the data that matches the current pixel's depth.\n// You can turn this off and see how the lighting bleeds across parts of the object without it.\n#define DEPTH_WEIGHTED_LIGHTING_INTERPOLATION 1\n\nvec3 ColorForRayWithDepth( vec3 seed, vec4 reflectionData, vec3 shadowData, CameraInfo cam, vec2 uv, vec3 dir, float bestDepth, float weightedDepth )\n{\n    #if !SHOWBLOB\n\t    return GetBackgroundColorForRayGivenLightingData( seed, cam.origin, dir, shadowData CACHE );\n    #endif\n    \n    vec3 start = cam.origin;\n    vec3 hitPos;\n    vec3 colorPos;\n    \n    #if DEBUG_REFLECTION_RAYS\n    \tvec3 rayStart;\n    \tbool hitBlob = false;\n        if ( RayHitsBlobBounds( start, dir, rayStart ) )\n            hitBlob = MarchReflectionRay( rayStart, dir, hitPos CACHE );\n    \tcolorPos = hitPos;\n    #elif DEBUG_SHADOW_RAYS\n    \tvec3 rayStart;\n    \tbool hitBlob = false;\n        if ( RayHitsBlobBounds( start, dir, rayStart ) )\n            hitBlob = MarchShadowRay( rayStart, dir, hitPos CACHE );\n    \tif ( hitBlob )\n            return vec3( 0.0 );\n    \tcolorPos = hitPos;\n    #else\n    \tbool hitBlob = (bestDepth < NO_HIT_DEPTH);\n    \thitPos = start + dir * bestDepth;\n    \tcolorPos = start + dir * weightedDepth;\n    #endif\n    \n    if ( !hitBlob )\n    {\n        #if DEBUG_BOUNDS\n            vec3 ignore;\n            if ( RayHitsBlobBounds( start, dir, ignore ) )\n                return vec3( 0.5, 0.5, 0.5 );\n        #endif\n        return GetBackgroundColorForRayGivenLightingData( seed, start, dir, shadowData CACHE );\n    }\n    \n    #if DEBUG_BOUNDS\n        vec3 scaledHitPos = (hitPos - BLOB_BOUNDING_CENTER) * BLOB_BOUNDING_SCALE;\n        if ( dot( scaledHitPos, scaledHitPos ) > BLOB_BOUNDING_RADIUS_SQR * 0.99 )\n            return vec3( 1.0, 0.0, 0.0 );\n    #endif\n\n    #if DEBUG_SURFACE_REFINEMENT\n        if ( BlobDist( hitPos CACHE ) <= 0.0 )\n            return vec3( 1.0, 0.0, 0.0 );\n    #endif\n\n    vec3 firstDir = dir;\n    vec3 normal = GetNormal( hitPos CACHE );\n    vec3 pixelColor = BlobColorAtPos( colorPos );\n    \n    #if SHADOWS_ENABLED\n    vec3 ambientColor = mix( AMBIENT_LIGHT_FROM_BELOW, AMBIENT_LIGHT_FROM_ABOVE, normal.y * 0.5 + 0.5 );\n    pixelColor *= LIGHT_COLOR * shadowData.x + ambientColor * shadowData.y + BLOB_EMISSION_LIGHT * shadowData.z;\n    #endif\n    \n    pixelColor += BlobEmissionAtPos( colorPos );\n\n    #if REFLECTION_ENABLED\n    float backgroundReflectionAmount = reflectionData.w;\n    if ( backgroundReflectionAmount > 0.0 )\n    {\n        // need to do a little bit of antialiasing for places where the reflection changes abruptly (tight surface curves).\n        // we just intersect the camera rays with the plane at hitPos with 'normal', and then calculate the normals at the intersection points.\n        // the intersection points probably aren't exactly on the surface, but the normals at those points should be close enough.\n        \n        vec3 reflectionColor = vec3( 0.0 );\n        \n        float camDistOverPlane = -dot( cam.origin - hitPos, normal );\n        for ( int y = 0; y < FULLRES_REFLECTION_SAMPLE_COUNT; y++ )\n        {\n            for ( int x = 0; x < FULLRES_REFLECTION_SAMPLE_COUNT; x++ )\n            {\n                vec2 r2 = rand2( seed );\n                seed.xy += r2 * 100.0;\n                \n                vec2 subUv = uv + (vec2( float( x ) + r2.x, float( y ) + r2.y ) / float( FULLRES_REFLECTION_SAMPLE_COUNT ) - vec2( 0.5 )) / iResolution.xy;\n                \n                vec3 subDir = normalize( cam.bottomLeft + cam.right * subUv.x + cam.up * subUv.y );\n                \n                float dirDotN = dot( subDir, normal );\n                float t = camDistOverPlane / dirDotN;\n                \n                vec3 subHitPos = cam.origin + subDir * t;\n                \n                vec3 subNormal = GetNormal( subHitPos CACHE );\n\n                dir = reflect( subDir, RandomizeNormal( subNormal, seed, BLOB_REFLECT_BLUR ) );\n\n                vec3 bgColor = GetBackgroundColorForRayGivenLightingData( seed, hitPos, dir, FAKE_BACKGROUND_SHADOW_DATA_FOR_REFLECTIONS * GetBrightnessForTime( blobTime ) CACHE );\n\n                reflectionColor += bgColor;\n            }\n        }\n        \n        pixelColor += reflectionColor * backgroundReflectionAmount / float( FULLRES_REFLECTION_SAMPLE_COUNT * FULLRES_REFLECTION_SAMPLE_COUNT );\n    }\n    pixelColor += reflectionData.xyz;\n    #endif\n    \n    return pixelColor;\n}\n\nconst int NearbyPixelOffsetCount = 8;\nconst vec2[8] nearbyPixelOffsets = vec2[8](\n    vec2( 0.0, 1.0 ),\n    vec2( 0.0, -1.0 ),\n    vec2( 1.0, 0.0 ),\n    vec2( -1.0, 0.0 ),\n    vec2( -1.0, 1.0 ),\n    vec2( 1.0, -1.0 ),\n    vec2( 1.0, 1.0 ),\n    vec2( -1.0, -1.0 )\n);\n\nvec4 GetLightingDataWeightsForDepth( vec4 baseLightingDataSampleWeights, float depth, vec4 shadowDataSamples[4] )\n{\n    #if DEPTH_WEIGHTED_LIGHTING_INTERPOLATION\n    vec4 weights;\n    float totalWeight = 0.0;\n    for ( int j = 0; j < 4; j++ )\n        weights[j] = baseLightingDataSampleWeights[j] * WeightForDepthDiff( depth, shadowDataSamples[j].w );\n    weights /= dot( weights, vec4( 1.0 ) );\n    return weights;\n\n    #else\n\n    return baseLightingDataSampleWeights;\n    #endif\n}\n\nvec4 WeightSamples( vec4 samples[4], vec4 weights )\n{\n    return samples[0] * weights.x + samples[1] * weights.y + samples[2] * weights.z + samples[3] * weights.w;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    State state;\n    GetStateAndSetGlobals( iFrame, iTime, iResolution.xy, iChannel0, iChannel3, state );\n    \n    CameraInfo cam;\n    GetCameraInfo( state, iResolution.xy, cam );\n\n    vec2 BUFFER_SIZE = min( PREFERRED_BUFFER_SIZE, iResolution.xy / 2.0 );\n    \n    vec2 uvToBufferCoord = BUFFER_SIZE / iResolution.xy;\n    \n    vec4 intersectionData = textureLod( iChannel0, fragCoord / iResolution.xy, 0.0 );\n\n    // manual texture interpolation for lighting data so that we can discard samples for which the depth doesn't match\n    vec2 lightingDataSamplePos = (fragCoord / iResolution.xy /*+ vec2( 1.0, 0.0 )*/) * BUFFER_SIZE;\n    vec2 lightingDataLowerLeftPixelCenter = floor( lightingDataSamplePos - vec2( 0.5 ) ) + vec2( 0.5 );\n    vec2 lightingPixelFrac = lightingDataSamplePos - lightingDataLowerLeftPixelCenter;\n    vec2 lightingLowerLeftPixelUV = lightingDataLowerLeftPixelCenter / iResolution.xy;\n    vec3 lightingBufPixelSize = vec3( 1.0, 1.0, 0.0 ) / iResolution.xyx;\n    vec4 lightingDataPixelFracs = vec4( lightingPixelFrac, vec2( 1.0 ) - lightingPixelFrac );\n    vec4 lightingDataSampleWeights = lightingDataPixelFracs.zzxx * lightingDataPixelFracs.wywy;\n\n    vec4 reflectionDataSamples[4] = vec4[4](\n        texture( iChannel2, lightingLowerLeftPixelUV ), // lower left\n        texture( iChannel2, lightingLowerLeftPixelUV + lightingBufPixelSize.zy ), // upper left\n        texture( iChannel2, lightingLowerLeftPixelUV + lightingBufPixelSize.xz ), // lower right\n        texture( iChannel2, lightingLowerLeftPixelUV + lightingBufPixelSize.xy ) // upper right\n    );\n\n    vec2 shadowLowerLeftPixelUV = lightingLowerLeftPixelUV + vec2( BUFFER_SIZE.x / iResolution.x, 0.0 );\n    vec4 shadowDataSamples[4] = vec4[4](\n        texture( iChannel2, shadowLowerLeftPixelUV ), // lower left\n        texture( iChannel2, shadowLowerLeftPixelUV + lightingBufPixelSize.zy ), // upper left\n        texture( iChannel2, shadowLowerLeftPixelUV + lightingBufPixelSize.xz ), // lower right\n        texture( iChannel2, shadowLowerLeftPixelUV + lightingBufPixelSize.xy ) // upper right\n    );\n    \n    vec2 uv = fragCoord / iResolution.xy;\n    vec3 dir = normalize( cam.bottomLeft + cam.right * uv.x + cam.up * uv.y );\n\n    vec3 randomSeed = vec3( uv, blobTime + 75.0 );\n    \n    // intersectionData.x and .y are two intersection depths, and .z is the balance between them.\n    // If they both hit the object ( < NO_HIT_DEPTH), we still only shoot one ray,\n    // but we take the weighted average of the depths for color calculation, which sort of antialiases\n    // the color. We also calculate the reflection and shadow weights separately for each depth and \n    // take the weighted average of those weights. So we effectively get antiliasing with a single iteration.\n    float firstSampleContribution = intersectionData.z;\n    \n    vec3 pixelColor = vec3( 0, 0, 0 );\n    \n    vec4 lightingDataWeights = GetLightingDataWeightsForDepth( lightingDataSampleWeights, intersectionData.x, shadowDataSamples );\n\n    float bestDepth = intersectionData.x;\n    float weightedDepth;\n    if ( intersectionData.y < NO_HIT_DEPTH && firstSampleContribution < 1.0 )\n    {\n        vec4 secondSampleLightingDataWeights = GetLightingDataWeightsForDepth( lightingDataSampleWeights, intersectionData.y, shadowDataSamples );\n        lightingDataWeights = mix( secondSampleLightingDataWeights, lightingDataWeights, firstSampleContribution ); \n\t    weightedDepth = mix( intersectionData.y, intersectionData.x, firstSampleContribution );\n    }\n    else\n    {\n        weightedDepth = bestDepth;\n    }\n\n    vec4 reflectionData = WeightSamples( reflectionDataSamples, lightingDataWeights );\n    vec3 shadowData = WeightSamples( shadowDataSamples, lightingDataWeights ).xyz;\n    \n    pixelColor = min( ColorForRayWithDepth( randomSeed, reflectionData, shadowData, cam, uv, dir, bestDepth, weightedDepth ), vec3( 1.0 ) );\n    \n    // If one of the intersection depths missed the object ( >= NO_HIT_DEPTH), we do a separate call\n    // to get the background color, which is cheap.\n    if ( intersectionData.y >= NO_HIT_DEPTH && firstSampleContribution < 1.0 )\n    {\n        vec4 lightingDataWeights = GetLightingDataWeightsForDepth( lightingDataSampleWeights, NO_HIT_DEPTH, shadowDataSamples );\n        vec3 shadowData = WeightSamples( shadowDataSamples, lightingDataWeights ).xyz;\n\n        vec3 secondSampleColor = GetBackgroundColorForRayGivenLightingData( randomSeed, cam.origin, dir, shadowData CACHE );\n        pixelColor = mix( min( secondSampleColor, 1.0 ), min( pixelColor, 1.0 ), firstSampleContribution );\n    }\n    \n    // Output to screen\n    fragColor = vec4( pixelColor, 1.0 );\n    \n    #if DEBUG_INTERSECTION_BUFFER\n    \tfragColor = vec4( intersectionData.xyz / vec3( 40.0, 40.0, 1.0 ), 1.0 );\n    #elif DEBUG_LIGHTING_BUFFER_RAW\n    \tif ( all( lessThan( fragCoord, BUFFER_SIZE * vec2( 2.0, 1.0 ) ) ) )\n    \t\tfragColor = texture( iChannel1, uv );\n    #elif DEBUG_REFLECTION_BUFFER\n    \tvec4 debugData = texture( iChannel1, fragCoord / iResolution.xy * BUFFER_SIZE / iResolution.xy );\n    \tfragColor = vec4( debugData.xyz + vec3( 1.0 ) * debugData.w, 1.0 );\n    #elif DEBUG_SHADOW_BUFFER\n    \tfragColor = vec4( texture( iChannel1, (fragCoord / iResolution.xy + vec2( 1.0, 0.0 )) * BUFFER_SIZE / iResolution.xy ) );\n    #elif DEBUG_BLURRED_LIGHTING_BUFFER_RAW\n    \tif ( all( lessThan( fragCoord, BUFFER_SIZE * vec2( 2.0, 1.0 ) ) ) )\n    \t\tfragColor = texture( iChannel2, uv );\n    #elif DEBUG_BLURRED_REFLECTION_BUFFER\n    \tvec4 debugData = texture( iChannel2, fragCoord / iResolution.xy * BUFFER_SIZE / iResolution.xy );\n    \tfragColor = vec4( debugData.xyz + vec3( 1.0 ) * debugData.w, 1.0 );\n    #elif DEBUG_BLURRED_SHADOW_BUFFER\n    \tfragColor = vec4( texture( iChannel2, (fragCoord / iResolution.xy + vec2( 1.0, 0.0 )) * BUFFER_SIZE / iResolution.xy ) );\n    #endif\n    \n    //fragColor = texture( iChannel3, fragCoord / iResolution.xy );\n}\n\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"\n#define REFLECTION_ENABLED 1\n#define SHADOWS_ENABLED 1\n\n#define SHOWBLOB 1\n#define NOISE_IN_BLOB_COLOR 1\n#define NOISE_IN_BLOB_SHAPE 1 // disable to see the core shape\n\n#define DEBUG_BOUNDS 0\n\n#define DEBUG_SHADOW_RAYS 0 // uses shadow ray parameters for initial rays\n#define DEBUG_REFLECTION_RAYS 0 // uses reflection ray parameters for initial rays\n\nconst vec2 PREFERRED_BUFFER_SIZE = vec2( 320.0, 180.0 );\n\nconst vec3 CAMERA_LOOK_AT = vec3( 0, -3.0, 0 );\nconst float CAMERA_DIST = 25.0;\nconst float CAMERA_ZOOM = 2.6;\nconst float PI = 3.14159;\nconst float TWOPI = 2.0 * PI;\n\nconst float CAM_PITCH_MIN = -PI * 0.34;\nconst float CAM_PITCH_MAX = PI * 0.45;\n\nconst vec3 BLOB_ORIGIN = vec3( 0.0, 0.0, 0.0 );\n\nconst vec3 BLOB_SCALE = vec3( 0.7, 1.1, 1.0 );\nconst float BLOB_RADIUS = 4.0;\nconst vec3 BLOB_BOUNDING_CENTER = vec3( 0.0, -2.0, 0.0 );\nconst vec3 BLOB_BOUNDING_SCALE = vec3( 0.9, 1.0, 1.4 );\nconst float BLOB_BOUNDING_RADIUS = 9.0;\nconst float BLOB_BOUNDING_RADIUS_SQR = BLOB_BOUNDING_RADIUS * BLOB_BOUNDING_RADIUS;\n\nconst float NOISE_CHANGE_RATE = 0.25;\n\nconst vec3 BLOB_COLOR = vec3( 0.4, 0.3, 1.0 ) * 0.5;\nconst float BLOB_REFLECT = 0.25;\nconst float BLOB_REFLECT_BLUR = 0.05;\n\nconst float EPSILON = 0.005;\nconst float NORMALEPSILON = 0.1;\n\nconst float GROUND_PLANE_HEIGHT = -10.0;\nconst float CAMERA_CLIP_HEIGHT = GROUND_PLANE_HEIGHT + 0.3;\nconst float HALLWAY_HALF_WIDTH = 60.0;\nconst float HALLWAY_HALF_LENGTH = 400.0;\nconst float CEILING_HEIGHT = 130.0;\nconst float LIGHT_BOX_HEIGHT = 100.0;\nconst vec3 BG_BOX_CENTER = vec3( 0.0, (GROUND_PLANE_HEIGHT + CEILING_HEIGHT) * 0.5, 0.0 );\nconst vec3 BG_BOX_SCALE = vec3( HALLWAY_HALF_LENGTH, (CEILING_HEIGHT - GROUND_PLANE_HEIGHT) * 0.5, HALLWAY_HALF_WIDTH );\n\nconst float FOG_MIN_DIST = 20.0;\nconst float FOG_THICKNESS_SCALAR = 0.01;\nconst vec3 FOG_COLOR = vec3( 0.9, 0.8, 1.0 ) * 0.3;\n\nconst float LIGHT_RAMP_UP_TIME = 10.0;\n\nconst vec3 LIGHT_DIR = normalize( vec3( 0, 1, 0 ) );\nconst vec3 LIGHT_COLOR = vec3( 1.15, 1.08, 1.0 ) * 1.5;\n\nconst vec3 AMBIENT_LIGHT_FROM_ABOVE = vec3( 1.0, 1.0, 1.1 ) * 0.15;\nconst vec3 AMBIENT_LIGHT_FROM_BELOW = vec3( 1.1, 1.05, 1.0 ) * 0.3;\nconst float MIN_AMBIENT = 0.15; // always let a little bit of ambient lighting in, regardless of occlusion\nconst vec3 BLOB_EMISSION_LIGHT = vec3( 1.0, 0.7, 0.5 ) * 1.0;\n\nconst int MAX_REFLECTIONS = 2;\nconst int BUF_REFLECTION_SAMPLE_COUNT = 1;\nconst int FULLRES_REFLECTION_SAMPLE_COUNT = 3; // X and Y\nconst int BUF_DIRECT_LIGHTING_SAMPLE_X_COUNT = 6;\nconst int BUF_DIRECT_LIGHTING_SAMPLE_Z_COUNT = 2;\nconst int BUF_AMBIENT_LIGHTING_SAMPLE_RADIUS_COUNT = 4;\nconst int BUF_AMBIENT_LIGHTING_SAMPLE_ANGLE_COUNT = 4;\nconst int GROUND_SHADOW_TEST_X_COUNT = 20;\nconst int GROUND_SHADOW_TEST_Z_COUNT = 3;\n\nconst float NO_HIT_DEPTH = 99999.0;\n\n\nconst float MIN_GRADIENT = 8.0;\nconst int MAX_RAYMARCH_STEPS = 256;\n\nconst float REFLECTION_EPSILON = EPSILON * 4.0;\nconst float MIN_GRADIENT_FOR_REFLECTION_RAYS = MIN_GRADIENT * 0.5;\nconst int MAX_REFLECTION_RAYMARCH_STEPS = 50;\n\nconst float SHADOW_EPSILON = EPSILON * 8.0;\nconst float MIN_GRADIENT_FOR_SHADOW_RAYS = MIN_GRADIENT * 0.2;\nconst int MAX_SHADOW_RAYMARCH_STEPS = 10;\n\n// floor shadow is soft enough that it's not really worth simulating for blurry reflections,\n// so just pass this fake lighting data in.\nconst vec3 FAKE_BACKGROUND_SHADOW_DATA_FOR_REFLECTIONS = vec3( 0.7, 1.0, 0.0 ); // (overhead light, ambient light)\n\n\n/* 5 queens AA sampling:\n_____________\n|       .   |\n| .         |\n|     .     |\n|         . |\n|   .       |\n|___________|\n*/\nconst int AA_SAMPLE_COUNT = 5;\nconst vec2[AA_SAMPLE_COUNT] AA_SAMPLE_OFFSETS = vec2[AA_SAMPLE_COUNT] (\n    vec2( -0.4,  0.2 ),\n    vec2( -0.2, -0.4 ),\n    vec2(  0.0,  0.0 ),\n    vec2(  0.2,  0.4 ),\n    vec2(  0.4, -0.2 )\n);\n\nfloat blobTime;\n\nconst float SIMILAR_DEPTH_THRESHOLD = 0.5;\n\n// For two depths, gets a value for how relevant they are to each other\nfloat WeightForDepthDiff( float deptha, float depthb )\n{\n    float diff = (deptha - depthb) / 0.15;\n    return 1.0 / (1.0 + diff * diff);\n}\n\n\n// the min() trick doesn't have any effect on compile times for me. =(\n#define ZERO_NO_LOOP_UNROLL 0 // (min( 0, iFrame ))\n\n\n// ================================================================\n\n\n#define VARY_3D_NOISE_OVER_TIME 1\n\n// These are a holdover from when I implemented noise with a gradient cache that could be passed around.\n// It helped framerate but hurt compile times. =(\n//#define CACHEARG , inout DistanceSampleLocalityCache cache\n//#define CACHE , cache\n#define CACHEARG\n#define CACHE\n\nvec3 LatticeGradient3D( vec3 pos, float time )\n{\n    vec3 res = vec3(\n        dot( pos, vec3( -0.133, 0.933, -0.437 ) ),\n        dot( pos, vec3( 0.742, -0.148, 0.70297 ) ),\n        dot( pos, vec3( -0.344, -0.796, 0.166 ) )\n    );\n    res = sin( res ) * vec3( 73464.138, 36246.143, 40375.332 ) + vec3( 0.123 );\n#if VARY_3D_NOISE_OVER_TIME\n    return sin( res + time * vec3( 0.8, 1.0, 1.2 ) ) * 0.8;\n#else\n    return normalize( sin( res ) );\n#endif\n}\n\n//nst vec3 Noise3DCornerOffsets_0 = vec3( 0.0, 0.0, 0.0 ),\nconst vec3 Noise3DCornerOffsets_1 = vec3( 0.0, 0.0, 1.0 );\nconst vec3 Noise3DCornerOffsets_2 = vec3( 0.0, 1.0, 0.0 );\nconst vec3 Noise3DCornerOffsets_3 = vec3( 0.0, 1.0, 1.0 );\nconst vec3 Noise3DCornerOffsets_4 = vec3( 1.0, 0.0, 0.0 );\nconst vec3 Noise3DCornerOffsets_5 = vec3( 1.0, 0.0, 1.0 );\nconst vec3 Noise3DCornerOffsets_6 = vec3( 1.0, 1.0, 0.0 );\nconst vec3 Noise3DCornerOffsets_7 = vec3( 1.0, 1.0, 1.0 );\n\n// Perlin noise. 4th component is time for morphing\nfloat Noise3D( vec4 pos CACHEARG )\n{\n    vec3 baseCorner = floor( pos.xyz );\n    \n    vec3 frac = pos.xyz - baseCorner;\n    vec3 fracSmooth = frac * frac * (3.0 - 2.0 * frac);\n    \n    vec4 vals[2];\n\t// Manually unrolling this loop helped compile times a lot.\n\t/*for ( int i = 0; i < 4; i++ )\n    {\n        for ( int j = 0; j < 2; j++ )\n        {\n            vec3 offset = frac - Noise3DCornerOffsets[i * 4 + j];\n            vals[i][j] = dot( offset, cache.gradients[i * 4 + j] );\n        }\n    }*/\n    vals[0] = vec4(\n        dot( frac                         , LatticeGradient3D( baseCorner                         , pos.w ) ),\n    \tdot( frac - Noise3DCornerOffsets_1, LatticeGradient3D( baseCorner + Noise3DCornerOffsets_1, pos.w ) ),\n    \tdot( frac - Noise3DCornerOffsets_2, LatticeGradient3D( baseCorner + Noise3DCornerOffsets_2, pos.w ) ),\n    \tdot( frac - Noise3DCornerOffsets_3, LatticeGradient3D( baseCorner + Noise3DCornerOffsets_3, pos.w ) )\n    );\n    vals[1] = vec4(\n        dot( frac - Noise3DCornerOffsets_4, LatticeGradient3D( baseCorner + Noise3DCornerOffsets_4, pos.w ) ),\n    \tdot( frac - Noise3DCornerOffsets_5, LatticeGradient3D( baseCorner + Noise3DCornerOffsets_5, pos.w ) ),\n    \tdot( frac - Noise3DCornerOffsets_6, LatticeGradient3D( baseCorner + Noise3DCornerOffsets_6, pos.w ) ),\n    \tdot( frac - Noise3DCornerOffsets_7, LatticeGradient3D( baseCorner + Noise3DCornerOffsets_7, pos.w ) )\n    );\n    \n    vec4 xvals = mix( vals[0], vals[1], fracSmooth.x );\n    \n    vec2 yvals = mix( xvals.xy, xvals.zw, fracSmooth.y );\n    \n    return mix( yvals.x, yvals.y, fracSmooth.z );\n}\n\n\n\nvec4 TwoLatticeGradients2D( vec4 pos01 )\n{\n    vec4 res = vec4(\n        dot( pos01.xy, vec2( -0.133, 0.933 ) ),\n        dot( pos01.xy, vec2( 0.742, -0.148 ) ),\n        dot( pos01.zw, vec2( -0.133, 0.933 ) ),\n        dot( pos01.zw, vec2( 0.742, -0.148 ) )\n    );\n    res = sin( res ) * vec4( 73464.138, 36246.143, 73464.138, 36246.143 ) + vec4( 0.123 );\n    return vec4( normalize( sin( res.xy ) ), normalize( sin( res.zw ) ) );\n}\n\n//nst vec2 Noise2DCornerOffsets_0 = vec2( 0.0, 0.0 ),\nconst vec2 Noise2DCornerOffsets_1 = vec2( 0.0, 1.0 );\nconst vec2 Noise2DCornerOffsets_2 = vec2( 1.0, 0.0 );\nconst vec2 Noise2DCornerOffsets_3 = vec2( 1.0, 1.0 );\n\nfloat Noise2D( vec2 pos )\n{\n    vec2 baseCorner = floor( pos );\n    \n    vec4 gradients_01 = vec4( TwoLatticeGradients2D( vec4( baseCorner                         , baseCorner + Noise2DCornerOffsets_1 ) ) );\n    vec4 gradients_23 = vec4( TwoLatticeGradients2D( vec4( baseCorner + Noise2DCornerOffsets_2, baseCorner + Noise2DCornerOffsets_3 ) ) );\n    \n    vec2 frac = pos - baseCorner;\n    vec2 fracSmooth = frac * frac * (3.0 - 2.0 * frac);\n    \n    vec4 vals = vec4(\n        dot( frac                         , gradients_01.xy ),\n        dot( frac - Noise2DCornerOffsets_1, gradients_01.zw ),\n        dot( frac - Noise2DCornerOffsets_2, gradients_23.xy ),\n        dot( frac - Noise2DCornerOffsets_3, gradients_23.zw )\n    );\n    \n    vec2 xvals = mix( vals.xy, vals.zw, fracSmooth.x );\n    \n    return mix( xvals.x, xvals.y, fracSmooth.y );\n}\n\n\n\n\n\n// ================================================================\n\n\n\n\n\n\n// rand from https://www.shadertoy.com/view/Xt23Ry\nfloat rand(float co) { return fract(sin(co*(91.3458)) * 47453.5453); }\n\nvec3 rand3( vec3 seed )\n{\n    // this vec2 is from https://www.shadertoy.com/view/Xt23Ry\n    float base = dot( seed.xy, vec2( 12.9898, 78.233 ) );\n    return vec3( rand( base + base * seed.z * 0.011 ), rand( base + base * seed.z * 0.017 ), rand( base + base * seed.z * 0.023 ) );\n}\n\nvec2 rand2( vec3 seed )\n{\n    float base = dot( seed.xy, vec2( 12.9898, 78.233 ) );\n    return vec2( rand( base + base * seed.z * 0.017 ), rand( base + base * seed.z * 0.011 ) );\n}\n\nvec3 RandomPointInSphere( vec3 seed )\n{\n    vec3 r3 = rand3( seed );\n    // https://mathworld.wolfram.com/SpherePointPicking.html\n    float theta = r3.x * TWOPI;\n    float z = r3.y * 2.0 - 1.0;\n    float r = sqrt( 1.0 - z * z );\n    vec3 pointOnSphere = vec3( r * cos( theta ), r * sin( theta ), z );\n    return pointOnSphere * pow( r3.z, 0.33333 );\n}\n\nvec3 RandomizeNormal( vec3 normal, vec3 seed, float amount )\n{\n    return normalize( normal + RandomPointInSphere( seed ) * amount );\n}\n\nvec2 Rotate2( vec2 pos, float amount )\n{\n    float theta = length( pos ) * amount;\n    vec2 sincos = vec2( cos( theta ), sin( theta ) );\n    return pos.xx * sincos.xy + pos.yy * vec2( -sincos.y, sincos.x );\n}\n\nbool RayHitsBlobBounds( vec3 start, vec3 dir, out vec3 hitPos )\n{\n    vec3 relStart = start - BLOB_BOUNDING_CENTER;\n    relStart *= BLOB_BOUNDING_SCALE;\n    vec3 relDir = dir * BLOB_BOUNDING_SCALE;\n    \n    float c = dot( relStart, relStart ) - BLOB_BOUNDING_RADIUS_SQR;\n    \n    if ( c < 0.0 )\n    {\n        // starts inside sphere\n        hitPos = start;\n        return true;\n    }\n\n    float a = dot( relDir, relDir );\n    float b = dot( relStart, relDir );\n\n    float discriminant = b * b - a * c;\n    if ( discriminant < 0.0 )\n        return false; // infinite line misses sphere\n    \n    if ( b >= 0.0 )\n        return false; // ray points away from sphere\n    \n    // (this is the quadratic formula with b being half its normal value, which cancels out the 4 and 2 normally in the formula)\n    float t = (-b - sqrt( discriminant )) / a;\n    hitPos = start + dir * t;\n    \n    return true;\n}\n\nfloat smin( float a, float b, float mixrange )\n{\n    // h is 1 when a and b are near each other, and 0 when they are mixrange apart\n    float h = max( mixrange - abs( a - b ), 0.0 ) / mixrange;\n    h *= 0.5; // now it's 0.5 when they're near each other\n    return min( a, b ) - h * h * mixrange;\n}\n\nfloat smax( float a, float b, float mixrange )\n{\n    float h = max( mixrange - abs( a - b ), 0.0 ) / mixrange;\n    h *= 0.5;\n    return max( a, b ) + h * h * mixrange;\n}\n\nvec3 Droop( vec3 pos )\n{\n    // rotate pos upward a bit, mostly on the sides and farther from the center\n    float len = length( pos );\n    \n    float ydiff = pos.y / len;\n    float amount = (1.0 - ydiff * ydiff);\n    float distScale = len / BLOB_RADIUS;\n    amount *= distScale * distScale * distScale;\n    float angle = amount * (0.08 * PI);\n    \n    vec3 right = normalize( vec3( pos.z, 0.0, -pos.x ) );\n    vec3 up = cross( pos, right );\n    return pos * cos( angle ) + up * sin( angle );\n}\n\nvec3 WorldPosToBlobSpherePos( vec3 pos )\n{\n    pos -= BLOB_ORIGIN;\n    // tilt slightly\n    pos.y -= pos.x * 0.1;\n    pos *= BLOB_SCALE;\n    return pos;\n}\n\nvec3 BlobSpherePosToWorldPos( vec3 pos )\n{\n    pos *= (1.0 / BLOB_SCALE);\n    pos.y += pos.x * 0.1;\n    pos += BLOB_ORIGIN;\n    return pos;\n}\n\nfloat BlobDist( vec3 pos CACHEARG )\n{\n    // base sphere\n    vec3 sphereRelPos = WorldPosToBlobSpherePos( pos );\n    float dist = length( sphereRelPos ) - BLOB_RADIUS;\n    \n    // minus a smaller sphere under the base sphere\n    float smallSphereDist = length( sphereRelPos - vec3( 0.0, -5.0, 0.0 ) ) - BLOB_RADIUS * 0.7;\n    dist = smax( dist, -smallSphereDist, BLOB_RADIUS * 0.8 );\n    \n    // stand\n    vec3 standPos = pos;\n    standPos.y = max( standPos.y, 0.0 );\n    standPos.z *= 1.3;\n    \n    float aboveGroundAmount = pos.y - GROUND_PLANE_HEIGHT;\n\n    float angle = aboveGroundAmount * (-1.5 * PI / (BLOB_ORIGIN.y - GROUND_PLANE_HEIGHT));\n    vec2 sincos = vec2( cos( angle ), sin( angle ) );\n    standPos.xz = standPos.xx * sincos + standPos.zz * vec2( -sincos.y, sincos.x );\n    \n    standPos.x += aboveGroundAmount * 0.4; // slant a bit\n    \n    float standThickness = 5.0 / (aboveGroundAmount * 1.0 + 1.0);\n    float standDist = length( standPos ) - standThickness;\n    standDist *= 6.0; // make stronger so the noise function can't change it as much\n    \n    dist = smin( dist, standDist, 4.0 );\n    \n    #if NOISE_IN_BLOB_SHAPE\n    // noise\n    vec3 noisePos = sphereRelPos;\n    noisePos = Droop( noisePos );\n    noisePos = BlobSpherePosToWorldPos( noisePos );\n    noisePos *= 0.9;\n    noisePos.y += blobTime * 0.2; // gradually translate downward\n    float noise = Noise3D( vec4( noisePos, blobTime * NOISE_CHANGE_RATE ) CACHE ) * 3.5;\n    \n    dist += noise * smoothstep( 0.0, 4.0, aboveGroundAmount );\n    #endif\n    \n    // disappear at ground plane height\n    float nearGroundFrac = max( (1.0 - aboveGroundAmount) / 1.0, 0.0 );\n    nearGroundFrac *= nearGroundFrac;\n    nearGroundFrac *= nearGroundFrac;\n    //nearGroundFrac *= nearGroundFrac;\n    dist += nearGroundFrac * 8.0;\n    dist = smax( dist, aboveGroundAmount * -6.0, 6.0);\n    \n    return dist;\n}\n\nvec3 GetNormal( vec3 pos CACHEARG )\n{\n    float val = BlobDist( pos CACHE );\n    return normalize( vec3( BlobDist( pos + vec3( NORMALEPSILON, 0.0, 0.0 ) CACHE ), BlobDist( pos + vec3( 0.0, NORMALEPSILON, 0.0 ) CACHE ), BlobDist( pos + vec3( 0.0, 0.0, NORMALEPSILON ) CACHE ) ) - vec3( val ) );\n}\n\nvec3 GetHemisphereDirForDiscPoint( vec3 normal, vec2 discPoint )\n{\n    // get two perpendicular vectors\n    // right = normal x (0,0,1)\n    vec3 right = normalize( vec3( normal.y, -normal.x, 0.0 ) );\n    vec3 up = cross( right, normal );\n    return right * discPoint.x + up * discPoint.y + normal * sqrt( 1.0 - dot( discPoint, discPoint ) );\n}\n\nvec3 GetRandomWeightedHemisphereDir( vec3 seed, vec3 normal )\n{\n    // gets a point on a hemisphere oriented toward normal,\n    // but weighted by cosine of angle from the normal\n    \n    // start with random point on disc\n    vec2 r2 = rand2( seed );\n    float angle = r2.x * TWOPI;\n    vec2 discPoint = vec2( cos( angle ), sin( angle ) ) * sqrt( r2.y );\n    \n    return GetHemisphereDirForDiscPoint( normal, discPoint );\n}\n\n#define DEBUG_SURFACE_REFINEMENT 0 // draws red where this surface refinement fails to get the point out of the object\nvec3 RefineSurfacePos( vec3 pos, vec3 dir, float surfaceDist, float prevSurfaceDist, float prevMarchDist, float epsilon CACHEARG )\n{\n\t// backtrack position to an epsilon above surface;\n    // up to 3 times or until the distance is not negative\n\tfor ( int i = 0; ; i++ )\n    {\n        float backtrackDist = prevMarchDist * (epsilon - surfaceDist) / (prevSurfaceDist - surfaceDist);\n        backtrackDist = clamp( backtrackDist, 0.0, 1.0 ); // avoids massive numbers when prevSurfaceDist == surfaceDist\n        pos -= dir * backtrackDist;\n        \n        if ( i == 3 )\n            break;\n\n        float newSurfaceDist = BlobDist( pos CACHE );\n        if ( newSurfaceDist >= 0.0 )\n            break;\n\n        prevMarchDist -= backtrackDist;\n        surfaceDist = newSurfaceDist;\n        epsilon *= 4.0; // be less picky for each iteration; if we're failing, the gradient of the function is probably very nonlinear here\n    }\n    return pos;\n}\n\n\nbool MarchCameraRay( vec3 start, vec3 dir, out vec3 pos CACHEARG )\n{\n    vec3 boundsStart;\n    if ( !RayHitsBlobBounds( start, dir, boundsStart ) )\n\t    return false;\n    \n    // assumes dir is normalized\n    pos = boundsStart + dir * EPSILON;\n    \n    float prevMarchDist = EPSILON;\n    float prevSurfaceDist = BlobDist( boundsStart CACHE );\n    \n    #if DEBUG_BOUNDS\n    \tif ( prevSurfaceDist <= 0.0 )\n        {\n            pos = boundsStart;\n            return true;\n        }\n    #endif\n    \n    for ( int i = 0; i < MAX_RAYMARCH_STEPS; i++ )\n    {\n        float surfaceDist = BlobDist( pos CACHE );\n        if ( surfaceDist <= EPSILON )\n        {\n            if ( surfaceDist < 0.0 )\n            \tpos = RefineSurfacePos( pos, dir, surfaceDist, prevSurfaceDist, prevMarchDist, EPSILON CACHE );\n            return true;\n        }\n        \n        // calculate the gradient of the function along the ray.\n        // we're hoping that the gradient doesn't get suddenly steeper ahead of us.\n        // to protect against that, we don't go lower than MIN_GRADIENT.\n        // we want MIN_GRADIENT as low as possible without artifacts.\n        float gradientAlongRay = (prevSurfaceDist - surfaceDist) / prevMarchDist;\n        float safeGradient = max( gradientAlongRay, MIN_GRADIENT );\n        \n        float addDist = (surfaceDist + EPSILON) / safeGradient;\n        prevMarchDist = addDist;\n        \n        prevSurfaceDist = surfaceDist;\n        pos += dir * addDist;\n        \n        vec3 relPos = pos - BLOB_BOUNDING_CENTER;\n        relPos *= BLOB_BOUNDING_SCALE;\n        if ( dot( relPos, relPos ) > BLOB_BOUNDING_RADIUS_SQR )\n            return false;\n    }\n    \n    return true;\n}\n\nbool MarchReflectionRay( vec3 start, vec3 dir, out vec3 pos CACHEARG )\n{\n    // same as MarchCameraRay except lower tolerances because artifacts won't be very noticeable.\n    // no bounds checking because reflection rays always start near the surface\n    \n    // assumes dir is normalized\n    pos = start + dir * REFLECTION_EPSILON;\n    \n    float prevMarchDist = REFLECTION_EPSILON;\n    float prevSurfaceDist = BlobDist( start CACHE );\n    \n    for ( int i = 0; i < MAX_REFLECTION_RAYMARCH_STEPS; i++ )\n    {\n        float surfaceDist = BlobDist( pos CACHE );\n        if ( surfaceDist < EPSILON )\n        {\n            if ( surfaceDist < 0.0 )\n            \tpos = RefineSurfacePos( pos, dir, surfaceDist, prevSurfaceDist, prevMarchDist, REFLECTION_EPSILON CACHE );\n            return true;\n        }\n        \n        float gradientAlongRay = (prevSurfaceDist - surfaceDist) / prevMarchDist;\n        float safeGradient = max( gradientAlongRay, MIN_GRADIENT_FOR_REFLECTION_RAYS );\n        \n        float addDist = (surfaceDist + REFLECTION_EPSILON) / safeGradient;\n        prevMarchDist = addDist;\n        \n        prevSurfaceDist = surfaceDist;\n        pos += dir * addDist;\n        \n        vec3 relPos = pos - BLOB_BOUNDING_CENTER;\n        relPos *= BLOB_BOUNDING_SCALE;\n        if ( dot( relPos, relPos ) > BLOB_BOUNDING_RADIUS_SQR )\n            return false;\n    }\n    \n    return true;\n}\n\nbool MarchShadowRay( vec3 start, vec3 dir, out vec3 pos CACHEARG )\n{\n    // Same as MarchCameraRay except lower tolerances because artifacts will barely be noticeable,\n    // and we don't care about hit pos being accurate.\n    // Caller should check bounds because sometimes we want to call this when we already know we're inside the bounds.\n    \n    pos = start + dir * SHADOW_EPSILON;\n    \n    float prevMarchDist = SHADOW_EPSILON;\n    float prevSurfaceDist = BlobDist( start CACHE );\n    \n    for ( int i = 0; i < MAX_SHADOW_RAYMARCH_STEPS; i++ )\n    {\n        float surfaceDist = BlobDist( pos CACHE );\n        if ( surfaceDist <= EPSILON )\n            return true;\n        \n        float gradientAlongRay = (prevSurfaceDist - surfaceDist) / prevMarchDist;\n        float safeGradient = max( gradientAlongRay, MIN_GRADIENT_FOR_SHADOW_RAYS );\n        \n        float addDist = (surfaceDist + SHADOW_EPSILON) / safeGradient;\n        prevMarchDist = addDist;\n        \n        prevSurfaceDist = surfaceDist;\n        pos += dir * addDist;\n\n        vec3 relPos = pos - BLOB_BOUNDING_CENTER;\n        relPos *= BLOB_BOUNDING_SCALE;\n        if ( dot( relPos, relPos ) > BLOB_BOUNDING_RADIUS_SQR )\n            return false;\n\t}\n    \n    return true;\n}\n\nvec3 GetFloorColor( vec2 pos )\n{\n    vec2 origPos = pos;\n    \n    //pos = pos.xx * vec2( 0.9, 0.42 ) + pos.yy * vec2( -0.42, 0.9 );\n    pos *= 0.1;\n    \n    // turbulence\n    pos.y += Noise2D( pos * 55.0 ) * 0.015;\n    pos.y += Noise2D( pos * 15.0 ) * 0.04;\n    pos.y += Noise2D( pos * 5.0 ) * 0.1;\n    \n    float twist = (TWOPI) / (1.0 + dot( pos, pos ) * 1.0);\n    //twist *= (sin( blobTime )*0.5 + 0.5); // uncomment to see the twist effect\n    vec2 twistSinCos = vec2( cos( twist ), sin( twist ) );\n    pos = pos.xx * twistSinCos.xy + pos.yy * vec2( -twistSinCos.y, twistSinCos.x );\n    \n    pos.y += Noise2D( pos * 1.5 ) * 0.8;\n    pos.y += Noise2D( pos * 0.35 ) * 2.0;\n\n    pos.y += 4.215;\n    float val = abs( fract( pos.y * 0.5 ) - 0.5 ) * 2.0;\n    //val = max( val * 1.05 - 0.05, 0.0 ); // thicken dark part\n    val = pow( val, 0.35 );\n    val = val * val * (3.0 - 2.0 * val);\n    val = val * val * (3.0 - 2.0 * val);\n    float lightScale = 0.65;\n    float darkScale = 0.15 + 0.1 * Noise2D( origPos * 0.05 );\n    return mix( vec3( 1.0, 1.0, 1.15 ) * darkScale, vec3( 1.0, 1.0, 1.0 ) * lightScale, val );\n}\n\nfloat lightBrightness = 1.0;\nfloat GetBrightnessForTime( float t )\n{\n    return smoothstep( 0.0, LIGHT_RAMP_UP_TIME, t ) * lightBrightness;\n}\n\nfloat GetFloorSpotlightBrightness( vec3 bgPos )\n{\n    vec2 spotlightPos = bgPos.xz / vec2( 100.0, 60.0 );\n    return mix( 0.0, 1.0, smoothstep( 1.0, 0.0, length( spotlightPos ) ) );\n}\n\nvec3 RandomPointOnCeiling( vec3 seed )\n{\n    vec3 ceilingPos = vec3( BG_BOX_CENTER.x - BG_BOX_SCALE.x, CEILING_HEIGHT, BG_BOX_CENTER.z - BG_BOX_SCALE.z );\n    ceilingPos += rand3( seed ) * vec3( BG_BOX_SCALE.x * 2.0, 0.0, BG_BOX_SCALE.z * 2.0 );\n    return ceilingPos;\n}\n\nconst float FOG_MAX_SAMPLE_DIST = 100.0;\nvec3 AddBackgroundFog( vec3 bgColor, vec3 start, vec3 dir, float dist, float brightnessForTime )\n{\n    float fogDist = max( dist - FOG_MIN_DIST, 0.0 );\n    float thickness = 1.0 - exp( -fogDist * FOG_THICKNESS_SCALAR );\n    thickness = thickness * smoothstep( 0.6, 0.0, dir.y );\n    \n    // sample fog density from the midpoint of the ray\n    float distAlongRay = 0.9 * smin( dist, FOG_MAX_SAMPLE_DIST, FOG_MAX_SAMPLE_DIST * 0.2 );\n    vec3 samplePoint = start + dir * distAlongRay;\n    samplePoint /= 0.9 * FOG_MAX_SAMPLE_DIST;\n    \n    float fogTime = blobTime * 0.5;\n    vec4 fogTranslate = blobTime * vec4( 0.0, -0.2, 0.0, 0.0 );\n    float fog = Noise3D( vec4( samplePoint * 3.0, fogTime ) + fogTranslate );\n    fog += Noise3D( vec4( samplePoint * 8.0, fogTime ) + fogTranslate ) * 0.5;\n    fog += Noise3D( vec4( samplePoint * 20.0, fogTime ) + fogTranslate ) * 0.1;\n    fog = fog * 0.4 + 0.4;\n    \n    fog *= thickness;\n    fog = clamp( fog, 0.0, 1.0 );\n    return fog * FOG_COLOR * brightnessForTime + (1.0 - fog) * bgColor;\n}\n\nvec3 GetBackgroundColorForSky( vec3 start, vec3 dir )\n{\n    float brightnessForTime = GetBrightnessForTime( blobTime );\n    \n    // intersect with background box\n    vec3 bgBoxRelStart = start - BG_BOX_CENTER;\n    bvec3 dirPositive = greaterThan( dir, vec3( 0 ) );\n    vec4 bounds = vec4( mix( -BG_BOX_SCALE, BG_BOX_SCALE, dirPositive ), BG_BOX_SCALE.y + LIGHT_BOX_HEIGHT );\n    bounds.x *= brightnessForTime;\n    vec4 ts = (bounds - bgBoxRelStart.xyzy) / dir.xyzy;\n\n    float t = min( min( ts.x, ts.y ), ts.z );\n    vec3 bgPos = start + dir * t;\n    \n    vec3 bgColor;\n    if ( t != ts.y )\n    {\n        bgColor = vec3( 0.0 );\n    }\n    else\n    {\n        // lightbox\n        // top of lightbox intersection is in ts.w\n        float t2 = min( min( ts.x, ts.w ), ts.z );\n\n        float endBrightness = ((start.y + dir.y * t2) - (BG_BOX_CENTER.y + BG_BOX_SCALE.y)) / LIGHT_BOX_HEIGHT;\n\n        float brightness = (t2 - t) * 0.01 * endBrightness;\n\n        if ( t2 == ts.w )\n            brightness += 2.0; // hit top of light box\n\n        brightness *= brightnessForTime;\n\n        bgColor = brightness * LIGHT_COLOR;\n    }\n    \n    bgColor = AddBackgroundFog( bgColor, start, dir, 999999.0, brightnessForTime );\n\n    return bgColor;\n}\n\nvec3 GetBackgroundColorForRayGivenLightingData( vec3 seed, vec3 start, vec3 dir, vec3 shadowData CACHEARG )\n{\n    if ( dir.y >= 0.0 )\n        return GetBackgroundColorForSky( start, dir );\n\n    // intersect with ground plane\n    float t = (GROUND_PLANE_HEIGHT - start.y) / dir.y;\n    vec3 bgPos = start + dir * t;\n    \n    vec3 bgColor;\n    float spotlightBrightness = GetFloorSpotlightBrightness( bgPos );\n    if ( spotlightBrightness == 0.0 )\n    {\n        bgColor = vec3( 0.0 );\n    }\n    else\n    {\n        bgColor = GetFloorColor( bgPos.xz );\n        bgColor *= spotlightBrightness;\n\n        bgColor *= LIGHT_COLOR * shadowData.x + AMBIENT_LIGHT_FROM_ABOVE * shadowData.y + BLOB_EMISSION_LIGHT * shadowData.z;\n    }\n    \n    bgColor = AddBackgroundFog( bgColor, start, dir, t, GetBrightnessForTime( blobTime ) );\n    \n    return bgColor;\n}\n\nvec3 BlobBaseColorAtPos( vec3 pos )\n{\n    pos = WorldPosToBlobSpherePos( pos );\n    float dist = length( pos ) * 1.1 / BLOB_RADIUS;\n    \n    const vec3 Color0 = vec3( 1.5, 0.1, 0.2 ) * 1.0;\n    const float Color0Dist = 0.6;\n    const vec3 Color1 = vec3( 1.0, 0.4, 1.0 ) * 0.7;\n    const float Color1Dist = 1.1;\n    const vec3 Color2 = vec3( 0.1, 0.3, 0.6 ) * 0.7;\n    const float Color2Dist = 1.5;\n    const vec3 Color3 = vec3( 0.2, 0.22, 0.3 ) * 1.0;\n    const float Color3Dist = 2.4;\n    \n    if ( dist < Color1Dist )\n    {\n        if ( dist < Color0Dist )\n            return Color0;\n        else\n            return mix( Color0, Color1, smoothstep( Color0Dist, Color1Dist, dist ) );\n    }\n    else\n    {\n    \tif ( dist < Color2Dist )\n\t    \treturn mix( Color1, Color2, smoothstep( Color1Dist, Color2Dist, dist ) );\n        else if ( dist < Color3Dist )\n            return  mix( Color2, Color3, smoothstep( Color2Dist, Color3Dist, dist ) );\n        else\n\t    \treturn Color3;\n    }\n}\n\nvec3 BlobColorAtPos( vec3 pos )\n{\n    #if NOISE_IN_BLOB_COLOR\n    vec3 baseColor = BlobBaseColorAtPos( pos );\n    \n    float noise0 = Noise3D( vec4( pos * 20.0, 0.0 ) CACHE );\n    float noise1 = Noise3D( vec4( pos * 53.0, 0.0 ) CACHE );\n    return baseColor * (0.9 + noise0 * 0.3 + noise1 * 0.3 );\n    \n    #else\n    return BlobBaseColorAtPos( pos );\n    #endif\n}\n\nvec3 BlobEmissionAtPos( vec3 pos )\n{\n    pos = WorldPosToBlobSpherePos( pos );\n    float dist = length( pos ) / BLOB_RADIUS;\n    \n    const vec3 Color0 = vec3( 1.0, 0.8, 0.6 ) * 1.5;\n    const float Color0Dist = 0.4;\n    const vec3 Color1 = vec3( 1.0, 0.4, 0.4 ) * 0.3;\n    const float Color1Dist = 0.7;\n    const vec3 Color2 = vec3( 0.0 );\n    const float Color2Dist = 1.0;\n    \n    if ( dist < Color0Dist )\n        return Color0;\n    else if ( dist < Color1Dist )\n        return mix( Color0, Color1, smoothstep( Color0Dist, Color1Dist, dist ) );\n    else if ( dist < Color2Dist )\n        return mix( Color1, Color2, sqrt( smoothstep( Color1Dist, Color2Dist, dist ) ) );\n    else\n        return Color2;\n}\n\nfloat BlobEmissionAmountAtPos( vec3 pos )\n{\n    return dot( BlobEmissionAtPos( pos ).xy, vec2( 1.0 / 1.8 ) );\n}\n\nvec3 CalcLightingForPointOnBlob( vec3 seed, vec3 pos, vec3 normal CACHEARG )\n{\n    vec3 light = vec3( 0.0 );\n    vec3 ceilingPos = RandomPointOnCeiling( seed );\n    vec3 lightDir = normalize( ceilingPos - pos );\n\n    float lightDot = dot( lightDir, normal );\n    vec3 ignoreHitPos;\n    if ( lightDot > 0.0 && !MarchShadowRay( pos, lightDir, ignoreHitPos CACHE ) )\n        light += LIGHT_COLOR * lightDot;\n\n    vec3 ambientTestDir = GetRandomWeightedHemisphereDir( seed, normal );\n    vec3 ambientColor = mix( AMBIENT_LIGHT_FROM_BELOW, AMBIENT_LIGHT_FROM_ABOVE, ambientTestDir.y * 0.5 + 0.5 );\n    vec3 shadowApproxHitPos;\n    if ( MarchShadowRay( pos, ambientTestDir, shadowApproxHitPos CACHE ) )\n        light += MIN_AMBIENT * ambientColor + BLOB_EMISSION_LIGHT * BlobEmissionAmountAtPos( shadowApproxHitPos );\n    else\n        light += ambientColor;\n    \n    light *= GetBrightnessForTime( blobTime );\n    \n    return light;\n}\n\nstruct State\n{\n    vec2 mouse;\n    vec2 camAngles;\n};\n\nvoid GetStateAndSetGlobals( int frame, float time, vec2 resolution, sampler2D stateChannel, sampler2D keyboardChannel, out State state )\n{\n    blobTime = time;\n    lightBrightness = 1.0 - texelFetch( keyboardChannel, ivec2( 76, 2 ), 0 ).x; // 76 == 'L'\n\n    vec4 val = texelFetch( stateChannel, ivec2( 0, 0 ), 0 );\n    state.mouse = val.xy;\n    state.camAngles = val.zw;\n}\n\nstruct CameraInfo\n{\n    vec3 origin;\n    vec3 forward;\n    vec3 right;\n    vec3 up;\n    vec3 bottomLeft;\n};\n\nvoid GetCameraInfo( State state, in vec2 resolution, out CameraInfo cam )\n{\n    float aspectRatio = resolution.x / resolution.y;\n    \n    float camPitch = state.camAngles.y;\n    if ( state.mouse.x == 0.0 )\n    {\n        // no input yet\n        camPitch = max( camPitch - 0.25 * PI * smoothstep( 7.0, 0.0, blobTime ), CAM_PITCH_MIN );\n    }\n    \n    float cosCamOffsetPitch = cos( camPitch );\n    vec3 camOffset = CAMERA_DIST * vec3( cos( state.camAngles.x ) * cosCamOffsetPitch, sin( camPitch ), sin( state.camAngles.x ) * cosCamOffsetPitch );\n    \n    float offsetScale = 1.0;\n    if ( CAMERA_LOOK_AT.y + camOffset.y < CAMERA_CLIP_HEIGHT )\n        offsetScale = (CAMERA_CLIP_HEIGHT - CAMERA_LOOK_AT.y) / camOffset.y;\n    camOffset *= offsetScale;\n\n    cam.origin = CAMERA_LOOK_AT + camOffset;\n    cam.forward = normalize( -camOffset );\n    cam.right = normalize( vec3( -cam.forward.z, 0.0, cam.forward.x ) ); // cross( camForward, (0,1,0) )\n    cam.up = cross( cam.right, cam.forward );\n    \n    cam.forward *= CAMERA_ZOOM * (0.5 + 0.5 * offsetScale);\n    \n    cam.bottomLeft = cam.forward - cam.right * aspectRatio - cam.up;\n    \n    cam.right *= 2.0 * aspectRatio;\n    cam.up *= 2.0;\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// \"Intersection\" buffer.\n\n// This buffer just does the initial intersection with the blob at screen resolution.\n// It shoots multiple rays and stores the two most common ray depths discovered for each pixel\n// so that we can sort of antialias.\n// The result is vec4( most common depth, second most common depth, fraction of samples that were the most common, 0 )\n// This is good because it does work that all the other buffers need,\n// But it's also good because it reduces all future antialiasing to just one or two iterations.\n// It also makes a cool stylized version of the blob (turn on DEBUG_INTERSECTION_BUFFER in Image)!\n\n// Also, the lower left pixel contains camera state.\n\nvoid UpdateState( int frame, float dt, vec4 mouse, vec2 resolution, sampler2D stateChannel, sampler2D keyboardChannel, inout State state )\n{\n    float rotate = texelFetch( keyboardChannel, ivec2( 82, 2 ), 0 ).x; // 82 == 'R'\n\n    if ( frame == 0 )\n        state.camAngles = vec2( 0.39 * PI, 0.0 );\n    \n    if ( mouse.z > 0.0 )\n    {\n        // mouse is down\n        if ( state.mouse.x > 0.0 )\n        {\n            // mouse was and is down\n            vec2 mouseDiff = mouse.xy - state.mouse;\n            mouseDiff.y = -mouseDiff.y;\n            state.camAngles += mouseDiff * 0.02;\n            state.camAngles.y = clamp( state.camAngles.y, CAM_PITCH_MIN, CAM_PITCH_MAX );\n        }\n\t    state.mouse = mouse.xy;\n    }\n    else\n    {\n\t    state.mouse = -mouse.xy;\n    }\n    \n    if ( rotate > 0.0 || mouse.x == 0.0 )\n        state.camAngles.x += dt * 0.07;\n}\n\nvoid mainImage( out vec4 res, in vec2 fragCoord )\n{\n    State state;\n    GetStateAndSetGlobals( iFrame, iTime, iResolution.xy, iChannel0, iChannel3, state );\n    UpdateState( iFrame, iTimeDelta, iMouse, iResolution.xy, iChannel0, iChannel3, state );\n    \n    CameraInfo cam;\n    GetCameraInfo( state, iResolution.xy, cam );\n    \n    // we shoot a bunch of rays and record the depth of each one (how far it goes).\n    float depths[AA_SAMPLE_COUNT];\n\n    for ( int i = 0; i < AA_SAMPLE_COUNT; i++ )\n    {\n        vec2 uv = (fragCoord + AA_SAMPLE_OFFSETS[i]) / iResolution.xy;\n        vec3 dir = normalize( cam.bottomLeft + cam.right * uv.x + cam.up * uv.y );\n\n        float depth;\n        vec3 hitPos;\n    \tif ( MarchCameraRay( cam.origin, dir, hitPos CACHE ) )\n        \tdepth = length( hitPos - cam.origin );\n        else\n            depth = NO_HIT_DEPTH;\n        \n        // insertion sort into depths array\n        int j;\n        for ( j = i; j > 0; j-- )\n        {\n            if ( depths[j - 1] <= depth )\n                break;\n            depths[j] = depths[j - 1];\n        }\n        depths[j] = depth;\n    }\n\n    // group the depths by similarity\n    float groupedDepths[AA_SAMPLE_COUNT];\n    int groupSize[AA_SAMPLE_COUNT];\n    int groupCount = 0;\n    \n    int first = 0;\n    for ( int i = 1; i < AA_SAMPLE_COUNT; i++ )\n    {\n        if ( depths[i] - depths[i - 1] > SIMILAR_DEPTH_THRESHOLD )\n        {\n            // take smallest of the depths so we don't try to sample from within the surface\n            groupedDepths[groupCount] = depths[first];\n            groupSize[groupCount] = i - first;\n            groupCount++;\n            \n            first = i;\n        }\n    }\n\n    groupedDepths[groupCount] = depths[first];\n    groupSize[groupCount] = AA_SAMPLE_COUNT - first;\n    groupCount++;\n    \n    // find the two biggest depth groups (formed by the most samples).\n    int biggestGroupSize = groupSize[0];\n    int secondBiggestGroupSize = 0;\n    \n    res = vec4( groupedDepths[0], groupedDepths[0], 0.0, 0.0 );\n    \n    for ( int i = 1; i < groupCount; i++ )\n    {\n        if ( groupSize[i] > secondBiggestGroupSize )\n        {\n            if ( groupSize[i] > biggestGroupSize )\n            {\n                secondBiggestGroupSize = biggestGroupSize;\n                biggestGroupSize = groupSize[i];\n                res.y = res.x;\n                res.x = groupedDepths[i];\n            }\n            else\n            {\n                secondBiggestGroupSize = groupSize[i];\n                res.y = groupedDepths[i];\n            }\n        }\n    }\n    \n    res.z = float( biggestGroupSize ) / float( biggestGroupSize + secondBiggestGroupSize );\n    \n    if ( fragCoord.y < 1.0 && fragCoord.x < 1.0 )\n\t    res = vec4( state.mouse, state.camAngles );\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// \"Lighting\" buffer.\n\n// This buffer creates two images at low resolution (half the normal display resolution).\n// It is low res for speed because all of this information is supposed to look blurry anyway.\n// The first is the reflection color for the surface of the blob, omitting background from the first reflection,\n// and including the amount of background that should be from the first reflection in w.\n// The second is three lighting components: the fraction of incoming overhead light,\n// the fraction of incoming ambient light, and the fraction of light from the emissive color of the blob.\n// The w component is depth so that the blur pass and main image can avoid blurring this data across edges.\n//\n// All of this data will be blurred in Buffer C before being used by the final image.\n\n\n#define SHADOW_Y_HACK 1\n\n#if REFLECTION_ENABLED || SHADOWS_ENABLED\n\n#if REFLECTION_ENABLED\nvec4 ReflectionInfoForRay( vec3 seed, vec3 start, vec3 firstDir, float depth )\n{\n    vec3 hitPos;\n\n    if ( depth >= NO_HIT_DEPTH )\n        return vec4( 0.0, 0.0, 0.0, BLOB_REFLECT );\n    \n    vec3 firstHitPos = start + firstDir * depth;\n\n    vec3 firstHitNormal = GetNormal( firstHitPos CACHE );\n\n    vec4 reflectionColor = vec4( 0.0 );\n\n    for ( int r = 0; r < BUF_REFLECTION_SAMPLE_COUNT; r++ )\n    {\n        float remainingColorFrac = BLOB_REFLECT;\n\n        vec3 dir = firstDir;\n        hitPos = firstHitPos;\n        vec3 normal = firstHitNormal;\n\n        seed += rand3( seed ) * 100.0;\n\n        // We can't afford to do random sampling here (compile time issue, not runtime issue)\n        // So BUF_REFLECTION_SAMPLE_COUNT is just 1 and we don't randomize the normal (too flickery even with the blur).\n        // We just rely on the buffer blur to make it soft, and it mostly does.\n        dir = reflect( dir, normal ); // RandomizeNormal( normal, seed, BLOB_REFLECT_BLUR ) );\n        start = hitPos;\n\n        if ( !MarchReflectionRay( start, dir, hitPos CACHE ) )\n        {\n            reflectionColor.w += remainingColorFrac;\n            continue;\n        }\n\n        for ( int reflectionIndex = 1; reflectionIndex < MAX_REFLECTIONS; reflectionIndex++ )\n        {\n            normal = GetNormal( hitPos CACHE );\n\n            // average two lighting samples. i'm finding i don't need as many reflection samples if the lighting is less noisy\n            vec3 light = CalcLightingForPointOnBlob( seed, hitPos, normal CACHE );\n            seed += vec3( 13.2, 2.5, 1.0 );\n            light += CalcLightingForPointOnBlob( seed, hitPos, normal CACHE );\n            light *= 0.5;\n\n            reflectionColor.xyz += BlobColorAtPos( hitPos ) * light * remainingColorFrac;\n            reflectionColor.xyz += BlobEmissionAtPos( hitPos ) * remainingColorFrac;\n\n            if ( !MarchReflectionRay( start, dir, hitPos CACHE ) )\n            {\n                vec3 bgColor = GetBackgroundColorForRayGivenLightingData( seed, start, dir, FAKE_BACKGROUND_SHADOW_DATA_FOR_REFLECTIONS * GetBrightnessForTime( blobTime ) CACHE );\n\n                reflectionColor.xyz += bgColor * remainingColorFrac;\n                break;\n            }\n        }\n    }\n\n    return reflectionColor / float( BUF_REFLECTION_SAMPLE_COUNT );\n}\n#endif\n\n#if SHADOWS_ENABLED\nvec4 ShadowInfoForBackground( vec3 seed, vec3 start, vec3 dir CACHEARG )\n{\n    if ( dir.y >= 0.0 )\n        return vec4( 0.0 );\n    \n    // intersect with ground plane\n    float t = (GROUND_PLANE_HEIGHT - start.y) / dir.y;\n    vec3 bgPos = start + dir * t;\n    \n    // I'm having trouble with artifacts near the bottom of the sculpture because the shadow turns dark\n    // very abruptly there and so the low resolution of the shadow buffer becomes obvious.\n    // By artificially lowering the shadow sampling point a tad, the shadow gets softer and the artifacts\n    // are less noticeable.\n    #if SHADOW_Y_HACK\n    bgPos.y -= 0.75;\n    #endif\n    \n    float spotlightBrightness = GetFloorSpotlightBrightness( bgPos );\n    if ( spotlightBrightness == 0.0 )\n        return vec4( 0.0 );\n    \n    vec4 res = vec4( 0.0 );\n    \n    const vec3 DirectLightingSampleScale = vec3( 2.0 * BG_BOX_SCALE.x / float( GROUND_SHADOW_TEST_X_COUNT ), 0.0, 2.0 * BG_BOX_SCALE.z / float( GROUND_SHADOW_TEST_Z_COUNT ) );\n    for ( int z = ZERO_NO_LOOP_UNROLL; z < GROUND_SHADOW_TEST_Z_COUNT; z++ )\n    {\n        for ( int x = ZERO_NO_LOOP_UNROLL; x < GROUND_SHADOW_TEST_X_COUNT; x++ )\n        {\n            vec2 r2 = rand2( seed );\n            seed.xy += r2 * 100.0;\n\n            vec3 ceilingPos = vec3( BG_BOX_CENTER.x - BG_BOX_SCALE.x, CEILING_HEIGHT, BG_BOX_CENTER.z - BG_BOX_SCALE.z );\n            ceilingPos += vec3( float( x ) + r2.x, 0.0, float( z ) + r2.y ) * DirectLightingSampleScale;\n\t\t\tceilingPos.x *= GetBrightnessForTime( blobTime );\n            vec3 lightDir = normalize( ceilingPos - bgPos );\n\n            // have to check bounds because the floor isn't always inside them\n            vec3 boundsStart;\n            vec3 ignoreHitPos;\n            if ( !RayHitsBlobBounds( bgPos, lightDir, boundsStart ) || !MarchShadowRay( boundsStart, lightDir, ignoreHitPos CACHE ) )\n                res.x += 1.0;\n        }\n    }\n    res.x /= float( GROUND_SHADOW_TEST_X_COUNT * GROUND_SHADOW_TEST_Z_COUNT );\n\n    const float RadiusScale = 1.0 / float( BUF_AMBIENT_LIGHTING_SAMPLE_RADIUS_COUNT );\n    const float AngleScale = TWOPI / float( BUF_AMBIENT_LIGHTING_SAMPLE_ANGLE_COUNT );\n    for ( int r = ZERO_NO_LOOP_UNROLL; r < BUF_AMBIENT_LIGHTING_SAMPLE_RADIUS_COUNT; r++ )\n    {\n        for ( int a = ZERO_NO_LOOP_UNROLL; a < BUF_AMBIENT_LIGHTING_SAMPLE_ANGLE_COUNT; a++ )\n        {\n            // get a weighted point on the hemisphere oriented toward normal.\n            // start with random point on unit disc.\n\n            vec2 r2 = rand2( seed );\n            seed.xy += r2 * 100.0;\n\n            float angle = (float( a ) + r2.x) * AngleScale;\n            float radius = sqrt( (float( r ) + r2.y) * RadiusScale );\n\n            vec2 discPoint = vec2( cos( angle ), sin( angle ) ) * radius;\n\n            vec3 ambientTestDir = GetHemisphereDirForDiscPoint( vec3( 0.0, 1.0, 0.0 ), discPoint );\n\n            // have to check bounds because the floor isn't always inside them\n            vec3 boundsStart;\n            vec3 shadowApproxHitPos;\n            if ( RayHitsBlobBounds( bgPos, ambientTestDir, boundsStart ) && MarchShadowRay( boundsStart, ambientTestDir, shadowApproxHitPos CACHE ) )\n                res.z += BlobEmissionAmountAtPos( shadowApproxHitPos );\n            else\n\t            res.y += 1.0;\n        }\n    }\n    res.yz /= float( BUF_AMBIENT_LIGHTING_SAMPLE_RADIUS_COUNT * BUF_AMBIENT_LIGHTING_SAMPLE_ANGLE_COUNT );\n    res.y = MIN_AMBIENT + res.y * (1.0 - MIN_AMBIENT);\n\n    res.xy *= GetBrightnessForTime( blobTime );\n    \n    // we don't include spotlight brightness here because we do include it in GetBackgroundColorForRayGivenLightingData.\n    // we include it there because it's good for reflections, which don't sample from this texture.\n    //res *= spotlightBrightness;\n    \n    return res;\n}\n\nvec4 ShadowInfoForRay( vec3 seed, vec3 start, vec3 dir, float depth )\n{\n    if ( depth >= NO_HIT_DEPTH )\n\t    return ShadowInfoForBackground( seed, start, dir CACHE );\n\n    vec3 hitPos = start + dir * depth;\n    \n    vec4 res = vec4( 0.0 );\n    \n    vec3 normal = GetNormal( hitPos CACHE );\n    \n    const vec3 DirectLightingSampleScale = vec3( 2.0 * BG_BOX_SCALE.x / float( BUF_DIRECT_LIGHTING_SAMPLE_X_COUNT ), 0.0, 2.0 * BG_BOX_SCALE.z / float( BUF_DIRECT_LIGHTING_SAMPLE_Z_COUNT ) );\n    for ( int z = 0; z < BUF_DIRECT_LIGHTING_SAMPLE_Z_COUNT; z++ )\n    {\n        for ( int x = 0; x < BUF_DIRECT_LIGHTING_SAMPLE_X_COUNT; x++ )\n        {\n            vec2 r2 = rand2( seed );\n            seed.xy += r2 * 100.0;\n\n            vec3 ceilingPos = vec3( BG_BOX_CENTER.x - BG_BOX_SCALE.x, CEILING_HEIGHT, BG_BOX_CENTER.z - BG_BOX_SCALE.z );\n            ceilingPos += vec3( float( x ) + r2.x, 0.0, float( z ) + r2.y ) * DirectLightingSampleScale;\n            ceilingPos.x *= GetBrightnessForTime( blobTime );\n            vec3 lightDir = normalize( ceilingPos - hitPos );\n\n            float lightDot = dot( lightDir, normal );\n            vec3 ignoreHitPos;\n            if ( lightDot > 0.0 && !MarchShadowRay( hitPos, lightDir, ignoreHitPos CACHE ) )\n                res.x += 1.0;\n        }\n    }\n    res.x /= float( BUF_DIRECT_LIGHTING_SAMPLE_X_COUNT * BUF_DIRECT_LIGHTING_SAMPLE_Z_COUNT );\n    \n    const float RadiusScale = 1.0 / float( BUF_AMBIENT_LIGHTING_SAMPLE_RADIUS_COUNT );\n    const float AngleScale = TWOPI / float( BUF_AMBIENT_LIGHTING_SAMPLE_ANGLE_COUNT );\n    for ( int r = 0; r < BUF_AMBIENT_LIGHTING_SAMPLE_RADIUS_COUNT; r++ )\n    {\n        for ( int a = 0; a < BUF_AMBIENT_LIGHTING_SAMPLE_ANGLE_COUNT; a++ )\n        {\n            // get a weighted point on the hemisphere oriented toward normal.\n            // start with random point on unit disc.\n\n            vec2 r2 = rand2( seed );\n            seed.xy += r2 * 100.0;\n\n            float angle = (float( a ) + r2.x) * AngleScale;\n            float radius = sqrt( (float( r ) + r2.y) * RadiusScale );\n\n            vec2 discPoint = vec2( cos( angle ), sin( angle ) ) * radius;\n\n            vec3 ambientTestDir = GetHemisphereDirForDiscPoint( normal, discPoint );\n\n            vec3 shadowApproxHitPos;\n            if ( MarchShadowRay( hitPos, ambientTestDir, shadowApproxHitPos CACHE ) )\n                res.z += BlobEmissionAmountAtPos( shadowApproxHitPos );\n            else\n                res.y += 1.0;\n        }\n    }\n    res.yz /= float( BUF_AMBIENT_LIGHTING_SAMPLE_RADIUS_COUNT * BUF_AMBIENT_LIGHTING_SAMPLE_ANGLE_COUNT );\n    res.y = MIN_AMBIENT + res.y * (1.0 - MIN_AMBIENT);\n    \n    res.xy *= GetBrightnessForTime( blobTime );\n    \n    return res;\n}\n#endif\n\n#endif\n\nvoid mainImage( out vec4 res, in vec2 fragCoord )\n{\n    vec2 BUFFER_SIZE = min( PREFERRED_BUFFER_SIZE, iResolution.xy / 2.0 );\n    \n    if ( any( greaterThan( fragCoord, BUFFER_SIZE * vec2( 2.0, 1.0 ) ) ) )\n    {\n        res = vec4( fragCoord / iResolution.xy, 0.5, 1.0 );\n        return;\n    }\n    \n    State state;\n    GetStateAndSetGlobals( iFrame, iTime, iResolution.xy, iChannel0, iChannel3, state );\n    \n    CameraInfo cam;\n    GetCameraInfo( state, iResolution.xy, cam );\n\n\n    res = vec4( 0.0 );\n    \n    if ( fragCoord.x < BUFFER_SIZE.x )\n    {\n\t\t#if REFLECTION_ENABLED\n        vec2 uv = fragCoord / BUFFER_SIZE;\n        vec4 intersectionData = texture( iChannel0, (floor( uv * iResolution.xy ) + vec2( 0.5 ))/ iResolution.xy );\n\n        vec3 dir = normalize( cam.bottomLeft + cam.right * uv.x + cam.up * uv.y );\n\n        vec3 randomSeed = vec3( uv, blobTime + 56.0 );\n\n        res = ReflectionInfoForRay( randomSeed, cam.origin, dir, intersectionData.x );\n        //if ( BlobDist( camOrigin + dir * intersectionData.x ) < 0.0 )\n        //    res = vec4( 1.0, 0.0, 0.0, 0.0 );\n\n        #else\n        \n        // reflections disabled\n        res = vec4( 0.0 );\n        \n        #endif\n    }\n    else\n    {\n        fragCoord.x -= BUFFER_SIZE.x;\n        \n        vec2 uv = fragCoord / BUFFER_SIZE;\n        vec4 intersectionData = texture( iChannel0, (floor( uv * iResolution.xy ) + vec2( 0.5 ))/ iResolution.xy );\n\n        #if SHADOWS_ENABLED\n\n        vec3 dir = normalize( cam.bottomLeft + cam.right * uv.x + cam.up * uv.y );\n\n        vec3 randomSeed = vec3( uv, blobTime + 82.0 );\n\n        res = ShadowInfoForRay( randomSeed, cam.origin, dir, intersectionData.x );\n        res.w = intersectionData.x;\n        \n        /*vec3 ourNormal = GetNormal( cam.origin + dir * intersectionData.x );\n        vec3 hitPos;\n    \tMarchCameraRay( camOrigin, dir, hitPos CACHE );\n        vec3 realNormal = GetNormal( hitPos );\n        res = vec4( realNormal - ourNormal, 0.0 );*/\n        \n        \n        #else\n        \n        // shadows disabled\n        res = vec4( 1.0 );\n        res.w = intersectionData.x;\n        \n        #endif   \n    }\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// \"Smoothed lighting\" buffer.\n\n// This buffer takes buffer B's data and blurs it by one pixel,\n// using depth information to avoid blurring across edges.\n\nvec2 BUFFER_SIZE;\n\nconst int BlurSampleCount = 21;\nconst vec3 BlurOffsetsAndWeights[BlurSampleCount] = vec3[BlurSampleCount]\n(\n    vec3(  0.0,  0.0, 1.0 ),\n    vec3( -1.0,  0.0, 0.9 ),\n    vec3(  1.0,  0.0, 0.9 ),\n    vec3(  0.0, -1.0, 0.9 ),\n    vec3(  0.0,  1.0, 0.9 ),\n    vec3( -1.0,  1.0, 0.7 ),\n    vec3(  1.0,  1.0, 0.7 ),\n    vec3(  1.0, -1.0, 0.7 ),\n    vec3( -1.0, -1.0, 0.7 ),\n    \n    vec3( -2.0, -1.0, 0.3 ),\n    vec3( -2.0,  0.0, 0.5 ),\n    vec3( -2.0,  1.0, 0.3 ),\n    vec3(  2.0, -1.0, 0.3 ),\n    vec3(  2.0,  0.0, 0.5 ),\n    vec3(  2.0,  1.0, 0.3 ),\n    vec3( -1.0, -2.0, 0.3 ),\n    vec3(  0.0, -2.0, 0.5 ),\n    vec3(  1.0, -2.0, 0.3 ),\n    vec3( -1.0,  2.0, 0.3 ),\n    vec3(  0.0,  2.0, 0.5 ),\n    vec3(  1.0,  2.0, 0.3 )\n);\n\nvoid GetBlurSamples( vec2 uv, out vec4[BlurSampleCount] samples )\n{\n    for ( int i = 0; i < BlurSampleCount; i++ )\n        samples[i] = textureLod( iChannel0, uv + BlurOffsetsAndWeights[i].xy / iResolution.xy, 0.0 );\n}\n\nvec4 DoBlur( vec4[BlurSampleCount] samples, vec4[BlurSampleCount] depthSamples )\n{\n    vec4 res = samples[0];\n    float totalWeight = 1.0;\n    float baseDepth = depthSamples[0].w;\n    for ( int i = 1; i < BlurSampleCount; i++ )\n    {\n        float weight = BlurOffsetsAndWeights[i].z * WeightForDepthDiff( depthSamples[i].w, baseDepth );\n        res += samples[i] * weight;\n        totalWeight += weight;\n    }\n    return res / totalWeight;\n}\n\nvoid mainImage( out vec4 res, in vec2 fragCoord )\n{\n    BUFFER_SIZE = min( PREFERRED_BUFFER_SIZE, iResolution.xy / 2.0 );\n    \n    if ( any( greaterThan( fragCoord, BUFFER_SIZE * vec2( 2.0, 1.0 ) ) ) )\n    {\n        res = vec4( fragCoord / iResolution.xy, 0.5, 1.0 );\n        return;\n    }\n    \n    vec2 uv = fragCoord / iResolution.xy;\n    \n    if ( fragCoord.x < BUFFER_SIZE.x )\n    {\n        vec4 blurSamples[BlurSampleCount];\n        vec4 depthSamples[BlurSampleCount]; // have to get depth from the shadow part of the buffer\n        GetBlurSamples( uv, blurSamples );\n        GetBlurSamples( uv + vec2( BUFFER_SIZE.x / iResolution.x, 0.0 ), depthSamples );\n        \n        res = DoBlur( blurSamples, depthSamples );\n    }\n    else\n    {\n        vec4 blurSamples[BlurSampleCount];\n        GetBlurSamples( uv, blurSamples );\n        \n        res = DoBlur( blurSamples, blurSamples );\n    }\n}\n","name":"Buffer C","description":"","type":"buffer"}]}
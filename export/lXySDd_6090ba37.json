{"ver":"0.1","info":{"id":"lXySDd","date":"1721854819","viewed":59,"name":"â–“ CRT Screen with Bloom â–“","username":"___lampada","description":"A CRT Screen filter. It first turns the input image into a CRT image and then blurs it.","likes":3,"published":1,"flags":32,"usePreview":0,"tags":["crt","pixelized","tvscreen"],"hasliked":0,"parentid":"MXySDK","parentname":"ğ™°ğš‚ğ™²ğ™¸ğ™¸ ğ™µğš’ğš•ğšğšğš› ğ™¾_ğš˜"},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*CRT SCREEN VISUALIZAER\nThis shader implements a CRT screen visualizer. It involves a two step renderization:\n1. Buffer A: The orinal effect is created with chroma shift, channel segmentation, \nnoising and renderization band addition.\n2. Image: A final blooming effect is added*/\n\nfloat sigma_from_window(float window_size, float sig_depth){\n    //1.0*sigma ~ 68%\n    //2.0*sigma ~ 95%\n    //3.0*sigma ~ 99%\n    \n    sig_depth = sig_depth*3.0;\n    return window_size/(2.0*sig_depth);\n}\n\nfloat gaussian(vec2 coord, vec2 center, float sigma){\n    /*Returns the gaussian function value in a given position.\n    \n    Parameters\n    ----------\n    \n    coord : vec2\n        Fragment coordinates.\n    center : vec2 \n        Gaussian center.\n    sigma : float\n        The standard deviation of the gaussian.*/\n    vec2 xy = coord - center;\n    float gamma = iResolution.y/iResolution.x;\n    \n    float g = exp(-0.5*(xy.x*xy.x + gamma*gamma*xy.y*xy.y)/(sigma*sigma));\n    \n    return g;\n}\n\n\nvec3 convolve_gaussian(vec2 uv, sampler2D sampler, float window_size){\n    /*Convolves a gaussian with a given fragment given a window size.\n    \n    Parameters\n    ----------\n    \n    uv : vec2\n        Texture coordinates.\n    sampler : sampler2D\n        Texture sampler.\n    window_size : float\n        Window size, in pixels.*/\n\n    float win_r = floor(window_size/2.0);\n    \n    float stepx = 1.0/iResolution.x;\n    float stepy = 1.0/iResolution.y;\n    vec2 gamma = vec2(1.0, iResolution.y/iResolution.x);\n    \n    float sigma = sigma_from_window(window_size*stepx, 1.0);\n    vec3 color = vec3(0.0);vec2 offset = vec2(0.0);\n    for(float i = 0.0; i < window_size*window_size; i++){\n        offset = vec2( (mod(i, window_size) - win_r)*stepx, (floor(i/window_size) - win_r)*stepy );\n        vec3 tex = texture(sampler, uv + offset).rgb;\n        color += gaussian(uv + offset, uv, sigma)*tex;\n    }\n   \n    return color;\n}\n   \n   \nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n   \n       vec2 uv = fragCoord.xy/iResolution.xy;\n       \n       // bloom\n       vec3 result = convolve_gaussian(uv, iChannel0, 7.0);\n       \n       fragColor = vec4(result, 1.0);\n       \n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"Xdf3Rn","filepath":"/media/a/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","previewfilepath":"/media/ap/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","type":"video","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGzn","filepath":"/media/a/0c7bf5fe9462d5bffbd11126e82908e39be3ce56220d900f633d58fb432e56f5.png","previewfilepath":"/media/ap/0c7bf5fe9462d5bffbd11126e82908e39be3ce56220d900f633d58fb432e56f5.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"/*CRT conversion step\n\nThis step converts a given image into a CRT screen visualizer. The substeps to it are:\n1. Image downsample\n2. Chroma shift.\n3. Channel segmentation.\n4. Noise addition.\n5. Renderization band along with noise addition.\n\n*/\n\n#define CHAR_SIZE 3.0\n#define SPACING 1.0\n#define PI 3.14159265358979\n\nfloat grayscale(vec3 p){\n    /*Convertes a given pixel to grayscale.\n    Parameters\n    ----------\n    \n    p : vec3\n        rgb pixel.\n    */\n    return 0.299*p.r + 0.587*p.g + 0.114*p.b;\n}\n\nvec2 downsampled_uv(vec2 coord, float d){\n    /*Maps the current position to a downsampled position\n    \n    Parameters\n    ----------\n    \n    coord : vec2\n        Current pixel position.\n    d : float\n        downsample proportion (image will be d times smaller)\n    */\n\n    // Below line maps the current position to a downsampled uv\n    // mod(fragCoord.x, d) is the distance from the current position from the target\n    // position, so it is just subtracted.\n    return vec2( coord.x - mod(coord.x, d), coord.y - mod(coord.y, d) ) / iResolution.xy; \n}\n\nfloat color_channel(float color, vec2 p){\n    /*Returns if current pixel corresponds to character bounds\n    \n    Parameters\n    ----------\n    \n    color : float\n        color channel. accepted values are 0.0 (red), 1.0 (green) or 2.0 (blue)\n    p : vec2\n        fragment position.\n    */\n    float char_s = CHAR_SIZE*3.0;\n    p += 0.5;\n    \n    \n    float stripe = 0.0 + 1.0*float(sin( PI/(char_s + 2.0*SPACING)*p.x) > 0.0);\n    \n    \n    vec2 local_p = vec2( mod(p.x, char_s + 2.0*SPACING), // ALWAYS sum +0.5\n                         mod(p.y + char_s/2.0*float(stripe == 0.0), char_s + 2.0*SPACING));// ALWAYS sum +0.5\n                         \n\n    //Checks if pixel position is beyond character limits, if yes then returns 0.0\n    if(local_p.x < SPACING || local_p.x > char_s + (SPACING - 1.0)) \n        return 0.0;\n    if(local_p.y < SPACING || local_p.y > char_s + (SPACING - 1.0))\n        return 0.0;\n\n    //Starts at bottom-left position\n    vec2 real_p = vec2(0.0);\n    real_p += local_p - SPACING;\n\n    //checks if pixel is inside the area of the chosen color channel\n    if(real_p.x >= (color)*(char_s/3.0) && \n       real_p.x <  (color + 1.0)*(char_s/3.0)   )\n       return 1.0;\n    else return 0.0;\n\n\n}\n\nvec3 contrast(vec3 color, float x0, float intensity, float k){\n    /*Applies a contrast to a given pixel. The contrast is applied \n    using a logistic function.\n    \n    Parameters\n    ----------\n    \n    color : vec3\n        Fragment color.\n    x0 : float\n        Center of the logistic function.\n    intensity : float\n        Max value of the function.\n    k : float\n        Inclination of the function.\n    */\n    float gray = grayscale(color);\n    float f = intensity/(1.0 + exp(-1.0*k*(gray - x0)));\n\n    return f*color;\n}\n\nfloat window_f(vec2 coord, vec2 center, float window_size){\n    /*Returns a horizontal white band.\n    \n    Parameters\n    ----------\n    \n    coord : vec2\n        Fragment coordinates.\n    center : vec2\n        Center of the band.\n    window_size : float\n        Total vertical size of the window.\n    */\n\n    vec2 xy = coord - center;\n    float gamma = iResolution.y/iResolution.x;\n    \n    return 0.0 + 1.0*float(gamma*xy.y > -window_size/2.0 && \n                           gamma*xy.y <= window_size/2.0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    //downsamples the image\n    vec2 uv = downsampled_uv(fragCoord.xy, CHAR_SIZE*3.0 + 2.0*SPACING);\n    \n    //chroma shift\n    float stepx = 1.0/iResolution.x;\n    float pix_shift = 2.0;\n    vec3 tex;\n    tex.r = texture(iChannel0, uv + vec2(pix_shift*stepx, 0.0)).r;\n    tex.g = texture(iChannel0, uv + vec2(pix_shift*(-stepx), 0.0)).g;\n    tex.b = texture(iChannel0, uv).b;\n    \n    //channel segmentation\n    vec3 color = vec3(tex.r*color_channel(0.0, fragCoord.xy),\n                      tex.g*color_channel(1.0, fragCoord.xy),\n                      tex.b*color_channel(2.0, fragCoord.xy));\n\n    //noise\n    float noise = texture(iChannel1, uv).r;\n    float noise_speed = 5.0;\n    \n    //bands\n    float band_speed = 0.3;\n    float band_size = 20.0;\n    float band = window_f(uv, vec2(mod(-band_speed*iTime, 1.0)), band_size/iResolution.y);\n    band += window_f(uv, vec2(mod(-band_speed*iTime - 0.3, 1.0)), band_size/iResolution.y);\n  \n    //final output\n    float final_noise = mod(noise_speed*(iTime + uv.x), noise);\n    fragColor = vec4(contrast(color + 0.0*float(color != vec3(0.0, 0.0, 0.0)) + \n                                      0.05*final_noise + \n                                      0.1*final_noise*band*float(color != vec3(0.0, 0.0, 0.0)), 0.5, 1.0, 2.0), 1.0);\n\n}","name":"Buffer A","description":"","type":"buffer"}]}
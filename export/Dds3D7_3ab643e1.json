{"ver":"0.1","info":{"id":"Dds3D7","date":"1666277129","viewed":178,"name":"Strong noise removing.","username":"ivangor1997","description":"Removing strong noise using blur, sharpening, median, Kuwahara and temporal filters.\nThe temporal filter is very FPS dependent.\nIt needs a pretty powerful GPU.","likes":3,"published":1,"flags":32,"usePreview":0,"tags":["kuwahara","medianfilter","denoising","temporaldenoising"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XdfGRr","filepath":"/media/a/35c87bcb8d7af24c54d41122dadb619dd920646a0bd0e477e7bdc6d12876df17.webm","previewfilepath":"/media/ap/35c87bcb8d7af24c54d41122dadb619dd920646a0bd0e477e7bdc6d12876df17.webm","type":"video","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n * De-noise filter for dynamic noise.\n * \n * Takes 3 passes:\n *   1. circular blur (with optional \"sharpening\")\n *   2. Kuwahara + median filters:\n *       Averaging the results of these filters, suddenly,\n *       gives a better result than applying each of them individually!\n *       It was a very random idea, and it works!\n *   3. Motion detection and temporal filter:\n *       The averaging of the Kuwahara filter and the median filter\n *       would hardly give such a result without the temporal filter.\n *  Bottom left corner is the original video.\n *  Top right - noised original\n *  Top left - spatial filters\n *  Bottom right - final result after spatial and temporal filters\n *  All settings in \"Common\" file\n */\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    ivec2 uv = ivec2(fragCoord*iChannelResolution[2].xy / vec2(iResolution.xy));\n    vec2 edges = vec2(iResolution.x / 3.0, iResolution.y / 2.0);\n    if (iMouse.z > 0.5) {\n        edges = vec2(iMouse.xy);\n    }\n    if (fragCoord.y < edges.y) {\n        if (fragCoord.x < edges.x) {\n            fragColor.rgb = texelFetch(iChannel2, uv, 0).rgb;\n            //fragColor.rgb = blur(iChannel2, uv, 1);\n        } else {\n            vec3 big_kernel = new_blur(iChannel3, ivec2(fragCoord) , 6);\n            vec3 small_kernel = new_blur(iChannel3, ivec2(fragCoord) , 5);\n            fragColor.rgb = texelFetch(iChannel3, ivec2(fragCoord), 0).rgb;\n            fragColor.rgb = fragColor.rgb + (small_kernel - big_kernel) * 0.0;\n            fragColor.rgb = (fragColor.rgb - 0.5) * CONTRAST + 0.5;\n        }\n    } else {\n        if (fragCoord.x > edges.x) {\n            fragColor.rgb = texelFetch(iChannel0, ivec2(fragCoord), 0).rgb;\n        } else {\n            fragColor.rgb = texelFetch(iChannel1, ivec2(fragCoord), 0).rgb;\n        }\n    }\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"#define PRESET_BALANCED\n//#define PRESET_LITE 4.0\n#define USE_DIRECTIONAL_KUWAHARA\n\n// For a weak noise\n#ifdef PRESET_LITE\n    #define NOISE_MULTIPLIER 0.2\n    #define BLUR_RADIUS 1\n    #define USE_MEDIAN\n    #define MEADIAN_FILTER_RADIUS 4\n    #define USE_KUWAHARA\n    #define KUWAHARA_RADIUS 1\n    // Mix resilts of buffer B and C\n    #define MIX_B_C 0.5\n    // The lower the value, the less blur, but more noise. The higher the value, the more blur, but less noise.\n    #define SENSITIVITY 40.0\n    #define SEARCH_RADIUS 16\n    #define SEARCH_KERNEL 3\n    #define CONTRAST 1.0\n#endif\n\n// Basig settings\n#ifdef PRESET_BALANCED\n    #define NOISE_MULTIPLIER 0.4\n    #define BLUR_RADIUS 1\n    #define USE_MEDIAN\n    #define MEADIAN_FILTER_RADIUS 4\n    #define USE_KUWAHARA\n    #define KUWAHARA_RADIUS 4\n    #define MIX_B_C 0.5\n    \n    #define SENSITIVITY 30.0\n    #define SEARCH_RADIUS 16\n    #define SEARCH_KERNEL 3\n    #define CONTRAST 1.0\n#endif\n\n#ifdef PRESET_HIGH\n    #define NOISE_MULTIPLIER 1.0\n    #define BLUR_RADIUS 3\n    #define USE_MEDIAN\n    #define MEADIAN_FILTER_RADIUS 4\n    #define USE_KUWAHARA\n    #define KUWAHARA_RADIUS 8\n    #define MIX_B_C 0.4\n    \n    #define SENSITIVITY 12.0\n    #define SEARCH_RADIUS 16\n    #define SEARCH_KERNEL 3\n    #define BRIGHTNESS 0.5\n    #define CONTRAST 1.0\n#endif\n\n#ifdef PRESET_ULTRA\n    #define NOISE_MULTIPLIER 3.0\n    #define BLUR_RADIUS 8\n    #define USE_MEDIAN\n    #define MEADIAN_FILTER_RADIUS 10\n    #define USE_KUWAHARA\n    #define KUWAHARA_RADIUS 12\n    #define SENSITIVITY 2.0\n    #define MIX_B_C 0.2\n    #define SEARCH_RADIUS 16\n    #define SEARCH_KERNEL 3\n    #define CONTRAST 1.0\n#endif\n\n// Motion detection parameters\n//#define SEARCH_RADIUS 8\n//#define SEARCH_KERNEL 5\n\n// Value of additional contribution to the pixel difference when searching for a vector.\n#define COLOR_IMPORTANCE 0.0\n\n#define DETECT_MOTION_SNAKE_STEP 5\n#define COMPARE_SNAKE_STEP 1\n\nfloat pix_diff(vec3 a, vec3 b)\n{\n    vec3 lum_a = vec3(dot(a, vec3(1.0/3.0)));\n    vec3 lum_b = vec3(dot(b, vec3(1.0/3.0)));\n    a = mix(a, a/lum_a, COLOR_IMPORTANCE);\n    b = mix(b, b/lum_b, COLOR_IMPORTANCE);\n    return dot(pow(a - b, vec3(2.0)), vec3(1.0/3.0));\n}\n\nfloat compare_squares(sampler2D prev, ivec2 crd1, sampler2D curr, ivec2 crd2, int radius, float if_less)\n{\n    float result = 0.0;\n    int n = 0;\n    int square = radius*2+1;\n    square *= square;\n    int x=0,y=0;\n    int dx=0,dy=-COMPARE_SNAKE_STEP;\n    int check_counter = 0;\n    for (n = 0; n < square; n++) {\n        if ((-radius < x && x <= radius) && (-radius < y && y <= radius))\n        {\n            ivec2 offset = ivec2(x, y);\n            vec3 a = texelFetch(prev, crd1+offset, 0).rgb;\n            vec3 b = texelFetch(curr, crd2+offset, 0).rgb;\n            float l = pix_diff(a, b);\n            result += l;\n            check_counter += 1;\n            if (check_counter >= 10) {\n                if (result / float(n - 1) > if_less) {\n                    return if_less;\n                }\n                check_counter = 0;\n            }\n        }\n        if (x == y || (x < 0 && x == -y) || (x > 0 && x == 1-y)) {\n            int swap = dx;\n            dx = -dy;\n            dy =  swap;\n        } else {\n            x += dx;\n            y += dy;\n        }\n    }\n    return result / float(n - 1);\n}\n\n\n// Original from https://www.shadertoy.com/view/lls3WM\nvoid kuwahara( out vec4 fragColor, in vec2 fragCoord, sampler2D iChannel0, vec3 iResolution ) {\n    vec2 iChannel0_size = iResolution.xy;\n    vec2 uv = fragCoord.xy / iChannel0_size;\n    const int radius = KUWAHARA_RADIUS;\n    float n = float((radius + 1) * (radius + 1));\n\n    vec3 m[4];\n    vec3 s[4];\n    for (int k = 0; k < 4; ++k) {\n        m[k] = vec3(0.0);\n        s[k] = vec3(0.0);\n    }\n\n    for (int j = -radius; j <= 0; ++j)  {\n        for (int i = -radius; i <= 0; ++i)  {\n            vec3 c = texture(iChannel0, uv + vec2(i,j) / iChannel0_size).rgb;\n            m[0] += c;\n            s[0] += c * c;\n        }\n    }\n\n    for (int j = -radius; j <= 0; ++j)  {\n        for (int i = 0; i <= radius; ++i)  {\n            vec3 c = texture(iChannel0, uv + vec2(i,j) / iChannel0_size).rgb;\n            m[1] += c;\n            s[1] += c * c;\n        }\n    }\n\n    for (int j = 0; j <= radius; ++j)  {\n        for (int i = 0; i <= radius; ++i)  {\n            vec3 c = texture(iChannel0, uv + vec2(i,j) / iChannel0_size).rgb;\n            m[2] += c;\n            s[2] += c * c;\n        }\n    }\n\n    for (int j = 0; j <= radius; ++j)  {\n        for (int i = -radius; i <= 0; ++i)  {\n            vec3 c = texture(iChannel0, uv + vec2(i,j) / iChannel0_size).rgb;\n            m[3] += c;\n            s[3] += c * c;\n        }\n    }\n\n\n    float min_sigma2 = 1e+2;\n    for (int k = 0; k < 4; ++k) {\n        m[k] /= n;\n        s[k] = abs(s[k] / n - m[k] * m[k]);\n\n        float sigma2 = s[k].r + s[k].g + s[k].b;\n        if (sigma2 < min_sigma2) {\n            min_sigma2 = sigma2;\n            fragColor = vec4(m[k], 1.0);\n        }\n    }\n}\n\n\n// Original from https://www.shadertoy.com/view/DslGzj\nvoid directional_kuwahara( out vec4 fragColor, in vec2 fragCoord, sampler2D iChannel0, vec3 iResolution ) {\n    // sobel operator\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    float kernelx[9] = float[9](-1.0f, -2.0f, -1.0f, 0.0f, 0.0f, 0.0f, 1.0f, 2.0f, 1.0f);\n    float kernely[9] = float[9](-1.0f, 0.0f, 1.0f, -2.0f, 0.0f, 2.0f, -1.0f, 0.0f, 1.0f);\n    \n    int i = 0;\n    \n    vec2 texelSize = 1.0f / iResolution.xy;\n\n    float Gx = 0.0f;\n    float Gy = 0.0f;\n\n    for (int x = -1; x <= 1; x++)\n    {\n        for (int y = -1; y <= 1; y++)\n        {\n            if (i == 4)\n            {\n                i++;\n                continue;\n            }\n            \n            vec2 offset = vec2(x, y) * texelSize;\n            vec3 c = texture(iChannel0, uv + offset).xyz;\n            \n            // relative luminance\n            float l = dot(c, vec3(0.2125f, 0.7152f, 0.0722f));\n            \n            Gx += l * kernelx[i];\n            Gy += l * kernely[i];\n            \n            i++;\n        }\n    }\n    \n    float angle = 0.0f;\n    if (abs(Gx) > 0.001f)\n    {\n        angle = atan(Gy / Gx); \n    }\n    \n    float s = sin(angle);\n    float c = cos(angle);\n    \n    // kuwahara\n    vec3 mean[4] = vec3[4](\n        vec3(0.0f, 0.0f, 0.0f),\n        vec3(0.0f, 0.0f, 0.0f),\n        vec3(0.0f, 0.0f, 0.0f),\n        vec3(0.0f, 0.0f, 0.0f)\n    );\n    \n\n    vec3 sigma[4] = vec3[4](\n        vec3(0.0f, 0.0f, 0.0f),\n        vec3(0.0f, 0.0f, 0.0f),\n        vec3(0.0f, 0.0f, 0.0f),\n        vec3(0.0f, 0.0f, 0.0f)\n    );\n    \n    int radius = KUWAHARA_RADIUS;\n    \n    vec2 offsets[4] = vec2[4](\n        vec2(-radius, -radius),\n        vec2(-radius, 0),\n        vec2(0, -radius),\n        vec2(0, 0)\n    );\n    \n    // for every region\n    for(int i = 0; i < 4; ++i)\n    {\n        // sample x axis\n        for (int j = 0; j <= radius; ++j)\n        {\n            // sample y axis\n            for (int k = 0; k <= radius; ++k)\n            {\n                vec2 pos = vec2(j, k) + offsets[i];\n                //vec2 uvpos = uv + pos/iResolution.xy;\n                vec2 offs = pos * texelSize; \n                offs = vec2(offs.x * c - offs.y * s, offs.x * s + offs.y * c);\n                vec2 uvpos = uv + offs;\n            \n                vec4 col = texture(iChannel0, uvpos);\n                \n                mean[i] += col.xyz;\n                sigma[i] += col.xyz * col.xyz; \n            }\n        }\n    \n    }\n    \n    float n = pow(float(radius + 1), 2.0f);\n\n    // calculate standard deviation\n    float sigma_f;\n    float min = 1.0;\n    for(int i = 0; i < 4; ++i)\n    {\n        mean[i] /= n;\n        sigma[i] = abs(sigma[i] / n - mean[i] * mean[i]);\n        sigma_f = sigma[i].b + sigma[i].y + sigma[i].z;\n        if(sigma_f < min)\n        {\n            min = sigma_f;\n            fragColor = vec4(mean[i], 1.0f);\n        }\n    }\n}\n\n\n// from https://www.shadertoy.com/view/WdX3Wj\n// Replaced readInput with texelFetch\n\n//#define ADAPTIVE_QUANTIZATION\n//#define BIN_COUNT 4\n//#define BIN_COUNT 8\n#define BIN_COUNT 12\n//#define BIN_COUNT 24\n//#define BIN_COUNT 48\n\n//\n\n#if BIN_COUNT == 4\n\t#define UNROLL(X) X(0)X(1)X(2)X(3)\n\n#elif BIN_COUNT == 8\n\t#define UNROLL(X) X(0)X(1)X(2)X(3)X(4)X(5)X(6)X(7)\n\n#elif BIN_COUNT == 12\n\t#define UNROLL(X) X(0)X(1)X(2)X(3)X(4)X(5)X(6)X(7)X(8)X(9)X(10)X(11)\n\n#elif BIN_COUNT == 24\n\t#define U00_11(X) X(0)X(1)X(2)X(3)X(4)X(5)X(6)X(7)X(8)X(9)X(10)X(11)\n\t#define U12_23(X) X(12)X(13)X(14)X(15)X(16)X(17)X(18)X(19)X(20)X(21)X(22)X(23)\n\t#define UNROLL(X) U00_11(X)U12_23(X)\n            \n#elif BIN_COUNT == 48\n\t#define U00_11(X) X(0)X(1)X(2)X(3)X(4)X(5)X(6)X(7)X(8)X(9)X(10)X(11)\n\t#define U12_23(X) X(12)X(13)X(14)X(15)X(16)X(17)X(18)X(19)X(20)X(21)X(22)X(23)\n\t#define U24_35(X) X(24)X(25)X(26)X(27)X(28)X(29)X(30)X(31)X(32)X(33)X(34)X(35)\n\t#define U36_47(X) X(36)X(37)X(38)X(39)X(40)X(41)X(42)X(43)X(44)X(45)X(46)X(47)\n\t#define UNROLL(X) U00_11(X)U12_23(X)U24_35(X)U36_47(X)\n            \n#endif\n\nvec3 readInput(sampler2D iChannel0, ivec2 uv, int dx, int dy)\n{\n    return texelFetch(iChannel0, uv + ivec2(dx, dy), 0).xyz;\n}\n\n\nvoid fastMedian( out vec4 fragColor, in vec2 fragCoord, sampler2D iChannel0, vec3 iResolution )\n{\n    fragColor = texelFetch(iChannel0, ivec2(fragCoord), 0);\n#ifndef MEADIAN_FILTER_RADIUS\n    return;\n#else\n    // Fit image to touch screen from outside\n    /*vec2 img_res = iChannelResolution[0].xy;\n    vec2 res = iResolution.xy / img_res;\n    vec2 img_size = img_res * max(res.x, res.y);\n    vec2 img_org = 0.5 * (iResolution.xy - img_size);*/\n    ivec2 uv = ivec2(fragCoord);\n\n    vec3 ocol = readInput(iChannel0, uv, 0, 0);\n    vec3 col = ocol;\n    \n    const int r = MEADIAN_FILTER_RADIUS;\n    \n\tvec4 bins[BIN_COUNT];\n\t#define INIT(n) bins[n] = vec4(0);\n    UNROLL(INIT)\n\n#ifdef ADAPTIVE_QUANTIZATION        \n\tfloat vmin = 1.0;\n\tfloat vmax = 0.0;\n\n\tfor (int y = -r; y <= r; y++)\n\tfor (int x = -r; x <= r; x++)\n\t{\n        vec3 img = readInput(iChannel0, uv, x, y);\n\t\tfloat v = (img.r + img.g + img.b) / 3.0;\n\n\t\tvmin = min(vmin, v);\n\t\tvmax = max(vmax, v);\n\t}\n    \n#else\n   \tfloat vmin = 0.0;\n\tfloat vmax = 1.0;\n    \n#endif\n\n\tfor (int y = -r; y <= r; y++)\n\tfor (int x = -r; x <= r; x++)\n\t{\n        vec3 img = readInput(iChannel0, uv, x, y);\n\t\tfloat v = (img.r + img.g + img.b) / 3.0;\n\n\t\tint i = int(0.5 + ((v - vmin) / (vmax - vmin)) * float(BIN_COUNT));\n\n\t\t#define UPDATE(n) if (i == n) bins[n] += vec4(img.rgb, 1.0);\n        UNROLL(UPDATE)\n\t}\n    \n\tfloat mid = floor((float(r * 2 + 1) * float(r * 2 + 1)) / 2.0);\n\tfloat pos = 0.0;\n\n    #define M1(i) col.rgb = pos <= mid && bins[i].a > 0.0 ?\n    #define M2(i) bins[i].rgb / bins[i].aaa : col.rgb;\n    #define M3(i) pos += bins[i].a;\n    #define MEDIAN(i) M1(i)M2(i)M3(i)\n    UNROLL(MEDIAN)\n\n    fragColor = vec4(col, 1.0);\n#endif\n}\n\nvec3 new_blur(sampler2D img, ivec2 crd, int radius)\n{\n    vec3 col = vec3(0.0);\n    float att = 0.0;\n    for (int i=-radius; i<=radius; i++)\n    for (int j=-radius; j<=radius; j++) {\n        float d = sqrt(float(i*i + j*j));\n        float w = 1.0 - clamp(d / float(radius), 0.0, 1.0);\n        w *= w;\n        col += texelFetch(img, crd + ivec2(i, j), 0).rgb * w;\n        att += w;\n    }\n    \n    return col / att;\n}\n\nvec3 blur(sampler2D img, ivec2 crd, int radius)\n{\n    vec3 col = vec3(0.0);\n    float att = 0.0;\n    for (int i=-radius; i<=radius; i++)\n    for (int j=-radius; j<=radius; j++) {\n        float w = float(radius) * inversesqrt(float(i*i + j*j)+1.0);\n        w = 1.0 / clamp(1.0/w, 0.0, 1.0);\n        w *= w;\n        col += texelFetch(img, crd + ivec2(i, j), 0).rgb * w;\n        att += w;\n    }\n    \n    return col / att;\n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGzn","filepath":"/media/a/0c7bf5fe9462d5bffbd11126e82908e39be3ce56220d900f633d58fb432e56f5.png","previewfilepath":"/media/ap/0c7bf5fe9462d5bffbd11126e82908e39be3ce56220d900f633d58fb432e56f5.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGRr","filepath":"/media/a/35c87bcb8d7af24c54d41122dadb619dd920646a0bd0e477e7bdc6d12876df17.webm","previewfilepath":"/media/ap/35c87bcb8d7af24c54d41122dadb619dd920646a0bd0e477e7bdc6d12876df17.webm","type":"video","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"float hash1(inout float seed) {\n    return fract(sin(seed += 0.1)*43758.5453123);\n}\n\nvec2 hash2(inout float seed) {\n    return fract(sin(vec2(seed+=0.1,seed+=0.1))*vec2(43758.5453123,22578.1459123));\n}\n\nvec3 hash3(inout float seed) {\n    return fract(sin(vec3(seed+=0.1,seed+=0.1,seed+=0.1))*vec3(43758.5453123,22578.1459123,19642.3490423));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    float seed = fract(1.12345314312*iTime);\n    vec2 disp = hash2(seed);\n    float noise = hash1(seed);\n    noise = texelFetch(iChannel1, ivec2(mod(fragCoord + disp*500.0, vec2(textureSize(iChannel1, 0).xy))), 0).r;\n    // Coordinates for channel, in texel space.\n    vec2 uv = vec2(fragCoord / vec2(iResolution.xy));\n    vec3 col = texture(iChannel0, uv).rgb;\n    //col *= mix(noise*2.0, 1.0, 0.0);\n    col += (noise-0.5) * NOISE_MULTIPLIER;\n    /*col.x = col.x > 0.5 ? 1.0 : 0.0;\n    col.y = col.y > 0.5 ? 1.0 : 0.0;\n    col.z = col.z > 0.5 ? 1.0 : 0.0;*/\n    // Output to screen\n    fragColor = vec4(clamp(col, -10.0, 10.0),1.0);\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec3 big_kernel   = blur(iChannel0, ivec2(fragCoord), BLUR_RADIUS);\n#ifdef SHARPENING\n    vec3 small_kernel = blur(iChannel0, ivec2(fragCoord), BLUR_RADIUS-1);\n    fragColor.rgb = small_kernel + (small_kernel - big_kernel) * SHARPENING;\n#else\n    fragColor.rgb = big_kernel;\n#endif\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec4 filter1 = vec4(0.0);\n    vec4 filter2 = vec4(0.0);\n    float s = 0.0;\n    float props = 0.5;\n#ifdef USE_KUWAHARA\n#ifdef USE_DIRECTIONAL_KUWAHARA\n    directional_kuwahara(filter1, fragCoord, iChannel0, iResolution);\n#else\n    kuwahara(filter1, fragCoord, iChannel0, iResolution);\n#endif\n    s += 1.0-props;\n#endif\n#ifdef USE_MEDIAN\n    fastMedian(filter2, fragCoord, iChannel0, iResolution);\n    s += props;\n#endif\n#if !defined(USE_KUWAHARA) && !defined(USE_MEDIAN)\n    fragColor.rgb = texelFetch(iChannel0, ivec2(fragCoord), 0).rgb;\n#else\n    fragColor.rgb = mix(filter1.rgb, filter2.rgb, props) / s;\n    fragColor.rgb = mix(fragColor.rgb, texelFetch(iChannel0, ivec2(fragCoord), 0).rgb, MIX_B_C);\n#endif\n}","name":"Buffer C","description":"","type":"buffer"},{"inputs":[{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XdfGR8","channel":0}],"code":"ivec2 detect_motion(sampler2D prev, ivec2 crd1, sampler2D curr, ivec2 crd2, int radius, out float diff)\n{\n    int stp = DETECT_MOTION_SNAKE_STEP;\n    int n = 0;\n    int square = radius*2+1;\n    square *= square;\n    int x=0,y=0;\n    int dx=0,dy=-stp;\n    ivec2 result = ivec2(0);\n    diff = 65536.0;\n    for (n = 0; n < square; n++) {\n        //if ((-radius < x && x <= radius) && (-radius < y && y <= radius))\n        {\n            float d = compare_squares(prev, crd1 + ivec2(x, y), curr, crd2, SEARCH_KERNEL, diff);\n            if (d < diff) {\n                diff = d;\n                result = ivec2(x, y);\n            }\n        }\n        if (x == y || (x < 0 && x == -y) || (x > 0 && x == 1-y)) {\n            int swap = dx;\n            dx = -dy;\n            dy =  swap;\n            /*x += dx;\n            y += dy;*/\n        } else {\n            x += dx;\n            y += dy;\n        }\n    }\n    return result;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    \n    float diff    = 0.0;\n    ivec2 vector  = detect_motion(\n        iChannel1, ivec2(fragCoord),\n        iChannel0, ivec2(fragCoord/iResolution.xy*iChannelResolution[0].xy), SEARCH_RADIUS, diff);\n    vec3 current  = texelFetch(iChannel0, ivec2(fragCoord), 0).rgb;\n    vec3 current_big_kernel = new_blur(iChannel0, ivec2(fragCoord) , 15);\n    vec3 prev = texelFetch(iChannel1, ivec2(fragCoord) + vector, 0).rgb;\n    vec3 prev_small_kernel = blur(iChannel0, ivec2(fragCoord), 1);\n    vec3 prev_big_kernel = blur(iChannel0, ivec2(fragCoord), 3);\n    float x = clamp(diff*SENSITIVITY, 0.001, 1.0);\n    prev += (prev_small_kernel - prev_big_kernel) * diff * SENSITIVITY * 5.0;\n    current = mix(current, current_big_kernel, clamp(diff * SENSITIVITY * 0.5, 0.0, 1.0));\n    //current += (current - texelFetch(iChannel1, ivec2(fragCoord), 0).rgb)*0.5; //\n    //current += small_kernel;\n    fragColor.rgb = mix(prev, current, pow(x,0.5));\n}","name":"Buffer D","description":"","type":"buffer"}]}
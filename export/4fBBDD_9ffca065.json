{"ver":"0.1","info":{"id":"4fBBDD","date":"1725147052","viewed":16,"name":"Reflections with Raymarching","username":"Quazerix","description":"I decided to try making reflections with raymarching techniques. Calculating reflections is easy, so I just take the new ray direction and keep marching, making sure to accumulate color with each surface I hit.","likes":0,"published":1,"flags":48,"usePreview":0,"tags":["raymarching","reflection"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/* USE ARROW KEYS TO CONTROL THE DIRECTION OF THE CAMERA (MODE 1) OR ORIENTATION OF THE SCENE (MODE 2)\n *\n * USE \"W\" AND \"S\" TO MOVE THE CAMERA FORWARD AND BACKWARD\n * (\"WALKS\" THE CAMERA IN MODE 1, CONTROLS \"ZOOM\" IN MODE 2)\n *\n * USE \"R\" TO RESET THE CAMERA POSITION\n * USE \"T\" TO TOGGLE BETWEEN CAMERA MODES (POSITIONS ARE PRESERVED BETWEEN MODES)\n *\n * SEE BUFFER A FOR MORE DETAILS\n */\n\n\n/* After messing around with transpareny and color accumulation calculations in some of my previous shaders\n * (e.g. https://www.shadertoy.com/view/XcBfDR), I realized I could do reflections in a simlar way. The color of\n * a surface would be determined by the surface color (rgb) and it's reflectivity (alpha), and every time a ray hit\n * a surface, color would accumulate based off the surface reflectivity. The lower the alpha, the higher the\n * reflectivity of a surface, since less of the surface's color will contribute to the final color.\n * Reflecting the ray is also easy. Once I hit a surface, I can do the normal reflection calculations to figure out\n * the new ray direction, and the new ray origin is the collision point.\n *\n * FUTURE WORK: I'd like to extend this to refraction as well. Theotretically, it should be roughly the same logic,\n *              where color is accumulated from the surfaces that are hit, and the new ray direction is based on the\n *              refraction angle of the ray. I tried doing that in this scene, but I was getting weird visuals on the\n *              edges of objects that didn't look right, and no amount of tweaking parameters fixed it. So I abandoned\n *              it for now and will start over in a new scene.\n *\n *              I'd also like to experiment with other aspects of raytracing, such as shadows and area lights,\n *              but I suspect I'd have to lean more towards methods associated with raytracing than raymarching\n *              to get beleivable results.\n *\n *              EDIT: Naturally, I'm not the first person to do this, and the name \"Raymarched Reflections\" was\n *                    already taken. But that led me to find a few other people who had done this before me and\n *                    had included things like shadows. So I'll probably be looking at those for inspiration with\n *                    what I do in the future.\n */\n \n \n /* Feel free to use this (or pieces of it) in your own projects with appropriate credits. */\n\n\nfloat sdBox( vec3 p, vec3 b )\n{\n  vec3 q = abs(p) - b;\n  return length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n}\n\n\n// Rotate the torus on the x axis, just for a more interesting scene.\nfloat sdRTorus( vec3 p, vec2 t )\n{\n  float theta = iTime*.5;\n  mat3 r = mat3(1, 0, 0, 0, cos(theta), -sin(theta), 0, sin(theta), cos(theta));\n  p = r*p;\n  vec2 q = vec2(length(p.xz)-t.x,p.y);\n  return length(q)-t.y;\n}\n\nfloat map(vec3 p) {\n    vec3 q = p;\n    // Wobbly sphere\n    q.x += 15.;\n    float d = length(q)-7.+sin(q.y*2.5+iTime*3.)*.3+.3;\n    // Floating cube\n    q.x -= 30.;\n    d = min(d, sdBox(vec3(q.x, q.y+sin(iTime*2.)*2., q.z), vec3(5)));\n    // Turning torus\n    q.z+=15.;\n    q.x += 15.;\n    d = min(d, sdRTorus(q, vec2(6,3)));\n    // Infinite cylinder\n    q.z-=30.;\n    d = min(d, length(q.xz)-4.);\n    // Ground plane\n    d = min(d, abs(p.y+9.5));\n    return d*.3;\n}\n\nvec3 calcNormal( in vec3 p ) {\n    float e = 0.001;\n    vec2 h = vec2(1.0,-1.0)*0.5773;\n    return normalize( h.xyy*map( p + h.xyy*e ) + \n\t\t\t\t\t  h.yyx*map( p + h.yyx*e ) + \n\t\t\t\t\t  h.yxy*map( p + h.yxy*e ) + \n\t\t\t\t\t  h.xxx*map( p + h.xxx*e ) );\n}\n\n// Based on the current color and new color both with transparency,\n// figure out what the combined color should be.\n// Unfortunately, I lost the StackOverflow link I used for this.\nvec4 colorTransp(vec4 c1, vec4 c2) {\n        // Alpha should always be positive, otherwise the color calculation will have 0-division\n        float a = clamp(c1.a+c2.a - c1.a*c2.a, 0.001, 1.);\n        vec3 c = clamp((c1.rgb*c1.a + c2.rgb*c2.a - c1.a*c2.a*c2.rgb)/a, 0., 1.);\n        return vec4(c,a);\n}\n\n// Based on point in space and distance to surface, what color should the surface be?\nvec4 colorLookup(vec3 p, float d) {\n    return p.y>-9.3 ? vec4(abs(calcNormal(p)),.3) : vec4(sin(p.x),sin(p.y),sin(p.z),.5);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = (fragCoord * 2. - iResolution.xy) / iResolution.y;\n\n    // Initialization\n    float T = texelFetch(iChannel0, ivec2(6, 0), 0).r;                                   // Camera mode\n    vec3 rd = texelFetch(iChannel0, ivec2(fragCoord), 0).gba;                            // ray direction\n    vec3 ro = texelFetch(iChannel0, ivec2(1.-T, 0), 0).gba + vec3(0.,0.,(1.-T)*-3.1);    // ray origin\n\n    const float MAX_DIST = 50.;   // Render distance\n    float t = 0.;        // total distance travelled (for each bounce)\n    float i;                      // Number of steps\n    float d = MAX_DIST;     // Distance to our scene\n    vec3 p;                // Current point in space\n    \n    vec4 col = vec4(0);\n    \n    // Raymarching\n    for (i = 0.; i < 300. && t < MAX_DIST; i++) {\n        p = ro + rd * t;\n        d = map(p);\n        \n        // To allow reflections inside objects. Because why not?\n        float b = abs(d);\n        t += b;\n        \n        if (b<.05) {\n            vec3 norm = calcNormal(p)*sign(d);\n            // New starting position is where we hit the surface,\n            // with some offset to keep the ray on the correct side of the surface (and to save a few marches)\n            ro=p+norm*.5;\n            // New direction is the reflected vector\n            rd = reflect(normalize(rd), norm);\n            // Reset travelled distance for marching\n            t=0.;\n            \n            // Accumulate color. Treat reflective surfaces as having some transparent color.\n            // The lower the alpha value, the more reflective the surface (less surface color will be picked up)\n            col = colorTransp(col, colorLookup(p, d));\n        }\n        \n        if (col.a > .95) break; // Break early if we hit an opaque object (or acquire so much color it can't be seen through)\n    }\n\n    // Color the background\n    col = colorTransp(col, vec4(.85,1,1,.9));\n\n    fragColor = vec4(col);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Concept of storing keyboard-modified data in a buffer came from Assossa\n// https://www.shadertoy.com/view/ltsyRS\n//\n// But it is not a unique concept.\n// (E.g. \"Not today\" by ODtian - https://www.shadertoy.com/view/lcXyDj)\n\n/* This buffer stores the ray direction and ray origin for the camera in 2 different modes\n * 1. Free-cam (or 1st-person) has the camera rotate in place\n * 2. Arcball (or 3rd-person) has the camera rotate around (and always look at) a central point\n * Most of the pixels will store the ray direction, since that's different per-pixel\n * but we need to reserve 2 pixels to store data for the camera position for each mode.\n * I put these at the bottom right for minimum visual disturbance in the final scene.\n \n * CONTROLS:\n * \"W\" - Move the camera forward along its direction vector.\n * \"S\" - Move the camera backward along its direction vector.\n * UP ARROW - Increase the azimuthal angle of the camera. Capped at 89.9 degrees.\n * DOWN ARROW - Decrease the azimuthal angle of the camera. Capped at -89.9 degrees.\n * RIGHT ARROW - Increase the polar angle of the camera.\n * LEFT ARROW - Decrease the polar angle of the camera.\n * \"T\" - Toggle between the camera modes.\n * \"R\" - Reset the camera angle/position for the current camera mode.\n */\n \n \n \n /* Feel free to use this buffer in your own projects with appropriate credits. */\n\n\nconst int KEY_LEFT  = 37;\nconst int KEY_UP    = 38;\nconst int KEY_RIGHT = 39;\nconst int KEY_DOWN  = 40;\nconst int KEY_W     = 87;\nconst int KEY_S     = 83;\nconst int KEY_R     = 82;\nconst int KEY_T     = 84;\n\nconst float rotateSpeed = 100.0;\nconst float zoomSpeed = 20.0;\n\n// Offset along the negative z-axis for initial camera position.\n// Also dictates minumum radius for the arcball camera.\nconst float STARTING_CAMERA_DIST = 25.1;\nconst float MIN_CAMERA_DIST = 3.1;\n\nvec3 rotateVector(vec3 v, float theta, float phi) {\n    float thetaRad = -radians(theta); // Convert to radians (really just a scaling factor to limit the rotation speed)\n    float phiRad = radians(phi);     // Convert to radians (really just a scaling factor to limit the rotation speed)\n\n    // Rotation matrix around the Y-axis\n    mat3 R_y = mat3(\n        cos(thetaRad), 0, sin(thetaRad),\n        0, 1, 0,\n        -sin(thetaRad), 0, cos(thetaRad)\n    );\n\n    // Rotation matrix around the X-axis\n    mat3 R_x = mat3(\n        1, 0, 0,\n        0, cos(phiRad), -sin(phiRad),\n        0, sin(phiRad), cos(phiRad)\n    );\n\n    // Combined rotation matrix\n    mat3 R = R_y * R_x;\n\n    // Apply rotation to vector\n    return R * v;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    // Read data from the previous frame\n    float tf = texelFetch(iChannel0, ivec2(2, 0), 0).r; // Theta (free-cam)\n    float pf = texelFetch(iChannel0, ivec2(3, 0), 0).r; // Phi (free-cam)\n    float ta = texelFetch(iChannel0, ivec2(4, 0), 0).r; // Theta (arcball)\n    float pa = texelFetch(iChannel0, ivec2(5, 0), 0).r; // Phi (free-cam)\n\n    float t = texelFetch(iChannel1, ivec2(KEY_T, 2), 0).r; // Camera mode\n    t = 1.-t; // Uncomment this line to switch the starting camera mode on first load. Default is free-cam mode.\n\n    float theta = (tf*(1.-t))+(ta*t); // Theta for current camera mode\n    float phi   = (pf*(1.-t))+(pa*t)+30.*t; // Phi for current camera mode\n    \n    vec2 uv = (fragCoord * 2. - iResolution.xy) / iResolution.y;\n    vec3 rd = normalize(vec3(uv, 1));\n    vec3 currentPosition = rotateVector(rd, (1.-2.*t)*theta, (1.-2.*t)*phi); // Ray direction\n    float outData = 0.0; // Theta, phi, or radius\n    \n    if (int(fragCoord.y) == 0){\n        // Read data from the previous frame\n        float rad = texelFetch(iChannel0, ivec2(0, 0), 0).r; // Arcball radius/position\n        vec3 fp = texelFetch(iChannel0, ivec2(1, 0), 0).gba; // Free-cam position\n        \n        float r = texelFetch(iChannel1, ivec2(KEY_R, 1), 0).r; // If we need to reset the position/rotation\n        \n        // Calculate camera angle and position based on keyboard presses\n        switch(int(fragCoord.x)) {\n            case 0:\n                // Radius (arcball)\n                outData = (1.-r*t)*(rad +\n                    t*((iTimeDelta * zoomSpeed) * texelFetch(iChannel1, ivec2(KEY_S, 0), 0).r -\n                    (iTimeDelta * zoomSpeed) * texelFetch(iChannel1, ivec2(KEY_W, 0), 0).r));\n                outData = max(outData, MIN_CAMERA_DIST-STARTING_CAMERA_DIST);\n\n                // Position (arcball)\n                currentPosition = rotateVector(vec3(0, 0, -1), -theta, -phi)*(outData+STARTING_CAMERA_DIST);\n\n                break;\n            case 1:\n                // Position (free-cam)\n                currentPosition = fp + (1.-t)*(rotateVector(vec3(0.,0.,1.), theta, phi)*zoomSpeed/2.*\n                                     ((iTimeDelta) * texelFetch(iChannel1, ivec2(KEY_W, 0), 0).r -\n                                      (iTimeDelta) * texelFetch(iChannel1, ivec2(KEY_S, 0), 0).r));                      \n                                \n                if (r==1. && t==0.) { // Reset position if 'R' is pressed\n                    currentPosition = vec3(0,0,-STARTING_CAMERA_DIST);\n                }\n                \n                break;\n            case 2:\n                // Theta (freecam)\n                outData = (1.-r*(1.-t))*(tf +\n                    ((iTimeDelta * rotateSpeed) * texelFetch(iChannel1, ivec2(KEY_RIGHT, 0), 0).r -\n                    (iTimeDelta * rotateSpeed) * texelFetch(iChannel1, ivec2(KEY_LEFT, 0), 0).r) * (1.-t));\n                break;\n\n            case 3:\n                // Phi (freecam)\n                outData = (1.-r*(1.-t))*(pf +\n                    ((iTimeDelta * rotateSpeed) * texelFetch(iChannel1, ivec2(KEY_UP, 0), 0).r -\n                    (iTimeDelta * rotateSpeed) * texelFetch(iChannel1, ivec2(KEY_DOWN, 0), 0).r) * (1.-t));\n                outData = clamp(outData, -89.9, 89.9); // Used for camera angle, clamp to prevent camera from going upside-down\n                break;\n            case 4:\n                // Slowly rotate the camera if no buttons have been pressed. (Just for the Shadertoy preview.)\n                float offset = float(texelFetch(iChannel0, ivec2(7, 0), 0).r == 0.) * 0.1;\n                \n                // Theta (arcball)\n                outData = (1.-r*t)*(ta +\n                    ((iTimeDelta * rotateSpeed) * texelFetch(iChannel1, ivec2(KEY_RIGHT, 0), 0).r -\n                    (iTimeDelta * rotateSpeed) * texelFetch(iChannel1, ivec2(KEY_LEFT, 0), 0).r + offset) * t);\n                break;\n            case 5:\n                // Phi (arcball)\n                outData = (1.-r*t)*(pa +\n                    ((iTimeDelta * rotateSpeed) * texelFetch(iChannel1, ivec2(KEY_UP, 0), 0).r -\n                    (iTimeDelta * rotateSpeed) * texelFetch(iChannel1, ivec2(KEY_DOWN, 0), 0).r) * t);\n                // Offset clamp by starting angle (30)\n                outData = clamp(outData, -119.9, 59.9); // Used for camera angle, clamp to prevent camera from going upside-down\n                break;\n            case 6:\n                outData = t;\n                break;\n            case 7:\n                // If any buttons have been pressed.\n                outData = texelFetch(iChannel0, ivec2(7, 0), 0).r > 0. ? 1. :\n                            texelFetch(iChannel1, ivec2(KEY_RIGHT, 0), 0).r +\n                            texelFetch(iChannel1, ivec2(KEY_LEFT, 0), 0).r +\n                            texelFetch(iChannel1, ivec2(KEY_UP, 0), 0).r +\n                            texelFetch(iChannel1, ivec2(KEY_DOWN, 0), 0).r +\n                            texelFetch(iChannel1, ivec2(KEY_W, 0), 0).r +\n                            texelFetch(iChannel1, ivec2(KEY_R, 0), 0).r +\n                            texelFetch(iChannel1, ivec2(KEY_T, 0), 0).r +\n                            texelFetch(iChannel1, ivec2(KEY_S, 0), 0).r;\n                break;\n        }\n    }\n    \n    // outData is theta, phi, or radius.\n    // currentPosition is ray direction or ray origin.\n    fragColor = vec4(outData, currentPosition);\n}","name":"Buffer A","description":"","type":"buffer"}]}
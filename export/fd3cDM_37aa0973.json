{"ver":"0.1","info":{"id":"fd3cDM","date":"1653564294","viewed":239,"name":"Upscaled cloud / fog rendering","username":"jaszunio15","description":"Accelerating realtime cloud/fog rendering with low resolution buffer. Testing the idea that I've found here:\nhttps://www.guerrilla-games.com/media/News/Files/The-Real-time-Volumetric-Cloudscapes-of-Horizon-Zero-Dawn.pdf\nClick to see the low res buffer.\n","likes":6,"published":1,"flags":32,"usePreview":0,"tags":["filter","dither","fog","optimization","temporal"],"hasliked":0,"parentid":"Wtt3zj","parentname":"3D Grid with movable camera"},"renderpass":[{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//Shader License: CC BY 3.0\n//Author: Jan Mr√≥z (jaszunio15)\n\n/*\n\nMany modern realtime effects are using temporal filtering to store data from previous frames for quicker computation of a current frame.\nHere is my attempt to accelerate realtime cloud/fog rendering by upscaling low resolution buffer.\n\nThe idea is yoinked from this presentation (slides 93-95): \nhttps://www.guerrilla-games.com/media/News/Files/The-Real-time-Volumetric-Cloudscapes-of-Horizon-Zero-Dawn.pdf\n\nIt works nice only for slow and blurry images. It can keep the same amount of detail as full resolution rendering, but starts to show\ndithering artifacts and motion blurring when the image moves too fast. Motion blurring should be able to be fixed by implementing motion\nvectors.\n\nOn integrated GPU original image with 800x450 resolution gives 5-7FPS fiesta, but after switching to 1/3 temporal filtering i got stable\n50-60 FPS.\n\nHow it works:\nShader renders only 1/2, 1/3, or 1/4 of the full resolution each frame and later combines those frames to get the current frame.\nEach frame has small subpixel offset to match the final frame pixel.\n\nFor example, if low resolution buffer is 1/2 of full resolution, it will divide the final image into 2x2 pixel squares, and will render\ndifferent pixel of those squares each frame with dithered order. So it will take 4 frames to get a full frame.\n-----------------\n| 2 | 1 | 2 | 1 |\n-----------------\n| 0 | 3 | 0 | 3 |\n-----------------\n| 2 | 1 | 2 | 1 |\n-----------------\n| 0 | 3 | 0 | 3 |\n-----------------\n\nClick on the screen to see temporal buffer. You will see that those frames are laggy, but final image is smooth.\n\nThe default setting is 1/3 resolution, so it takes 9 frames to update the image.\nYou can change the temporal buffer size in the Common tab.\n*/\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    \n    vec2 temporalResolution = vec2(ivec2(iResolution.xy) / TEMPORAL_DIVISION);\n\n    ivec2 pixelQuadID = ivec2(fragCoord) % TEMPORAL_DIVISION;\n    int frame = pixelQuadID.x + pixelQuadID.y * TEMPORAL_DIVISION;\n    vec2 resolutionOffset = temporalFilteringOffsets[frame].xy;    \n    \n    if (iMouse.z < 1.0)\n        fragColor = texelFetch(iChannel0, ivec2((fragCoord / float(TEMPORAL_DIVISION)) + resolutionOffset * temporalResolution), 0);\n    \n    // postprocess\n    fragColor = smoothstep(0.0, 0.37, fragColor * fragColor * 0.95);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"// Uncomment some define below to select temporal frames count.\n\n//#define TEMPORAL_16\n#define TEMPORAL_9\n//#define TEMPORAL_4\n//#define NO_TEMPORAL\n\n#define RAYMARCH_STEPS 70.0\n#define RAYMARCH_STEP_SIZE 0.15\n#define LIGHTMARCH_STEPS 7\n#define LIGHTMARCH_STEP_SIZE 0.5\n#define CAMERA_FOV 0.8\n#define FOG_DENSITY 15.0\n#define FOG_EDGE_MIN 0.6\n#define FOG_EDGE_MAX 0.7\n\n#ifdef TEMPORAL_16\n\n#define TEMPORAL_FRAMES_COUNT 16\n#define TEMPORAL_DIVISION 4\n\n\nint[] ditherPattern = int[]\n(\n    0, 10, 8, 2, 5, 15, 13, 7, 4, 14, 12, 6, 1, 11, 9, 3\n);\n\nvec4[] temporalFilteringOffsets = vec4[] (\n    vec4(0.0, 0.0, -0.375, -0.375),\n    vec4(1.0, 0.0, -0.125, -0.375),\n    vec4(2.0, 0.0, 0.125, -0.375),\n    vec4(3.0, 0.0, 0.375, -0.375),\n    vec4(0.0, 1.0, -0.375, -0.125),\n    vec4(1.0, 1.0, -0.125, -0.125),\n    vec4(2.0, 1.0, 0.125, -0.125),\n    vec4(3.0, 1.0, 0.375, -0.125),\n    vec4(0.0, 2.0, -0.375, 0.125),\n    vec4(1.0, 2.0, -0.125, 0.125),\n    vec4(2.0, 2.0, 0.125, 0.125),\n    vec4(3.0, 2.0, 0.375, 0.125),\n    vec4(0.0, 3.0, -0.375, 0.375),\n    vec4(1.0, 3.0, -0.125, 0.375),\n    vec4(2.0, 3.0, 0.125, 0.375),\n    vec4(3.0, 3.0, 0.375, 0.375)\n);\n\n#elif defined(TEMPORAL_9)\n\n#define TEMPORAL_FRAMES_COUNT 9\n#define TEMPORAL_DIVISION 3\n\nint[] ditherPattern = int[]\n(\n    0, 7, 5, 6, 1, 8, 3, 2, 4\n);\n\nvec4[] temporalFilteringOffsets = vec4[] (\n    vec4(0.0, 0.0, -0.333, -0.333),\n    vec4(1.0, 0.0, 0.00, -0.333),\n    vec4(2.0, 0.0, 0.333, -0.333),\n    vec4(0.0, 1.0, -0.333, 0.0),\n    vec4(1.0, 1.0, 0.0, 0.0),\n    vec4(2.0, 1.0, 0.333, 0.0),\n    vec4(0.0, 2.0, -0.333, 0.333),\n    vec4(1.0, 2.0, 0.0, 0.333),\n    vec4(2.0, 2.0, 0.333, 0.333)\n);\n\n\n#elif defined(TEMPORAL_4)\n\n#define TEMPORAL_FRAMES_COUNT 4\n#define TEMPORAL_DIVISION 2\n\nint[] ditherPattern = int[]\n(\n    0, 3, 2, 1\n);\n\nvec4[] temporalFilteringOffsets = vec4[] (\n    vec4(0.0, 0.0, -0.25, -0.25),\n    vec4(1.0, 0.0, 0.25, -0.25),\n    vec4(0.0, 1.0, -0.25, 0.25),\n    vec4(1.0, 1.0, 0.25, 0.25)\n);\n\n#elif defined(NO_TEMPORAL)\n\n#define TEMPORAL_FRAMES_COUNT 1\n#define TEMPORAL_DIVISION 1\n\nint[] ditherPattern = int[]\n(\n    0\n);\n\nvec4[] temporalFilteringOffsets = vec4[] (\n    vec4(0.0, 0.0, 0.0, 0.0)\n);\n\n#endif\n\n#define PI 3.1415\n\nfloat hash12(vec2 uv)\n{\n    return fract(sin(dot(uv, vec2(12.4897231, 13.4897325))) * 15.583245);\n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4sfGRr","filepath":"/media/a/27012b4eadd0c3ce12498b867058e4f717ce79e10a99568cca461682d84a4b04.bin","previewfilepath":"/media/ap/27012b4eadd0c3ce12498b867058e4f717ce79e10a99568cca461682d84a4b04.bin","type":"volume","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"vec3 UvToCastPlane(vec2 uv)\n{\n \treturn vec3(uv.x, uv.y, CAMERA_FOV);   \n}\n\nfloat SphereSDF(vec3 coord, vec3 sphereCenter, float radius)\n{\n \treturn distance(coord, sphereCenter) - radius;\n}\n\nfloat ObjectSDF(vec3 coord)\n{\n\tfloat obj = SphereSDF(coord, vec3(0.0), 10.0);\n    return obj;\n}\n\n#define TIME (iTime * 0.9)\n#define DISTORTION_POW 1.8\n#define DISTORTION_SPEED 0.4\n#define DISTORTION_BASE_ITERATION 1.0\n#define DISTORTION_ITERATIONS 5.0\n#define STRENGTH 0.9\n#define LIGHT_POSITION (vec3(1.0, 3.0, 1.0) * 5.0)\n\nfloat CustomNoise(vec3 uv)\n{\n    float p = pow(DISTORTION_POW, DISTORTION_BASE_ITERATION);\n    for (float i = DISTORTION_BASE_ITERATION; i <= DISTORTION_BASE_ITERATION + DISTORTION_ITERATIONS; i++)\n    {\n     \tuv.x += STRENGTH * sin(uv.y * p + TIME * DISTORTION_SPEED + i * 0.18) / p;\n        uv.y += STRENGTH * sin(uv.z * p + TIME * DISTORTION_SPEED + i * 0.244234) / p;        \n        uv.z += STRENGTH * sin(uv.x * p + TIME * DISTORTION_SPEED + i * 0.275453) / p;\n        p *= p;\n    }\n    \n    return textureLod(iChannel1, uv * 0.012 + vec3(0.3, -1.0, 0.6) * TIME * 0.002 + 0.51, 0.0).r;\n}\n\nvec3 RayMarch(vec3 rayOrigin, vec3 rayDirection)\n{\n \tfor (int i = 0; i < 5; i++)\n    {\n     \tfloat sdf = ObjectSDF(rayOrigin);\n        rayOrigin += sdf * rayDirection;\n    }\n    \n    return rayOrigin;\n}\n\nfloat FogDensity(vec3 coord)\n{\n    return smoothstep(FOG_EDGE_MIN, FOG_EDGE_MAX, CustomNoise(coord)) * smoothstep(10.0, 2.0, length(coord));// * smoothstep(3.0, 5.0, length(coord));\n}\n\nstruct FogData\n{\n    float density;\n    float lightTransmitance;\n};\n\nfloat GatherFogDensity(vec3 rayOrigin, vec3 rayDirection, int stepCount, float stepSize)\n{\n    rayOrigin += rayDirection * hash12(rayOrigin.xz + sin(iTime)) * stepSize * 0.5;\n    float density = 0.0;\n    for (int i = 0; i < stepCount; i++)\n    {\n        float localDensity = FogDensity(rayOrigin);\n        density += localDensity;//smoothstep(0.0, 0.3, localDensity);\n        rayOrigin += stepSize * rayDirection * mix(1.0, 2.0, 1.0 - localDensity * localDensity);\n    }\n    \n    return density / float(stepCount);\n}\n\nFogData RayMarchFog(vec3 rayOrigin, vec3 rayDirection)\n{\n    float density = 0.0;\n    float stepSize = RAYMARCH_STEP_SIZE;\n    float light = 0.0;\n    \n    for (float i = 0.0; i < RAYMARCH_STEPS; i++)\n    {\n        float localDensity = FogDensity(rayOrigin);\n\n        vec3 toLight = normalize(-LIGHT_POSITION);\n        float lightDensity = GatherFogDensity(rayOrigin, toLight, LIGHTMARCH_STEPS, 0.5);\n        light += 1.0 - (exp(-lightDensity * FOG_DENSITY * 10.0)) * 0.7;\n        density += localDensity;\n        rayOrigin += stepSize * rayDirection * mix(1.0, 4.0, 1.0 - localDensity * localDensity);\n    }\n       \n    FogData fogData;\n    fogData.density = density / RAYMARCH_STEPS;\n    fogData.lightTransmitance = light / RAYMARCH_STEPS;\n    \n    return fogData;\n}\n\n// Frame rendering function with option to set arbitrary rendering resolution\nvoid GenerateImage(out vec4 fragColor, vec2 fragCoord, vec2 resolution)\n{\n    vec2 uv = fragCoord / resolution;\n    uv = abs(uv - 0.5);\n    if (max(uv.x, uv.y) > 0.5)\n        return;\n        \n    uv = (2.0 * fragCoord - resolution.xy) / resolution.y;\n    \n    // Camera setup\n    vec3 cameraPos = vec3(1.0, 1.0, 1.0) * 7.0 * CAMERA_FOV;\n    vec2 mousePos = iMouse.xy / iResolution.xy - 0.5;\n    if (iMouse.x < 1.0 && iMouse.y < 1.0) mousePos = vec2(0.0); \n    float yaw = 3.9;\n    float pitch = -0.6;\n    mat3 cameraRotation = mat3(cos(yaw), 0.0, -sin(yaw),\n                            0.0, 1.0, 0.0,\n                            sin(yaw), 0.0, cos(yaw)) *\n                      mat3(1.0, 0.0, 0.0,\n                              0.0, cos(pitch), -sin(pitch),\n                              0.0, sin(pitch), cos(pitch));\n                            \n\t//Creating ray\n    vec3 rayOrigin = cameraPos;\n    vec3 rayDirection = normalize(cameraRotation * UvToCastPlane(uv));\n    rayOrigin += rayDirection * hash12(rayDirection.xz + sin(iTime) * 2.0) * 0.1; //dithering\n    \n    \n    // Raymarching bounding sphere\n    vec3 hitPoint = RayMarch(rayOrigin, rayDirection);\n    float sdf = ObjectSDF(hitPoint);\n    \n    vec4 col = vec4(0.2);\n    vec3 fogTint = sin(iTime * 0.1 + 1.0 + vec3(0.0, 0.66666 * PI, 1.33333 * PI + iTime * 0.1)) * 0.15 + 0.9;\n    \n    bool isObjectHit = sdf < 0.5;\n    if (isObjectHit)\n    {\n        // Raymarching fog\n        FogData fog = RayMarchFog(hitPoint, rayDirection);\n        float alpha = 1.0 - exp(-fog.density * FOG_DENSITY);\n        col = mix(col, vec4(fog.lightTransmitance) * vec4(fogTint, 1.0), sqrt(alpha));\n    }\n\n    \n    fragColor = col;\n}\n\n\n// Rendering lower resolution frame\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = texelFetch(iChannel0, ivec2(fragCoord), 0).rgba;\n    vec2 temporalResolution = vec2(ivec2(iResolution.xy) / TEMPORAL_DIVISION);\n\n    int frame = ditherPattern[iFrame % TEMPORAL_FRAMES_COUNT];\n    vec2 resolutionOffset = temporalFilteringOffsets[frame].xy;    \n    vec2 pixelOffset = temporalFilteringOffsets[frame].zw;\n    \n    GenerateImage(fragColor, fragCoord - resolutionOffset * temporalResolution + pixelOffset, temporalResolution);\n}","name":"Buffer B","description":"","type":"buffer"}]}
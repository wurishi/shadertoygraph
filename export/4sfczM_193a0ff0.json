{"ver":"0.1","info":{"id":"4sfczM","date":"1487360539","viewed":227,"name":"IWC Raymarching demo","username":"tamassanta","description":"Features:\n- Raymarching\n- object transformation based on real-time audio channel\n- 2 type of primitive distance field calculation (box, sphere)\n- volumetric fog effect\n- camera movement (sample animation using iGlobelTime)\n- vigneting","likes":0,"published":1,"flags":0,"usePreview":0,"tags":["raymarching","tutorial","iwc"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4sXGRr","filepath":"/media/a/48e2d9ef22ca6673330b8c38a260c87694d2bbc94c19fec9dfa4a1222c364a99.mp3","previewfilepath":"/media/ap/48e2d9ef22ca6673330b8c38a260c87694d2bbc94c19fec9dfa4a1222c364a99.mp3","type":"music","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"#define PI 3.141592654\n\n// ------ FEATURE DEFINITIONS -------\n// coloring & movement - hint: try max distance here!\nconst bool f_coloring_iteration = true;\nconst bool f_camera_movement \t= true;\nconst bool f_sphere_audio \t\t= true;\n\n// eye candies & post processing\nconst bool f_volumetric_fog \t= true;\nconst bool f_smooth_merge \t\t= true;\nconst bool f_vigneting \t\t\t= true;\n\n\n// ------ CONSTANTS -------\nconst float focalLength = 1.9; \t\t\t\t// Distance between the eye and the image plane\nconst int \trmSteps \t= 64; \t\t\t\t// Max raymarch steps\nconst float rmEpsilon \t= 0.001; \t\t\t// Surface threshold\nconst vec4 \tskyColor \t= vec4(1.0);\nconst vec3 \teye \t\t= vec3(0, 0, -2.5); // eye vector - normalised\nconst vec3 \tcamUp \t\t= vec3(0, 1, 0);\t// up vector - normalised\nconst vec3 \tcamRight \t= vec3(1, 0, 0);\t// right vector - normalised\nconst float fogDistance = 2.7;\t\t\t\t// fog fade out distance\n\n// smooth minimum function - credit goes to Iq\nfloat smin( float a, float b, float k )\n{\n    float res = exp( -k*a ) + exp( -k*b );\n    return -log( res )/k;\n}\n\n// sphere distance field calculation\nfloat distSphere(vec3 p, float radius)\n{\n    float freq = (f_sphere_audio) ? texture( iChannel0, vec2( 0.01, 0.2 ) ).x * 1.1 : 1.0;    \n  \treturn length(p) - clamp(0.2, 1.0, radius * freq);\n}\n\n// returns the max component of the input vector (x, y or z)\nfloat maxcomp(in vec3 p ) {\n    return max(p.x,max(p.y,p.z));\n}\n\n// signed box primitive distance field calculation\n// b.x = Width\n// b.y = Height\n// b.z = Depth\n// Leave r=0 if radius not needed\nfloat distBox(vec3 p, vec3 b, float r) {\n    vec3 d = abs(p) - b;\n    return min(maxcomp(d),0.0) - r + length(max(d,0.0));\n}\n\nfloat getDistanceOfNearestObject(vec3 point)\n{\n\t// calculate distances from the objects\n    float dSphere = distSphere(point, 0.6);  \n    float dBox = distBox(point, vec3(0.47,0.47,0.47), 0.05);    \n    float minDist = min(dSphere, dBox);\n    \n    // get the minimum distance from our objects   \n    return (f_smooth_merge) ? min(smin(dSphere, dBox, 32.0), minDist) : minDist;\n}\n\nvec4 getObjectColor(int iterationCount)\n{\n    float redChannel = (f_coloring_iteration) ? 1.0 / float(iterationCount) * 1.5 : 1.0;\n    return vec4(redChannel, 0.1,0.2, 1);\n}\n\nvec4 applyFog(vec4 color, float distFromEye)\n{\n    if(distFromEye > fogDistance && f_volumetric_fog)\n    {\n        return mix(color, \n                   vec4(1.0,1.0,1.0,1.0), \n                   clamp(0.0,1.0,distFromEye - fogDistance));\n    }\n\n    return color;\n}\n\nvec4 applyVignette(vec4 color, vec2 fragCoord)\n{\n    if(f_vigneting)\n    {\n\t\tvec2 q = fragCoord.xy/iResolution.xy;\n    \tcolor *= 0.3 + 0.8 * pow(16.0 * q.x * q.y * (1.0 - q.x) * (1.0 - q.y), 0.2);\n    }\n    \n    return color;\n}\n\n\nvec4 RayTrace(in vec2 fragCoord)\n{    \n    // forward vector from camera\n    vec3 camForward = cross(camRight, camUp);\n    \n    float aspectRatio = iResolution.x / iResolution.y;\n    \n    // map the fragment coordinates to the 3D (UV) coordinate system\n    float u = fragCoord.x * 2.0 / iResolution.x - 1.0;\n    float v = fragCoord.y * 2.0 / iResolution.y - 1.0;   \n    float rotX, rotZ = 0.0;\n    \n    if(f_camera_movement)\n    {\n    \tfloat nRotate = iTime * 0.1; // slow rotation  \n    \trotX = cos(PI * nRotate);\n    \trotZ = sin(PI * nRotate);\n    }\n    \n    // Cast a ray from the eye through the pixel (using focal length)\n    vec3 rayOrigin = vec3(eye.x + rotX, eye.y, eye.z + rotZ);\n    vec3 rayDirection = normalize(camForward * focalLength + camRight * u * aspectRatio + camUp * v);;\n    \n    // set default color, this will be rendered if the ray doesn't hit anything\n    vec4 color = skyColor;\n    \n    // Raymarching starts here\n    float distFromEye = 0.0;\n    for(int i = 0; i < rmSteps; ++i)\n    {\n        // define current point on the ray\n        vec3 p = rayOrigin + rayDirection * distFromEye;      \n        float d = getDistanceOfNearestObject(p);     \n        \n        // if the point is close _enough_ to the object surface, render the object\n        if(d < rmEpsilon)\n        {\n            // render the object color - we use only one color here\n            color = getObjectColor(i);\n            color = applyFog(color, distFromEye);\n            break;\n        }\n\n        distFromEye += d;   \n    }\n\n    return color;\n}\n\n// the entry point of the shader\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec4 color = RayTrace(fragCoord);   \n    fragColor = applyVignette(color, fragCoord);\n}","name":"Image","description":"","type":"image"}]}
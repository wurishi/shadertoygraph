{"ver":"0.1","info":{"id":"dls3Dr","date":"1671652823","viewed":67,"name":"backward_mapping_lkg_quilt","username":"holophone3d","description":"Synthesizes all views between L and R given a rectified stereo pair with depth maps (designed for 3ds)\nClick and hold mouse on the image and move left/right to view synthesized intermediate views\n\n","likes":3,"published":1,"flags":0,"usePreview":0,"tags":["backwardmapping"],"hasliked":0,"parentid":"mlX3Wr","parentname":"backward_mapping_lkg"},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\nLOAD THE FOUR TEXTURES BELOW TO RUN THE SHADER:\n\nThe idea is to call directly the SetTexture function found in Shadertoy js code \n(https://www.shadertoy.com/view/lsGGDd)\n\nHere is how to loads the three textures needed for this shader:\n - Open the javascript console of your browser:\n\t\t\t\t   Mac      /     Windows\n\tChrome:  cmd + opt + J  /  ctrl + shift J\n\tFirefox: cmd + opt + K  /  ctrl + shift K\n    Edge:          na         /  ctrl + shift J   \n\n- Then copy the following lines in the console:\n\ngShaderToy.SetTexture(0, {mSrc:'https://i.imgur.com/3OLvCTo.png', mType:'texture', mID:1, mSampler:{ filter: 'mipmap', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\ngShaderToy.SetTexture(1, {mSrc:'https://i.imgur.com/f9mS6d1.png', mType:'texture', mID:1, mSampler:{ filter: 'mipmap', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\ngShaderToy.SetTexture(2, {mSrc:'https://i.imgur.com/d4J40Dm.png', mType:'texture', mID:1, mSampler:{ filter: 'mipmap', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\ngShaderToy.SetTexture(3, {mSrc:'https://i.imgur.com/j7HF7oF.png', mType:'texture', mID:1, mSampler:{ filter: 'mipmap', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\n\n- hit return to execute and load the textures.\n\n*/\n\n// DETAILS:\n// Synthesizes all views between L and R given a rectified stereo pair with depth maps (designed for 3ds)\n// POC shader to enable 3DS emulator Citra to natively render into Looking Glass hologram display\n// Uses a depth based warping and blending approach to create virtual frames\n// backward mapping - loosely based on the paper below\n// https://www.cc.gatech.edu/conferences/3DPVT08/Program/Papers/paper213.pdf\n\n// USAGE:\n// Synthesizes all views between L and R given a rectified stereo pair with depth maps (designed for 3ds)\n// Click and hold mouse on the image and move left/right to view synthesized intermediate views\n\n// NEED SOME MATH HELP/BRAINSTORMING HERE:\n// As you can see, I'm trying to determine the disparity between the rectified RGB+D stereo images\n// In theory, I have enough data to do this with the depth maps because the formula is: disparity = (focalLength * baseline) / depth\n// However, I think the normalized z data (0-1) isn't enough, I think I need it in world space\n// I think I just need a little math insight or brainstormin (maybe guessing at a projection matrix?)\n// Any thoughts or ideas are very welcome!\n\n\nfloat get_depth_shift(float depth)\n{   \n    // Below is a good approximation function - returns warp disparity based on depth\n    // This was just created by finding a best fit function for a set of manually measured points \n    return -((45.6614-0.223286*(depth))/iChannelResolution[0].x);\n}\n\nvec3 get_Im(vec2 normalized_coords, float alpha)\n{\n    float depth_l = texture(iChannel1, normalized_coords).x*255.0;\n    float depth_r = texture(iChannel3, normalized_coords).x*255.0;\n    float depth_shifted_x_l = normalized_coords.x - alpha*get_depth_shift(depth_l);\n    float depth_shifted_x_r = normalized_coords.x + (1.0-alpha)*get_depth_shift(depth_r);\n    vec3 left_rgb = (1.0-alpha)*texture(iChannel0, vec2(depth_shifted_x_l, normalized_coords.y)).xyz;\n    vec3 right_rgb = alpha*texture(iChannel2, vec2(depth_shifted_x_r, normalized_coords.y)).xyz;\n    return left_rgb + right_rgb;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{        \n    vec2 normalized_coords = fragCoord.xy/iResolution.xy;\n    float alpha = iMouse.x/iResolution.x; // coefficient 0-1 of camera angle (L-R) DEBUG: use mouse to see warping and blending\n    \n    bool generate_quilt = false; // Looking Glass Mode    \n        \n    if (generate_quilt)\n    {\n        // quilt config\n        float cols = 8.0; \n        float rows = 6.0;\n        \n        // alter virtual camera angle for each quilt image\n        float alpha_delta = 1.0/(rows*cols); //step per quilt view\n        float active_row = floor(normalized_coords.y/(1.0/rows));\n        float active_col = floor(normalized_coords.x/(1.0/cols));\n        alpha = active_row*cols*alpha_delta + active_col*alpha_delta; // update alpha virtual camera angle based on quilt view \n        \n        // update coordinates for quilt space\n        normalized_coords = vec2(normalized_coords.x*cols - active_col, normalized_coords.y * rows);\n    }\n    \n    fragColor = vec4(get_Im(normalized_coords, alpha), 1.0);\n}\n","name":"Image","description":"","type":"image"}]}
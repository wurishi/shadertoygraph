{"ver":"0.1","info":{"id":"flG3zd","date":"1638336280","viewed":630,"name":"NTSC Codec (w/Overshoot & Noise)","username":"Astherix","description":"This filter is a highly tweakeable NTSC codec. It encodes and decodes an NTSC signal, generating artifacts.\n\nI've commented the code as much as possible for documentation purposes.\n\nPlease read the comments on every pass to get more useful information!","likes":6,"published":1,"flags":32,"usePreview":0,"tags":["tv","vhs","ntsc","codec"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Input on Buffer A or Buffer A's iChannel0\n\n// This final pass lowpasses (blurs) the image some.\n// Also applies some small sync noise\n\n// Developer's note:\n// I found that most NTSC codecs/decoders on this site are pretty\n// hard to understand.\n//\n// I made this filter to document a lot on how these filters work\n// as information on the matter is scarce even on the internet.\n// That is why this code is littered with comments everywhere.\n//\n// As for actual documents or specifications:\n// The ITU-R BT.1700 recommendation goes into a lot of detail on how\n// an encoder can be implemented both in Hardware and Software.\n// (its \"usefulness\" for software implementations was probably unintentional)\n//\n// Here's a link to that recommendation's papers download page:\n// - https://www.itu.int/rec/R-REC-BT.1700-0-200502-I/en\n//\n// I hope all of this can help you implement your own NTSC/VHS\n// filter!\n\n// To-do list:\n// - Filter out chroma from luma, decode them separately\n// - Improve lowpass filters overall using window functions\n\n// Strength of the 2D low-pass (blur) filter\n#define FIR_SIZE_H 3\n#define FIR_SIZE_V 1\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec3 s;\n    \n    float counter = 0.0;\n    \n    float xoffset = hash12(vec2(fragCoord.y, float(iFrame))) * 1.0;\n\n    for (int i = -FIR_SIZE_H; i <= FIR_SIZE_H; i++) {\n        for (int y = -FIR_SIZE_V; y <= FIR_SIZE_V; y++) {\n            vec2 uv = vec2(fragCoord.x + float(i) + xoffset, fragCoord.y + float(y))/iResolution.xy;\n\n            s = s + texture(iChannel0, uv).xyz;\n            counter += 1.0;\n        }\n    }\n    \n    //s /= (float(FIR_SIZE) * 16.0) + 1.0;\n    s /= counter;\n    fragColor = vec4(s, 1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4df3zn","filepath":"/media/a/3405e48f74815c7baa49133bdc835142948381fbe003ad2f12f5087715731153.ogv","previewfilepath":"/media/ap/3405e48f74815c7baa49133bdc835142948381fbe003ad2f12f5087715731153.ogv","type":"video","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Replace this pass with whatever you want\n// It currently only outputs what's on iChannel0\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec3 color = texture(iChannel0, fragCoord.xy / iResolution.xy).xyz;\n\n    if (enable_interlace) {\n        if ((iFrame & 0x1) > 0) {\n            if ((int(fragCoord.y) & interlace_size) > 1) color = vec3(0.0);\n        } else {\n            if ((int(fragCoord.y) & interlace_size) == 0) color = vec3(0.0);\n        }\n    }\n\n    fragColor = vec4(color, 1.0);\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// Encoder or Modulator\n// This pass converts RGB colors on iChannel0 to\n// a YIQ (NTSC) Composite signal.\n\n#define PI   3.14159265358979323846\n#define TAU  6.28318530717958647693\n\n// Hue adjustment, I've found that rotating the hue\n// by -0.15Â° yields nicer colors, though its not really\n// necessary. Change this value to your liking\n#define HUE_ADJUSTMENT (-0.15)\n\nconst mat3 rgb_to_yiq = mat3(0.299, 0.596, 0.211,\n                             0.587,-0.274,-0.523,\n                             0.114,-0.322, 0.312);\n\n// Alternative RGB to YIQ matrix\n// const mat3 rgb_to_yiq = mat3(0.299, 0.587, 0.114,\n//                              0.596,-0.274,-0.322,\n//                              0.211,-0.523, 0.312);\n\n// Noise (not required)\nfloat hash13(vec3 p3) {\n\tp3  = fract(p3 * .1031);\n    p3 += dot(p3, p3.zyx + 31.32);\n    return fract((p3.x + p3.y) * p3.z);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    // Chroma encoder oscillator frequency \n    float fc = iResolution.x * ENCODER_CHROMA_FREQ_FACTOR;\n    \n    // Base oscillator angle for this dot\n    float t = float(fragCoord.x);\n    \n    // Tuning error offset (not necessary)\n    float offset = hash12(vec2(fragCoord.y, float(iFrame))) * TUNING_ERROR;\n    vec2 pos = vec2(mod(fragCoord.x + offset, iResolution.x), mod(fragCoord.y + (TUNING_ERROR * (float(iFrame) / 10.0) * (iResolution.y / 10.0)), iResolution.y)) / iResolution.xy;\n\n    vec3 rgb = texture(iChannel0, pos).rgb;\n    vec3 yiq = rgb_to_yiq * rgb;\n    \n    // This is a phase offset based on the Y coordinate of the pixel\n    // Its not necessary for decoding, it just adds some movement\n    // to otherwise completely static images.\n    float y_phase_offset = (fragCoord.y / 3.0) + (float(iFrame & 0x1) * PI);\n    \n    // Final oscillator angle\n    float f = fc * t + HUE_ADJUSTMENT + (offset * 10.0) - (fragCoord.y / 3.0) + (float(iFrame & 0x1) * PI);\n\n    float i = yiq.y * cos(f), // I signal\n          q = yiq.z * sin(f); // Q signal\n    \n    if (enable_interlace) yiq.x *= 1.5;\n\n    float c = yiq.x + (i + q); // Composite\n    \n    c -= hash13(vec3(fragCoord.xy, iTime)) * (fragCoord.y / iResolution.y) * (TUNING_ERROR / MAX_TUNING_ERROR);\n    \n    // Return a grayscale representation of the signal\n    fragColor = vec4(vec3(c), 1.0);\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// Decoder or Demodulator\n// This pass takes the Composite signal generated on Buffer B\n// and decodes it\n\n// Also applies some noise and generates black bars on the sides\n// of the video frame.\n// These two are post-processing effects, and thus, not necessary\n// for decoding/encoding.\n\n#define PI   3.14159265358979323846\n#define TAU  6.28318530717958647693\n\n// Size of the black bars on the sides, as a fraction\n// of the entire horizontal resolution\n#define BARS_SIZE                (1.0 / 500.0)\n\n// Noise visibility factor\n// Values between 1.0 and 2.0 are the most realistic\n#define LUMA_NOISE_FACTOR        0.0\n#define LUMA_NOISE_DENSITY       0.0\n#define CHROMA_NOISE_FACTOR      0.0\n#define CHROMA_NOISE_DENSITY     0.0\n\n#define BRIGHTNESS_FACTOR        40.0\n\n// The decoded IQ signals get multiplied by this\n// factor. Bigger values yield more color saturation\n#define CHROMA_SATURATION_FACTOR 30.0\n\n// Size of the decoding FIR filter. bigger values\n// yield more smuggly video and are more expensive\n#define CHROMA_DECODER_FIR_SIZE         20\n#define LUMA_DECODER_FIR_SIZE           1\n\nconst mat3 yiq_to_rgb = mat3(1.000, 1.000, 1.000,\n                             0.956,-0.272,-1.106,\n                             0.621,-0.647, 1.703);\n\nfloat hann(float i, int size, float phase) {\n    return pow(sin((PI * (i + phase)) / float(size)), 2.0);\n}\n\n// Noise (not required)\nfloat hash13(vec3 p3) {\n\tp3  = fract(p3 * .1031);\n    p3 += dot(p3, p3.zyx + 31.32);\n    return fract((p3.x + p3.y) * p3.z);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    // Tuning error (not necessary)\n    float error = (TUNING_ERROR * 0.001);\n\n    // Chroma decoder oscillator frequency\n    float fc = iResolution.x * (DECODER_CHROMA_FREQ_FACTOR + error);\n    \n    float counter = 1.0;\n    \n    // Sum and decode NTSC samples\n    // This is essentially a simple averaging filter\n    // that happens to be weighted by two cos and sin\n    // oscillators at a very specific frequency\n    vec3 yiq;\n    \n    for (int d = -CHROMA_DECODER_FIR_SIZE; d < CHROMA_DECODER_FIR_SIZE; d++) {\n        vec2 pos = vec2(fragCoord.x + float(d), fragCoord.y);\n\n        vec3 s = texture(iChannel0, pos / iResolution.xy).rgb;\n\n        float t = fc * (fragCoord.x + float(d)) - (fragCoord.y / 3.0) + (float(iFrame & 0x1) * PI);\n\n#ifdef DECODE_LUMA_CHROMA_SEPARATELY\n        yiq += s * vec3(0.0, cos(t) * 2.0, sin(t) * 2.0);\n#else\n        yiq += s * vec3(BRIGHTNESS_FACTOR, cos(t), sin(t));\n#endif\n        counter++;\n    }\n\n    yiq /= counter;\n    \n#ifdef DECODE_LUMA_CHROMA_SEPARATELY\n    for (int d = -LUMA_DECODER_FIR_SIZE; d < LUMA_DECODER_FIR_SIZE; d++) {\n        vec2 pos = vec2(fragCoord.x + float(d), fragCoord.y);\n\n        vec3 s = texture(iChannel0, pos / iResolution.xy).rgb;\n\n        float t = fc * (fragCoord.x + float(d)) - (fragCoord.y / 3.0) + (float(iFrame & 0x1) * PI);\n        \n        yiq += s * vec3(BRIGHTNESS_FACTOR, cos(t), sin(t)) * hann(float(d), LUMA_DECODER_FIR_SIZE * 2, 0.0);\n\n        counter++;\n    }\n\n    yiq /= counter;\n#endif\n    \n    // Everything below this line (excluding the YIQ to RGB conversion)\n    // isn't absolutely necessary. The core of the decoder is above\n    // this line.\n\n    // Saturate chroma (IQ)\n    yiq.yz *= CHROMA_SATURATION_FACTOR;\n    \n    // Noise\n    float f = hash13(vec3(fragCoord.xy, iTime)),\n          af = (f - 0.5) * 0.5;\n    yiq.xyz *= (f > (1.0 - LUMA_NOISE_DENSITY)) ? (f * LUMA_NOISE_FACTOR) : 1.0;\n    \n    if (abs(af) > (1.0 - CHROMA_NOISE_DENSITY)) yiq.yz += af * CHROMA_NOISE_FACTOR;\n    \n    // Black bars\n    float u = fragCoord.x / iResolution.x;\n    \n    if (!((u >= BARS_SIZE) && (u <= (1.0 - BARS_SIZE)))) {\n        yiq.yz = vec2(0.0);\n        yiq.x = 0.01;\n    }\n\n    fragColor = vec4((yiq_to_rgb * yiq), 1.0);\n}","name":"Buffer C","description":"","type":"buffer"},{"inputs":[{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XdfGR8","channel":0}],"code":"// Adapted from https://www.shadertoy.com/view/7dyXWG\n\n// This pass applies a simulation of analog overshoot, which\n// is the cause for ghosting artifacts around edges (sharp transitions)\n// This is not necessary for encoding/decoding.\n\n// These two define the tension and bias parameters\n// of the Hermite interpolation function\n// Values closer to 0.5 on both parameters yield\n// more aggressive ghosting artifacts\n#define HERMITE_TENSION 0.25\n#define HERMITE_BIAS 0.75\n\nfloat hermite(float y0, float y1, float y2, float y3, float m, float tension, float bias) {\n    float m2 = m*m,\n          m3 = m2*m,\n          m0 =      (y1-y0)*(1.0+bias)*(1.0-tension)/2.0;\n          m0 = m0 + (y2-y1)*(1.0-bias)*(1.0-tension)/2.0;\n    float m1 =      (y2-y1)*(1.0+bias)*(1.0-tension)/2.0;\n          m1 = m1 + (y3-y2)*(1.0-bias)*(1.0-tension)/2.0;\n    float a0 =  2.0*m3 - 3.0*m2 + 1.0,\n          a1 =      m3 - 2.0*m2 + m,\n          a2 =      m3 -     m2,\n          a3 = -2.0*m3 + 3.0*m2;\n     \n     return (a0*y1+a1*m0+a2*m1+a3*y2);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 fcm1 = vec2(fragCoord.x-4.0, fragCoord.y)/iResolution.xy,\n         fcm0 = vec2(fragCoord.x-0.0, fragCoord.y)/iResolution.xy,\n         fcp1 = vec2(fragCoord.x+4.0, fragCoord.y)/iResolution.xy,\n         fcp2 = vec2(fragCoord.x+8.0, fragCoord.y)/iResolution.xy;\n    \n    vec3 y0 = texture(iChannel0, fcm1).xyz,\n         y1 = texture(iChannel0, fcm0).xyz,\n         y2 = texture(iChannel0, fcp1).xyz,\n         y3 = texture(iChannel0, fcp2).xyz;\n    \n    vec3 o = y1;\n         \n    float l = HERMITE_TENSION, y = HERMITE_BIAS;\n         \n    vec3 f = vec3(\n        hermite(y0.x, y1.x, y2.x, y3.x, l, y, y * 50.0),\n        hermite(y0.y, y1.y, y2.y, y3.y, l, y, y * 50.0),\n        hermite(y0.z, y1.z, y2.z, y3.z, l, y, y * 50.0)\n    );\n    \n#ifdef DECODE_CHROMA_LUMA_SEPARATELY\n    fragColor = vec4(y1, 1.0);\n#else\n    fragColor = vec4(f, 1.0);\n#endif\n}","name":"Buffer D","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"// Allows scaling the encoder and decoder chroma frequency oscillators\n// individually. These should be the same to get accurate colors.\n#define ENCODER_CHROMA_FREQ_FACTOR 1.0\n#define DECODER_CHROMA_FREQ_FACTOR 1.0\n\n// Tuning error, values between 0.5 and 1.0 are the most\n// realistic. This parameter tweaks various parameters\n// across the filter.\n// Change this to (iMouse.x / iResolution.x) to get\n// mouse controls for tuning error\n\nfloat tuning_error_max = 1000.0;\nfloat tuning_error = 0.0;\nbool enable_interlace = true;\nint interlace_size = 0x2;\n\n#define MAX_TUNING_ERROR (1000.0)\n#define TUNING_ERROR ((iMouse.x / iResolution.x) * MAX_TUNING_ERROR)\n\n#define DECODE_LUMA_CHROMA_SEPARATELY\n\n// We use this noise function very often\nfloat hash12(vec2 p) {\n\tvec3 p3  = fract(vec3(p.xyx) * .1031);\n    p3 += dot(p3, p3.yzx + 33.33);\n    return fract((p3.x + p3.y) * p3.z);\n}","name":"Common","description":"","type":"common"}]}
{"ver":"0.1","info":{"id":"tljczR","date":"1593620281","viewed":318,"name":"Sound Input Example","username":"TrevallionJ","description":"This is the texture input from sound formats.","likes":3,"published":1,"flags":0,"usePreview":0,"tags":["soundvisualisation"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4sXGRr","filepath":"/media/a/48e2d9ef22ca6673330b8c38a260c87694d2bbc94c19fec9dfa4a1222c364a99.mp3","previewfilepath":"/media/ap/48e2d9ef22ca6673330b8c38a260c87694d2bbc94c19fec9dfa4a1222c364a99.mp3","type":"music","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//\tThe sound is input as a 512x2 texture with the bottom layer being the wave form where the brightness corrosponds\n//\twith the amplitude of the sample and the top layer being a frequency spectrum of the underlying sine wave\n//\tfrequencies where brightness is the amplitude of the wave and each line represents average of 23 hz frequencies.\n//\tThe texture is single channel red so the texture, when drawn, is red.\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord / iResolution.xy;\n    \n    //\tThis splits the two channels into each half of the screen\n    if(fragCoord.y < iResolution.xy.y / 2.0){uv.y = 1.0;}else{uv.y = 0.0;}\n    \n    fragColor = texture(iChannel0, uv);\n}\n\n//\tFor music and audio visualisers the first channel is mainly used as its reactions to music are more noticable\n//\tand understandable. The bottom layer can be converted into a wave.\n//\tI recomend checking this out  --> https://www.shadertoy.com/view/Xds3Rr\n\n//\tOne final point is that the inbuilt music and soundcloud music are handled the same way and give the same input","name":"Image","description":"","type":"image"}]}
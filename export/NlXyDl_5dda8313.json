{"ver":"0.1","info":{"id":"NlXyDl","date":"1648868928","viewed":65,"name":"Multi object illumination","username":"Lumos320","description":"Multi object illumination and anti aliasing based on SDF","likes":0,"published":1,"flags":0,"usePreview":0,"tags":["3d","sdf"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"#define PI 3.14159265\n//最大迭代次数\n#define Traymarch 128\n//阈值精度\n#define Precision .001\n#define R 1.;\n//光照系数\n#define Ka 0.2\n//抗锯齿\n#define AA 4\n//软阴影系数\n#define K 10.\n\nvec2 fixUV(in vec2 uv)\n{\n    return (2.*uv - iResolution.xy)/ min(iResolution.x,iResolution.y);\n}\n\nfloat sdfSphere(in vec3 p)\n{\n    return length(p) - R;\n}\n\nfloat sdfRect(in vec3 p, vec3 wh)\n{\n    vec3 d = abs(p) - wh;\n    return length(max(d, 0.)) + min(max(d.x, max(d.y, d.z)),0.);\n}\n\nvec2 operate(vec2 a, vec2 b)\n{\n    return a.x<b.x ? a : b;\n}\n\n//返回最短距离和具体物体\nvec2 map(in vec3 p)\n{   \n    vec2 d = vec2(sdfSphere(p - vec3(0.,1.,0.)), 2.);\n    d = operate(d, vec2(sdfRect(p- vec3(2.,1.,0.),vec3(.5,1.,1.)), 3.));\n    return d;\n}\n\nvec2 rayMarching(in vec3 ro, in vec3 rd)\n{\n    //射线走的距离\n    float t = 0.1;\n    float tmax = 40.;\n    vec2 res = vec2(-1.);\n    //和平面相交,射线向下走\n    if(rd.y < 0.){\n        float ty = -ro.y/rd.y;\n        tmax = min(tmax,ty);\n        res = vec2(ty,1.);\n    }\n    for(int i=0; i<Traymarch && t<tmax; ++i){\n        //当前位置\n        vec3 pos = ro + t*rd;\n        vec2 d = map(pos);\n        if(d.x < Precision) {\n            res = vec2(t, d.y);\n            break;\n        }\n        t += d.x;\n    }\n    return res;\n}\n\n//SDF的法向量 : https://iquilezles.org/articles/normalsSDF\nvec3 calcNormal( in vec3  p ) \n{\n    const float h = 0.0001; // 步长\n    const vec2 k = vec2(1,-1);\n    return normalize( k.xyy*map( p + k.xyy*h ).x + \n                      k.yyx*map( p + k.yyx*h ).x + \n                      k.yxy*map( p + k.yxy*h ).x + \n                      k.xxx*map( p + k.xxx*h ).x);\n}\n\n//摄像机变换矩阵\nmat3 setCamera(vec3 target, vec3 cpos, float theta)\n{\n    vec3 z = normalize(target - cpos);\n    //theta是y轴绕z旋转的角度，cp能确定相机上方向\n    vec3 cp = vec3(sin(theta),cos(theta),0.);\n    vec3 x = normalize(cross(z,cp));\n    vec3 y = cross(x,z);\n\n    return mat3(x,y,z);\n}\n\n//优化的软阴影\nfloat softshadow( in vec3 ro, in vec3 rd)\n{\n    float res = 1.0;\n    float ph = 1e20;\n    float tmin = .1;\n    float tmax = 10.;\n    for( float t=tmin; t<tmax; )\n    {\n        float h = map(ro + rd*t).x;\n        if( h<0.001 )\n            return 0.0;\n        float y = h*h/(2.0*ph);\n        float d = sqrt(h*h-y*y);\n        res = min( res, K*d/max(0.0,t-y) );\n        ph = h;\n        t += h;\n    }\n    return res;\n}\n\n// more details: https://iquilezles.org/articles/checkerfiltering\n// triangular signal\nvec2 tri( in vec2 x )\n{\n    vec2 h = fract(x*.5)-.5;\n    return 1.-2.*abs(h);\n}\n\n//反走样\nfloat checkersGrad( in vec2 uv, in vec2 ddx, in vec2 ddy )\n{\n    vec2 w = max(abs(ddx), abs(ddy)) + 0.01;    // filter kernel\n    vec2 i = (tri(uv+0.5*w)-tri(uv-0.5*w))/w;   // analytical integral (box filter)\n    return 0.5 - 0.5*i.x*i.y;                   // xor pattern\n}\n\nvec3 render(vec2 uv, in vec2 px, in vec2 py)\n{\n    vec3 color = vec3(0.);\n    \n    //摄像机位置\n    //vec3 ro = vec3(0.,0.,-2.);\n    vec3 ro = vec3(4.*cos(0.2*iTime), 2. , 4.*sin(0.2*iTime));\n\n    //鼠标控制时\n    if(iMouse.z > 0.1){\n        //鼠标(0,1) 旋转角度(0,2pi)\n        float theta = iMouse.x/iResolution.x * 2. * PI;\n        ro = vec3(4. * cos(0.2*theta), 2., 4. * sin(0.2*theta));\n    }\n    \n    vec3 target = vec3(0.);\n    //摄像机变换矩阵\n    mat3 camera = setCamera(target, ro, 0.);\n    //焦距\n    float fl = 1.;\n    //方向要归一化\n    //ro是view坐标系原点，不用减\n    vec3 rd = normalize(camera * vec3(uv,fl));\n    vec2 t = rayMarching(ro,rd);\n    \n    //背景颜色\n    vec3 bgcolor = vec3(0.36, 0.51, 0.8);\n    color = bgcolor;\n\n    if(t.y > 0.){\n        //光线打到的位置\n        vec3 pos = ro + t.x*rd;\n        //球和平面分开计算法向量\n        vec3 normal = t.y<1.1 ? vec3(0.,1.,0.) : calcNormal(pos);\n        //设置一个光源\n        vec3 light = vec3(2.,3.,0.);\n        //漫反射\n        float diffuse = dot(normalize(light-pos), normal);\n        diffuse = clamp(diffuse,0.,1.);\n        //软阴影(能否看到光源)\n        float sd = softshadow(pos,normalize(light - pos));\n        diffuse *= sd;\n        //环境光\n        float ambi = Ka + Ka * dot(normal, vec3(0., 1., 0.));\n        vec3 ctmp = vec3(0.23);\n        //circle\n        if(t.y > 1.9 && t.y < 2.1){\n            ctmp = vec3(0.,1.,0.);\n        }\n        //rect\n        else if(t.y > 2.9 && t.y < 3.1){\n            ctmp = vec3(0.,2.,6.);\n        }\n        //rect\n        else if(t.y > 0.9 && t.y < 1.1){\n            //ctmp = vec3(5.,1.,6.);\n            //格子棋盘\n            //vec2 grid = floor(pos.xz);\n            //ctmp = vec3(0.43) + 2. * mod(grid.x + grid.y,2.);\n            vec3 rdx = normalize(camera * vec3(px,fl));\n            vec3 rdy = normalize(camera * vec3(py,fl));\n            // 缩放的差距：rd/rd.y - rdx/rdx.y\n            vec3 ddx = ro.y * (rd/rd.y - rdx/rdx.y);\n            vec3 ddy = ro.y * (rd/rd.y - rdy/rdy.y);\n            //贴图坐标\n            ctmp = vec3(.3) + vec3(.2) * checkersGrad(pos.xz,ddx.xz,ddy.xz);\n        }\n        color = ambi * ctmp + diffuse * vec3(1.);\n    }\n    //伽马校正<1\n    return sqrt(color);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    //vec2 uv = fixUV(fragCoord);\n    vec3 color = vec3(0.);\n    //抗锯齿\n    for(int i=0; i<AA; ++i){\n        for(int j=0; j<AA; ++j){\n            //偏移量在(0,1)\n            vec2 offset = 2. * (vec2(float(i),float(j))/float(AA) - 0.5);\n            vec2 uv = fixUV(fragCoord+offset);\n            vec2 dx = fixUV(fragCoord + vec2(1.,0.) + offset);\n            vec2 dy = fixUV(fragCoord + vec2(0.,1.) + offset);\n            color += render(uv, dx, dy);\n        }\n    }\n    //color归一化\n    fragColor = vec4(color/float(AA*AA),1.);\n}","name":"Image","description":"","type":"image"}]}
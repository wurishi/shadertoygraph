{"ver":"0.1","renderpass":[{"outputs":[{"channel":0,"id":"4dfGRr"}],"inputs":[],"code":"// Original shader by Yohei Nishitsuji (https://x.com/YoheiNishitsuji/status/1865218967083847886)\n// Adapted for Shadertoy\n\n// 3D Rotation Matrix Generation\nmat3 rotate3D(float angle, vec3 axis){\n    vec3 a = normalize(axis);\n    float s = sin(angle);\n    float c = cos(angle);\n    float r = 1.0 - c;\n    return mat3(\n        a.x * a.x * r + c,\n        a.y * a.x * r + a.z * s,\n        a.z * a.x * r - a.y * s,\n        a.x * a.y * r - a.z * s,\n        a.y * a.y * r + c,\n        a.z * a.y * r + a.x * s,\n        a.x * a.z * r + a.y * s,\n        a.y * a.z * r - a.x * s,\n        a.z * a.z * r + c\n    );\n}\n\n// HSV to RGB color conversion\nvec3 hsv(float h, float s, float v){\n    vec4 t = vec4(1.0, 2.0/3.0, 1.0/3.0, 3.0);\n    vec3 p = abs(fract(vec3(h) + t.xyz) * 6.0 - vec3(t.w));\n    return v * mix(vec3(t.x), clamp(p - vec3(t.x), 0.0, 1.0), s);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    vec2 r = iResolution.xy;\n    vec2 FC = fragCoord.xy;\n    float t = iTime;\n    vec4 o = vec4(0.0, 0.0, 0.0, 1.0);\n\n    // Implements a form of Distance Estimated Ray Marching (DE-RM)\n    // with 99 iterations for detailed surface generation\n    float i = 0.0;\n    float g = 0.0;\n    float q = 0.0;\n    float s = 0.0;\n    \n    for(int j = 0; j < 99; j++){\n        // Initial ray setup with screen-space to world-space transformation\n        // Applies 3D rotation for dynamic movement\n        vec3 p = vec3((FC.xy - 0.5 * r) / r.y * 7.0 + vec2(-2.0, 8.0), g + 4.0) * rotate3D(sin(t * 0.5) * 0.005 - 1.8, vec3(0.0, 9.0, -1.0));\n        \n        s = 1.8; // Initial scale factor for the fractal\n\n        // Inner loop: Mandelbulb-inspired fractal iteration\n        // Creates a modified Mandelbulb fractal using absolute value operations\n        for(int k = 0; k < 19; k++){\n            q = 7.1 / dot(p, p * 0.5);\n            p = vec3(0.05, 4.0, -1.0) - abs(abs(p) * q - vec3(3.1, 4.0, 2.9));\n            s *= q;\n        }\n        \n        // Accumulate geometric features\n        // g accumulates the y-component weighted by the inverse scale\n        // This creates a form of ambient occlusion effect\n        g += p.y / s;\n        \n        // Final scale adjustment using logarithmic compression\n        // This creates a non-linear depth effect and helps prevent overflow\n        s = log(s) / exp(q);\n\n        o.rgb += 0.01 - hsv(0.1, g * 0.013, s / 200.0);\n        i += 1.0;\n    }\n\n    fragColor = o;\n}","name":"Image","description":"","type":"image"}],"flags":{"mFlagVR":false,"mFlagWebcam":false,"mFlagSoundInput":false,"mFlagSoundOutput":false,"mFlagKeyboard":false,"mFlagMultipass":false,"mFlagMusicStream":false},"info":{"id":"XfKfDy","date":"1734416155","viewed":1235,"name":"simulated reality -c-","username":"YoheiNishitsuji","description":"“simulated reality -c-” is the climax how GLSL can simulate the world we optically recognize.","likes":42,"published":3,"flags":0,"usePreview":0,"tags":["simulatedreality","simulationhypothesis"],"hasliked":0,"parentid":"","parentname":""}}
{"ver":"0.1","info":{"id":"X3tGWH","date":"1716427067","viewed":74,"name":"Drawing Stars","username":"GarlicGraphix","description":"Drawing Stars\n\nInspired by the way CRT tvs display images","likes":2,"published":1,"flags":32,"usePreview":0,"tags":["stars","drawing"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n    // Get pixel colour from iChannel0\n    vec3 col = texture(iChannel0, uv).rgb*0.7;\n    // Gamma correction\n    col = pow(col, vec3(1.0/2.2));\n\n    // Output to screen\n    fragColor = vec4(col,1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"#define BPM 60.0\n\nconst int VC = 10;\nconst vec2 vecs[VC] = vec2[](\n    vec2(0.5, 1.0),\n    vec2(0.6, 0.6),\n    vec2(1.0, 0.6),\n    vec2(0.7, 0.4),\n    vec2(0.8, 0.0),\n    vec2(0.5, 0.3),\n    vec2(0.2, 0.0),\n    vec2(0.3, 0.4),\n    vec2(0.0, 0.6),\n    vec2(0.4, 0.6)\n);\n\nmat2 rot2D(float angle) {\n    float c = cos(angle);\n    float s = sin(angle);\n    \n    return mat2(c, -s, s, c);\n}\n\nfloat lineSegment( vec2 a, vec2 b, vec2 p, float w ) {\n    vec2 ba = b - a;\n    vec2 pa = p - a;\n\n    float h = clamp(dot(pa, ba) / dot(ba, ba), 0.0, 1.0);\n    vec2 cp = a + h * ba;\n\n    float d = length(p - cp);\n\n    if (d < w) {\n        return 1.0;\n    } else {\n        return 0.0;\n    }\n\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    float bpm = BPM/60.0;\n    vec2 uv = fragCoord/iResolution.y*2.-1.;\n    vec2 absUV = uv;\n    uv.x -= 0.85;\n    uv *= rot2D(iTime*0.4*bpm);\n    float p = fract(iTime*10.0*bpm/float(VC))*float(VC);\n\n    int c = int(floor(p));\n    int n = (c+1)%VC;\n    vec2 d = vecs[n]-vecs[c];\n    vec2 r = vecs[c]+fract(p)*d;\n    vec2 t = r-0.2*d;\n    \n    // Snap ray to nearest vert\n    if (length(r-vecs[n]) <= 0.15*bpm) {\n        r = vecs[n];\n    }\n    if (length(t-vecs[c]) <= 0.15*bpm) {\n        t = vecs[c];\n    }\n    uv = fract(uv)-0.5;\n    r-=0.5;\n    t-=0.5;\n    r*= rot2D(iTime*0.8*bpm);\n    t*=rot2D(iTime*0.8*bpm);\n    vec3 col = 0.5 + 0.5*cos(iTime*.1*bpm+absUV.xyx+vec3(0,2,4));\n    col *= lineSegment(r, t, uv, 0.01);\n    \n    vec3 pCol = texture(iChannel0,fragCoord/iResolution.xy).rgb;\n    vec3 bgCol = texture(iChannel0,fragCoord*0.4/iResolution.xy).rgb;\n    col = clamp(col + (0.995-fract(iTime*bpm)*0.05)*pCol, 0.0, 1.0);\n    if (fract(iTime*bpm) <= 0.02) {\n        col += 0.25*bgCol;\n    }\n\n    // Output to screen\n    fragColor = vec4(col,1.0);\n    \n}","name":"Buffer A","description":"","type":"buffer"}]}
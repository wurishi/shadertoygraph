{"ver":"0.1","info":{"id":"4tVSWG","date":"1485701006","viewed":453,"name":"Spatial Recurrent Neuralnet","username":"public_int_i","description":"Spatial recurrent neural net attempting to match soundcloud song, bars shown is difference between neural network and soundcloud song, click to show neural network.","likes":11,"published":1,"flags":32,"usePreview":0,"tags":["net","neural","recurrent","spatial"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//Ethan Alexander Shulman 2017\n\n//Bars shown is loss/difference between neural network and soundcloud song, \n//click to show neural network.\n\n//Neural network confined by space, neurons only connect to other neurons local to them(up, up-right, right, etc...).\n//Backward connections make the neural network recurrent.\n\n//In this example the neural network is trained to match the soundcloud song.\n\n\n\n\n//generate seed from current iDate.w\nfloat timeSeed() {\n    float tseed = floor(iDate.w);\n    return fract(tseed*.73624+fract(iDate.w-tseed*.0928275)*1974.3252+float(iFrame)*.98726);\n}\n\n//random float3 with values from 0-1 seeded from float3\nvec3 hash33(vec3 p) {\n\treturn fract(abs(cos(p*.19487)*9284.3459 + cos(p.zxy*29.97612)*37.92384));\n}\n\n//random float from 0-1 seeded from float3\nfloat hash13(vec3 s) {\n\treturn fract(abs(cos(dot(s, vec3(7, 157, 113))))*43758.5453);\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n    \n    \n\n    \n    if (iMouse.w > 0.) {\n        //show neuralnet forward-propagation        \n\t\tfragColor = abs(texture(iChannel1, uv));\n        \n        //show neuralnet back-propagation\n        //fragColor = abs(texture(iChannel0, uv));\n    } else {\n                    //dithered average\n        /*\n\t\tif (hash13(vec3(uv,timeSeed())) < 0.95) {\n            discard;\n            return;\n        }\n*/\n        \n        //show difference between soundcloud and neural net\n        fragColor = vec4(abs(texture(iChannel0,vec2(uv.x,1.)).x));\n        \n        //show neural net output\n        //fragColor = vec4(texture(iChannel1,vec2(uv.x,1.)).x);\n    \n    \t//show actual soundcloud\n        //fragColor = vec4(texture(iChannel1,vec2(uv.x,1.)).x-texture(iChannel0,vec2(uv.x,1.)).x);\n    }\n    \n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//Ethan Alexander Shulman 2017\n\n\n//Buf A - Neural network weights/bias data.\n\n\n\nconst float LEARNING_RATE = 0.3,\n    \t\tMAX_SHIFT = 1.0;\n\n\n\n//generate seed from current iDate.w\nfloat timeSeed() {\n    float tseed = floor(iDate.w);\n    return fract(tseed*.73624+fract(iDate.w-tseed*.0928275)*1974.3252+float(iFrame)*.98726);\n}\n\n//random float3 with values from 0-1 seeded from float3\nvec3 hash33(vec3 p) {\n\treturn fract(abs(cos(p*.19487)*9284.3459 + cos(p.zxy*29.97612)*37.92384));\n}\n\n//random float from 0-1 seeded from float3\nfloat hash13(vec3 s) {\n\treturn fract(abs(cos(dot(s, vec3(7, 157, 113))))*43758.5453);\n}\n\n//encode fixed3(clamped -10-10) to hdr float\nfloat encodeVec3(vec3 c) {\n    c = c*0.05+0.5;\n    \n\treturn floor(c.x*255.) / 256. +\n\t\tfloor(c.y*255.) +\n\t\tfloor(c.z*255.)*256.;\n}\n//decode hdr float to fixed3\nvec3 decodeVec3(float v) {\n\tfloat q = v;\n\tvec3 c;\n\n\tc.z = floor(q / 256.0);\n\tq -= c.z*256.0;\n\n\tc.y = floor(q);\n\tq -= c.y;\n\n\tc.x = floor(q*256.0);\n    \n    c /= 255.0;\n    c = c*20.0-10.0;\n\treturn c;\n}\n\nfloat getNeuronDeriv(vec2 ncoord) {\n    if (min(ncoord.x, ncoord.y) < 0. ||\n        max(ncoord.x-iResolution.x, ncoord.y-iResolution.y) > 0.) return 0.;\n    \n    return texture(iChannel2, ncoord/iResolution.xy).x;\n}\nfloat getNeuronState(vec2 ncoord) {\n    if (min(ncoord.x, ncoord.y) < 0. ||\n        max(ncoord.x-iResolution.x, ncoord.y-iResolution.y) > 0.) return 0.;\n    \n    return texture(iChannel1, ncoord/iResolution.xy).x;\n}\n\n\nfloat apDeriv(float d) {\n    return (-LEARNING_RATE*d);//sqrt(d*d+1e-4);\n}\n\n\nconst float WEIGHT_SCALE = 0.2,\n    \t\tFORWARD_WEIGHT_BIAS = 0.5;\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n   float tseed = timeSeed();\n\n    if (iFrame < 10) {\n        //first frame init neural net       \t        \n        float w0 = hash13(vec3(uv, tseed))*WEIGHT_SCALE,\n            w1 = hash13(vec3(uv, tseed+0.02893))*WEIGHT_SCALE+FORWARD_WEIGHT_BIAS,\n            w2 = hash13(vec3(uv, tseed+0.098))*WEIGHT_SCALE,\n            w3 = hash13(vec3(uv, tseed+0.192))*WEIGHT_SCALE,\n            w4 = hash13(vec3(uv, tseed+0.134))*WEIGHT_SCALE,\n            w5 = hash13(vec3(uv, tseed+0.2337))*WEIGHT_SCALE,\n            w6 = hash13(vec3(uv, tseed+0.2988))*WEIGHT_SCALE,\n            w7 = hash13(vec3(uv, tseed+0.3734))*WEIGHT_SCALE,\n            w8 = hash13(vec3(uv, tseed+0.449))*WEIGHT_SCALE,\n            b0 = 0.;//hash13(vec3(uv, tseed+0.5));\n        \n        fragColor = vec4(encodeVec3(vec3(w0,w1,w2)),\n                         encodeVec3(vec3(w3,w4,w5)),\n                         encodeVec3(vec3(w6,w7,w8)),\n                         b0);\n    \treturn;\n    }\n    \n    //wait for first propagation\n    if (iFrame < 60) {\n        discard; return;\n    }\n    \n    \n    //training\n    vec4 nd = texture(iChannel0, fragCoord/iResolution.xy);\n    vec3 w012 = decodeVec3(nd.x),\n         w345 = decodeVec3(nd.y),\n         w678 = decodeVec3(nd.z);\n    \n    float weights[9];\n    weights[0] = w012.x;\n    weights[1] = w012.y;\n    weights[2] = w012.z;\n    \n    weights[3] = w345.x;\n    weights[4] = w345.y;\n    weights[5] = w345.z;\n    \n    weights[6] = w678.x;\n    weights[7] = w678.y;\n    weights[8] = w678.z;\n    \n        \n    float bderiv = clamp(getNeuronDeriv(fragCoord),-1.,1.);\n    \n    float shiftsum = apDeriv(bderiv);\n    nd.w = clamp(nd.w+shiftsum,-1.,1.);\n    for (int i = 0; i < 9; i++) {\n        vec2 xy = vec2(mod(float(i),3.)-1.,\n                                           float(i/3)-1.),\n            nc = fragCoord+xy;\n                        \n        float aderiv = apDeriv(bderiv*getNeuronState(nc));\n        shiftsum += abs(aderiv);\n        weights[i] = clamp(weights[i]+aderiv, -1., 1.);\n    }\n\n    fragColor = vec4(encodeVec3(vec3(weights[0],weights[1],weights[2])),\n                         encodeVec3(vec3(weights[3],weights[4],weights[5])),\n                         encodeVec3(vec3(weights[6],weights[7],weights[8])),\n                         nd.w);\n}","name":"Buf A","description":"","type":"buffer"},{"inputs":[{"id":"4sXGRr","filepath":"/media/a/48e2d9ef22ca6673330b8c38a260c87694d2bbc94c19fec9dfa4a1222c364a99.mp3","previewfilepath":"/media/ap/48e2d9ef22ca6673330b8c38a260c87694d2bbc94c19fec9dfa4a1222c364a99.mp3","type":"music","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"//Ethan Alexander Shulman 2017\n\n//Buf B - Neural network forward propagation.\n\n\n#define SLOW 1\n\n\n\n//encode fixed3(clamped -10-10) to hdr float\nfloat encodeVec3(vec3 c) {\n    c = c*0.05+0.5;\n    \n\treturn floor(c.x*255.) / 256. +\n\t\tfloor(c.y*255.) +\n\t\tfloor(c.z*255.)*256.;\n}\n//decode hdr float to fixed3\nvec3 decodeVec3(float v) {\n\tfloat q = v;\n\tvec3 c;\n\n\tc.z = floor(q / 256.0);\n\tq -= c.z*256.0;\n\n\tc.y = floor(q);\n\tq -= c.y;\n\n\tc.x = floor(q*256.0);\n    \n    c /= 255.0;\n    c = c*20.0-10.0;\n\treturn c;\n}\n\nfloat activationFunction(float v) {\n    return clamp(sin(v), 0., 1.);\n}\n\n\nfloat getNeuronState(vec2 ncoord) {\n    if (min(ncoord.x, ncoord.y) < 0. ||\n        max(ncoord.x-iResolution.x, ncoord.y-iResolution.y) > 0.) return 0.;\n    \n    return texture(iChannel2, ncoord/iResolution.xy).x;\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    if (fragCoord.y < 1.5) {\n        fragColor = texture(iChannel0, vec2(fragCoord.x/iResolution.x,0.));\n        return;\n    }\n    \n    if (iFrame < 10) {\n        //first frame init\n        fragColor = vec4(0.);\n        return;\n    }\n    \n    vec4 nd = texture(iChannel1, fragCoord/iResolution.xy);\n    vec3 w012 = decodeVec3(nd.x),\n         w345 = decodeVec3(nd.y),\n         w678 = decodeVec3(nd.z);\n    \n    float weights[9];\n    weights[0] = w012.x;\n    weights[1] = w012.y;\n    weights[2] = w012.z;\n    \n    weights[3] = w345.x;\n    weights[4] = w345.y;\n    weights[5] = w345.z;\n    \n    weights[6] = w678.x;\n    weights[7] = w678.y;\n    weights[8] = w678.z;\n    \n    float v = nd.w;\n    for (int i = 0; i < 9; i++) {\n        vec2 xy = vec2(mod(float(i),3.)-1.,\n                       float(i/3)-1.);\n        \n        //if ((fragCoord.y > iResolution.y-1.1 && xy.y > -1.) || xy.y > 0.) continue;//propagate +y direction only\n        v += getNeuronState(fragCoord+xy)*weights[i];\n    }\n    \n    //last state stack\n    vec4 ns = texture(iChannel2, fragCoord/iResolution.xy);\n    ns.yzw = ns.xyz;\n    ns.x = activationFunction(v);\n    fragColor = ns;\n}","name":"Buf B","description":"","type":"buffer"},{"inputs":[{"id":"4sXGRr","filepath":"/media/a/48e2d9ef22ca6673330b8c38a260c87694d2bbc94c19fec9dfa4a1222c364a99.mp3","previewfilepath":"/media/ap/48e2d9ef22ca6673330b8c38a260c87694d2bbc94c19fec9dfa4a1222c364a99.mp3","type":"music","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"//Ethan Alexander Shulman 2017\n\n//Buf C - Neural network back propagation.\n\n\n\nfloat desiredOutput(float x) {\n    return texture(iChannel0, vec2(x,0.)).x;\n}\n\n\n\n//encode fixed3(clamped -10-10) to hdr float\nfloat encodeVec3(vec3 c) {\n    c = c*0.05+0.5;\n    \n\treturn floor(c.x*255.) / 256. +\n\t\tfloor(c.y*255.) +\n\t\tfloor(c.z*255.)*256.;\n}\n//decode hdr float to fixed3\nvec3 decodeVec3(float v) {\n\tfloat q = v;\n\tvec3 c;\n\n\tc.z = floor(q / 256.0);\n\tq -= c.z*256.0;\n\n\tc.y = floor(q);\n\tq -= c.y;\n\n\tc.x = floor(q*256.0);\n    \n    c /= 255.0;\n    c = c*20.0-10.0;\n\treturn c;\n}\n\n\n\nfloat getNeuronState(vec2 ncoord) {\n    if (min(ncoord.x, ncoord.y) < 0. ||\n        max(ncoord.x-iResolution.x, ncoord.y-iResolution.y) > 0.) return 0.;\n    \n    return texture(iChannel2, ncoord/iResolution.xy).x;\n}\n\nfloat getNeuronLastState(vec2 ncoord) {\n    if (min(ncoord.x, ncoord.y) < 0. ||\n        max(ncoord.x-iResolution.x, ncoord.y-iResolution.y) > 0.) return 0.;\n    \n    return texture(iChannel2, ncoord/iResolution.xy).y;\n}\n\nfloat getNeuronDeriv(vec2 ncoord) {\n    if (min(ncoord.x, ncoord.y) < 0. ||\n        max(ncoord.x-iResolution.x, ncoord.y-iResolution.y) > 0.) return 0.;\n    \n    return texture(iChannel3, ncoord/iResolution.xy).x;\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{    \n    if (iFrame < 10) {\n        fragColor = vec4(0.);\n        return;\n    }\n    if (fragCoord.y > iResolution.y-1.) {\n        //source derivative\n        fragColor = vec4(getNeuronState(fragCoord)-desiredOutput(fragCoord.x/iResolution.x));\n        return;\n    }\n    \n    vec4 nd = texture(iChannel1, fragCoord/iResolution.xy);\n    vec3 w012 = decodeVec3(nd.x),\n         w345 = decodeVec3(nd.y),\n         w678 = decodeVec3(nd.z);\n    \n    float weights[9];\n    weights[0] = w012.x;\n    weights[1] = w012.y;\n    weights[2] = w012.z;\n    \n    weights[3] = w345.x;\n    weights[4] = w345.y;\n    weights[5] = w345.z;\n    \n    weights[6] = w678.x;\n    weights[7] = w678.y;\n    weights[8] = w678.z;\n    \n    \n        vec4 ld = texture(iChannel3, fragCoord/iResolution.xy);\n\n    float v = 0.;\n    for (int i = 0; i < 9; i++) {        \n        vec2 xy = vec2(mod(float(i),3.)-1.,\n                          float(i/3)-1.);\n                \n        vec2 nc = fragCoord+xy;\n        float state = getNeuronLastState(nc),\n            nd = getNeuronDeriv(nc)/(1.+(1.-xy.y));\n        v += (1.0-state*state)*nd*weights[i];\n    }\n    \n    \n    ld.yzw = ld.xyz;\n    const float DERIV_RANGE = 1.0;\n    ld.x = clamp(v,-DERIV_RANGE,DERIV_RANGE);\n    fragColor = ld;\n}","name":"Buf C","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"4fKXRK","date":"1715459474","viewed":230,"name":"Monte-Carlo sampling methods","username":"ukeshet","description":"Pause+click anywhere to see the outcome of 1 sample/pixel with:\n1. Stratified sampling (top right of crosshairs);\n2. Importance sampling (effective; bottom right);\n3. Unbiased sampling (left of crosshair).\nReplay for split scene accumulation.","likes":10,"published":1,"flags":32,"usePreview":1,"tags":["3d","raytracing","raymarching","reflection","sampling","montecarlo"],"hasliked":0,"parentid":"dssXRj","parentname":"Photorealism"},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Monte Carlo sampling: stratified vs. (effective) importance vs. unbaised.\n// Demo for ICP course, by ukeshet.\n//\n// Scene based on Photorealism by Poisson: https://www.shadertoy.com/view/dssXRj\n//\n// Pause + click screen to see different outcomes of Mo (default 1) sample/pixel:\n// Stratified sampling (default + crosshairs upper right) reduces speckle noise.\n// Importance sampling (bottom right) highlights bright regions. \n// Unbiased sampling (left of crosshairs) converges slowly. \n// Replay for accumulation of scene split to different samplings.\n//\n// Sampling is based on presampling Mn*Mn (default 2*2) sub-pixels per pixel. \n// Namely, Mo samples/pixel distributed among Mn*Mn sub-pixels in proprtional to: \n// ~ standard deviation, for stratified sampling;\n// ~ 'brightness' (luminance formula), for effective 'importance sampling'.\n// ~ 1, for normal (unbiased) sampling;\n//\n// The 'importance sampling' demostrated here is only effective, as we vary sample \n// numbers rather than the probability distributions. \n// Raise Mn=subpixels/pixel (to 3 or more; Common line 2) to better see the effect \n// of importance sampling; however, the outcome would be slow. \n//\n// Superceded by the much faster Monte-Carlo sampling 2, https://www.shadertoy.com/view/XcKXR3\n// _______________________________________________________________________________\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec4 data = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    vec3 col = data.rgb/data.a;        // normalize by accumulated samples\n    col = pow(col,vec3(.4545));        // gamma correction\n    col = ACES(col);                   // tonemapping\n    vec2 p = fragCoord/iResolution.xy; // vignette\n    col *= .5+.5*pow(16. * p.x*p.y*(1.-p.x)*(1.-p.y), .1);\n    fragColor = vec4(col,1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"XsfGRn","filepath":"/media/a/1f7dca9c22f324751f2a5a59c9b181dfe3b5564a04b724c657732d0bf09c99db.jpg","previewfilepath":"/media/ap/1f7dca9c22f324751f2a5a59c9b181dfe3b5564a04b724c657732d0bf09c99db.jpg","type":"texture","channel":2,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdX3zn","filepath":"/media/a/488bd40303a2e2b9a71987e48c66ef41f5e937174bf316d3ed0e86410784b919.jpg","previewfilepath":"/media/ap/488bd40303a2e2b9a71987e48c66ef41f5e937174bf316d3ed0e86410784b919.jpg","type":"cubemap","channel":1,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Buffer A\n// mainImage pre-samples Mn*Mn (=2*2 default) subpixels, then takes Mo (=1 default) \n// samples according to pre-inferred weights. \n// Presampled pixels are wastefully overwhelmed to highlight sampling comparison.\n//\n// Initial scene from Photorealism by Poisson (https://www.shadertoy.com/view/dssXRj).\n// Some adjustments (bowl, smaller curvatures, ...) to bring out different proeperties.\n// _______________________________________________________________________________\n\n\n// plane intersection function\n// thanks to iq: https://iquilezles.org/articles/intersectors/\nfloat plaIntersect(vec3 ro, vec3 rd, vec3 n, float h, vec3 mat, int type, vec2 v, \n                   float tmax, inout vec3 outn, inout vec3 outmat, inout int outtype, inout vec2 outv) {\n    float t = (h-dot(n,ro))/dot(rd,n);\n    if (t>.0001 && t<tmax) {\n\t\toutn = n;\n        vec3 p = ro + rd*t;\n        outmat = pow(texture(iChannel2, p.xz*.5).rgb,vec3(2.2)); // wood texture\n        outtype = type;\n        outv = v;\n\t    return t;\n    }\n    return tmax;\n}\n\n\n// scene intersection function\n// n is the normal, mat is the object albedo, type is the material type\n// v is the material propreties: \n//  ROUGH -> rougness and reflectance\n//  DIELECTRIC -> refraction index\nfloat intersect(vec3 ro, vec3 rd, out vec3 n, out vec3 mat, out int type, out vec2 v) {\n    float t = 1e10;\n    \n    t = plaIntersect(ro, rd, vec3(0,1,0), -1., vec3(1), ROUGH, vec2(1,-.5), t, n, mat, type, v);\n    \n    t = sphIntersect(ro, rd, vec3(-1.2,-.7,-1.7), .3, vec3(1), DIELECTRIC, vec2(1.5,0), t, n, mat, type, v); // watery\n    t = sphIntersect(ro, rd, vec3(0.4,-.5,-2.0), .5, vec3(.2,.5,1), ROUGH, vec2(1,.03), t, n, mat, type, v); // bluish\n    t = sphIntersect(ro, rd, vec3(1.2,-.55,-2.65), .45, vec3(1,.3,.1), ROUGH, vec2(1,.005), t, n, mat, type, v); // orange\n    t = sphIntersect(ro, rd, vec3(-1.9,-.7,-.6), .3, vec3(1,.4,.2), ROUGH, vec2(0,-1e10), t, n, mat, type, v); // metallic\n    t = sphIntersect(ro, rd, vec3(-1.5,-.75,-1.1), .25, vec3(.6,.4,.7), DIELECTRIC, vec2(1.4,0), t, n, mat, type, v); // pinkish\n    t = sphIntersect(ro, rd, vec3(-2.4,-.75,-1.1), .25, 3.*vec3(.5,.5,.1), DIELECTRIC, vec2(1.4,0), t, n, mat, type, v); // yellow\n        \n    t = raymarch(ro, rd, t, n, mat, type, v);\n  \n    return t;\n}\n\n\n// rendering function\nvec3 render(vec3 ro, vec3 rd) {\n    vec3 col = vec3(1);\n    \n    for (int i=0; i<6; i++) { // ray bounces: reduced 12 to 6\n        vec3 n, mat; int type; vec2 v;\n        float t = intersect(ro, rd, n, mat, type, v);\n        if (t>=1e10) {\n            // hdr skybox\n            vec3 sky = pow(textureLod(iChannel1, rd, 0.).rgb,vec3(4));\n            sky = 8.*pow(sky,vec3(.9,.9,1));\n            return col*sky;\n        } else {\n            vec3 p = ro + rd*t; // hit point\n            ro = p;\n            \n            float fre = dot(rd, n); // fresnel\n            if (type==ROUGH) {\n                vec3 rd0 = reflect(rd, n); // reflected ray\n                vec3 rd1 = cosineDirection(n); // diffuse ray\n                \n                float refProb = v.y + (1.-v.y)*pow(1.+fre, 5.);\n                if (hash1()<refProb) {\n                    rd = rd0;\n                } else {\n                    rd = normalize(mix(rd0, rd1, v.x));\n                    col *= mat;\n                }\n            } else if (type==DIELECTRIC) { // transparent\n                float cosine;\n                if (fre>0.) {\n                    cosine = sqrt(1.-v.x*v.x*(1.-fre*fre));\n                } else {\n                    cosine = -fre;\n                }\n                float s = sign(fre);\n                vec3 m = -n*s;\n                float i = (.5-.5*s)/v.x+v.x*(.5+.5*s);\n    \n                fre = dot(rd, m);\n                \n                float refProb;\n                // reflected and refracted ray\n                vec3 rd1, rd0 = reflect(rd, n);\n                \n                float h = 1.-i*i*(1.-fre*fre);\n                if (h>0.) {\n                    rd1 = i*(rd - m*fre) - m*sqrt(h); // refraction\n                    \n                    float r0 = (1.-v.x)/(1.+v.x);\n                    r0 = r0*r0;\n                    refProb = r0 + (1.-r0)*pow((1.-cosine),5.);\n                } else {\n                    refProb = 1.;\n                }\n        \n                if (hash1()<refProb) {\n                    rd = rd0;\n                } else {\n                    ro -= m*.0009; // bump the point\n                    rd = rd1;\n                    col *= mat;\n                }\n            }\n        }\n    }\n    return vec3(0); // return black if the ray stops\n}\n\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{       \n    //#ifdef MOVE_CAMERA\n    if (iMouse.z>0.) {\n        fragColor *= 0.;\n        if (abs(fragCoord.x-iMouse.x)<1. || abs(fragCoord.y-iMouse.y)<1.)\n            fragColor += 1.;\n        return;\n    }\n    //#endif\n\n    int mode = 2;  // Stratified sampling\n    if (fragCoord.x>iMouse.x && fragCoord.y<iMouse.y) \n        mode = 1;  // Importance sampling\n    if (fragCoord.x<iMouse.x) \n        mode -= 2; // Unbiased sampling\n    if (abs(fragCoord.x-iMouse.x)<1. || abs(fragCoord.y-iMouse.y)<1.)\n        mode = 4;  // Crosshairs\n        \n    vec3 tot = vec3(0);\n    for (int i=0; i<SAMPLES; i++) {\n        // init randoms seed\n        seed = float(i)+iTime + dot(sin(fragCoord),vec2(443.712,983.234));\n        seed += hash1()*434.251;\n        \n        vec3 ro, ro0;\n        #ifdef MOVE_CAMERA\n        float an = (-iMouse.x/iResolution.x-.5)*3.141592;\n            ro0 = vec3(8.*sin(an), iMouse.y/iResolution.y*4.-2., 8.*cos(an)); // camera position\n        #else\n        ro0 = vec3(8.*sin(3.8), .3, 8.*cos(3.8)); // camera position\n        #endif\n        vec3 ta = vec3(0,.5,0); // target\n        vec3 n, mat; int type; vec2 v;\n    \n        mat3 ca = setCamera(ro0, ta); // camera matrix\n        vec3 cOff = vec3(uniformVector().xy,0)*.0; // <- change this value for the aperture\n      \n        // depth of field\n        float t = intersect(ro0, normalize(ta - ro0), n, mat, type, v);\n        vec2 of; // AA offset\n        vec3 ren, col=vec3(0);\n\n        //mode = 0;\n        \n        // pre-sample:\n        float len, Map[Mn*Mn], MI2[Mn*Mn];\n        for (int Mj=0;Mj<Mn;Mj++)\n            for (int Mk=0;Mk<Mn;Mk++) {\n                Map[Mj*Mn+Mk]=0.; MI2[Mj*Mn+Mk]=0.;\n                for (int Ml=0;Ml<Mm;Ml++) {\n                    ro=ro0;\n                    seed += hash1()*434.251;\n                    if (mode!=1 && mode !=2)\n                        of = hash2()-.5;\n                    else\n                        of = (vec2(Mj,Mk)+hash2())/float(Mn)-.5; \n                    vec2 p = (fragCoord + of - .5*iResolution.xy) / iResolution.y;\n                    vec3 rd = ca * normalize(vec3(p,1.78)); // ray direction\n                    vec3 fp = ro + rd*t; // focus plane\n                    ro += ca*cOff;\n                    rd = normalize(fp - ro);\n                    ren=render(ro, rd);\n                    col+=ren;\n                    //len=length(ren);\n                    len=dot(ren, vec3(0.2126, 0.7152, 0.0722)); // brightness alternative.\n                    Map[Mj*Mn+Mk] += len;\n                    MI2[Mj*Mn+Mk] += dot(len,len);\n                }\n            }\n\n        // Evaluate # of refinement samples needed in each subpixel.\n        float MoW=100000.; // weight to overwhelm pre-sampling\n        float ImpPL=1.;\n        int Mn1=Mn;\n        int RefN=Mo, RefNN[Mn*Mn]; float RefNNf[Mn*Mn]; // # of samples per pixel and subpixel.\n        if (mode!=1 && mode!=2) \n            Mn1=1; // no need for subpixels.\n        else {\n            float ImpSamp=0., StrSamp=0.;\n            for (int Mj=0;Mj<Mn;Mj++)\n                for (int Mk=0;Mk<Mn;Mk++) { // compute weights\n                    len = Map[Mj*Mn+Mk];\n                    ImpSamp += pow(abs(len),ImpPL);\n                    StrSamp += sqrt(MI2[Mj*Mn+Mk]-len*len);\n                    RefNN[Mj*Mn+Mk] = 0;\n                }\n            for (int Mj=0;Mj<Mn;Mj++)\n                for (int Mk=0;Mk<Mn;Mk++) { // estimate # samples in each sub-pixel \n                    len = Map[Mj*Mn+Mk];\n                    if (mode==1)\n                        RefNNf[Mj*Mn+Mk] = pow(abs(len),ImpPL)*float(Mo)/float(Mn*Mn)/ImpSamp; \n                    if (mode==2)\n                        RefNNf[Mj*Mn+Mk] = sqrt(MI2[Mj*Mn+Mk]-len*len)*float(Mo)/float(Mn*Mn)/StrSamp; \n                }   \n            if (Mo>4) // then the above should be good enough for a comparison\n                for (int Mj=0;Mj<Mn;Mj++)\n                    for (int Mk=0;Mk<Mn;Mk++) \n                        RefNN[Mj*Mn+Mk] = int(round(RefNNf[Mj*Mn+Mk]));\n            else { // careful: distribute exactly Mo samples total among all subpixels.\n                for (int q=0; q<RefN; q++) { // Greedy distribution\n                    float maxf = -7.e19;\n                    for (int Mj=0;Mj<Mn;Mj++)\n                        for (int Mk=0;Mk<Mn;Mk++) \n                            maxf = max(maxf, RefNNf[Mj*Mn+Mk]); \n                    int fnd=0;\n                    for (int Mj=0;Mj<Mn && fnd==0; Mj++)\n                        for (int Mk=0;Mk<Mn && fnd==0; Mk++) \n                            if (RefNNf[Mj*Mn+Mk] == maxf) { // present subpixel is best\n                                RefNN[Mj*Mn+Mk]++; fnd=1; \n                                if (mode==1)\n                                    RefNNf[Mj*Mn+Mk] -= ImpSamp/float(Mn*Mn); \n                                if (mode==2)\n                                    RefNNf[Mj*Mn+Mk] -= StrSamp/float(Mn*Mn);                                 \n                             }\n                }\n            }\n        }\n\n        float cnt=0.;\n        for (int Mj=0;Mj<Mn1;Mj++)\n            for (int Mk=0;Mk<Mn1;Mk++) {  \n                if (mode==1 || mode==2)\n                    RefN = RefNN[Mj*Mn+Mk] ; \n                for (int Ml=0;Ml<RefN;Ml++) {\n                    ro=ro0;\n                    seed += hash1()*334.251;\n                    if (mode!=1 && mode!=2) \n                        of = hash2()-.5; \n                    else\n                        of = (vec2(Mj,Mk)+hash2())/float(Mn1)-.5; \n                    vec2 p = (fragCoord + of - .5*iResolution.xy) / iResolution.y;\n                    vec3 rd = ca * normalize(vec3(p,1.78)); // ray direction\n                    vec3 fp = ro + rd*t; // focus plane\n                    ro += ca*cOff;\n                    rd = normalize(fp - ro);\n                    col += render(ro, rd)*MoW/float(RefN);\n                    cnt += MoW/float(RefN);\n                }\n            }        \n\n        col/=(float(Mn*Mn*Mm)+cnt);\n        tot += col;\n    }\n    tot /= float(SAMPLES);\n    \n    // accumulate\n    vec4 data = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    data += vec4(tot,1);\n\n    if (mode==4) // crosshairs\n        data*=0.;\n\n    // output\n    fragColor = data;\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"// Monte-Carlo sampling\n#define Mn 2 // # of subpixels in each direction. Increase to 3 to see the effect of importance sampling.\n#define Mm 4 // # of test samples per subpixel. \n#define Mo 1 // # of samples per pixel (not subpixel)\n\n\n//#define MOVE_CAMERA\n#define SAMPLES 1 // renders per frame\n#define S smoothstep\n\n// materials indices\n#define ROUGH 1 // metal and lambertian\n#define DIELECTRIC 2 // glass\n\nfloat seed; // randoms seed\n\n// hash functions by Poisson\nfloat hash1() {return fract(sin(seed+=.1)*4561.7564);}\n\nvec2 hash2() {return fract(sin((seed+=1.1)*vec2(8472.5636,9854.4213)));}\n\nvec2 hash2b() {return fract(sin((seed+=1.1)*vec2(8472.5636,9854.4213)));}\n\nvec3 hash3() {return fract(sin(seed+=.1)*vec3(7653.1285,6912.8512,5914.7134));}\n\n// random normalized vector\nvec3 uniformVector() {\n    vec3 v = hash3()*2.-1.;\n    return normalize(v);\n}\n\n// sphere intersection function\n// thanks to iq: https://iquilezles.org/articles/intersectors/\nfloat sphIntersect(vec3 ro, vec3 rd, vec3 ce, float ra, vec3 mat, int type, vec2 v,\n                   float tmax, inout vec3 outn, inout vec3 outmat, inout int outtype, inout vec2 outv) {\n    vec3 oc = ro - ce;\n    float b = dot(oc, rd);\n    float c = dot(oc, oc) - ra*ra;\n    float h = b*b - c;\n    if (h<0.) return tmax;\n    \n    h = sqrt(h);\n    float t1 = -b - h;\n    float t2 = -b + h;\n    float t = t1<.0001 ? t2 : t1;\n    if (t>.0001 && t<tmax) {\n        outn = (oc + rd*t)/ra;\n        outmat = mat;\n        outtype = type;\n        outv = v;\n        return t;\n    }\n    return tmax;\n}\n\n\n// torus sdf\nfloat sdTorus(vec3 p, float ra, float rb) {\n    return length(vec2(length(p.xz)-ra,p.y))-rb;\n}\n\n// full torus sdf\nfloat sdTorusF(vec3 p, float ra, float rb) {\n    return length(max(vec2(length(p.xz)-ra,p.y),0.))-rb;\n}\n\n// glass curve\n// https://www.desmos.com/calculator/u9oxcvjhqp\nfloat glassCurve(float x) {\n//    return .1*S(.95,1.,x)+.35*S(.46,.4,x)*S(-1.3,1.1,x);\n    return .2*S(.95,1.,x)+.22*S(.56,.4,x)*S(-1.3,.4,x);\n}\n\n// glass sdf\nfloat sdGlass(vec3 p) {\n    p.y -= 1.;\n    float h = clamp(-p.y*0.6779661017, 0., 1.);\n    return sdTorus(p + vec3(0,1.475,0)*h, glassCurve(h), .02);\n}\n\n// full glass sdf\nfloat sdGlassF(vec3 p) {\n    p.y -= 1.;\n    float h = clamp(-p.y*0.6779661017, 0., 1.);\n    return sdTorusF(p + vec3(0,1.475,0)*h, glassCurve(h)-.022, 0.);\n}\n\n// bottle curve\n// https://www.desmos.com/calculator/nftvjzacqh\nfloat bottleCurve(float x) {\n    return .07+.12*pow(S(.2,.57,x),1.2);\n}\n\n// bottle sdf\nfloat sdBottle(vec3 p) {\n    p.y -= 1.;\n    float h = clamp(-p.y*0.6779661017, 0., 1.);\n    return sdTorus(p + vec3(0,1.475,0)*h, bottleCurve(h), .025);\n}\n\n// full bottle sdf\nfloat sdBottleF(vec3 p) {\n    p.y -= 1.;\n    float h = clamp(-p.y*0.6779661017, 0., 1.);\n    return sdTorusF(p + vec3(0,1.475,0)*h, bottleCurve(h)-.027, 0.);\n}\n\nfloat bowlCurve(float x) {\n//    return .4*(1.-.3*S(.57,.9,x));\n    return .3*(1.-clamp((x-.999)/.001,0.,1.));\n}\n\n\n// bowl sdf\nfloat sdBowl(vec3 p) {\n    p.y -= 1.;\n    float h = clamp(-p.y*0.6779661017, 0.95, 1.);\n    return sdTorus(p + vec3(0,1.475,0)*h, bowlCurve(h), .03);\n}\n\n// materials indices\n#define MAT_GLASS 0.\n#define MAT_BOTTLE 1.\n#define MAT_WINE 2.\n#define MAT_BOWL 3.\n\n// union of two objects\nvec2 opU(vec2 a, vec2 b) {return a.x<b.x ? a : b;}\n\n// scene sdf\nvec2 map(vec3 p) {\n    vec2 d = vec2(1e10);\n\n    // wine\n    d = opU(d, vec2(max(sdGlassF(p*.5),abs(p.y-1.15+.6)-.4), MAT_WINE));\n    d = opU(d, vec2(max(sdGlassF(p*.5-vec3(-1.4,0,-.0)),abs(p.y-1.08+.0)-.4), MAT_WINE));\n    d = opU(d, vec2(max(sdBottleF((p-vec3(-1.8,.975,1.7))*.25),abs(p.y-1.5+1.2)-1.2), MAT_WINE));    \n\n    // glasses\n    d = opU(d, vec2(sdGlass(p*.5)*.5, MAT_GLASS));\n    d = opU(d, vec2(sdGlass(p*.5-vec3(-1.4,0,-.0))*.5, MAT_GLASS));\n        \n    // bottle\n    d = opU(d, vec2(sdBottle((p-vec3(-1.8,.975,1.7))*.25), MAT_BOTTLE));\n\n    // bowl\n    d = opU(d, vec2(sdBowl((p-vec3(0.8,.975,-2.2))*.25), MAT_BOWL));\n\n    return d;\n}\n\n// normal estimation\nvec3 calcNormal(vec3 p) {\n    float h = map(p).x;\n    const vec2 e = vec2(.0001,0); // epsilon\n    \n    return normalize(h - vec3(map(p-e.xyy).x,\n                              map(p-e.yxy).x,\n                              map(p-e.yyx).x));\n}\n\n// raymarching loop\nfloat raymarch(vec3 ro, vec3 rd, float tmax, inout vec3 outn, inout vec3 outmat, inout int outtype, inout vec2 outv) {\n    float t = 0.; // distance\n    float s = sign(map(ro).x); // inside and outside the surface\n    vec2 h; // scene sdf + material idx;\n    \n    float ttmax = tmax;\n    tmax = min(tmax, 16.);\n    \n    for (int i=0; i<256 && t<tmax; i++) {\n        vec3 p = ro + rd*t;\n        h = map(p); h.x *= s;\n        if (abs(h.x)<.0001) break;\n        t += h.x;\n    }\n    \n    if (t>.0001 && t<tmax) {\n        vec3 p = ro + rd*t; // hit point\n        outn = calcNormal(p);\n        outtype = DIELECTRIC;\n        \n        if (h.y==MAT_GLASS) { // glass\n            outmat = vec3(.99);\n            outv = vec2(1.5,0); // ior 1.5\n        } else if (h.y==MAT_BOTTLE) { // bottle\n            outmat = vec3(.2,.7,.2);\n            outv = vec2(1.4,0); // ior 1.4\n        } else if (h.y==MAT_WINE) { // wine\n            outmat = vec3(.15,0,0);\n            outv = vec2(1.3,0); // ior 1.3\n        }  else if (h.y==MAT_BOWL) { // bowl\n            outmat = vec3(.1,.2,.8);\n            outv = vec2(1.0,0); // ior 1.6\n        }\n        return t;\n    }\n    return ttmax;\n}\n\n\n\n// diffuse BRDF\nvec3 cosineDirection(vec3 n) {\n  \tvec2 r = hash2b();\n    \n\tvec3 u = normalize(cross(n, vec3(0,1,1)));\n\tvec3 v = cross(u, n);\n\t\n\tfloat ra = sqrt(r.y);\n\tfloat rx = ra*cos(2.*3.141592*r.x); \n\tfloat ry = ra*sin(2.*3.141592*r.x);\n\tfloat rz = sqrt(1.-r.y);\n\treturn normalize(rx*u + ry*v + rz*n);\n}\n\n\n// camera function\nmat3 setCamera(vec3 ro, vec3 ta) {\n\tvec3 w = normalize(ta - ro);\n\tvec3 u = normalize(cross(w, vec3(0,1,0)));\n\tvec3 v = cross(u, w);\n    return mat3(u, v, w);\n}\n\n\n// realistic color range\nvec3 ACES(vec3 x) {\n    float a = 2.51;\n    float b =  .03;\n    float c =  2.1;\n    float d =   .7;\n    float e =  .12;\n    return (x*(a*x+b))/(x*(c*x+d)+e);\n}\n\n\n\n","name":"Common","description":"","type":"common"}]}
{"ver":"0.1","renderpass":[{"outputs":[{"channel":0,"id":"4dfGRr"}],"inputs":[{"channel":0,"type":"buffer","id":"4dXGR8","filepath":"/media/previz/buffer00.png","sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}},{"channel":1,"type":"buffer","id":"4sXGR8","filepath":"/media/previz/buffer02.png","sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}},{"channel":2,"type":"texture","id":"Xsf3zn","filepath":"/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"}}],"code":"// oilArt - Image\n//\n// Final shader in the pipeline. Draw thumbnail when resolution is too small\n// or when in sort of preview mode. Fit image to avoid cropping.\n// Increase sharpness and additionally refine edges without introducing ringing.\n// Render decoder's internal state for debugging.\n// \n// Created by Dmitry Andreev - and'2016\n// License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\n#define DO_SHARPEN       1\n#define DO_OILIFY        1\n\n#define DEBUG_DECODER    0\n#define DEBUG_SAMPLERATE 0\n\n//\n\nvoid drawThumbnail(out vec4 fragColor, in vec2 fragCoord)\n{\n    // 3rd order 2D polynomial.\n\n    vec3 c0  = vec3(  0.94,  0.70,  0.43);\n    vec3 c1  = vec3(  0.41,  0.52, -0.06);\n    vec3 c2  = vec3( -1.39, -0.94,  2.21);\n    vec3 c3  = vec3(  0.78,  0.51, -1.62);\n    vec3 c4  = vec3( -0.75, -0.96, -0.79);\n    vec3 c5  = vec3(  6.46, 10.74,  1.49);\n    vec3 c6  = vec3(-11.55,-21.27, -0.07);\n    vec3 c7  = vec3(  5.77, 11.48, -0.64);\n    vec3 c8  = vec3(  1.14,  1.16,  3.35);\n    vec3 c9  = vec3(-11.94,-22.10,-14.41);\n    vec3 c10 = vec3( 23.46, 48.26, 21.20);\n    vec3 c11 = vec3(-12.36,-27.09,-10.25);\n    vec3 c12 = vec3( -0.70, -0.62, -2.90);\n    vec3 c13 = vec3(  5.93, 12.16, 14.62);\n    vec3 c14 = vec3(-11.05,-26.58,-24.21);\n    vec3 c15 = vec3(  5.60, 14.77, 12.52);\n\n    vec2  t = floor(fragCoord / 12.0) * 12.0 / iResolution.xy;\n    float x = t.x;\n    float y = 1.0 - t.y;\n\n    vec3 f = vec3(\n           ( c0 + ( c1 + ( c2 +  c3*x)*x)*x) +\n        y*(( c4 + ( c5 + ( c6 +  c7*x)*x)*x) +\n        y*(( c8 + ( c9 + (c10 + c11*x)*x)*x) +\n        y*( c12 + (c13 + (c14 + c15*x)*x)*x))));\n\n    vec3 clr = smoothstep(0.0, 1.0, f*f*f*f);\n\n    // Playback triangle.\n\n    vec2 tc = fragCoord / iResolution.xy;\n    vec2 p = 1.5 * (tc - 0.5) * vec2(1.0, iResolution.y / iResolution.x);\n    float d = length( p );\n\n    clr = mix(clr, vec3(0), 0.6 * clamp(23.0 - 128.0 * d, 0.0, 1.0));\n    clr = mix(clr, vec3(1), clamp(3.0 - 128.0 * abs(0.5 - d * 3.0), 0.0, 1.0));\n\n    p *= 1.5;\n    p += vec2(0.06, 0);\n\n    float m = dot(p, vec2(2.0, 0.0));\n    m = min(m, dot(p + vec2(0.0, 0.15), vec2(-0.8, 1.0)));\n    m = min(m, dot(p + vec2(0.0,-0.15), vec2(-0.8,-1.0)));\n    m = max(m, 0.0);\n\n    fragColor.rgb = mix(clr, vec3(1.0), vec3(m * 200.0));\n}\n\nvoid oilify3(inout vec2 h[16], float d, vec2 tc, vec2 tc_max)\n{\n    vec3 c = texture(iChannel1, min(tc / iResolution.xy, tc_max)).rgb;\n\n    float luma = dot(c, vec3(0.33));\n    float L = floor(0.5 + luma * 15.0 + d);\n\n    #define H(n) h[n] += L == float(n) ? vec2(luma, 1) : vec2(0);\n\n    H(0)H(1)H(2)H(3)H(4)H(5)H(6)H(7)\n    H(8)H(9)H(10)H(11)H(12)H(13)H(14)H(15)\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    if (iResolution.x < 500.0 || iResolution.y < 280.0)\n    {\n        drawThumbnail(fragColor, fragCoord);\n        return;\n    }\n\n    // Fit image to touch screen from inside.\n\n    vec2 img_res = vec2(496, 279);\n    vec2 res = iResolution.xy / img_res;\n    vec2 img_size = img_res * min(res.x, res.y);\n    vec2 img_org = 0.5 * (iResolution.xy - img_size);\n    vec2 tc = (fragCoord - img_org) / img_size;\n\n    fragColor = texture(iChannel1, tc * img_res / iResolution.xy);\n\n    #if DO_SHARPEN\n    {\n        // Regular high-pass filter to recover some sharpness.\n\n        fragColor *= 8.0;\n        fragColor -= texture(iChannel1, min((tc * img_res + vec2( 1,0)) / iResolution.xy, vec2(img_res) / iChannelResolution[1].xy));\n        fragColor -= texture(iChannel1, min((tc * img_res + vec2(-1,0)) / iResolution.xy, vec2(img_res) / iChannelResolution[1].xy));\n        fragColor -= texture(iChannel1, min((tc * img_res + vec2(0, 1)) / iResolution.xy, vec2(img_res) / iChannelResolution[1].xy));\n        fragColor -= texture(iChannel1, min((tc * img_res + vec2(0,-1)) / iResolution.xy, vec2(img_res) / iChannelResolution[1].xy));\n        fragColor *= 0.25;\n    }\n    #endif\n\n    #if DO_OILIFY\n    {\n        // Additinal edge sharpening assuming it is a painting.\n        // Effect similar to GIMP's Oilify.\n        // Calculate 16 bin histogram for 3x3 neighborhood\n        // and pick averaged color of bin that had most pixels.\n\n        vec2 h[16];\n\n        for (int i = 0; i < 16; i++) h[i] = vec2(0);\n\n        // Add some noise to hide low bin count.\n\n        float d = 0.5 * texture(iChannel2, 0.95 * fragCoord / iChannelResolution[2].xy).x;\n\n        for (int y = -1; y <= 1; y++)\n        {\n            oilify3(h, d, tc * img_res + vec2(-1, y), img_res / iChannelResolution[1].xy);\n            oilify3(h, d, tc * img_res + vec2( 0, y), img_res / iChannelResolution[1].xy);\n            oilify3(h, d, tc * img_res + vec2( 1, y), img_res / iChannelResolution[1].xy);\n        }\n\n        vec2 q = vec2(0);\n\n        #define Q(n) q = h[n].y > q.y ? h[n] : q;\n\n        Q(0)Q(1)Q(2)Q(3)\n        Q(4)Q(5)Q(6)Q(7)\n        Q(8)Q(9)Q(10)Q(11)\n        Q(12)Q(13)Q(14)Q(15)\n\n        vec4 org = texture(iChannel1, tc * img_res / iResolution.xy);\n        float luma = dot(org.rgb, vec3(0.33));\n        vec3 clr = org.rgb - luma + q.x / q.y;\n\n        fragColor.rgb = mix(fragColor.rgb, clr.rgb, 0.3);\n\n        float emb =\n            texture(iChannel2, 0.95 * (fragCoord + vec2(0.5, -0.5)) / iChannelResolution[2].xy).x -\n            texture(iChannel2, 0.95 * (fragCoord - vec2(0.5, -0.5)) / iChannelResolution[2].xy).x;\n\n        fragColor.rgb *= 0.95 + 0.20 * d + 0.1 * emb;\n    }\n    #endif\n\n    // Add black bars around the image when needed.\n\n    fragColor = any(greaterThan(abs(tc - 0.5), vec2(0.5))) ? vec4(0) : fragColor;\n\n    #if DEBUG_DECODER\n    {\n        fragColor = texture(iChannel0, fragCoord.xy / iResolution.xy);\n        if (all(equal(fragColor, vec4(0)))) fragColor = vec4(0.5,0,0,0);\n    }\n    #endif\n\n    #if DEBUG_SAMPLERATE\n    {\n        if (fragCoord.x > iResolution.x - 5.0)\n        {\n            float n = texture(iChannel0, vec2(0.5, 1.5) / iChannelResolution[0].xy).w;\n            fragColor.xyz = mix(fragColor.xyz, vec3(1,0,0), 0.5 * float(fragCoord.y < n * 20.0));\n            fragColor.xyz = mix(fragColor.xyz, vec3(1,0,0), pow(fract(fragCoord.y / 20.0), 8.0));\n        }\n    }\n    #endif\n}\n","name":"Image","description":"","type":"image"},{"outputs":[{"channel":0,"id":"4dXGR8"}],"inputs":[{"channel":0,"type":"musicstream","id":"4dfGD4","filepath":"https://soundcloud.com/user-470401467/st-image-2e","sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}},{"channel":1,"type":"buffer","id":"4dXGR8","filepath":"/media/previz/buffer00.png","sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}}],"code":"// oilArt - Buf A/B\n//\n// Main audio decoder.\n// Buf B is redundant and runs the same code as Buf A but reads slightly delayed\n// audio stream to increase reliability when FPS drops or high sample rate is used.\n//\n// Audio stream is made up of 160 samples long packets that come in buckets of 6\n// packets in a row needed to have stable frequency content within ~1000 sample wide\n// window to minimize frequency masking during mp3 compression. Though SoundCloud\n// is streaming 128 kBps mp3 @ 44.1 kHz, in reality its closer to FM radio quality\n// with 32 kHz sample rate. Thus out of 80 available frequency bands only 61 are used.\n// \n// Shadertoy reads content of web audio analyzer node and clamps input buffer to 512.\n// Having 6x packet redundancy helps to remedy that as well. Additionally, some\n// browsers like Firefox do some funky stuff to that buffer applying some pinching\n// effect around some buffer boundaries once in a while making some packets unusable.\n//\n// Out of 61 frequency bands fundamental (carrier) is used for packet location,\n// 4 bands are used to encode block location within the image using quantized phase,\n// Then 48 DCT luminance coefficients are interleaved with 8 chrominance coefficients\n// representing final 496x280 image plane that gets processed further.\n//\n// Currently, Shadertoy doesn't provide any access to current web audio sample rate.\n// iSampleRate doesn't work correctly. To solve that a pilot tone is provided\n// in the beginning of the stream, its period is measured and standard sample rates\n// are deduced. Supported rates are 44.1, 48, 88.2, 96 kHz.\n//\n// The best case is 44.1 kHz @ 60 fps. When fps drops or sample rate increased then\n// we will receive fewer packets and more sparsely. That takes more stream runs\n// for image to form. Meanwhile, missing block reconstruction is performed.\n//\n// Created by Dmitry Andreev - and'2016\n// License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\n#define PI 3.14159265\n\n#define BUFFER_SIZE 500\n#define PACKET_SIZE 160\n#define RESAMPLE_WINDOW_RADIUS 7\n\n#define DO_MINIMIZE_ERROR 1\n\n// Fourier transform utilities.\n\nstruct FFTBand\n{\n    vec2 di;\n    vec2 df;\n    vec2 f;\n};\n\nFFTBand FFTBand_create(const float n, const int fft_size)\n{\n    FFTBand band;\n\n    float fi = (float(n) / float(fft_size / 2)) * float(fft_size) * 0.5;\n    float angle = 2.0 * PI * fi / float(fft_size);\n\n    band.di = vec2(cos(angle), sin(angle));\n    band.df = vec2(1.0 / float(fft_size), 0.0);\n    band.f  = vec2(0.0, 0.0);\n\n    return band;\n}\n\nvoid FFTBand_update(inout FFTBand band, float value)\n{\n    band.f += band.df * value;\n    band.df = vec2(\n        band.df.x * band.di.x - band.df.y * band.di.y,\n        band.df.y * band.di.x + band.df.x * band.di.y\n        );\n}\n\nfloat FFTBand_amplitude(FFTBand band)\n{\n    return length(band.f);\n}\n\nfloat FFTBand_angle(FFTBand band)\n{\n    return degrees(atan(band.f.y, band.f.x));\n}\n\n// Additional helpers.\n\nfloat decodePhase(float x)\n{\n    return mod(111.0 - x, 360.0) - 20.0;\n}\n\nfloat angDiff(float a, float b)\n{\n    return mod(a - b + 180.0, 360.0) - 180.0;\n}\n\nfloat windowedSinc(float x, float radius)\n{\n    float w = abs(x) < 0.001 ? 1.0 : sin(PI * x) / (PI * x);\n\n    // Zero-phase Hamming window\n    w *= 0.54 + 0.46 * cos(PI * x / radius);\n\n    return w;\n}\n\nvec4 loadSelf(int x, int y)\n{\n    return textureLod(iChannel1, (vec2(x, y) + 0.5) / iChannelResolution[1].xy, 0.0);\n}\n\n//\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    // Discard everything outside of working area\n    // to increase performance.\n\n    if (any(greaterThan(fragCoord, vec2(500, 280-60)))) discard;\n\n    vec2 pos = floor(fragCoord);\n    vec2 last_pos = pos;\n    bool is_expecting_data  = iChannelTime[0] > 1.5;\n    bool is_expecting_pilot = iChannelTime[0] > 1.1 && iChannelTime[0] < 1.5;\n\n    // Propagate decoded data down the pipeline during reduction.\n\n    last_pos.y -=\n           (56.0 <= pos.y && pos.y < 56.0 + 16.0)\n        || (40.0 <= pos.y && pos.y < 40.0 + 16.0)\n        || (24.0 <= pos.y && pos.y < 24.0 + 16.0)\n        ?\n        16.0 : 0.0;\n\n    vec4 last_color = loadSelf(int(last_pos.x), int(last_pos.y));\n\n    fragColor = last_color;\n\n    // Read detected sample rate.\n\n    float sample_rate_index = floor(0.5 + loadSelf(0, 1).w);\n    float sample_rate_khz = 44.1;\n\n    sample_rate_khz = sample_rate_index == 2.0 ? 48.0 : sample_rate_khz;\n    sample_rate_khz = sample_rate_index == 3.0 ? 88.2 : sample_rate_khz;\n    sample_rate_khz = sample_rate_index == 4.0 ? 96.0 : sample_rate_khz;\n\n    // Downsample incoming sound wave by reconstructing\n    // continuous signal using windowed Sinc kernel\n    // and resampling @ 44.1 kHz.\n    // Supported rates are 44.1, 48, 88.2, 96 kHz.\n\n    if (pos.y == 0.0\n        // Bypass FFT during pilot and inject wave directly into phase channel.\n        || (pos.y == 8.0 && is_expecting_pilot)\n        )\n    {\n        float k = pos.x;\n\n        // Do not resample during pilot as sample rate not yet known.\n\n        if (is_expecting_data)\n        {\n            k *= sample_rate_khz / 44.1;\n        }\n\n        // Windowed Sinc reconstruction and resampling.\n\n        float v = 0.0;\n        float total_weight = 0.0;\n        float f = fract(k);\n\n        for (int n = -RESAMPLE_WINDOW_RADIUS; n <= RESAMPLE_WINDOW_RADIUS; n++)\n        {\n            float fn = float(n);\n            float weight = windowedSinc(fn - f, float(RESAMPLE_WINDOW_RADIUS));\n\n            float source_wave =\n                texture(iChannel0, vec2((floor(k) + fn + 0.5) / iChannelResolution[0].x, 0.75)).x;\n\n            v += weight * source_wave;\n            total_weight += weight;\n        }\n\n        v /= total_weight;\n\n        // Clear area outside of buffer with virtual zero.\n\n        if (k >= float(BUFFER_SIZE)) v = 128.0 / 255.0;\n\n        fragColor = vec4(v * 2.0 - 1.0);\n    }\n\n    // Perform Fourier transform and convert 160 samples @ 44.1 kHz\n    // into 61 complex coefficients of orthogonal bases.\n    // Though SoundCloud is streaming 128 kBps MP3 @ 44.1 kHz\n    // in reality audio is cutoff at around 16.something kHz.\n    // Encoder is aware of that and only 61 out of 80 bases are used.\n\n    if (8.0 <= pos.y && pos.y < 8.0 + 16.0)\n    {\n        int i = int(pos.x);\n        int line_index = int(pos.y - 8.0);\n\n        //  0     : fundamental.xy, dcY.xy\n        //  1     : block_pos.xy, 0, 0\n        //  2..13 : 48 DCT luma   coefficients including DC\n        // 14..15 :  8 DCT chroma coefficients\n\n        FFTBand coeff[4];\n        vec4    ic = vec4(0);\n\n        if (line_index ==  0) ic = vec4( 1, 6, 0, 0);\n        if (line_index ==  1) ic = vec4( 2, 3, 4, 5);\n        if (line_index == 14) ic = vec4( 6, 7,14,15) + 6.0;\n        if (line_index == 15) ic = vec4(22,23,30,31) + 6.0;\n\n        if (2 <= line_index && line_index <= 13)\n        {\n            float icoeff4 = float(line_index - 2);\n            vec4  idx = icoeff4 * 4.0 + vec4(0, 1, 2, 3);\n\n            // Chrominance coefficients are interleaved with\n            // luminance for safe failure.\n            // Build indexes jumping over chroma when needed.\n\n            ic = mix(idx + 8.0, mod(idx, vec4(6)) + 8.0 * floor(idx / vec4(6.0)), vec4(lessThan(idx, vec4(24)))) + 6.0;\n        }\n\n        coeff[0] = FFTBand_create(ic.x, PACKET_SIZE);\n        coeff[1] = FFTBand_create(ic.y, PACKET_SIZE);\n        coeff[2] = FFTBand_create(ic.z, PACKET_SIZE);\n        coeff[3] = FFTBand_create(ic.w, PACKET_SIZE);\n\n        for (int k = 0; k < PACKET_SIZE; k++)\n        {\n            float v = loadSelf(i + k, 0).w;\n\n            FFTBand_update(coeff[0], v);\n            FFTBand_update(coeff[1], v);\n            FFTBand_update(coeff[2], v);\n            FFTBand_update(coeff[3], v);\n        }\n\n        float cf[4];\n\n        for (int k = 0; k < 4; k++)\n        {\n            // Coefficient sign is encoded in phase.\n\n            float s = FFTBand_angle(coeff[k]) >= 0.0 ? 1.0 : -1.0;\n            cf[k] = s * FFTBand_amplitude(coeff[k]) * 127.0;\n        }\n\n        if (line_index == 2)\n        {\n            // DC coefficient is encoded with reduced amplitude\n            // to minimize frequency masking during mp3 encoding\n            // and interfering with meta data.\n\n            cf[0] *= 2.0;\n        }\n\n        fragColor = vec4(cf[0], cf[1], cf[2], cf[3]);\n\n        if (line_index == 0)\n        {\n            // Store fundamental and DC components as raw complex numbers\n            // required by packet locator.\n\n            fragColor = vec4(coeff[0].f.xy, coeff[1].f.xy);\n        }\n\n        if (line_index == 1)\n        {\n            // Decode metadata.\n            // Amplitude of a low frequency signal may be altered\n            // by mp3 compression quite a lot and is unreliable.\n            // However constant amplitude is less prone to that.\n            // Use quantized phase instead to encode\n            // low and high parts of block positions.\n\n            vec4 phi = vec4(\n                decodePhase(FFTBand_angle(coeff[0])),\n                decodePhase(FFTBand_angle(coeff[1])),\n                decodePhase(FFTBand_angle(coeff[2])),\n                decodePhase(FFTBand_angle(coeff[3]))\n                );\n            vec4 amp = vec4(\n                FFTBand_amplitude(coeff[0]),\n                FFTBand_amplitude(coeff[1]),\n                FFTBand_amplitude(coeff[2]),\n                FFTBand_amplitude(coeff[3])\n                );\n\n            ivec4 op = ivec4(0.425 + (phi / 45.0));\n            vec2  fp = vec2(op.xz * 8 + op.yw) / 64.0;\n\n            // Amplitudes must be in expected range.\n\n            const vec4 lvl = vec4(3.7 / 127.0);\n            const vec4 th  = vec4(0.3 / 127.0);\n\n            bool is_amp_ok = all(lessThan(abs(amp - lvl), th));\n            fp = is_amp_ok ? fp : vec2(1000);\n\n            fragColor = vec4(fp.xy, 0, 0);\n        }\n\n        if (i >= BUFFER_SIZE - PACKET_SIZE) fragColor = vec4(0);\n    }\n\n    // Locate packets in processed data.\n\n    if (pos.y == 72.0)\n    {\n        int i = int(pos.x);\n\n        fragColor = vec4(0);\n\n        vec4 prev = loadSelf(i - 1, 8);\n        vec4 curr = loadSelf(i    , 8);\n        vec4 next = loadSelf(i + 1, 8);\n\n        // Check if we are above expected noise level.\n\n        bool has_carrier = length(curr.xy) > (100.0 / 32767.0);\n        bool has_dc =\n               length(curr.zw) > (120.0 / 32767.0)\n            && length(prev.zw) > (120.0 / 32767.0)\n            && length(next.zw) > (120.0 / 32767.0);\n\n        // Use fundamental frequency for coarse synchronisation.\n        // It is the lowerest frequency in the stream\n        // and phase shifts may occur after mp3 compression.\n\n        if (prev.x * curr.x <= 0.0 // carrier phase crosses 90 degree point\n            && ((prev.x <= curr.x  // it's rising\n                 && curr.x >= 0.0) // and it's 90 but not -90 degrees.\n                || is_expecting_pilot)\n            )\n        {\n            if (has_carrier)\n            {\n                bool  is_valid = true;\n                float max_err = 16.0;\n\n                // Use phase of DC wave for location refinement.\n\n                float m = has_dc ? 99.0    : 45.0;\n                vec2  p = has_dc ? prev.zw : prev.xy;\n                vec2  c = has_dc ? curr.zw : curr.xy;\n                vec2  n = has_dc ? next.zw : next.xy;\n\n                float l2 = degrees(atan(p.y, p.x));\n                float c2 = degrees(atan(c.y, c.x));\n                float r2 = degrees(atan(n.y, n.x));\n\n                float l2_0 = abs(angDiff(l2, 90.0));\n                float c2_0 = abs(angDiff(c2, 90.0));\n                float r2_0 = abs(angDiff(r2, 90.0));\n                float l2_1 = abs(angDiff(l2,-90.0));\n                float c2_1 = abs(angDiff(c2,-90.0));\n                float r2_1 = abs(angDiff(r2,-90.0));\n\n                m = min(min(m, min(l2_0, l2_1)), min(min(c2_0, c2_1), min(r2_0, r2_1)));\n\n                int delta = 0;\n\n                if (m == l2_0 || m == l2_1) delta = -1;\n                if (m == r2_0 || m == r2_1) delta = +1;\n\n                if (has_dc)\n                {\n                    is_valid = m < max_err;\n                }\n                else\n                {\n                    // Even though DC is bellow threshold and can't be used for refinement,\n                    // it can still be used for error estimation.\n\n                    c = (delta == -1 ? prev : delta == 1 ? next : curr).zw;\n\n                    c2 = degrees(atan(c.y, c.x));\n                    c2_0 = abs(angDiff(c2, 90.0));\n                    c2_1 = abs(angDiff(c2,-90.0));\n\n                    // Overestimate by 20% so that block that has_dc can override it.\n                    m = min(c2_0, c2_1) * 1.2;\n                }\n\n                float err = 0.001 + m;\n\n                if (is_expecting_data)\n                {\n                    // Additional validation to account for resampling.\n\n                    is_valid = is_valid && (\n                        pos.x > float(RESAMPLE_WINDOW_RADIUS + 1)\n                        && pos.x < (float(BUFFER_SIZE) - float(PACKET_SIZE) * sample_rate_khz / 44.1\n                            - float(RESAMPLE_WINDOW_RADIUS + 1))\n                        );\n                }\n\n                fragColor = is_valid ? vec4(10.0 + float(delta), err, 0, 0) : fragColor;\n            }\n\n            if (is_expecting_pilot && pos.x < float(BUFFER_SIZE - PACKET_SIZE))\n            {\n                fragColor = vec4(10, 0, 0, 0);\n            }\n        }\n    }\n\n    // Transform location array into array of packet locations\n    // by reduction over multiple frames.\n\n    int px = 0;\n    int py = 74;\n\n    if (pos.y == 74.0) py = 73, px = int(pos.x);\n    if (pos.y == 73.0) py = 72, px = int(pos.x);\n\n    vec2 bp[8];\n    {\n        // bp[] is not really an array. Can't write to it in a loop. Unroll.\n        #define IBP(k)IBP1(k)IBP2(k)IBP3(k)\n        #define IBP1(k) bp[k] = loadSelf(px * 8 + k, py).xy;\n        #define IBP2(k) bp[k].x = floor(bp[k].x);\n        // Location array stores relative deltas that we need\n        // to convert to absolute positions for later stages.\n        #define IBP3(k) bp[k].x += pos.y == 73.0 && bp[k].x > 0.0 ? float(px * 8 + k) : 0.0;\n\n        IBP(0)IBP(1)IBP(2)IBP(3)IBP(4)IBP(5)IBP(6)IBP(7)\n    }\n\n    if (pos.y == 73.0 || pos.y == 74.0)\n    {\n        // Blocks are sparse enough that we don't worry about collisions.\n        // Just grab a single location. This could be improved.\n\n        vec2 p = vec2(0.0, 1000.0);\n        float cnt = 0.0;\n\n        for (int k = 0; k < 8; k++)\n        {\n            p = bp[k].x > 0.0 ? bp[k] : p;\n            cnt += bp[k].x > 0.0 ? 1.0 : 0.0;\n        }\n\n        // If we have more than one block per bin then something went wrong.\n        // Packets can't be that close. Reject everything.\n        p = cnt > 1.0 ? vec2(0.0, 1000.0) : p;\n\n        fragColor = vec4(p, 0, 0);\n    }\n\n    // Copy located packets into corresponding image blocks.\n\n    if (is_expecting_data)\n    {\n        vec2 cpos = ((pos - vec2(0, 140-60)) / 4.0);\n        cpos.y = 34.0 - cpos.y;\n        vec2 lpos = fract(cpos) * 4.0;\n        cpos = floor(cpos);\n\n        int icoeff = int(lpos.x + 4.0 * lpos.y);\n\n        if (all(lessThan(cpos, vec2(64, 35))))\n        {\n        #if DO_MINIMIZE_ERROR\n            ivec2 cp = ivec2(cpos.xy * 4.0);\n            float old_err = loadSelf(cp.x, 140-60 + 140 - 4 - (cp.y + 3)).x;\n            float err = old_err > 0.0 ? min(old_err, 100.0) : 100.0;\n        #endif\n\n            for (int k = 0; k < 8; k++)\n            {\n                if (all(greaterThan(bp[k], vec2(0))))\n                {\n                    int i = int(bp[k].x - 10.0);\n                    vec2 bpos = floor(64.0 * loadSelf(i, 57).xy);\n\n                    if (all(equal(bpos, cpos)))\n                    {\n                    #if DO_MINIMIZE_ERROR\n                        // Generally it is true that the less the phase error\n                        // of fundamental and DC waves the better the quality.\n                        // We keep track of the error in current block\n                        // and only accept new data when the error is smaller.\n\n                        float new_err = bp[k].y;\n\n                        if (new_err < err)\n                        {\n                            err = new_err;\n                            fragColor = icoeff < 12 ? loadSelf(i, 58 + icoeff) : vec4(err);\n                        }\n                    #else\n\n                        fragColor = icoeff < 12 ? loadSelf(i, 58 + icoeff) : vec4(0);\n                    #endif                        \n                    }\n                }\n            }\n        }\n    }\n\n    // Predict chroma blocks that have not been received yet.\n    // Chroma components are 1/8th size of the luminance and\n    // get bilinearly interpolated to full resolution in the\n    // next stage when combined with reconstructed luminance.\n    // This is needed to minimize desaturated bleeding.\n\n    if (255.0 <= pos.x && pos.x < 335.0\n        && pos.y >= 145.0 - 60.0\n        && last_color.w < 0.5\n        )\n    {\n        int x = int(pos.x);\n        int y = int(pos.y);\n\n        vec3 l = loadSelf(x-1, y).rgb;\n        vec3 r = loadSelf(x+1, y).rgb;\n        vec3 t = loadSelf(x, y+1).rgb;\n        vec3 b = loadSelf(x, y-1).rgb;\n\n        fragColor = vec4((l + r + t + b) / 4.0, 0);\n    }\n\n    // Decode chrominance in-place.\n    // CgCo components are coded at 1/8th size of luminance\n    // and represented by 8 DCT coefficients total.\n    // To take advantage of hardware filtering and simplify\n    // final reconstruction, perform IDCT in-place.\n\n    if (is_expecting_data)\n    {\n        vec2 cpos = ((pos.yx - vec2(150-60, 260)) / 2.0);\n        vec2 lpos = fract(cpos) * 2.0;\n        cpos = floor(cpos);\n\n        if (all(lessThan(cpos, vec2(64, 35))))\n        {\n            for (int k = 0; k < 8; k++)\n            {\n                if (all(greaterThan(bp[k], vec2(0))))\n                {\n                    int i = int(bp[k].x - 10.0);\n                    vec2 bpos = floor(64.0 * loadSelf(i, 57).xy);\n\n                    if (all(equal(bpos, cpos)))\n                    {\n                        vec4 a = 0.25 * loadSelf(i, 58 + 12) / vec4(1,1,2,2);\n                        vec4 b = 0.25 * loadSelf(i, 58 + 13) / vec4(3,3,4,4);\n                        \n                        vec2 val = vec2(0);\n                        \n                        val = all(equal(lpos, vec2(0,0))) ? a.xy + a.zw + b.xy + b.zw : val;\n                        val = all(equal(lpos, vec2(1,0))) ? a.xy - a.zw + b.xy - b.zw : val;\n                        val = all(equal(lpos, vec2(0,1))) ? a.xy + a.zw - b.xy - b.zw : val;\n                        val = all(equal(lpos, vec2(1,1))) ? a.xy - a.zw - b.xy + b.zw : val;\n\n                        fragColor = vec4(-val.x + val.y, val.x, -val.x - val.y, 1);\n                    }\n                }\n            }\n        }\n    }\n\n    // Detect sample rate by checking period of pure sine wave\n    // at the beginning of stream.\n\n    if (pos.y == 1.0)\n    {\n        float sample_rate_index = last_color.w;\n\n        if (is_expecting_pilot)\n        {\n            float f = 0.0;\n            float first_sync  = 0.0;\n            float second_sync = 0.0;\n\n            for (int k = 0; k < 8; k++)\n            {\n                bool sync = bp[k].x > 0.0;\n\n                first_sync  = sync && f == 0.0 ? bp[k].x : first_sync;\n                second_sync = sync && f == 1.0 ? bp[k].x : second_sync;\n\n                f += sync ? 1.0 : 0.0;\n            }\n\n            if (first_sync > 0.0 && second_sync > 0.0)\n            {\n                // We are measuring half period actually.\n                float size = 2.0 * (second_sync - first_sync);\n                float id = 0.0;\n\n                id = abs(size - 348.0) < 10.0 ? 4.0 : id; // 96.0\n                id = abs(size - 320.0) < 10.0 ? 3.0 : id; // 88.2\n                id = abs(size - 174.0) <  5.0 ? 2.0 : id; // 48.0\n                id = abs(size - 160.0) <  5.0 ? 1.0 : id; // 44.1\n\n                sample_rate_index = id > 0.0 ? id : sample_rate_index;\n            }\n        }\n\n        fragColor.w = sample_rate_index;\n    }\n}\n","name":"Buffer A","description":"","type":"buffer"},{"outputs":[{"channel":0,"id":"XsXGR8"}],"inputs":[{"channel":0,"type":"musicstream","id":"lsfGD4","filepath":"https://soundcloud.com/user-470401467/st-image-2e-3","sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}},{"channel":1,"type":"buffer","id":"XsXGR8","filepath":"/media/previz/buffer01.png","sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}}],"code":"// oilArt - Buf A/B\n//\n// Main audio decoder.\n// Buf B is redundant and runs the same code as Buf A but reads slightly delayed\n// audio stream to increase reliability when FPS drops or high sample rate is used.\n//\n// Audio stream is made up of 160 samples long packets that come in buckets of 6\n// packets in a row needed to have stable frequency content within ~1000 sample wide\n// window to minimize frequency masking during mp3 compression. Though SoundCloud\n// is streaming 128 kBps mp3 @ 44.1 kHz, in reality its closer to FM radio quality\n// with 32 kHz sample rate. Thus out of 80 available frequency bands only 61 are used.\n// \n// Shadertoy reads content of web audio analyzer node and clamps input buffer to 512.\n// Having 6x packet redundancy helps to remedy that as well. Additionally, some\n// browsers like Firefox do some funky stuff to that buffer applying some pinching\n// effect around some buffer boundaries once in a while making some packets unusable.\n//\n// Out of 61 frequency bands fundamental (carrier) is used for packet location,\n// 4 bands are used to encode block location within the image using quantized phase,\n// Then 48 DCT luminance coefficients are interleaved with 8 chrominance coefficients\n// representing final 496x280 image plane that gets processed further.\n//\n// Currently, Shadertoy doesn't provide any access to current web audio sample rate.\n// iSampleRate doesn't work correctly. To solve that a pilot tone is provided\n// in the beginning of the stream, its period is measured and standard sample rates\n// are deduced. Supported rates are 44.1, 48, 88.2, 96 kHz.\n//\n// The best case is 44.1 kHz @ 60 fps. When fps drops or sample rate increased then\n// we will receive fewer packets and more sparsely. That takes more stream runs\n// for image to form. Meanwhile, missing block reconstruction is performed.\n//\n// Created by Dmitry Andreev - and'2016\n// License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\n#define PI 3.14159265\n\n#define BUFFER_SIZE 500\n#define PACKET_SIZE 160\n#define RESAMPLE_WINDOW_RADIUS 7\n\n#define DO_MINIMIZE_ERROR 1\n\n// Fourier transform utilities.\n\nstruct FFTBand\n{\n    vec2 di;\n    vec2 df;\n    vec2 f;\n};\n\nFFTBand FFTBand_create(const float n, const int fft_size)\n{\n    FFTBand band;\n\n    float fi = (float(n) / float(fft_size / 2)) * float(fft_size) * 0.5;\n    float angle = 2.0 * PI * fi / float(fft_size);\n\n    band.di = vec2(cos(angle), sin(angle));\n    band.df = vec2(1.0 / float(fft_size), 0.0);\n    band.f  = vec2(0.0, 0.0);\n\n    return band;\n}\n\nvoid FFTBand_update(inout FFTBand band, float value)\n{\n    band.f += band.df * value;\n    band.df = vec2(\n        band.df.x * band.di.x - band.df.y * band.di.y,\n        band.df.y * band.di.x + band.df.x * band.di.y\n        );\n}\n\nfloat FFTBand_amplitude(FFTBand band)\n{\n    return length(band.f);\n}\n\nfloat FFTBand_angle(FFTBand band)\n{\n    return degrees(atan(band.f.y, band.f.x));\n}\n\n// Additional helpers.\n\nfloat decodePhase(float x)\n{\n    return mod(111.0 - x, 360.0) - 20.0;\n}\n\nfloat angDiff(float a, float b)\n{\n    return mod(a - b + 180.0, 360.0) - 180.0;\n}\n\nfloat windowedSinc(float x, float radius)\n{\n    float w = abs(x) < 0.001 ? 1.0 : sin(PI * x) / (PI * x);\n\n    // Zero-phase Hamming window\n    w *= 0.54 + 0.46 * cos(PI * x / radius);\n\n    return w;\n}\n\nvec4 loadSelf(int x, int y)\n{\n    return textureLod(iChannel1, (vec2(x, y) + 0.5) / iChannelResolution[1].xy, 0.0);\n}\n\n//\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    // Discard everything outside of working area\n    // to increase performance.\n\n    if (any(greaterThan(fragCoord, vec2(500, 280-60)))) discard;\n\n    vec2 pos = floor(fragCoord);\n    vec2 last_pos = pos;\n    bool is_expecting_data  = iChannelTime[0] > 1.5;\n    bool is_expecting_pilot = iChannelTime[0] > 1.1 && iChannelTime[0] < 1.5;\n\n    // Propagate decoded data down the pipeline during reduction.\n\n    last_pos.y -=\n           (56.0 <= pos.y && pos.y < 56.0 + 16.0)\n        || (40.0 <= pos.y && pos.y < 40.0 + 16.0)\n        || (24.0 <= pos.y && pos.y < 24.0 + 16.0)\n        ?\n        16.0 : 0.0;\n\n    vec4 last_color = loadSelf(int(last_pos.x), int(last_pos.y));\n\n    fragColor = last_color;\n\n    // Read detected sample rate.\n\n    float sample_rate_index = floor(0.5 + loadSelf(0, 1).w);\n    float sample_rate_khz = 44.1;\n\n    sample_rate_khz = sample_rate_index == 2.0 ? 48.0 : sample_rate_khz;\n    sample_rate_khz = sample_rate_index == 3.0 ? 88.2 : sample_rate_khz;\n    sample_rate_khz = sample_rate_index == 4.0 ? 96.0 : sample_rate_khz;\n\n    // Downsample incoming sound wave by reconstructing\n    // continuous signal using windowed Sinc kernel\n    // and resampling @ 44.1 kHz.\n    // Supported rates are 44.1, 48, 88.2, 96 kHz.\n\n    if (pos.y == 0.0\n        // Bypass FFT during pilot and inject wave directly into phase channel.\n        || (pos.y == 8.0 && is_expecting_pilot)\n        )\n    {\n        float k = pos.x;\n\n        // Do not resample during pilot as sample rate not yet known.\n\n        if (is_expecting_data)\n        {\n            k *= sample_rate_khz / 44.1;\n        }\n\n        // Windowed Sinc reconstruction and resampling.\n\n        float v = 0.0;\n        float total_weight = 0.0;\n        float f = fract(k);\n\n        for (int n = -RESAMPLE_WINDOW_RADIUS; n <= RESAMPLE_WINDOW_RADIUS; n++)\n        {\n            float fn = float(n);\n            float weight = windowedSinc(fn - f, float(RESAMPLE_WINDOW_RADIUS));\n\n            float source_wave =\n                texture(iChannel0, vec2((floor(k) + fn + 0.5) / iChannelResolution[0].x, 0.75)).x;\n\n            v += weight * source_wave;\n            total_weight += weight;\n        }\n\n        v /= total_weight;\n\n        // Clear area outside of buffer with virtual zero.\n\n        if (k >= float(BUFFER_SIZE)) v = 128.0 / 255.0;\n\n        fragColor = vec4(v * 2.0 - 1.0);\n    }\n\n    // Perform Fourier transform and convert 160 samples @ 44.1 kHz\n    // into 61 complex coefficients of orthogonal bases.\n    // Though SoundCloud is streaming 128 kBps MP3 @ 44.1 kHz\n    // in reality audio is cutoff at around 16.something kHz.\n    // Encoder is aware of that and only 61 out of 80 bases are used.\n\n    if (8.0 <= pos.y && pos.y < 8.0 + 16.0)\n    {\n        int i = int(pos.x);\n        int line_index = int(pos.y - 8.0);\n\n        //  0     : fundamental.xy, dcY.xy\n        //  1     : block_pos.xy, 0, 0\n        //  2..13 : 48 DCT luma   coefficients including DC\n        // 14..15 :  8 DCT chroma coefficients\n\n        FFTBand coeff[4];\n        vec4    ic = vec4(0);\n\n        if (line_index ==  0) ic = vec4( 1, 6, 0, 0);\n        if (line_index ==  1) ic = vec4( 2, 3, 4, 5);\n        if (line_index == 14) ic = vec4( 6, 7,14,15) + 6.0;\n        if (line_index == 15) ic = vec4(22,23,30,31) + 6.0;\n\n        if (2 <= line_index && line_index <= 13)\n        {\n            float icoeff4 = float(line_index - 2);\n            vec4  idx = icoeff4 * 4.0 + vec4(0, 1, 2, 3);\n\n            // Chrominance coefficients are interleaved with\n            // luminance for safe failure.\n            // Build indexes jumping over chroma when needed.\n\n            ic = mix(idx + 8.0, mod(idx, vec4(6)) + 8.0 * floor(idx / vec4(6.0)), vec4(lessThan(idx, vec4(24)))) + 6.0;\n        }\n\n        coeff[0] = FFTBand_create(ic.x, PACKET_SIZE);\n        coeff[1] = FFTBand_create(ic.y, PACKET_SIZE);\n        coeff[2] = FFTBand_create(ic.z, PACKET_SIZE);\n        coeff[3] = FFTBand_create(ic.w, PACKET_SIZE);\n\n        for (int k = 0; k < PACKET_SIZE; k++)\n        {\n            float v = loadSelf(i + k, 0).w;\n\n            FFTBand_update(coeff[0], v);\n            FFTBand_update(coeff[1], v);\n            FFTBand_update(coeff[2], v);\n            FFTBand_update(coeff[3], v);\n        }\n\n        float cf[4];\n\n        for (int k = 0; k < 4; k++)\n        {\n            // Coefficient sign is encoded in phase.\n\n            float s = FFTBand_angle(coeff[k]) >= 0.0 ? 1.0 : -1.0;\n            cf[k] = s * FFTBand_amplitude(coeff[k]) * 127.0;\n        }\n\n        if (line_index == 2)\n        {\n            // DC coefficient is encoded with reduced amplitude\n            // to minimize frequency masking during mp3 encoding\n            // and interfering with meta data.\n\n            cf[0] *= 2.0;\n        }\n\n        fragColor = vec4(cf[0], cf[1], cf[2], cf[3]);\n\n        if (line_index == 0)\n        {\n            // Store fundamental and DC components as raw complex numbers\n            // required by packet locator.\n\n            fragColor = vec4(coeff[0].f.xy, coeff[1].f.xy);\n        }\n\n        if (line_index == 1)\n        {\n            // Decode metadata.\n            // Amplitude of a low frequency signal may be altered\n            // by mp3 compression quite a lot and is unreliable.\n            // However constant amplitude is less prone to that.\n            // Use quantized phase instead to encode\n            // low and high parts of block positions.\n\n            vec4 phi = vec4(\n                decodePhase(FFTBand_angle(coeff[0])),\n                decodePhase(FFTBand_angle(coeff[1])),\n                decodePhase(FFTBand_angle(coeff[2])),\n                decodePhase(FFTBand_angle(coeff[3]))\n                );\n            vec4 amp = vec4(\n                FFTBand_amplitude(coeff[0]),\n                FFTBand_amplitude(coeff[1]),\n                FFTBand_amplitude(coeff[2]),\n                FFTBand_amplitude(coeff[3])\n                );\n\n            ivec4 op = ivec4(0.425 + (phi / 45.0));\n            vec2  fp = vec2(op.xz * 8 + op.yw) / 64.0;\n\n            // Amplitudes must be in expected range.\n\n            const vec4 lvl = vec4(3.7 / 127.0);\n            const vec4 th  = vec4(0.3 / 127.0);\n\n            bool is_amp_ok = all(lessThan(abs(amp - lvl), th));\n            fp = is_amp_ok ? fp : vec2(1000);\n\n            fragColor = vec4(fp.xy, 0, 0);\n        }\n\n        if (i >= BUFFER_SIZE - PACKET_SIZE) fragColor = vec4(0);\n    }\n\n    // Locate packets in processed data.\n\n    if (pos.y == 72.0)\n    {\n        int i = int(pos.x);\n\n        fragColor = vec4(0);\n\n        vec4 prev = loadSelf(i - 1, 8);\n        vec4 curr = loadSelf(i    , 8);\n        vec4 next = loadSelf(i + 1, 8);\n\n        // Check if we are above expected noise level.\n\n        bool has_carrier = length(curr.xy) > (100.0 / 32767.0);\n        bool has_dc =\n               length(curr.zw) > (120.0 / 32767.0)\n            && length(prev.zw) > (120.0 / 32767.0)\n            && length(next.zw) > (120.0 / 32767.0);\n\n        // Use fundamental frequency for coarse synchronisation.\n        // It is the lowerest frequency in the stream\n        // and phase shifts may occur after mp3 compression.\n\n        if (prev.x * curr.x <= 0.0 // carrier phase crosses 90 degree point\n            && ((prev.x <= curr.x  // it's rising\n                 && curr.x >= 0.0) // and it's 90 but not -90 degrees.\n                || is_expecting_pilot)\n            )\n        {\n            if (has_carrier)\n            {\n                bool  is_valid = true;\n                float max_err = 16.0;\n\n                // Use phase of DC wave for location refinement.\n\n                float m = has_dc ? 99.0    : 45.0;\n                vec2  p = has_dc ? prev.zw : prev.xy;\n                vec2  c = has_dc ? curr.zw : curr.xy;\n                vec2  n = has_dc ? next.zw : next.xy;\n\n                float l2 = degrees(atan(p.y, p.x));\n                float c2 = degrees(atan(c.y, c.x));\n                float r2 = degrees(atan(n.y, n.x));\n\n                float l2_0 = abs(angDiff(l2, 90.0));\n                float c2_0 = abs(angDiff(c2, 90.0));\n                float r2_0 = abs(angDiff(r2, 90.0));\n                float l2_1 = abs(angDiff(l2,-90.0));\n                float c2_1 = abs(angDiff(c2,-90.0));\n                float r2_1 = abs(angDiff(r2,-90.0));\n\n                m = min(min(m, min(l2_0, l2_1)), min(min(c2_0, c2_1), min(r2_0, r2_1)));\n\n                int delta = 0;\n\n                if (m == l2_0 || m == l2_1) delta = -1;\n                if (m == r2_0 || m == r2_1) delta = +1;\n\n                if (has_dc)\n                {\n                    is_valid = m < max_err;\n                }\n                else\n                {\n                    // Even though DC is bellow threshold and can't be used for refinement,\n                    // it can still be used for error estimation.\n\n                    c = (delta == -1 ? prev : delta == 1 ? next : curr).zw;\n\n                    c2 = degrees(atan(c.y, c.x));\n                    c2_0 = abs(angDiff(c2, 90.0));\n                    c2_1 = abs(angDiff(c2,-90.0));\n\n                    // Overestimate by 20% so that block that has_dc can override it.\n                    m = min(c2_0, c2_1) * 1.2;\n                }\n\n                float err = 0.001 + m;\n\n                if (is_expecting_data)\n                {\n                    // Additional validation to account for resampling.\n\n                    is_valid = is_valid && (\n                        pos.x > float(RESAMPLE_WINDOW_RADIUS + 1)\n                        && pos.x < (float(BUFFER_SIZE) - float(PACKET_SIZE) * sample_rate_khz / 44.1\n                            - float(RESAMPLE_WINDOW_RADIUS + 1))\n                        );\n                }\n\n                fragColor = is_valid ? vec4(10.0 + float(delta), err, 0, 0) : fragColor;\n            }\n\n            if (is_expecting_pilot && pos.x < float(BUFFER_SIZE - PACKET_SIZE))\n            {\n                fragColor = vec4(10, 0, 0, 0);\n            }\n        }\n    }\n\n    // Transform location array into array of packet locations\n    // by reduction over multiple frames.\n\n    int px = 0;\n    int py = 74;\n\n    if (pos.y == 74.0) py = 73, px = int(pos.x);\n    if (pos.y == 73.0) py = 72, px = int(pos.x);\n\n    vec2 bp[8];\n    {\n        // bp[] is not really an array. Can't write to it in a loop. Unroll.\n        #define IBP(k)IBP1(k)IBP2(k)IBP3(k)\n        #define IBP1(k) bp[k] = loadSelf(px * 8 + k, py).xy;\n        #define IBP2(k) bp[k].x = floor(bp[k].x);\n        // Location array stores relative deltas that we need\n        // to convert to absolute positions for later stages.\n        #define IBP3(k) bp[k].x += pos.y == 73.0 && bp[k].x > 0.0 ? float(px * 8 + k) : 0.0;\n\n        IBP(0)IBP(1)IBP(2)IBP(3)IBP(4)IBP(5)IBP(6)IBP(7)\n    }\n\n    if (pos.y == 73.0 || pos.y == 74.0)\n    {\n        // Blocks are sparse enough that we don't worry about collisions.\n        // Just grab a single location. This could be improved.\n\n        vec2 p = vec2(0.0, 1000.0);\n        float cnt = 0.0;\n\n        for (int k = 0; k < 8; k++)\n        {\n            p = bp[k].x > 0.0 ? bp[k] : p;\n            cnt += bp[k].x > 0.0 ? 1.0 : 0.0;\n        }\n\n        // If we have more than one block per bin then something went wrong.\n        // Packets can't be that close. Reject everything.\n        p = cnt > 1.0 ? vec2(0.0, 1000.0) : p;\n\n        fragColor = vec4(p, 0, 0);\n    }\n\n    // Copy located packets into corresponding image blocks.\n\n    if (is_expecting_data)\n    {\n        vec2 cpos = ((pos - vec2(0, 140-60)) / 4.0);\n        cpos.y = 34.0 - cpos.y;\n        vec2 lpos = fract(cpos) * 4.0;\n        cpos = floor(cpos);\n\n        int icoeff = int(lpos.x + 4.0 * lpos.y);\n\n        if (all(lessThan(cpos, vec2(64, 35))))\n        {\n        #if DO_MINIMIZE_ERROR\n            ivec2 cp = ivec2(cpos.xy * 4.0);\n            float old_err = loadSelf(cp.x, 140-60 + 140 - 4 - (cp.y + 3)).x;\n            float err = old_err > 0.0 ? min(old_err, 100.0) : 100.0;\n        #endif\n\n            for (int k = 0; k < 8; k++)\n            {\n                if (all(greaterThan(bp[k], vec2(0))))\n                {\n                    int i = int(bp[k].x - 10.0);\n                    vec2 bpos = floor(64.0 * loadSelf(i, 57).xy);\n\n                    if (all(equal(bpos, cpos)))\n                    {\n                    #if DO_MINIMIZE_ERROR\n                        // Generally it is true that the less the phase error\n                        // of fundamental and DC waves the better the quality.\n                        // We keep track of the error in current block\n                        // and only accept new data when the error is smaller.\n\n                        float new_err = bp[k].y;\n\n                        if (new_err < err)\n                        {\n                            err = new_err;\n                            fragColor = icoeff < 12 ? loadSelf(i, 58 + icoeff) : vec4(err);\n                        }\n                    #else\n\n                        fragColor = icoeff < 12 ? loadSelf(i, 58 + icoeff) : vec4(0);\n                    #endif                        \n                    }\n                }\n            }\n        }\n    }\n\n    // Predict chroma blocks that have not been received yet.\n    // Chroma components are 1/8th size of the luminance and\n    // get bilinearly interpolated to full resolution in the\n    // next stage when combined with reconstructed luminance.\n    // This is needed to minimize desaturated bleeding.\n\n    if (255.0 <= pos.x && pos.x < 335.0\n        && pos.y >= 145.0 - 60.0\n        && last_color.w < 0.5\n        )\n    {\n        int x = int(pos.x);\n        int y = int(pos.y);\n\n        vec3 l = loadSelf(x-1, y).rgb;\n        vec3 r = loadSelf(x+1, y).rgb;\n        vec3 t = loadSelf(x, y+1).rgb;\n        vec3 b = loadSelf(x, y-1).rgb;\n\n        fragColor = vec4((l + r + t + b) / 4.0, 0);\n    }\n\n    // Decode chrominance in-place.\n    // CgCo components are coded at 1/8th size of luminance\n    // and represented by 8 DCT coefficients total.\n    // To take advantage of hardware filtering and simplify\n    // final reconstruction, perform IDCT in-place.\n\n    if (is_expecting_data)\n    {\n        vec2 cpos = ((pos.yx - vec2(150-60, 260)) / 2.0);\n        vec2 lpos = fract(cpos) * 2.0;\n        cpos = floor(cpos);\n\n        if (all(lessThan(cpos, vec2(64, 35))))\n        {\n            for (int k = 0; k < 8; k++)\n            {\n                if (all(greaterThan(bp[k], vec2(0))))\n                {\n                    int i = int(bp[k].x - 10.0);\n                    vec2 bpos = floor(64.0 * loadSelf(i, 57).xy);\n\n                    if (all(equal(bpos, cpos)))\n                    {\n                        vec4 a = 0.25 * loadSelf(i, 58 + 12) / vec4(1,1,2,2);\n                        vec4 b = 0.25 * loadSelf(i, 58 + 13) / vec4(3,3,4,4);\n                        \n                        vec2 val = vec2(0);\n                        \n                        val = all(equal(lpos, vec2(0,0))) ? a.xy + a.zw + b.xy + b.zw : val;\n                        val = all(equal(lpos, vec2(1,0))) ? a.xy - a.zw + b.xy - b.zw : val;\n                        val = all(equal(lpos, vec2(0,1))) ? a.xy + a.zw - b.xy - b.zw : val;\n                        val = all(equal(lpos, vec2(1,1))) ? a.xy - a.zw - b.xy + b.zw : val;\n\n                        fragColor = vec4(-val.x + val.y, val.x, -val.x - val.y, 1);\n                    }\n                }\n            }\n        }\n    }\n\n    // Detect sample rate by checking period of pure sine wave\n    // at the beginning of stream.\n\n    if (pos.y == 1.0)\n    {\n        float sample_rate_index = last_color.w;\n\n        if (is_expecting_pilot)\n        {\n            float f = 0.0;\n            float first_sync  = 0.0;\n            float second_sync = 0.0;\n\n            for (int k = 0; k < 8; k++)\n            {\n                bool sync = bp[k].x > 0.0;\n\n                first_sync  = sync && f == 0.0 ? bp[k].x : first_sync;\n                second_sync = sync && f == 1.0 ? bp[k].x : second_sync;\n\n                f += sync ? 1.0 : 0.0;\n            }\n\n            if (first_sync > 0.0 && second_sync > 0.0)\n            {\n                // We are measuring half period actually.\n                float size = 2.0 * (second_sync - first_sync);\n                float id = 0.0;\n\n                id = abs(size - 348.0) < 10.0 ? 4.0 : id; // 96.0\n                id = abs(size - 320.0) < 10.0 ? 3.0 : id; // 88.2\n                id = abs(size - 174.0) <  5.0 ? 2.0 : id; // 48.0\n                id = abs(size - 160.0) <  5.0 ? 1.0 : id; // 44.1\n\n                sample_rate_index = id > 0.0 ? id : sample_rate_index;\n            }\n        }\n\n        fragColor.w = sample_rate_index;\n    }\n}\n","name":"Buffer B","description":"","type":"buffer"},{"outputs":[{"channel":0,"id":"4sXGR8"}],"inputs":[{"channel":0,"type":"buffer","id":"4dXGR8","filepath":"/media/previz/buffer00.png","sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}},{"channel":1,"type":"buffer","id":"XsXGR8","filepath":"/media/previz/buffer01.png","sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}},{"channel":2,"type":"buffer","id":"4sXGR8","filepath":"/media/previz/buffer02.png","sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}},{"channel":3,"type":"texture","id":"Xsf3zn","filepath":"/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"}}],"code":"// oilArt - Buf C\n//\n// Take DCT luminance coefficients from decoders that correspond to blocks with\n// smaller error, perform standard JPEG-like de-zigzagging and apply\n// Inverse Discrete Cosine Transform (IDCT) to get reconstructed luminance.\n// Then add interpolated chrominance that was reconstructed by corresponding\n// decoder to build final 496x280 image.\n//\n// Perform continious reconstruction (fill-in) of missing blocks in a stylized way\n// by scattering exising blocks around. And play brush-like revealing effect\n// on newly arrived blocks.\n//\n// Created by Dmitry Andreev - and'2016\n// License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\n#define STYLIZED_FILLIN    1\n#define DO_FILLIN_MISSING  1\n#define DO_PAINING_EFFECT  1\n#define DO_DUAL_DECODING   1\n\n#define PI 3.14159265\n\nvec4 loadA(int x, int y)\n{\n    return textureLod(iChannel0, (vec2(x, y) + 0.5) / iChannelResolution[0].xy, 0.0);\n}\n\nvec4 loadB(int x, int y)\n{\n    return textureLod(iChannel1, (vec2(x, y) + 0.5) / iChannelResolution[1].xy, 0.0);\n}\n\nvec4 sampleSelf(vec2 pos)\n{\n    return textureLod(iChannel2, pos / iChannelResolution[2].xy, 0.0);\n}\n\nvec4 dct(vec2 cpos, vec4 x, vec4 y)\n{\n    vec4 wx = 2.0 * cos(PI * x * float(cpos.x * 2.0 + 1.0) / 16.0);\n    vec4 wy = 2.0 * cos(PI * y * float(cpos.y * 2.0 + 1.0) / 16.0);\n\n    const float a = 0.17677669; // sqrt(1.0 / (4.0 * 8.0));\n    const float b = 0.25;       // sqrt(1.0 / (2.0 * 8.0));\n\n    wx.x *= x.x == 0.0 ? a : b;\n    wx.y *= x.y == 0.0 ? a : b;\n    wx.z *= x.z == 0.0 ? a : b;\n    wx.w *= x.w == 0.0 ? a : b;\n\n    wy.x *= y.x == 0.0 ? a : b;\n    wy.y *= y.y == 0.0 ? a : b;\n    wy.z *= y.z == 0.0 ? a : b;\n    wy.w *= y.w == 0.0 ? a : b;\n\n    return wx * wy;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    if (any(greaterThan(fragCoord, vec2(500, 280)))) discard;\n\n    vec2 bpos = floor(fragCoord / 8.0);\n    vec2 cpos = fract(floor(fragCoord) / 8.0) * 8.0;\n    cpos.y = 7.0 - cpos.y;\n\n    vec4 old = sampleSelf(bpos * 8.0 + 0.5);\n\n    int cx = int(bpos.x * 4.0);\n    int cy = int(bpos.y * 4.0) + 140-60;\n\n    vec4 chroma = vec4(0);\n    vec4 val4 = vec4(0);\n    vec4 c[12];\n\n    bool is_best_A = true;\n    float blockA = loadA(cx+0, cy-3).x;\n    float blockB = loadB(cx+0, cy-3).x;\n\n#if DO_DUAL_DECODING\n    // Take the best result of two decoders.\n\n    if (blockA > 0.0 && blockB > 0.0)\n    {\n        is_best_A = blockA <= blockB;\n    }\n    else if (blockA > 0.0)\n    {\n        is_best_A = true;\n    }\n    else\n    {\n        is_best_A = false;\n    }\n#else\n    is_best_A = true;\n#endif\n\n    if (is_best_A)\n    {\n        chroma = texture(iChannel0, (vec2(260+70, 150-60) + vec2(-1,1) * fragCoord.yx / 4.0) / iChannelResolution[0].xy);\n    }\n#if DO_DUAL_DECODING\n    else\n    {\n        chroma = texture(iChannel1, (vec2(260+70, 150-60) + vec2(-1,1) * fragCoord.yx / 4.0) / iChannelResolution[1].xy);\n    }\n\n    #define C(x,y) (is_best_A ? loadA(cx+x, cy+y) : loadB(cx+x, cy+y))\n#else\n    #define C(x,y) (loadA(cx+x, cy+y))\n#endif\n\n    // 8x8 IDCT of luminance with standard Jpeg zigzag.\n\n    val4 += C(0, 0) * dct(cpos, vec4(0,1,0,0), vec4(0,0,1,2));\n    val4 += C(1, 0) * dct(cpos, vec4(1,2,3,2), vec4(1,0,0,1));\n    val4 += C(2, 0) * dct(cpos, vec4(1,0,0,1), vec4(2,3,4,3));\n    val4 += C(3, 0) * dct(cpos, vec4(2,3,4,5), vec4(2,1,0,0));\n    val4 += C(0,-1) * dct(cpos, vec4(4,3,2,1), vec4(1,2,3,4));\n    val4 += C(1,-1) * dct(cpos, vec4(0,0,1,2), vec4(5,6,5,4));\n    val4 += C(2,-1) * dct(cpos, vec4(3,4,5,6), vec4(3,2,1,0));\n    val4 += C(3,-1) * dct(cpos, vec4(7,6,5,4), vec4(0,1,2,3));\n    val4 += C(0,-2) * dct(cpos, vec4(3,2,1,0), vec4(4,5,6,7));\n    val4 += C(1,-2) * dct(cpos, vec4(1,2,3,4), vec4(7,6,5,4));\n    val4 += C(2,-2) * dct(cpos, vec4(5,6,7,7), vec4(3,2,1,2));\n    val4 += C(3,-2) * dct(cpos, vec4(6,5,4,3), vec4(3,4,5,6));\n\n    float val = 0.5 + dot(val4, vec4(0.135));\n\n    fragColor = vec4(clamp(val + chroma * 0.55, 0.0, 1.0));\n\n#if DO_PAINING_EFFECT\n    // Simple brush-like strokes in empty areas.\n\n    vec2 offs = vec2(\n        cos((fragCoord.x + fragCoord.y) * 0.05) * 3.0 + 0.0 -\n        cos((fragCoord.x + fragCoord.y) * 3.47) * 0.5,\n        sin((fragCoord.x - fragCoord.y) * 0.05) * 3.0 + 3.0 -\n        sin((fragCoord.x - fragCoord.y) * 3.47) * 0.5\n        );\n\n    float noise = textureLod(iChannel3, (floor(fragCoord) + 0.5) / iChannelResolution[3].xy, 0.0).x;\n    vec4 prev = sampleSelf(fragCoord + offs * (0.1 + 0.9 * noise));\n\n    fragColor.rgb = mix(prev.rgb, fragColor.rgb, old.a * old.a);\n#endif\n\n    fragColor.rgb = clamp(fragColor.rgb, 0.0, 1.0);\n\n#if DO_FILLIN_MISSING || DO_PAINING_EFFECT\n    float block = is_best_A ? blockA : blockB;\n\n    fragColor.a = old.a;\n\n    if (block <= 0.0001)\n    {\n    #if STYLIZED_FILLIN\n        vec2 noise2 = texture(iChannel3, (floor(fragCoord * 1.9) + 0.5) / iChannelResolution[3].xy).xy;\n        fragCoord += (noise2 * 2.0 - 1.0) * 2.5;\n        fragCoord = min(fragCoord, vec2(498, 278));\n    #endif\n\n        // Diffuse surrounding if block doesn't exist.\n\n        fragCoord = min(fragCoord, vec2(498, 278));\n\n        vec3 c  = sampleSelf(fragCoord).rgb;\n        vec3 v0 = sampleSelf(fragCoord + vec2(-1, 0)).rgb;\n        vec3 v1 = sampleSelf(fragCoord + vec2( 1, 0)).rgb;\n        vec3 v2 = sampleSelf(fragCoord + vec2( 0,-1)).rgb;\n        vec3 v3 = sampleSelf(fragCoord + vec2( 0, 1)).rgb;\n\n        vec3 avg = (v0 + v1 + v2 + v3) * 0.25;\n        float wx = abs(v0.g - v1.g);\n        float wy = abs(v2.g - v3.g);\n\n        // Make it less uniform by using horizontal and vertical gradients.\n    #if DO_FILLIN_MISSING\n        fragColor.xyz = wx > wy ?\n              mix(avg, (v0 + v1) * 0.5, 0.75)\n            : mix(avg, (v2 + v3) * 0.5, 0.75);\n\n        fragColor.rgb = mix(fragColor.rgb, (v3 * 8.0 + v2 * 6.0 + v0 + v1) / 16.0, 0.5);\n    #endif\n    }\n    else\n    {\n        // Advance time of existing block for painting effect.\n        fragColor.a = min(1.0, old.a + (1.0 / 45.0));\n    }\n#endif\n\n    // Initialize with paper color.\n    fragColor = iFrame == 0 ? vec4(0.815, 0.815, 0.815, 0) : fragColor;\n}\n","name":"Buffer C","description":"","type":"buffer"}],"flags":{"mFlagVR":false,"mFlagWebcam":false,"mFlagSoundInput":false,"mFlagSoundOutput":false,"mFlagKeyboard":false,"mFlagMultipass":true,"mFlagMusicStream":true},"info":{"id":"lsKGDW","date":"1455757091","viewed":21547,"name":"oilArt","username":"and","description":"Image encoded in mp3 audio stream.\nOriginal painting by Leonid Afremov.\nSpecial thanks to Inna Cherneykina for \"brush\" choreography.","likes":357,"published":1,"flags":96,"usePreview":1,"tags":["2d","fft","image","encoding","soundcloud","dct"],"hasliked":0,"parentid":"","parentname":""}}
{"ver":"0.1","info":{"id":"NstcR7","date":"1653224915","viewed":106,"name":"bumpmap ashiato45","username":"ashiato45","description":"hoge","likes":1,"published":1,"flags":32,"usePreview":0,"tags":["texture"],"hasliked":0,"parentid":"Ns3cz4","parentname":"bump ashiato45 054"},"renderpass":[{"inputs":[{"id":"4sf3Rr","filepath":"/media/a/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","previewfilepath":"/media/ap/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//-----------------------------------------------------------------------------------------\n// The original framework of raymarching is from https://www.shadertoy.com/view/Msd3RN written by 834144373.\n//License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n// author: ashiato45\n//-----------------------------------------------------------------------------------------\n\n#define PI 3.1416\n\n///some tools for blend model\nvec3 Rot(vec3 p,vec3 angles)\n{\n    vec3 c = cos(angles);\n    vec3 s = sin(angles);\n    \n    mat3 rotX = mat3( 1.0, 0.0, 0.0, 0.0,c.x,s.x, 0.0,-s.x, c.x);\n    mat3 rotY = mat3( c.y, 0.0,-s.y, 0.0,1.0,0.0, s.y, 0.0, c.y);\n    mat3 rotZ = mat3( c.z, s.z, 0.0,-s.z,c.z,0.0, 0.0, 0.0, 1.0);\n\t    \n    return p*rotX * rotY * rotZ;\n}\n\n///some tools for blend model\nvec3 InvRot(vec3 p,vec3 angles)\n{\n    angles = -angles;\n    vec3 c = cos(angles);\n    vec3 s = sin(angles);\n    \n    mat3 rotX = mat3( 1.0, 0.0, 0.0, 0.0,c.x,s.x, 0.0,-s.x, c.x);\n    mat3 rotY = mat3( c.y, 0.0,-s.y, 0.0,1.0,0.0, s.y, 0.0, c.y);\n    mat3 rotZ = mat3( c.z, s.z, 0.0,-s.z,c.z,0.0, 0.0, 0.0, 1.0);\n\t    \n    return p*rotZ * rotY * rotX;\n}\n\nfloat smin(float a, float b, float k){\n    float h = clamp(.5+.5*(b-a)/k, 0., 1.);\n    return mix(b,a,h)-k*h*(1.-h);\n}\n\t\n\n// たぶん2の正方形にはおさまってる。\nfloat M(vec3 p) {\n\tfloat x = distance(p, vec3(0., 0., 0.)) - .5;\n    float y = distance(p, vec3(.5, .0, .0)) - .05;\n    return x;\n}\n\nfloat MRot(vec3 p, float t){\n    // camposの位置に使う\n    // いままでここからみれば、tだけ(0, t, 0)まわしたものをかえしたことになる。\n\tfloat t1 = 0.;// - min(mo.y*1.3,.4);\n\tfloat t2 = t*0.1;\n\tfloat t3 = 0.;\n    // \n\t\tvec3 campos = Rot(p,vec3(t1,t2,t3));\n        return M(campos);\n}\n\n\nfloat dis(vec3 campos,vec3 p, float t){\n\tfloat d = 0.;\n\tfloat dd = 1.;\n\tfor(int i = 0;i<100;++i){\n\t\tvec3 sphere = campos + dd*p;\n\t\td = MRot(sphere, t);\n\t\tdd += d;\n\t\tif(d<0.002 || dd>10.)break;\n\t}\n\treturn dd;\n}\n\n\nvec3 purenormal(vec3 p, float t){\n\tvec2 offset = vec2(0.,0.01);\n\tvec3 nDir = vec3(\n\t\tMRot(p+offset.yxx, t),\n\t\tMRot(p+offset.xyx, t),\n\t\tMRot(p+offset.xxy, t)\n\t)-MRot(p, t);\n\treturn normalize(nDir);\n}\n\n\nbool isFace(vec3 p, float t){\n    p = Rot(p, vec3(0., t, 0.));\n    return dot(normalize(p), vec3(0., 0., -1.)) > 0.;\n}\n\nvec3 getColor(vec3 p, float t){\np = Rot(p, vec3(0., t*0.1, 0.));\nfloat theta = acos(abs(dot(normalize(p), vec3(0., 0., -1.))));\nbool face = dot(normalize(p), vec3(0., 0., -1.)) > 0.;\nreturn texture(iChannel2, vec2(0.5, 0.5) + normalize(p.xy)*theta*.2).xyz;\n//float x = texture(iChannel2, vec2(0.5, 0.5) + normalize(p.xy)*theta*1.).x;\n//if(face){\n//    return vec3(x, 0., 0.);\n//}else{\n//    return vec3(0., x, 0.);\n//}\n// return vec3(p.x);  x,y,zを確認できるぞ\n}\n\n//vec3 getBump(vec3 p, float t){\n//}\n\n// https://shadertoyunofficial.wordpress.com/2019/01/02/programming-tricks-in-shadertoy-glsl/\nfloat line(vec2 p, vec2 a,vec2 b) { // --- distance to segment with caps\n    p -= a, b -= a;\n    float h = clamp(dot(p, b) / dot(b, b), 0., 1.);// proj coord on line\n    return length(p - b * h);                      // dist to segment\n    // We might directly return smoothstep( 3./R.y, 0., dist),\n    //     but its more efficient to factor all lines.\n    // We can even return dot(,) and take sqrt at the end of polyline:\n    // p -= b*h; return dot(p,p);\n}\n\nfloat sqDist(vec3 x){\n    return dot(x, x);\n}\n\nvec3 pointOnVScreen(vec3 dir, vec3 camDir, vec3 camPos){\n    return camPos + (sqDist(camDir) / dot(dir, camDir))*dir;\n}\n\nvec2 world2screen(vec3 p, vec3 camPos, vec3 camDir, vec3 camDirRight, vec3 camDirUp){\n    vec3 rightVScreen = pointOnVScreen(camDirRight, camDir, camPos);\n    vec3 origVScreen = camPos + camDir;\n    vec3 upVScreen = pointOnVScreen(camDirUp, camDir, camPos);\n    vec3 pVScreen = pointOnVScreen(p - camPos, camDir, camPos);\n    float right = dot(rightVScreen - origVScreen, pVScreen - origVScreen)/sqDist(rightVScreen - origVScreen);  // -1-1\n    float up = dot(upVScreen - origVScreen, pVScreen - origVScreen)/sqDist(upVScreen - origVScreen);\n    //right = atan(right)*4./PI;\n    //up = atan(up)*4./PI;\n    //float u = right = atan(right/length(camDir));  // -1-1\n    //float v = atan(up/length(camDir));  // -1-1\n    //u = u/2.*iResolution.x/iResolution.y;\n    //v = v/2.;\n    right = (right + 1.)/2.;\n    up = (up + 1.)/2.;\n\n    //return iResolution.xy*vec2(right, up);\n    return vec2(right, up)*iResolution.xy;\n}\n\nfloat line3d(vec2 fragCoord, vec3 p, vec3 q, vec3 camPos, vec3 camDir, vec3 camDirRight, vec3 camDirUp){\n    return line(fragCoord, world2screen(p, camPos, camDir, camDirRight, camDirUp), world2screen(q, camPos, camDir, camDirRight, camDirUp));\n}\n\nfloat atan2(float y, float x){\n    float eps = 0.0001;\n    if(-eps < x && x < eps){\n        return PI/2.;\n    }else if(0. < x){\n        return atan(y/x);\n    }else{\n        return atan(y/x)+PI;\n    }\n}\n\nvec3 goUpDir(vec3 p, float t){\n    float phi = atan2(p.z, p.x);\n    p = InvRot(p, vec3(0., phi, 0.));  // x-y平面にもってくる\n    p = Rot(p, vec3(0., 0., -PI/2.));  // x-y平面で回転\n    p = Rot(p, vec3(0., phi, 0.));\n    return normalize(p);\n}\n\nvec3 goRightDir(vec3 p, float t){\n    vec3 res = cross(purenormal(p, t*0.1), goUpDir(p, t));\n    if(!isFace(p, t)){\n        res *= -1.;\n    }\n    return res;\n}\n\nfloat oscillate(float a, float b, float t){\n    return (sin(t)+1.)/2.*(b - a) + a;\n}\n\n\nvec3 normal(vec3 p, float t){\n    vec3 right = goRightDir(p, t*0.1);\n    vec3 up = goUpDir(p, t*0.1);\n    vec3 n = purenormal(p, t*0.1);\n    vec3 col = getColor(p, t);\n    col.xy *= 2.;\n    col.xy -= vec2(1.);\n    col.xy *= -10.;// bump強度\n    mat3 m = mat3(right, up, n);\n    return m*col;\n}\n\n#define time iTime\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\n    // yのほうがちいさいので。上端が0.5になる。右はじは0.5をこえる。\n\tvec2 uv = ( fragCoord.xy - iResolution.xy/2. )/iResolution.y;\n\n\t\n    // camposの位置に使う\n\tfloat t1 = 0.;// - min(mo.y*1.3,.4);\n\t//float t2 = time*0.1+2.2;\n    float t2 = 0.;\n\tfloat t3 = 0.;\n\t\n\n\t//directiong。カメラのむき。カメラが1点で、スクリーン位置に応じていろんな方向をむく。\n    // カメラのむきといいつつ、カメラからでる光線のむきなことに注意。\n\tvec3 p = normalize(vec3(uv,2.3)); // 上端が0.5なので、atan(0.5/2.3)*2で視野角だいたい24度。\n\t\t//p = Rot(p,vec3(t1,t2,t3));\n\t//camera position\n\tvec3 campos = vec3(0.,0.,-4.2);\n\t\t//campos = Rot(campos,vec3(t1,t2,t3));\n\t//return surface distance\n\tfloat dd = dis(campos,p,time);\n\n\tvec4 col = vec4(0.);\n\tif(dd<10.){\n\t\tvec3 surface = campos + dd*p;\n\t\tvec3 nDir = normal(surface, time);\n\t\t\t//nDir = max(abs(nDir-0.13)-0.1,0.);\n        vec3 surface2eye = normalize(surface - p);\n        float ang = dot(nDir, surface2eye);\n        vec3 baseColor = getColor(surface, time);\n        col.rgb = ang*baseColor;\n        col.rgb = vec3(dot(vec3(0., 0., -1.), nDir));\n        \n\t}\n    \n    {\n        //float phi = oscillate(-PI/2.+0.01, PI/2.-0.01, time*0.5);\n        //float theta = -PI/4.;\n        float phi = 0.;\n        float theta = -time*.5;\n        vec3 pons = vec3(cos(-time*.1)*cos(phi), sin(phi), sin(-time*.1)*cos(phi))*.5;\n        pons = Rot(pons, vec3(0., theta, 0.));\n        //vec3 pons = vec3(cos(PI/.3)*cos(phi), sin(phi), sin(PI/.3)*cos(phi))*.5;\n        vec3 camDirUp = normalize(vec3(0., 0.5, 2.3));\n        vec3 camDirRight = normalize(vec3(0.5*iResolution.x/iResolution.y, 0., 2.3));\n        //pons = camDirRight;\n        //pons = normalize(vec3(-0.5*iResolution.x/iResolution.y, 0., 2.3)); // !?\n        //pons = normalize(vec3(0., -0.5*sin(time), 2.3));\n        \n        //res =world2screen(vec3(.5, .0, -.5), campos, vec3(0.0, 0.0, 2.3), camDirRight, camDirUp);\n        //if(distance(res, fragCoord) < 5.){\n        //    col.rgb = vec3(1., 1., 1.);\n        //}\n        //if(line3d(fragCoord, pons, pons + .2*normal(pons, time*0.1), campos, vec3(0.0, 0.0, 2.3), camDirRight, camDirUp) < 1.0){\n\n        if(distance(world2screen(pons, campos, vec3(0.0, 0.0, 2.3), camDirRight, camDirUp), fragCoord) < 2.){\n        col.rgb = vec3(1., 1., 1.);\n        }\n        \n        //up\n        if(line3d(fragCoord, pons, pons + goUpDir(pons, time*0.1)*.2, campos, vec3(0., 0., 2.3), camDirRight, camDirUp) < 1. ||\n        line3d(fragCoord, pons, pons + purenormal(pons, time*0.1)*.2, campos, vec3(0., 0., 2.3), camDirRight, camDirUp) < 1. ||\n        line3d(fragCoord, pons, pons + goRightDir(pons, time*0.1)*.2, campos, vec3(0., 0., 2.3), camDirRight, camDirUp) < 1.)\n        {\n            col.rgb = vec3(1., 0., 0.);\n            if(pons.z > 0.){\n                col.rgb *= .5;\n            }\n        }\n        if(line3d(fragCoord, pons, pons + normal(pons, time*0.1)*.2, campos, vec3(0., 0., 2.3), camDirRight, camDirUp) < 1.){\n        col.rgb = vec3(0., 0., 1.);\n        }\n    }\n\t\n\tfragColor = vec4( col.rgb, 1.0 );\n    \n    //fragColor = texture(iChannel2, ( fragCoord.xy )/iResolution.xy);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4sf3Rr","filepath":"/media/a/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","previewfilepath":"/media/ap/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"\nvec3 getColor(vec2 p){\n// pは解像度ベース\nreturn texture(iChannel1, p/iResolution.xy).xyz;\n}\n\n#define time iTime\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\n    // yのほうがちいさいので。上端が0.5になる。右はじは0.5をこえる。\n\tvec2 uv = ( fragCoord.xy )/iResolution.xy;\n    float xdiff = getColor(fragCoord.xy + vec2(1., 0.)).x - getColor(fragCoord.xy - vec2(1., 0.)).x;\n\txdiff /= 2.;\n    float ydiff = getColor(fragCoord.xy + vec2(0., 1.)).x - getColor(fragCoord.xy - vec2(0., 1.)).x;\n\tydiff /= 2.;\n    \n    vec2 diff = vec2(xdiff, ydiff);  // -1-+1\n    diff = (diff + vec2(1.))/2.;\n\t\n\tfragColor = vec4(diff, 1., 1.0);;\n    //fragColor = vec4(getColor(fragCoord), 1.);\n}","name":"Buffer A","description":"","type":"buffer"}]}
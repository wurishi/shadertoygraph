{"ver":"0.1","info":{"id":"7tycDG","date":"1662104824","viewed":291,"name":"Raytracing 7- BRDF Supersampling","username":"KylBlz","description":"This step halves the eval resolution (1/4spp) then uses the G buffer with spatiotemporal and BRDF reprojection super sampling to re-double it. BRDF reprojection almost eliminates smudging from long integration times. No indirect solutions yet :)","likes":8,"published":1,"flags":32,"usePreview":0,"tags":["ray","sampling","tracing","brdf","super","reprojection"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n\n    The shadows don't have any spatiotemporal (ST) or BRDF reprojection yet\n\n    To play with the ST BRDF reprojection you could pause it while the\n    light and camera are moving a lot. I like to click-drag the mouse on\n    the window to continue integration, then make sure it doesnt change\n    too much (except the shadows...)\n\n    [Buffer A] Full size G buffer\n    [Buffer B] Half size Specular buffer\n    [Buffer C] Half size Diffuse buffer\n    [Buffer D] Full size ST BRDF supersampling\n\n*/\n\n// Thanks Paniq\nvec3 linear_srgb(vec3 x) {\n    return mix(1.055*pow(x, vec3(1./2.4)) - 0.055, 12.92*x, step(x, vec3(0.0031308)));\n}\n\nvec3 srgb_linear(vec3 x) {\n    return mix(pow((x + 0.055)/1.055,vec3(2.4)), x / 12.92, step(x, vec3(0.04045)));\n}\n\n// Paniq's ACES fitted from https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl\nvec3 ACESFitted(vec3 color) {\n\t// ODT_SAT => XYZ => D60_2_D65 => sRGB\n    color = color * mat3(\n        0.59719, 0.35458, 0.04823,\n        0.07600, 0.90834, 0.01566,\n        0.02840, 0.13383, 0.83777\n    );\n    // Apply RRT and ODT\n    vec3 a = color * (color + 0.0245786) - 0.000090537;\n    vec3 b = color * (0.983729 * color + 0.4329510) + 0.238081;\n    color = a / b;\n\t// Back to color space\n    color = color * mat3(\n         1.60475, -0.53108, -0.07367,\n        -0.10208,  1.10813, -0.00605,\n        -0.00327, -0.07276,  1.07602\n    );\n    // Clamp to [0, 1]\n    return clamp(color, 0.0, 1.0);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    // tonemap\n    fragColor.rgb = linear_srgb(ACESFitted(texelFetch(iChannel0, ivec2(fragCoord.xy), 0).rgb));\n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"\n//////////////////////////////// Rendering Configuration ////////////////////////////////\n\n// raymarching steps\n#define STEPS 128\n// number of frames to reproject and smooth over time (max 32)\n#define TEMPORALSMOOTHING 16\n\n// direct lit lambert surface\n#define SMP_DIRECT_LAMBERT 1\n// lambert surface lit lambert surface\n#define SMP_LAMBERT_SURFACE_LAMBERT 1\n\n// direct lit phong surface\n#define SMP_DIRECT_PHONG 1\n// phong surface lit phong surface\n#define SMP_PHONG_SURFACE_PHONG 1\n\n// origin, direction, t\nstruct ray { vec3 o; vec3 d; float t; };\n// location, normal, curvature, object ID\nstruct hit { vec3 l; vec3 n; float c; int o; };\n// normal, t, object ID\nstruct pln { vec3 n; float t; int o; };\n// location, radius, object ID\nstruct sph { vec3 l; float r; int o; };\n// direction, pdf weight, path length\nstruct smp { vec3 d; float w; float l; };\n// color, path length, num samples, object ID\nstruct buf { vec4 c; int n; int o; };\n// normal, object ID, t, curvature\nstruct gbf { vec3 n; int o; float t; float c; };\n// surface color, emission, surface properties, PDF weight, path length\nstruct ctb { vec3 c; vec3 e; vec3 s; float w; float l; };\n\n//////////////////////////////// Math Toolkit ////////////////////////////////\n\nconst float\teps = 0.001, ieps = 0.999, zfar = 50.0, FOV = 2.0, epsCol = 0.00390625, sqrtEpsCol = 0.0625,\n            HPI = 1.5707963, PI = 3.1415926, TWOPI = 6.2831853, SQRT2 = 1.4142136, SC45 = 0.7071068;\nconst vec2\t  VEL = vec2(0.5, 0.5),   POS = vec2(1.5, 0.5),   ROT = vec2(2.5, 0.5),   MOU = vec2(3.5, 0.5);\nconst vec2\tL_VEL = vec2(4.5, 0.5), L_POS = vec2(5.5, 0.5), L_ROT = vec2(6.5, 0.5), L_MOU = vec2(7.5, 0.5);\n\nconst vec4 INIT_POS = vec4( 4.0, 3.0, 4.0, 0.0),\n    \t   INIT_VEL = vec4( 0.0, 0.0, 0.0, 0.0),\n    \t   INIT_ROT = vec4( 0.0, PI, 0.0, 0.0),\n           INIT_MOU = vec4( 0.0 );\n\n// some global material properties because im tired of finding them all\nfloat rough = 4.0;\nfloat ior = 16.0;\n\n// 2x2 quadrant helpers\nint quadrant(in vec2 uv) {\n    return 2 * int(uv.y > 0.5) + int(uv.x > 0.5);\n}\nvec2 quadrant(in vec2 uv, in int ind) {\n    return 0.5 * (uv + vec2(ind & 1, ind >> 1));\n}\nvec2 quadrants(in vec2 uv) {\n    return fract(uv * 2.0);\n}\nvec2 quadrantMax(int ind) {\n    return 0.5 * (1.0 + vec2(ind & 1, ind >> 1));\n}\n\n// generate a unique value for each pixel/frame\nint genSeed(in int f, in ivec2 c, in ivec2 r) {\n    return (c.x + c.y*2 + f*11) + (c.x*1155 ^ c.y*2244);\n}\n\n// https://www.shadertoy.com/view/7dByR1\nfloat weyl1(in int v) {\n    return fract(float(v*40503) / float(0xffffU));\n}\nvec2 weyl2(in int v) {\n    return fract(vec2(v*ivec2(49471, 37345)) / float(0xffffU));\n}\nvec3 weyl3(in int v) {\n    return fract(vec3(v*ivec3(53685, 43977, 36025)) / float(0xffffU));\n}\n\n// fudged a bit to cut it off close to the (0,1) interval\nvec2 quant2(in vec2 x) {\n    vec2 t = x - 0.5;\n    vec2 a =-0.0644 * t;\n    vec2 b = 1.8977 * t;\n    vec2 c = 0.3479 * t;\n    return a / (b*b - 1.0) + c + 0.5;\n}\nvec3 quant3(in vec3 x) {\n    vec3 t = x - 0.5;\n    vec3 a =-0.0644 * t;\n    vec3 b = 1.8977 * t;\n    vec3 c = 0.3479 * t;\n    return a / (b*b - 1.0) + c + 0.5;\n}\n\n// concentric mappnig square [0,1] to circle [0,1]\nvec2 concentric(in vec2 v) {\n    vec2 w = v * 2.0 - 1.0;\n    float thta, rad;\n    if (abs(w.x) > abs(w.y)) {\n        rad = w.x;\n        thta = PI/4.0 * (w.y/w.x);\n    } else {\n        rad = w.y;\n        thta = PI/2.0 - PI/4.0 * (w.x/w.y);\n    }\n    return rad * vec2(cos(thta), sin(thta));\n}\n\n// orthonormal basis at normal\nvoid basis(in vec3 n, out vec3 f, out vec3 r) {\n    float s = (n.z >= 0.0)? 1.0: -1.0;\n    float a = 1.0 / (s + n.z);\n    float b = -n.x*n.y*a;\n    f = vec3(1.0 - n.x*n.x*a*s, b*s, -n.x*s);\n    r = vec3(b, s - n.y*n.y*a, -n.y);\n}\n\nmat2 rotmat(float a) {\n    float c = cos(a), s = sin(a);\n    return mat2(c, s, -s, c);\n}\n\nvec3 rotateXY(in vec3 p, in vec2 angle) {\n\tvec2 c = cos(angle), s = sin(angle);\n    vec3 o = p;\n\to.yz *= mat2(c.x, s.x, -s.x, c.x); \n    o.xz *= mat2(c.y, s.y, -s.y, c.y);\n\treturn o;\n}\n\nfloat linearAngle(float d, float r) {\n    return asin(clamp(r/d, eps, ieps));\n}\n\n// BRDF functions\nfloat solidAngle(float d2, float r2) {\n    float sa = (1.0 - sqrt(1.0 - clamp(r2/d2, 0.0, 1.0))) * TWOPI;\n    return max(eps, sa);\n}\n\nfloat Schlick(in vec3 hn, in vec3 rfl, in float r1, in float r2) {\n   \tfloat r0 = (r1 - r2) / (r1 + r2);\n    float sch = mix(r0*r0, 1.0, pow(1.0 - max(0.0, dot(rfl, hn)), 5.0));\n\treturn max(eps, sch);\n}\n\nfloat Lambertian(in vec3 hn, in vec3 nlv) {\n    float lam = dot(nlv, hn);\n    return max(eps, lam);\n}\n\nfloat Phong(in vec3 nlv, in vec3 rfl, in float gloss) {\n    float ph = pow(max(0.0, dot(nlv, rfl)), gloss);\n    return max(eps, ph * sqrt(gloss));\n}\n\nfloat SchlickPhong(in vec3 rd, in vec3 hn, in vec3 nlv, in float r1, in float r2, in float gloss) {\n    vec3 rfl = reflect(rd, hn);\n    float sch = Schlick(hn, rfl, r1, r2);\n    float ph = Phong(nlv, rfl, gloss);\n    return max(eps, sch * ph);\n}\n\n// using gaussian distribution\nvec3 uniformSphere(int seed) {\n    vec3 rnd = quant3(weyl3(seed));\n    return rnd * 2.0 - 1.0;\n}\n\n// using normalized gaussian distribution\nvec3 uniformDir(int seed) {\n    return normalize(uniformSphere(seed));\n}\n\n// only one hemisphere\nvec3 uniformHemiDir(vec3 hn, int seed) {\n    vec3 rnd = uniformDir(seed);\n    return rnd * sign(dot(hn, rnd));\n}\n\n// cosine distribution\nvec3 cosHemiDir(vec3 hn, int seed) {\n    vec2 w = weyl2(seed);\n    vec2 c = concentric(w);\n    return vec3(c.x, c.y, sqrt(max(0.0, 1.0 - c.x*c.x - c.y*c.y)));\n}\n\n// uniform sample cone\nvec3 uniformConeDir(vec3 lv, float lr, in int seed) {\n    vec2 c = concentric(weyl2(seed));\n    // cone section\n    float sa = tan(linearAngle(length(lv), lr));\n    vec3 u, r, nlv = normalize(lv);\n    basis(nlv, r, u);\n    return normalize(nlv + sa * (r * c.x + u * c.y));\n}\n\nvec3 cosConeDir(vec3 lv, float lr, in int seed) {\n    vec2 c = concentric(weyl2(seed));\n    // cosine distributed\n\tc = quant2(c * 0.5 + 0.5) * 2.0 - 1.0;\n    // cone section\n    float sa = tan(linearAngle(length(lv), lr));\n    vec3 u, r, nlv = normalize(lv);\n    basis(nlv, r, u);\n    return normalize(nlv + sa * (r * c.x + u * c.y));\n}\n\n//////////////////////////////// Scene Modeling ////////////////////////////////\n\nvec2 sdMin(in vec2 a, in vec2 b) {\n    if (a.x < b.x)\n        return a;\n    return b;\n}\n\n// Thanks iq and Dave Smith\nfloat smin( float a, float b, float k ) {\n    float h = max( k-abs(a-b), 0.0 )/k;\n    return min( a, b ) - h*h*k*0.25;\n}\n\nfloat smax(float a, float b, float k) {\n    return -smin(-a,-b,k);\n}\n\nfloat sdBox(in vec3 p, in mat3 o, in vec3 s) {\n    vec3 d = abs(p * o) - s;\n    return min(0.0, max(d.x, max(d.y, d.z))) + length(max(d, 0.0));\n}\n\nconst int\n    LIGHT = 1,\n    FLOOR = 2,\n    WALL1 = 3,\n    WALL2 = 6,\n    CEIL = 7,\n    SPH = 10;\n\n// light parameters\nsph light = sph(vec3(4.0, 4.0, -5.0), 1.0, LIGHT);\nvec3 lightColor = vec3(1.0, 0.9, 0.8);\n// plane parameters\npln flr = pln(vec3( 0.0, 1.0, 0.0), 0.0, FLOOR);\npln cil = pln(vec3( 0.0,-1.0, 0.0), 8.0, CEIL);\npln wa1 = pln(vec3(-1.0, 0.0, 0.0), 10.0, WALL1);\npln wa2 = pln(vec3( 0.0, 0.0, 1.0), 10.0, WALL2);\n\nctb getSurface(in hit h) {\n    ctb ret;\n    if (h.o == LIGHT) {\n        ret.c = lightColor; // reflection color\n        ret.e = lightColor; // emission color\n        ret.s = vec3(1.0, 1.0, rough); // diffuse (x) specular (y)\n    } else if (h.o < 1) {\n        \n    } else {\n        float refl = float(int(h.o == FLOOR || h.o == CEIL)) * (0.5 + float(int(floor(h.l.x) + floor(h.l.y + 0.5) + floor(h.l.z)) & 1)) * 0.333 + 0.666;\n        float matCol = float(h.o);\n        float cm = cos(matCol) * 0.25;\n        float sm = sin(matCol) * 0.25;\n        ret.c = vec3(0.5 + cm, 0.5 + sm, 0.5 - (cm + sm) * 0.5) * 0.333;\n        ret.e = vec3(0.0); // emission color\n        ret.s = vec3(refl, refl, rough); // diffuse (x) specular (y) gloss (z)\n    }\n    \n    // loose the average energy for the material, based on measurements from unbiased rendering * 10\n    ret.w = 0.07 * 10.0;\n\n    return ret;\n}\n\nvec2 sdf(in vec3 l, in int o) {\n    vec2 d = vec2(zfar, 0.0);\n    d = (o == FLOOR)? d: sdMin(d, vec2(dot(l, flr.n) + flr.t, FLOOR));\n    d = (o == CEIL )? d: sdMin(d, vec2(dot(l, cil.n) + cil.t, CEIL));\n    d = (o == WALL1)? d: sdMin(d, vec2(dot(l, wa1.n) + wa1.t, WALL1));\n    d = (o == WALL2)? d: sdMin(d, vec2(dot(l, wa2.n) + wa2.t, WALL2));\n    d = (o == LIGHT)? d: sdMin(d, vec2(length(l - light.l) - light.r, LIGHT));\n    d = (o == SPH)?   d: sdMin(d, vec2(length(l - vec3(8.0, 1.0, -8.0)) - 1.0, SPH));\n    d = (o == SPH+1)? d: sdMin(d, vec2(length(l - vec3(6.0, 1.0, -8.0)) - 1.0, SPH+1));\n    d = (o == SPH+2)? d: sdMin(d, vec2(length(l - vec3(4.0, 1.0, -8.0)) - 1.0, SPH+2));\n    d = (o == SPH+3)? d: sdMin(d, vec2(length(l - vec3(2.0, 1.0, -8.0)) - 1.0, SPH+3));\n    d = (o == SPH+4)? d: sdMin(d, vec2(length(l - vec3(0.0, 1.0, -8.0)) - 1.0, SPH+4));\n    return d;\n}\n\nvoid updateScene(in float time) {\n    // do something\n    light.l.x -= sin(time) * 2.0;\n    light.l.z -= cos(time) * 1.0;\n}\n\nvec2 march(in vec3 l, in vec3 rd, in int ignore) {\n    float t = 0.0;\n    vec2 sdSmp;\n    for (int i = 0; i < STEPS; ++i) {\n        sdSmp = sdf(l + rd * t, ignore);\n        t += sdSmp.x;\n        if (sdSmp.x < eps)\n            break;\n        if (t > zfar)\n            return vec2(zfar, 0.0);\n    }\n    return vec2(min(t, zfar), sdSmp.y);\n}\n\n// Thanks Nimitz https://www.shadertoy.com/view/Xts3WM\nvec4 norcurv(in vec3 p, in float ep, int ignore) {\n    vec2 e = vec2(-1., 1.)*ep;\n    float t1 = sdf(p + e.yxx, ignore).x, t2 = sdf(p + e.xxy, ignore).x;\n    float t3 = sdf(p + e.xyx, ignore).x, t4 = sdf(p + e.yyy, ignore).x;\n    return vec4(normalize(e.yxx*t1 + e.xxy*t2 + e.xyx*t3 + e.yyy*t4), (t1+t2+t3+t4 - 4.0*sdf(p, ignore).x)/(ep*ep));\n}\n\n//////////////////////////////// PDF only ////////////////////////////////\n\n// surface illuminated by a sphere light, returns sample direction, pdf, and path length\nsmp SphereLightPDF(in hit h, in sph l, in int seed) {\n    vec3 lv = l.l - h.l;\n    float lv2 = dot(lv, lv);\n    vec3 lambDir = uniformConeDir(lv, l.r, seed);\n    float lpdf = solidAngle(lv2, l.r*l.r);\n    return smp(lambDir, lpdf, sqrt(lv2));\n}\n\n// surface illuminated by a lambertian surface, returns sample direction, pdf, and path length\nsmp LambertPlanePDF(in hit h, in sph l, in pln p, in int seed) {\n    // dot project light onto plane\n    vec3 d = l.l - p.n * (dot(l.l, p.n) + p.t);\n    // surface to diffuse point d\n    vec3 dv = d - h.l;\n    float dv2 = dot(dv,dv);\n    float ldv = sqrt(dv2);\n    // diffuse point to light\n    vec3 ld = l.l - d;\n    float ld2 = dot(ld,ld);\n    float lld = sqrt(ld2);\n    // sample disc on ground below\n    vec3 lambDir = uniformConeDir(normalize(dv), 0.8, seed);\n    // material and light functions\n    float lpdf = solidAngle(pow(ldv*0.1 + lld*0.5, 2.0), l.r*l.r);\n    float gpdf = Lambertian(p.n, normalize(ld));\n    // +0: keep surfaces sharp, +lld keep reflections sharp\n    return smp(lambDir, lpdf * gpdf, 0.0);\n}\n\n// surface illuminated by a phong surface, returns sample direction, pdf, and path length\nsmp PhongPlanePDF(in hit h, in sph l, in pln p, in int seed) {\n    // get distance from each point to the plane\n    float a = dot(h.l, p.n) + p.t;\n    float b = dot(l.l, p.n) + p.t;\n    // similar triangles, just use the ratio of side lengths\n    vec3 s = mix(h.l - a*p.n, l.l - b*p.n, a / (a + b));\n    // surface to specular point s\n    vec3 sv = s - h.l;\n    float sv2 = dot(sv, sv);\n    float lsv = sqrt(sv2);\n    // specular point to light\n    vec3 ls = l.l - s;\n    float ls2 = dot(ls, ls);\n    float lls = sqrt(ls2);\n    // sample the image of the specular reflection on the surface\n    vec3 ts = sv * lls;\n    vec3 phongDir = uniformConeDir(ts, l.r * lsv * (TWOPI / rough), seed);\n    // material and light functions\n    float lpdf = solidAngle(ls2, l.r*l.r);\n    float spdf = SchlickPhong(normalize(sv), -p.n, normalize(ls), 1.0, ior, rough);\n    // +0: keep surfaces sharp, +lls keep reflections sharp\n    return smp(phongDir, lpdf * spdf, lls);\n}\n\n//////////////////////////////// sampling only ////////////////////////////////\n\n// marches the light, returns contribution RGB\nctb LightContribution(in hit h, in smp s) {\n    vec2 lm = march(h.l, s.d, h.o);\n    if (int(lm.y) != LIGHT)\n        return ctb(vec3(0.0), vec3(0.0), vec3(0.0), 0.0, 0.0);\n    // surface color, surface properties, emission\n    return ctb(lightColor, lightColor, vec3(1.0, 1.0, rough), s.w, s.l);\n}\n\n// marches the surface and light, returns contribution RGB\nctb PlaneContribution(in smp s, in hit h, in pln p, in sph l, in int seed) {\n    // plane sample\n    vec2 res = march(h.l, s.d, h.o);\n    if (int(res.y) != p.o)\n        return ctb(vec3(0.0), vec3(0.0), vec3(0.0), 0.0, 0.0);\n    // move off the surface a little bit\n    vec3 _hl = h.l + s.d * res.x;\n    vec3 _lv = l.l - _hl;\n    float _lv2 = dot(_lv, _lv);\n    // light sampling\n    vec3 sampleDir = uniformConeDir(_lv, l.r, seed);\n    ctb li = LightContribution(hit(_hl, p.n, 0.0, p.o), smp(sampleDir, s.w, sqrt(_lv2)));\n    ctb surf = getSurface(hit(_hl, p.n, 0.0, p.o));\n    // surface color, material energy, light emission, light energy, pdf\n    return ctb(surf.c * surf.w * li.e * li.w, surf.e, surf.s, s.w, s.l);\n}\n\n//////////////////////////////// Sampling Strategy ////////////////////////////////\n\n// do unbiased sampling (diffuse BRDF)\nvec3 UnbiasedLambertian(in smp s, in hit h, in int seed) {\n    // unbiased sampling (GT)\n    vec3 smpUnbias = vec3(0.0);\n    for (int i = 0; i < SMP_DIRECT_LAMBERT; ++i) {\n        int si = seed + i;\n        // sample light\n        ctb cont = LightContribution(h, s);\n        // color * power\n        smpUnbias += cont.c * cont.w;\n    }\n    return smpUnbias /= float(SMP_DIRECT_LAMBERT);\n}\n\n// do unbiased sampling (specular BRDF)\nvec3 UnbiasedPhong(in ray r, in smp s, in hit h, in int seed) {\n    // march\n    vec2 pres = march(h.l, s.d, h.o);\n    int _ho = int(pres.y);\n    // hit light? good\n    if (_ho == LIGHT)\n        return lightColor * s.w;\n    // move off the surface a little bit\n    vec3 _hl = h.l + s.d * pres.x;\n    vec3 _lv = light.l - _hl;\n    float _lv2 = dot(_lv, _lv);\n    vec4 _hnc = norcurv(_hl, eps, -1);\n    hit _h = hit(_hl, _hnc.xyz, _hnc.w,  _ho);\n    // glossy reflection sampling\n    vec3 sampleDir = uniformConeDir(_lv, light.r, seed);\n    ctb li = LightContribution(_h, smp(sampleDir, s.w, sqrt(_lv2)));\n    ctb surf = getSurface(_h);\n    // surface color, material energy, light emission, light energy, surface emission\n    return surf.c * surf.w * li.e * li.w + surf.e;\n}\n\n// unbiased diffuse\nvoid brdfLambertian(inout ray r, inout hit h, in int seed) {\n    r.o = h.l + h.n * eps;\n    r.d = cosHemiDir(h.n, seed);\n}\n// unbiased specular\nvoid brdfPhong(inout ray r, inout hit h, in int seed) {\n    r.o = h.l + h.n * eps;\n    r.d = reflect(r.d, h.n); // not sure, replace with cone sample based on roughness\n}\n\n//////////////////////////////// Buffers ////////////////////////////////\n\n// from IQ's Normals Compression: https://www.shadertoy.com/view/llfcRl\nvec2 msign(vec2 v) {\n    return vec2((v.x >= 0.0)? 1.0: -1.0, (v.y >= 0.0)? 1.0: -1.0);\n}\n\nuint packSnorm2x8(vec2 v) {\n    uvec2 d = uvec2(round(127.5 + v * 127.5));\n    return d.x | (d.y << 8u);\n}\n\nuint octahedral_16(in vec3 nor) {\n    nor /= ( abs( nor.x ) + abs( nor.y ) + abs( nor.z ) );\n    nor.xy = (nor.z >= 0.0)? nor.xy: (1.0 - abs(nor.yx)) * msign(nor.xy);\n    return packSnorm2x8(nor.xy);\n}\n\nvec2 unpackSnorm2x8(uint d) {\n    return vec2(uvec2(d,d>> 8) & 255u) / 127.5 - 1.0;\n}\n\n// Rune Stubbe's version\nvec3 i_octahedral_16(uint data) {\n    vec2 v = unpackSnorm2x8(data);\n    vec3 nor = vec3(v, 1.0 - abs(v.x) - abs(v.y));\n    float t = max(0.0, -nor.z);\n    nor.x += (nor.x > 0.0)? -t: t;\n    nor.y += (nor.y > 0.0)? -t: t;\n    return normalize(nor);\n}\n\nvec4 encodeGbuffer(in gbf g) {\n    return vec4(octahedral_16(g.n), float(g.o) + eps, g.t, g.c);\n}\n\ngbf decodeGbuffer(in vec4 val) {\n    return gbf(i_octahedral_16(uint(val.x)), int(val.y), val.z, val.w);\n}\n\nvec4 encodeBuffer(in buf b) {\n    float m = 0.001;\n    return vec4(\n        float(packHalf2x16(b.c.rg * m)),\n        float(packHalf2x16(b.c.ba * m)),\n        float(b.n) + float(b.o) * 0.01001,\n        0.0\n    );\n}\n\nbuf decodeBuffer(in vec4 v) {\n    float m = 1000.0;\n    return buf(vec4(\n        unpackHalf2x16(uint(v.r)) * m,\n        unpackHalf2x16(uint(v.g)) * m),\n        int(v.b),\n        int(fract(v.b) * 100.1)\n    );\n}\n\nvoid decodeAll(in vec2 uv, in vec2 res, in int iFrame, in sampler2D g, in sampler2D f, out float asp, out ray r, out vec2 ir, out ray l, out vec2 lr, out hit h, out vec3 gli, out vec3 fli) {\n    asp = res.x / res.y;\n    vec2 ndca = (2.0 * uv - 1.0) * vec2(asp, 1.0);\n    if (iFrame > 1) {\n        // get current cam\n        vec4 g0 = texelFetch(g, ivec2(0, int(res.y) - 1), 0);\n        vec4 g1 = texelFetch(g, ivec2(int(res.x) - 1, int(res.y) - 1), 0);\n        vec4 f0 = texelFetch(f, ivec2(0, int(res.y) - 1), 0);\n        vec4 f1 = texelFetch(f, ivec2(int(res.x) - 1, int(res.y) - 1), 0);\n        r.o = g0.xyz;\n        ir = g1.xy;\n        l.o = f0.xyz;\n        lr = f1.xy;\n        gli = vec3(g1.zw, g0.w);\n        fli = vec3(f1.zw, f0.w);\n    } else {\n        // get initial cam\n        r.o = INIT_POS.xyz;\n        ir = INIT_ROT.xy;\n        l.o = INIT_POS.xyz;\n        lr = INIT_ROT.xy;\n        gli = light.l;\n        fli = light.l;\n    }\n    r.d = rotateXY(normalize(vec3(ndca, FOV)), ir);\n    l.d = rotateXY(normalize(vec3(ndca, FOV)), lr);\n    // get last trace\n    gbf gb = decodeGbuffer(textureLod(g, uv, 0.0));\n    r.t = gb.t;\n    h = hit(r.o + r.d * r.t, gb.n, gb.c, gb.o);\n}\n\n// mostly the same, just prevent from going to 0\nfloat fLambertian(in vec3 nlv, in vec3 hn) {\n    float l = max(0.1, dot(nlv, hn));\n    return l*l;\n}\nfloat fPhong(in vec3 nlv, in vec3 rfl, in float gloss) {\n    float p = pow(max(0.0, dot(nlv, rfl)), gloss) * sqrt(gloss);\n    return max(epsCol, p);\n}\n\n// proportional change in PDF (e.g. whatWeWant = whatWeHave * dBRDF(whereItWas, whereWeWant))\nfloat dSolidAngle(float dsq1, float dsq2, float rsq) {\n    float s1 = max(epsCol, solidAngle(dsq1, rsq));\n    float s2 = max(epsCol, solidAngle(dsq2, rsq));\n    return clamp(s2 / s1, 0.5, 2.0);\n}\n\nfloat dLambertian(in vec3 hn1, in vec3 nlv1, in vec3 hn2, in vec3 nlv2, in float rad) {\n    float d1 = max(sqrtEpsCol, Lambertian(hn1, nlv1));\n    float d2 = max(sqrtEpsCol, Lambertian(hn2, nlv2));\n    return clamp((d2*d2) / (d1*d1), 0.5, 2.0);\n}\n\nfloat dSchlickPhong(in vec3 rd1, in vec3 hn1, in vec3 nlv1, in vec3 rd2, in vec3 hn2, in vec3 nlv2, in float rad, in float r1, in float r2, in float gloss) {\n    vec3 rfl1 = reflect(rd1, hn1);\n    float p1 = max(sqrtEpsCol, Phong(nlv1, rfl1, gloss));\n    float s1 = max(sqrtEpsCol, Schlick(hn1, rfl1, r1, r2));\n    vec3 rfl2 = reflect(rd2, hn2);\n    float p2 = max(sqrtEpsCol, Phong(nlv2, rfl2, gloss));\n    float s2 = max(sqrtEpsCol, Schlick(hn2, rfl2, r1, r2));\n    return clamp((s2*p2) / (s1*p1), 0.5, 2.0);\n}\n\n// reproject geometry, brdf, time. xx1 is what we have, xx2 is what we want\nvec2 reprojectDiffuse(vec3 hl1, vec3 hn1, vec3 li1, vec3 hl2, vec3 hn2, vec3 li2, float rad) {\n    // fudged sphere light vectors\n    vec3 lv1 = (li1 - hl1) + hn1 * rad * ieps;\n    vec3 lv2 = (li2 - hl2) + hn2 * rad * ieps;\n    float dlv1 = dot(lv1, lv1);\n    float dlv2 = dot(lv2, lv2);\n    // BRDF reprojection\n    float dlamb = dLambertian(hn1, lv1 / sqrt(dlv1), hn2, lv2 / sqrt(dlv2), rad);\n    float dsa = dSolidAngle(dlv1, dlv2, rad*rad);\n    // this range should have to do with the varience\n    return vec2(dlamb * dsa, 1.0);\n}\n\nvec2 reprojectSpecular(vec3 rd1, vec3 hl1, vec3 hn1, vec3 li1, vec3 rd2, vec3 hl2, vec3 hn2, vec3 li2, float rad) {\n    // fudged sphere light vectors\n    vec3 lv1 = (li1 - hl1) + hn1 * rad * ieps;\n    vec3 lv2 = (li2 - hl2) + hn2 * rad * ieps;\n    float dlv1 = dot(lv1, lv1);\n    float dlv2 = dot(lv2, lv2);\n    // BRDF reprojection\n    float dsp = dSchlickPhong(rd1, hn1, lv1 / sqrt(dlv1), rd2, hn2, lv2 / sqrt(dlv2), rad, 1.003, ior, rough);\n    float dsa = dSolidAngle(dlv1, dlv2, rad*rad);\n    // this range should have to do with the varience\n    return vec2(dsp * dsa, 1.0);\n}\n\nvec2 reprojCoords(in vec3 ll, in vec2 lr, in vec3 hl, in float asp, in vec2 iChanRes) {\n    // last camera basis\n    vec3 lf = rotateXY(vec3(0.0, 0.0, 1.0), lr);\n    vec3 r = normalize(cross(vec3(0.0, 1.0, 0.0), lf));\n    vec3 u = normalize(cross(lf, r));\n    // dir to point\n    vec3 nhl = normalize(ll - hl);\n    // project into last cam basis\n    vec2 luv = vec2(dot(nhl, r), dot(nhl, u));\n    // project onto imaging plane NDC coords\n    luv = (luv * FOV) / (dot(nhl, lf) * vec2(asp, 1.0));\n    // ndc\n    return luv * 0.5 + 0.5;\n}\n\n// last loc, last orient, hit loc, hit object, 1/aspect, channel, resolution\nbuf reprojectBuffer(sampler2D iChannel, vec2 iChannelResolution, int qdr, in vec2 fc, in int o) {\n    // bounds check\n    if (any(lessThan(fc, vec2(-1.0))) || any(greaterThan(fc, quadrantMax(qdr) * iChannelResolution)))\n        return buf(vec4(0.0), 0, 0);\n    ivec2 ifc = ivec2(fc);\n    vec2 a = clamp(fc - vec2(ifc), vec2(0.0), vec2(1.0));\n    // samples with matching materials are considered\n    buf b   = decodeBuffer(texelFetch(iChannel, ifc,               0));\n    buf bx  = decodeBuffer(texelFetch(iChannel, ifc + ivec2(1, 0), 0));\n    buf by  = decodeBuffer(texelFetch(iChannel, ifc + ivec2(0, 1), 0));\n    buf bxy = decodeBuffer(texelFetch(iChannel, ifc + ivec2(1, 1), 0));\n    float c = float(int(b.o == o));\n    float cx = float(int(bx.o == o));\n    float cy = float(int(by.o == o));\n    float cxy = float(int(bxy.o == o));\n    // get number of samples that matched\n    float n = c + cx + cy + cxy;\n    if (n < 1.0)\n        return buf(vec4(0.0), 0, 0);\n    // fanciest mixing\n    if (n > 3.0) {\n        // TODO: brdf reprojection mixing\n        float ms = float(min(b.n, min(bx.n, min(by.n, bxy.n))));\n        return buf(\n            mix(mix(b.c  / max(1.0, float(b.n )), bx.c  / max(1.0, float(bx.n )), a.x),\n                mix(by.c / max(1.0, float(by.n)), bxy.c / max(1.0, float(bxy.n)), a.x), a.y) * ms,\n            int(ms), o\n        );\n    }\n    // fallback mixing\n    return buf(\n        vec4(c*b.c + cx*bx.c + cy*by.c + cxy*bxy.c) / n,\n        (int(c)*b.n + int(cx)*bx.n + int(cy)*by.n + int(cxy)*bxy.n) / int(n),\n        o\n    );\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//////////////////////////////// Full Size Geometry Buffer ////////////////////////////////\n\nmat3 cameraPoses(in float t) {\n    float time = mod(t, 8.0);\n    if (time < 2.)\n        return mat3(INIT_POS.xyz, INIT_ROT.xyz, vec3(0.0));\n    else if (time < 4.)\n        return mat3(vec3(-4.0, 1.5, -2.0), vec3(0.11, 2.2, 0.), vec3(0.0));\n    else if (time < 6.)\n        return mat3(vec3(8.0, 3.5, -2.0), vec3(-0.22, 3.5, 0.), vec3(0.0));\n    else if (time < 8.)\n        return mat3(vec3(-4.0, 5.5, -2.0), vec3(-0.33, 2.2, 0.), vec3(0.0));\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n\n    // update scene to this time\n    updateScene(iTime);\n    \n    vec3 lli = light.l;\n    if (iFrame > 1) {\n        vec4 g0 = texelFetch(iChannel0, ivec2(0, int(iResolution.y) - 1), 0);\n        vec4 g1 = texelFetch(iChannel0, ivec2(int(iResolution.x) - 1, int(iResolution.y) - 1), 0);\n        lli = vec3(g1.zw, g0.w);\n    }\n\n    float asp = iResolution.x / iResolution.y;\n    vec2 ndca = (2.0 * fragCoord.xy / iResolution.xy - 1.0) * vec2(asp, 1.0);\n\n    // get current cam\n\tvec3 l = INIT_POS.xyz;\n    vec2 o = INIT_ROT.xy;\n    if (true && iFrame > 1) {\n        // just smoothstep between some nice angles\n        float t = (iTime) * 0.5;\n        mat3 cLast = cameraPoses(t);\n        mat3 cNext = cameraPoses(t + 1.0);\n        float ft = fract(t);\n        ft = ft*ft*(3.0-2.0*ft);\n        l = mix(cLast[0], cNext[0], ft);\n        o = mix(cLast[1].xy, cNext[1].xy, ft);\n    }\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(l, light.l.z);\n            return;\n        } else if (x == int(iResolution.x) - 1) {\n            fragColor = vec4(o.xy, light.l.xy);\n            return;\n        }\n    }\n\n    // initial scene march\n    vec3 d = rotateXY(normalize(vec3(ndca, FOV)), o.xy);\n    vec2 h = march(l, d, -1);\n    vec3 hl = l + d * h.x;\n    int ho = int(h.y);\n    \n    // get second closest object to ignore during normal computation\n    int io = int(sdf(hl, ho).y);\n    vec4 nc = norcurv(hl, 0.01, io);\n    \n    // encode normal, object ID, depth, curvature\n    fragColor = encodeGbuffer(gbf(nc.xyz, ho, h.x, nc.w));\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"//////////////////////////////// Diffuse Buffer Quadrants ////////////////////////////////\n\n#if SMP_DIRECT_LAMBERT\nvec4 DIRECT_LAMBERT(in hit h, in int seed, in int lastFrameN) {\n    ctb contrib = ctb(vec3(0.0), vec3(0.0), vec3(0.0), 0.0, 0.0);\n    vec3 ret = vec3(0.0);\n    int si = seed;\n    // take direct light samples\n    vec3 smpDirect = vec3(0.0);\n    for (int i = 0; i < SMP_DIRECT_LAMBERT; ++i, ++si) {\n        // get all PDFs\n        smp dl = SphereLightPDF(h, light, si);\n#ifdef SUPERBIAS\n        if (lastFrameN == 0) {\n            // try to always hit light and compensate for overshooting the integral\n            vec3 flv = (light.l - h.l) + h.n * light.r * ieps;\n            float d2 = max(0.0625, Lambertian(h.n, normalize(flv)));\n            dl.w *= d2*d2;\n        } else {\n            dl.w *= Lambertian(h.n, dl.d);\n        }\n#else\n        // apply lambert pdf\n        dl.w *= Lambertian(h.n, dl.d);\n#endif\n        // compute CDF\n        //float lightCDF = dl.p;\n        // roulette sampling\n        //float rnd = weyl1(si) * lightCDF;\n        //if (rnd <= lightCDF)\n            contrib = LightContribution(h, dl);\n        // color * power * cdf (omitted)\n        smpDirect += contrib.c * contrib.w; // * lightCDF / max(eps, contrib.w);\n    }\n    ret += smpDirect / float(SMP_DIRECT_LAMBERT);\n    return vec4(ret, 0.0);\n}\n#endif\n\nvec4 LAMBERT_SURFACE_LAMBERT(in hit h, in int seed, in int lastFrameN) {\n    ctb contrib = ctb(vec3(0.0), vec3(0.0), vec3(0.0), 0.0, 0.0);\n    vec3 ret = vec3(0.0);\n    int si = seed;\n    // take indirect diffuse samples\n    vec3 smpIDD = vec3(0.0);\n    for (int i = 0; i < SMP_LAMBERT_SURFACE_LAMBERT; ++i, si += 4) {\n        // get all PDFs\n        smp fd = LambertPlanePDF(h, light, flr, si+1);\n        smp cd = LambertPlanePDF(h, light, cil, si+2);\n        smp w1d = LambertPlanePDF(h, light, wa1, si+3);\n        smp w2d = LambertPlanePDF(h, light, wa2, si+4);\n        // apply lambert pdf\n        fd.w *= Lambertian(h.n, fd.d);\n        cd.w *= Lambertian(h.n, cd.d);\n        w1d.w *= Lambertian(h.n, w1d.d);\n        w2d.w *= Lambertian(h.n, w2d.d);\n        // compute CDF\n        float floorDiffCDF = fd.w;\n        float ceilDiffCDF = floorDiffCDF + cd.w;\n        float w1DiffCDF = ceilDiffCDF + w1d.w;\n        float w2DiffCDF = w1DiffCDF + w2d.w;\n        // roulette sampling\n        float rnd = weyl3(si).z * w2DiffCDF;\n        if (rnd <= floorDiffCDF)\n            contrib = PlaneContribution(fd, h, flr, light, si+1);\n        else if (rnd <= ceilDiffCDF)\n            contrib = PlaneContribution(cd, h, cil, light, si+2);\n        else if (rnd <= w1DiffCDF)\n            contrib = PlaneContribution(w1d, h, wa1, light, si+3);\n        else\n            contrib = PlaneContribution(w2d, h, wa2, light, si+4);\n        // emissive + color * diffuse * cdf\n        smpIDD += contrib.e + contrib.c * contrib.s.x * w2DiffCDF / max(eps, contrib.w);\n    }\n    ret += smpIDD / float(SMP_LAMBERT_SURFACE_LAMBERT);\n    return vec4(ret, 0.0);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    float asp;\n    vec2 uv = fragCoord / iResolution.xy;\n    int qdr = quadrant(uv);\n    uv = quadrants(uv);\n\n    // update to this frame\n    updateScene(iTime);\n\n    // defines variables for current hit, current and last ray, current and last light, g light, last frame light\n    hit h;\n    ray l, r;\n    vec3 gli, fli;\n    vec2 ir, lr;\n    decodeAll(uv, iResolution.xy, iFrame, iChannel0, iChannel1, asp, r, ir, l, lr, h, gli, fli);\n\n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(r.o, light.l.z);\n            return;\n        } else if (x == int(iResolution.x) - 1) {\n            fragColor = vec4(ir, light.l.xy);\n            return;\n        }\n    }\n    \n    // geometric reprojection of our quadrant\n    vec2 suv = reprojCoords(l.o, lr, h.l, asp, iResolution.xy);\n    buf lastFrame = reprojectBuffer(iChannel1, iChannelResolution[1].xy, qdr, quadrant(suv, qdr) * iResolution.xy - 0.5, h.o);\n\n    if (qdr == 0) {\n        // direct lambert BRDF reprojection\n        lastFrame.c *= reprojectDiffuse(h.l, h.n, fli, h.l, h.n, gli, light.r).xxxy;\n    }\n\n    // temporal smoothing\n    if (lastFrame.n > TEMPORALSMOOTHING) {\n        float s = float(TEMPORALSMOOTHING) / float(lastFrame.n);\n        lastFrame.c *= s;\n        lastFrame.n = TEMPORALSMOOTHING;\n    }\n    \n    // sample from first surface\n    vec4 smp = vec4(0.0);\n    // not nothing\n    if (h.o != LIGHT) {\n        int seed = genSeed(iFrame, ivec2(fragCoord.xy), ivec2(iResolution.xy));\n        // do biased sampling 2 diffuse estimators\n#if SMP_DIRECT_LAMBERT\n        if (qdr == 0)\n            smp = DIRECT_LAMBERT(h, seed, lastFrame.n);\n#endif\n#if SMP_LAMBERT_SURFACE_LAMBERT\n        if (qdr == 1)\n            smp = LAMBERT_SURFACE_LAMBERT(h, seed, lastFrame.n);\n#endif\n    }\n#ifdef SUPERBIAS\n    int smpWeight = (lastFrame.n == 0)? SUPERBIAS_WEIGHT: 1;\n#else\n    int smpWeight = 1;\n#endif\n    fragColor = encodeBuffer(buf(lastFrame.c + smp * float(smpWeight), lastFrame.n + smpWeight, h.o));\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"//////////////////////////////// Specular Buffer Quadrants ////////////////////////////////\n\n#if SMP_DIRECT_PHONG\nvec4 DIRECT_PHONG(in ray r, in hit h, in int seed, in int lastFrameN) {\n    ctb contrib = ctb(vec3(0.0), vec3(0.0), vec3(0.0), 0.0, 0.0);\n    vec3 ret = vec3(0.0);\n    vec2 plen = vec2(0.0);\n    int si = seed;\n    // take direct light samples\n    vec3 smpDirect = vec3(0.0);\n    vec2 dirPthLn = vec2(0.0);\n    for (int i = 0; i < SMP_DIRECT_PHONG; ++i, ++si) {\n        // get all PDFs\n        smp dl = SphereLightPDF(h, light, si);\n#ifdef SUPERBIAS\n        if (lastFrameN == 0) {\n            // try to always hit light and compensate for overshooting the integral\n            dl.w *= SchlickPhong(r.d, h.n, normalize((light.l - h.l) + h.n * light.r * ieps), 1.0, ior, rough);\n        } else {\n            dl.w *= SchlickPhong(r.d, h.n, dl.d, 1.0, ior, rough);\n        }\n#else\n        // apply phong pdf\n        dl.w *= SchlickPhong(r.d, h.n, dl.d, 1.0, ior, rough);\n#endif\n        // compute CDF\n        //float lightCDF = dl.p;\n        // roulette sampling\n        //float rnd = weyl1(si) * lightCDF;\n        //if (rnd <= lightCDF)\n            contrib = LightContribution(h, dl);\n        // color * diffuse energy * cdf (omitted)\n        smpDirect += contrib.c * contrib.w; // * lightCDF / max(eps, contrib.w);\n        dirPthLn += vec2(contrib.l*contrib.w, contrib.w);\n    }\n    ret += smpDirect / float(SMP_DIRECT_PHONG);\n    plen += dirPthLn / float(SMP_DIRECT_PHONG);\n    return vec4(ret, plen.x / max(eps, plen.y));\n}\n#endif\n\nvec4 PHONG_SURFACE_PHONG(in ray r, in hit h, in int seed, in int lastFrameN) {\n    ctb contrib = ctb(vec3(0.0), vec3(0.0), vec3(0.0), 0.0, 0.0);\n    vec3 ret = vec3(0.0);\n    vec2 plen = vec2(0.0);\n    int si = seed;\n    // take indirect specular samples\n    vec3 smpIDS = vec3(0.0);\n    vec2 idsPthLn = vec2(0.0);\n    for (int i = 0; i < SMP_PHONG_SURFACE_PHONG; ++i, si += 4) {\n        // get all PDFs\n        smp fs = PhongPlanePDF(h, light, flr, si+1);\n        smp cs = PhongPlanePDF(h, light, cil, si+2);\n        smp w1s = PhongPlanePDF(h, light, wa1, si+3);\n        smp w2s = PhongPlanePDF(h, light, wa2, si+4);\n        // apply phong pdf\n        fs.w *= SchlickPhong(r.d, h.n, fs.d, 1.0, ior, rough);\n        cs.w *= SchlickPhong(r.d, h.n, cs.d, 1.0, ior, rough);\n        w1s.w *= SchlickPhong(r.d, h.n, w1s.d, 1.0, ior, rough);\n        w2s.w *= SchlickPhong(r.d, h.n, w2s.d, 1.0, ior, rough);\n        // compute CDF\n        float floorSpecCDF = fs.w;\n        float ceilSpecCDF = floorSpecCDF + cs.w;\n        float w1SpecCDF = ceilSpecCDF + w1s.w;\n        float w2SpecCDF = w1SpecCDF + w2s.w;\n        float rnd = weyl1(si) * w2SpecCDF;\n        // roulette sampling\n        if (rnd <= floorSpecCDF)\n            contrib = PlaneContribution(fs, h, flr, light, si+1);\n        else if (rnd <= ceilSpecCDF)\n            contrib = PlaneContribution(cs, h, cil, light, si+2);\n        else if (rnd <= w1SpecCDF)\n            contrib = PlaneContribution(w1s, h, wa1, light, si+3);\n        else\n            contrib = PlaneContribution(w2s, h, wa2, light, si+4);\n        // color * specular * cdf + surface emsision\n        smpIDS += (contrib.c * contrib.s.y + contrib.e) * w2SpecCDF / max(eps, contrib.w);\n        idsPthLn += vec2(contrib.l*contrib.w, contrib.w);\n    }\n    ret += smpIDS / float(SMP_PHONG_SURFACE_PHONG);\n    plen += idsPthLn / float(SMP_PHONG_SURFACE_PHONG);\n    return vec4(ret, plen.x / max(eps, plen.y));\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    float asp;\n    vec2 uv = fragCoord / iResolution.xy;\n    int qdr = quadrant(uv);\n    uv = quadrants(uv);\n\n    // update to this frame\n    updateScene(iTime);\n    \n    // defines variables for current hit, current and last ray, current and last light, g light, last frame light\n    hit h;\n    ray l, r;\n    vec3 gli, fli;\n    vec2 ir, lr;\n    decodeAll(uv, iResolution.xy, iFrame, iChannel0, iChannel1, asp, r, ir, l, lr, h, gli, fli);\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(r.o, light.l.z);\n            return;\n        } else if (x == int(iResolution.x) - 1) {\n            fragColor = vec4(ir, light.l.xy);\n            return;\n        }\n    }\n    \n    // get reprojected first surface properties\n    vec2 suv = reprojCoords(l.o, lr, h.l, asp, iResolution.xy);\n    // of our quadrant (glsl uses pixel centers)\n    buf b = decodeBuffer(texelFetch(iChannel1, ivec2(quadrant(suv, qdr) * iResolution.xy - 0.5), 0));\n    // light reprojection (space) 'virtual image' coordinate\n    float d_o = b.c.w / max(1.0, float(b.n));\n    float d_c = 1.0 / max(eps, h.c);\n    float d_f = d_c * 0.5;\n    float d_i = (d_f * d_o) / (d_f - d_o);\n    vec2 ruv = reprojCoords(l.o, lr, h.l + r.d * d_i, asp, iResolution.xy);\n    // of our quadrant (glsl uses pixel centers)\n    buf lastFrame = reprojectBuffer(iChannel1, iChannelResolution[1].xy, qdr, quadrant(ruv, qdr) * iResolution.xy - 0.5, h.o);\n    \n    if (qdr == 0) {\n        // direct specular BRDF reprojection (geometric handles ray difference)\n        lastFrame.c *= reprojectSpecular(r.d, h.l, h.n, fli, r.d, h.l, h.n, gli, light.r).xxxy;\n    }\n    \n    // temporal smoothing\n    if (lastFrame.n > TEMPORALSMOOTHING) {\n        float s = float(TEMPORALSMOOTHING) / float(lastFrame.n);\n        lastFrame.c *= s;\n        lastFrame.n = TEMPORALSMOOTHING;\n    }\n    \n    // sample from surface\n    vec4 smp = vec4(0.0);\n    // not nothing\n    if (h.o != LIGHT) {\n        int seed = genSeed(iFrame, ivec2(fragCoord.xy), ivec2(iResolution.xy));\n        // do biased sampling 3 specular estimators\n#if SMP_DIRECT_PHONG\n        if (qdr == 0)\n            smp = DIRECT_PHONG(r, h, seed, lastFrame.n);\n#endif\n#if SMP_PHONG_SURFACE_PHONG\n        if (qdr == 2)\n            smp = PHONG_SURFACE_PHONG(r, h, seed, lastFrame.n);\n#endif\n    }\n#ifdef SUPERBIAS\n    int smpWeight = (lastFrame.n == 0)? SUPERBIAS_WEIGHT: 1;\n#else\n    int smpWeight = 1;\n#endif\n    fragColor = encodeBuffer(buf(lastFrame.c + smp * float(smpWeight), lastFrame.n + smpWeight, h.o));\n}\n","name":"Buffer C","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XdfGR8","channel":0}],"code":"//////////////////////////////// Denoise buffers ////////////////////////////////\n\nconst float brightness = 10.0;\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n\n    // update to this frame\n    updateScene(iTime);\n\n    float asp;\n    vec2 uv = fragCoord / iResolution.xy;\n    \n    // get G hit\n    // define new ray with mouse\n    // reproject G\n\n    // defines variables for current hit, current and last ray, current and last light, g light, last frame light\n    hit gh;\n    ray gl, gr;\n    vec3 fli, gli;\n    vec2 gir, glr;\n    decodeAll(uv, iResolution.xy, iFrame, iChannel0, iChannel1, asp, gr, gir, gl, glr, gh, gli, fli);\n \n    // defines variables for current hit, current and last ray, current and last light, g light, last frame light\n    hit hh;\n    ray hl, hr;\n    vec3 hli;\n    vec2 hir, hlr;\n    decodeAll((floor(fragCoord * 0.5)*2.0 + 1.0) / iResolution.xy, iResolution.xy, iFrame, iChannel0, iChannel1, asp, hr, hir, hl, hlr, hh, hli, fli);\n    \n    // are we supersampling between materials?\n    bool mismatch = hh.o != gh.o;\n    // get full res first surface properties\n    ctb surf = getSurface(gh);\n    // get half res first surface properties\n    ctb hsurf = getSurface(hh);\n    // start with emissive\n    fragColor = vec4(surf.e, 1.0);\n\n    // geometric reprojected uv\n    vec2 ruv = reprojCoords(hl.o, hlr, hh.l, asp, iResolution.xy);\n\n#if SMP_DIRECT_LAMBERT\n    {\n        // pixel coordinates -0.5 for glsl pixel centers\n        buf b = reprojectBuffer(iChannel1, iChannelResolution[1].xy, 0, quadrant(ruv, 0) * iResolution.xy - 0.5, gh.o);\n        // if matching materials do direct lambert reprojection + supersampling\n        float dBRDF = mismatch? 1.0: reprojectDiffuse(hh.l, hh.n, hli, gh.l, gh.n, gli, light.r).x;\n        // use a multiplicative proportional change, then apply first surface properties here\n        fragColor.rgb += (b.c.rgb * dBRDF * surf.c.rgb * surf.s.x) / float(b.n);\n    }\n#endif\n#if SMP_LAMBERT_SURFACE_LAMBERT\n    {\n        buf b = reprojectBuffer(iChannel1, iChannelResolution[1].xy, 1, quadrant(ruv, 1) * iResolution.xy - 0.5, gh.o);\n        float dBRDF = 1.0;\n        fragColor.rgb += (b.c.rgb * dBRDF * surf.c.rgb * surf.s.y) / float(b.n);\n    }\n#endif\n#if SMP_DIRECT_PHONG\n    {\n        buf b = reprojectBuffer(iChannel2, iChannelResolution[2].xy, 0, quadrant(ruv, 0) * iResolution.xy - 0.5, gh.o);\n        float dBRDF = mismatch? 1.0: reprojectSpecular(hr.d, hh.l, hh.n, hli, gr.d, gh.l, gh.n, gli, light.r).x;\n        fragColor.rgb += (b.c.rgb * dBRDF * surf.c.rgb * surf.s.y) / float(b.n);\n    }\n#endif\n#if SMP_PHONG_SURFACE_PHONG\n    {\n        buf b = reprojectBuffer(iChannel2, iChannelResolution[2].xy, 2, quadrant(ruv, 2) * iResolution.xy - 0.5, gh.o);\n        float dBRDF = 1.0;\n        fragColor.rgb += (b.c.rgb * dBRDF * surf.c.rgb * surf.s.y) / float(b.n);\n    }\n#endif\n\n    // tonemap\n    fragColor.rgb = fragColor.rgb * brightness;\n}\n","name":"Buffer D","description":"","type":"buffer"}]}
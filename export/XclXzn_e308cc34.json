{"ver":"0.1","info":{"id":"XclXzn","date":"1715005717","viewed":29,"name":"bowl","username":"pozhu15","description":"test pbr","likes":1,"published":1,"flags":0,"usePreview":0,"tags":["pbr"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XsX3zn","filepath":"/media/a/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","previewfilepath":"/media/ap/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","type":"cubemap","channel":0,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\n\nconst int MAX_MARCHING_STEPS = 255;\nconst float MIN_DIST = 0.0;\nconst float MAX_DIST = 100.0;\nconst float EPSILON = 0.0001;\n\n/**\n * 中心位于原点半径为1的球体的符号距离函数定义\n */\nfloat sphereSDF(vec3 samplePoint) {\n    return length(samplePoint) - 1.0;\n}\n// r = sphere's radius\n// h = cutting's plane's position\n// t = thickness\nfloat sdCutHollowSphere( vec3 p, float r, float h, float t )\n{\n    vec2 q = vec2( length(p.xz), p.y );\n    \n    float w = sqrt(r*r-h*h);\n    \n    return ((h*q.x<w*q.y) ? length(q-vec2(w,h)) : \n                            abs(length(q)-r) ) - t;\n}\n\n/**\n * Signed distance function for a cube centered at the origin\n * with width = height = length = 2.0\n */\nfloat cubeSDF(vec3 p) {\n    // If d.x < 0, then -1 < p.x < 1, and same logic applies to p.y, p.z\n    // So if all components of d are negative, then p is inside the unit cube\n    vec3 d = abs(p) - vec3(1.0, 1.0, 1.0);\n    \n    // Assuming p is inside the cube, how far is it from the surface?\n    // Result will be negative or zero.\n    float insideDistance = min(max(d.x, max(d.y, d.z)), 0.0);\n    \n    // Assuming p is outside the cube, how far is it from the surface?\n    // Result will be positive or zero.\n    float outsideDistance = length(max(d, 0.0));\n    \n    return insideDistance + outsideDistance;\n}\n\n/*\n* 构造实体形状(CSG)操作\n*/\nfloat intersectSDF(float distA, float distB) {\n    return max(distA, distB);\n}\n\nfloat unionSDF(float distA, float distB) {\n    return min(distA, distB);\n}\n\nfloat differenceSDF(float distA, float distB) {\n    return max(distA, -distB);\n}\n\n\n/**\n * 用SDF描述场景\n */\nfloat sceneSDF(vec3 samplePoint) {\n    // return sphereSDF(samplePoint);\n    return sdCutHollowSphere(samplePoint,1.f,0.01f,0.1f);\n    // float sphereDist = sphereSDF(samplePoint ) ;\n    // float cubeDist = cubeSDF(samplePoint);\n    // return intersectSDF(cubeDist, sphereDist);\n}\n\n\n\n/**\n * 返回最短距离函数\n * \n * eye: 射线的起点，可理解为相机\n * marchingDirection: 射线的标准化方向向量\n * start: 从相机开始的最短距离\n * end: 最远距离\n */\nfloat shortestDistanceToSurface(vec3 eye, vec3 marchingDirection, float start, float end) {\n    float depth = start;\n    for (int i = 0; i < MAX_MARCHING_STEPS; i++) {\n        float dist = sceneSDF(eye + depth * marchingDirection);\n        if (dist < EPSILON) {\n\t\t\treturn depth;\n        }\n        depth += dist;\n        if (depth >= end) {\n            return end;\n        }\n    }\n    return end;\n}\n\n/**\n * 返回相机的标准化方向向量\n * \n * fieldOfView: 垂直视野的角度\n * size: 输出图像的分辨率\n * fragCoord: 输出图像中的像素坐标\n */\nvec3 rayDirection(float fieldOfView, vec2 size, vec2 fragCoord) {\n    vec2 xy = fragCoord - size / 2.0;\n    float z = size.y / tan(radians(fieldOfView) / 2.0);\n    return normalize(vec3(xy, -z));\n}\n\n\n// 这一部分略去， 拷贝上面part1的代码即可\n\n/**\n * 对于那些SDF求出来在曲面上的点求标准化的法线向量\n */\nvec3 estimateNormal(vec3 p) {\n    return normalize(vec3(\n        sceneSDF(vec3(p.x + EPSILON, p.y, p.z)) - sceneSDF(vec3(p.x - EPSILON, p.y, p.z)),\n        sceneSDF(vec3(p.x, p.y + EPSILON, p.z)) - sceneSDF(vec3(p.x, p.y - EPSILON, p.z)),\n        sceneSDF(vec3(p.x, p.y, p.z  + EPSILON)) - sceneSDF(vec3(p.x, p.y, p.z - EPSILON))\n    ));\n}\n\n/**\n * Lighting contribution of a single point light source via Phong illumination.\n * \n * The vec3 returned is the RGB color of the light's contribution.\n *\n * k_a: 环境色\n * k_d: 漫反射颜色\n * k_s: 镜面颜色\n * alpha: 光泽系数\n * p: position of point being lit\n * eye: 相机的位置\n * lightPos: 光的位置\n * lightIntensity: 光的颜色/强度\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongContribForLight(vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye, vec3 lightPos, vec3 lightIntensity) {\n    vec3 N = estimateNormal(p);\n    vec3 L = normalize(lightPos - p);\n    vec3 V = normalize(eye - p);\n    vec3 R = normalize(reflect(-L, N));\n    \n    float dotLN = dot(L, N);\n    float dotRV = dot(R, V);\n    \n    if (dotLN < 0.0) {\n        // Light not visible from this point on the surface\n        return vec3(0.0, 0.0, 0.0);\n    } \n    \n    if (dotRV < 0.0) {\n        // Light reflection in opposite direction as viewer, apply only diffuse\n        // component\n        return lightIntensity * (k_d * dotLN);\n    }\n    return lightIntensity * (k_d * dotLN + k_s * pow(dotRV, alpha));\n}\n\n/**\n * Lighting via Phong illumination.\n * \n * The vec3 returned is the RGB color of that point after lighting is applied.\n * k_a: 环境色\n * k_d: 漫反射颜色\n * k_s: 镜面颜色\n * alpha: 光泽系数\n * p: position of point being lit\n * eye: 相机的位置\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongIllumination(vec3 k_a, vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye) {\n    const vec3 ambientLight = 0.5 * vec3(1.0, 1.0, 1.0);\n    vec3 color = ambientLight * k_a;\n    \n    vec3 light1Pos = vec3(4.0 * sin(iTime),2.0, 4.0 * cos(iTime));\n    vec3 light1Intensity = vec3(0.4, 0.4, 0.4);\n    \n    color += phongContribForLight(k_d, k_s, alpha, p, eye, light1Pos, light1Intensity);\n    \n    vec3 light2Pos = vec3(2.0 * sin(0.37 * iTime),\n                        2.0 * cos(0.37 * iTime),\n                        2.0);\n    vec3 light2Intensity = vec3(0.4, 0.4, 0.4);\n    \n    color += phongContribForLight(k_d, k_s, alpha, p, eye,\n                                  light2Pos,\n                                  light2Intensity);    \n    return color;\n}\n\n/**\n * Return a transform matrix that will transform a ray from view space\n * to world coordinates, given the eye point, the camera target, and an up vector.\n *\n * This assumes that the center of the camera is aligned with the negative z axis in\n * view space when calculating the ray marching direction. See rayDirection.\n */\nmat4 viewMatrix2(vec3 eye, vec3 center, vec3 up) {\n    // Based on gluLookAt man page\n    vec3 f = normalize(center - eye);\n    vec3 s = normalize(cross(f, up));\n    vec3 u = cross(s, f);\n    return mat4(\n        vec4(s, 0.0),\n        vec4(u, 0.0),\n        vec4(-f, 0.0),\n        vec4(0.0, 0.0, 0.0, 1)\n    );\n}\n\nconst float PI = 3.14159265359;\n// --------------BRDF-------------\n/*\n* 法线分布函数\n*/\nfloat DistributionGGX(vec3 N, vec3 H, float roughness)\n{\n    float a = roughness*roughness;\n    float a2 = a*a;\n    float NdotH = max(dot(N, H), 0.0);\n    float NdotH2 = NdotH*NdotH;\n\n    float nom   = a2;\n    float denom = (NdotH2 * (a2 - 1.0) + 1.0);\n    denom = PI * denom * denom;\n\n    return nom / denom;\n}\n/*\n* 几何函数（阴影遮蔽）\n*/\nfloat GeometrySchlickGGX(float NdotV, float roughness)\n{\n    float r = (roughness + 1.0);\n    float k = (r*r) / 8.0;\n\n    float nom   = NdotV;\n    float denom = NdotV * (1.0 - k) + k;\n\n    return nom / denom;\n}\n// ----------------------------------------------------------------------------\nfloat GeometrySmith(vec3 N, vec3 V, vec3 L, float roughness)\n{\n    float NdotV = max(dot(N, V), 0.0);\n    float NdotL = max(dot(N, L), 0.0);\n    float ggx2 = GeometrySchlickGGX(NdotV, roughness);\n    float ggx1 = GeometrySchlickGGX(NdotL, roughness);\n\n    return ggx1 * ggx2;\n}\n/*\n* 菲涅尔方程\n*/\nvec3 fresnelSchlick(float cosTheta, vec3 F0)\n{\n    return F0 + (1.0 - F0) * pow(clamp(1.0 - cosTheta, 0.0, 1.0), 5.0);\n}\n// ----------------------------------------------------------------------------\n// lights\nvec3 lightPositions[3];\nvec3 lightColors[3];\n\nvoid updateLight(){\n    lightPositions[0] = vec3(4.0 ,2.0, 4.0);\n    lightColors[0] = vec3(1.0, 1.0, 1.0);\n    \n    lightPositions[1] = vec3(2.0 * sin(0.37 * iTime),\n                        2.0 * cos(0.37 * iTime),\n                        2.0);\n    lightColors[1] = vec3(1.0, 1.0, 1.0);\n\n    lightPositions[2] = vec3(.0 ,\n                        4.0,\n                        4.0);\n    lightColors[2] = vec3(0.0, 5., 1.0);\n}\n// ----------------------------------------------------------------------------\n// pbr material parameters\nvec3 albedo=vec3(1.0f, 0.8f, 0.7f);\nfloat metallic = 0.9f;\nfloat roughness = 0.3f;\nfloat ao = 0.5f;\n// ----------------------------------------------------------------------------\nvoid pbrColor(out vec4 FragColor,\n    in vec3 WorldPos,\n    in vec3 Normal,\n    in vec3 camPos\n){\t\t\n    vec3 N = normalize(Normal);\n    vec3 V = normalize(camPos - WorldPos);\n\n    // calculate reflectance at normal incidence; if dia-electric (like plastic) use F0 \n    // of 0.04 and if it's a metal, use the albedo color as F0 (metallic workflow)    \n    vec3 F0 = vec3(0.04); \n    F0 = mix(F0, albedo, metallic);\n\n    // reflectance equation\n    vec3 Lo = vec3(0.0);\n    for(int i = 0; i < 3; ++i) \n    {\n        // calculate per-light radiance\n        vec3 L = normalize(lightPositions[i] - WorldPos);\n        vec3 H = normalize(V + L);\n        float distance = length(lightPositions[i] - WorldPos);\n        float attenuation = 1.0 / (distance * distance);\n        vec3 radiance = lightColors[i] * attenuation;\n\n        // Cook-Torrance BRDF\n        float NDF = DistributionGGX(N, H, roughness);   \n        float G   = GeometrySmith(N, V, L, roughness);      \n        vec3 F    = fresnelSchlick(clamp(dot(H, V), 0.0, 1.0), F0);\n           \n        vec3 numerator    = NDF * G * F; \n        float denominator = 4.0 * max(dot(N, V), 0.0) * max(dot(N, L), 0.0) + 0.0001; // + 0.0001 to prevent divide by zero\n        vec3 specular = numerator / denominator;\n        \n        // kS is equal to Fresnel\n        vec3 kS = F;\n        // for energy conservation, the diffuse and specular light can't\n        // be above 1.0 (unless the surface emits light); to preserve this\n        // relationship the diffuse component (kD) should equal 1.0 - kS.\n        vec3 kD = vec3(1.0) - kS;\n        // multiply kD by the inverse metalness such that only non-metals \n        // have diffuse lighting, or a linear blend if partly metal (pure metals\n        // have no diffuse light).\n        kD *= 1.0 - metallic;\t  \n\n        // scale light by NdotL\n        float NdotL = max(dot(N, L), 0.0);        \n\n        // add to outgoing radiance Lo\n        Lo += (kD * albedo / PI + specular) * radiance * NdotL;  // note that we already multiplied the BRDF by the Fresnel (kS) so we won't multiply by kS again\n\n    }\n    // ambient lighting (note that the next IBL tutorial will replace \n    // this ambient lighting with environment lighting).\n    vec3 ambient = vec3(0.5) * albedo * ao;\n\n    vec3 color = ambient + Lo;\n\n    // HDR tonemapping\n    color = color / (color + vec3(1.0));\n    // gamma correct\n    color = pow(color, vec3(1.0/2.2)); \n\n    FragColor = vec4(color, 1.0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    updateLight();\n\tvec3 viewDir = rayDirection(45.0, iResolution.xy, fragCoord);\n    vec3 eye = vec3(8.0, 5.0, 7.0);\n    \n    mat4 viewToWorld = viewMatrix2(eye, vec3(0.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0));\n    \n    vec3 worldDir = (viewToWorld * vec4(viewDir, 0.0)).xyz;\n    \n    float dist = shortestDistanceToSurface(eye, worldDir, MIN_DIST, MAX_DIST);\n    \n    //skybox\n    vec2 uv=(fragCoord-.5*iResolution.xy)/iResolution.y;\n    vec4 s=vec4(0.,0.,2.,1.);  \n    float t=iTime*.5;\n    vec3 cam_pos=s.xyz+vec3(sin(t),0.,cos(t))*5.;\n    vec3 cam_dir=normalize(s.xyz-cam_pos);\n    vec3 cam_r=-cross(cam_dir,vec3(0,1,0));\n    vec3 cam_u=-cross(cam_r,cam_dir);\n    vec3 r=normalize(uv.x*cam_r+uv.y*cam_u+1.*cam_dir);\n\n    // r= normalize();\n\n    if (dist > MAX_DIST - EPSILON) {\n        // Didn't hit anything\n        fragColor =texture(iChannel0,r);\n\t\treturn;\n    }\n    \n    // The closest point on the surface to the eyepoint along the view ray\n    vec3 p = eye + dist * worldDir;\n    \n    vec3 K_a = vec3(0.2, 0.2, 0.2);\n    vec3 K_d = vec3(0.7, 0.2, 0.2);\n    vec3 K_s = vec3(1.0, 1.0, 1.0);\n    float shininess = 10.0;\n    \n    vec3 color = phongIllumination(K_a, K_d, K_s, shininess, p, eye);\n    fragColor = vec4(color, 1.0);\n\n    pbrColor(fragColor,p,estimateNormal(p),eye);\n}\n\n","name":"Image","description":"","type":"image"}]}
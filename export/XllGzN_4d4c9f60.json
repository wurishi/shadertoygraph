{"ver":"0.1","renderpass":[{"outputs":[],"inputs":[],"code":"// Started as Star Nest by Pablo RomÃ¡n Andrioli\n// Modifications by Beibei Wang and Huw Bowles.\n// This content is under the MIT License.\n\n// On reducing the spatial high frequency noise:\n\n// We simply limit the size of each contribution of each iteration of the fractal using min():\n// a += i > 7 ? min( 12.,abs(length(p)-pa)) : abs(length(p)-pa)\n// The test on the iteration count is optional, we found that most of the problem noise is introduced in the later\n// iterations so we found that keeping the original formula for the earlier iterations helps to retain the 'volume'\n// without the noise.\n\n\n// On reducing the temporal noise:\n\n// This version has volume samples aligned along view space Z isolines. When the camera moves\n// forwards, the samples are shifted towards the viewer, allowing the camera to move forward\n// smoothly without aliasing (besides the high frequency speckle noise).\n\n// However if the  camera were to rotate around its origin, the volume samples towards\n// the sides of the image sweep in Z and aliasing would occur. To make this case work, the samples\n// need to be arranged in concentric rings around the camera. However in this configuration\n// there will be some aliasing at the sides of the screen when the camera moves forward,\n// because the motion of the camera can no longer be compensated for completely - one can\n// pull in the vert rings but they will move at different rates in Z\n\n// I had similar issues in a different context and made some diagrams etc, see\n// http://advances.realtimerendering.com/s2013/OceanShoestring_SIGGRAPH2013_Online.pptx\n// And developed a fast realtime version of adaptive stationary sampling:\n// https://www.shadertoy.com/view/XdBXWW\n\n\n// Question - the derivative can be computed for \"free\" using dual numbers, as in https://www.shadertoy.com/view/Xd2GzR .\n// The derivate may help to eliminate noise? Or perhaps the second derivate. It would be very interesting to see these\n// derivatives rendered.\n\n#define iterations 17\n#define formuparam 0.53\n\n#define volsteps 18\n#define stepsize 0.050\n\n#define zoom   0.800\n#define tile   0.850\n#define speed  0.10 \n\n#define brightness 0.0015\n#define darkmatter 0.300\n#define distfading 0.760\n#define saturation 0.800\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\t//get coords and direction\n\tvec2 uv=fragCoord.xy/iResolution.xy-.5;\n\tuv.y*=iResolution.y/iResolution.x;\n\tvec3 dir=vec3(uv*zoom,1.);\n\tfloat time=(iTime-3311.)*speed;\n\n\t\n\tvec3 from=vec3(1.,.5,0.5);\n\t\n\t\n\tvec3 forward = vec3(0.,0.,1.);\n\t\n\t//mouse rotation\n\tfloat a1 = 0.3;//3.1415926 * (iMouse.x/iResolution.x-.5);\n\tmat2 rot1 = mat2(cos(a1),sin(a1),-sin(a1),cos(a1));\n\tfloat a2 = .6;//3.1415926 * (iMouse.y/iResolution.y-.5);\n\tmat2 rot2 = mat2(cos(a2),sin(a2),-sin(a2),cos(a2));\n\tdir.xz*=rot1;\n\tforward.xz *= rot1;\n\tdir.yz*=rot1;\n\tforward.yz *= rot1;\n\n\t// pan (dodgy)\n\tfrom += (iMouse.x/iResolution.x-.5)*vec3(-forward.z,0.,forward.x);\n\t\n\t//zoom\n\tfloat zooom = time;\n\tfrom += forward* zooom;\n\tfloat sampleShift = mod( zooom, stepsize );\n\tfloat zoffset = -sampleShift;\n\tsampleShift /= stepsize; // make from 0 to 1\n\t\n\t//volumetric rendering\n\tfloat s=0.1;\n\tvec3 v=vec3(0.);\n\tfor (int r=0; r<volsteps; r++) {\n\t\tvec3 p=from+(s+zoffset)*dir;// + vec3(0.,0.,zoffset);\n\t\tp = abs(vec3(tile)-mod(p,vec3(tile*2.))); // tiling fold\n\t\tfloat pa,a=pa=0.;\n\t\tfor (int i=0; i<iterations; i++) { \n\t\t\tp=abs(p)/dot(p,p)-formuparam; // the magic formula\n\t\t\t//p=abs(p)/max(dot(p,p),0.005)-formuparam; // another interesting way to reduce noise\n            float D = abs(length(p)-pa); // absolute sum of average change\n            a += i > 7 ? min( 12., D) : D;\n\t\t\tpa=length(p);\n\t\t}\n\t\t//float dm=max(0.,darkmatter-a*a*.001); //dark matter\n\t\ta*=a*a; // add contrast\n\t\t//if (r>3) fade*=1.-dm; // dark matter, don't render near\n\t\t// brightens stuff up a bit\n\t\tfloat s1 = s+zoffset;\n\t\t// need closed form expression for this, now that we shift samples\n\t\tfloat fade = pow(distfading,max(0.,float(r)-sampleShift));\n\t\tv+=fade;\n        \n\t\t// fade out samples as they approach the camera\n\t\tif( r == 0 )\n\t\t\tfade *= 1. - sampleShift;\n\t\t// fade in samples as they approach from the distance\n\t\tif( r == volsteps-1 )\n\t\t\tfade *= sampleShift;\n\t\tv+=vec3(2.*s1,4.*s1*s1,16.*s1*s1*s1*s1)*a*brightness*fade; // coloring based on distance\n\t\ts+=stepsize;\n\t}\n\tv=mix(vec3(length(v)),v,saturation); //color adjust\n\tfragColor = vec4(v*.01,1.);\t\n}\n","name":"Image","description":"","type":"image"}],"flags":{"mFlagVR":false,"mFlagWebcam":false,"mFlagSoundInput":false,"mFlagSoundOutput":false,"mFlagKeyboard":false,"mFlagMultipass":false,"mFlagMusicStream":false},"info":{"id":"XllGzN","date":"1419336787","viewed":1819,"name":"Cosmic 2","username":"huwb","description":"Original by Kali. Collaboration with Beibei Wang. Two noise reductions. Reduces temporal noise by keeping samples stationary in world. Reduces spatial high freq noise by limiting size of contribution from each fractal iteration.","likes":57,"published":1,"flags":0,"usePreview":0,"tags":["fractal","volume","raymarch","kaliset"],"hasliked":0,"parentid":"","parentname":""}}
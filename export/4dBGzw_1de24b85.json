{"ver":"0.1","renderpass":[{"outputs":[{"channel":0,"id":"4dfGRr"}],"inputs":[{"channel":0,"type":"texture","id":"Xsf3zn","filepath":"/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","sampler":{"filter":"mipmap","wrap":"repeat","vflip":"false","srgb":"false","internal":"byte"}}],"code":"// Hazel Quantock 2013\n// License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\nconst float tau = 6.28318530717958647692;\n\n\n// Gamma correction\n#define GAMMA (2.2)\n\nvec3 ToLinear( in vec3 col )\n{\n\t// simulate a monitor, converting colour values into light values\n\treturn pow( col, vec3(GAMMA) );\n}\n\nvec3 ToGamma( in vec3 col )\n{\n\t// convert back into colour values, so the correct light will come out of the monitor\n\treturn pow( col, vec3(1.0/GAMMA) );\n}\n\n// Set up a camera looking at the scene.\n// origin - camera is positioned relative to, and looking at, this point\n// distance - how far camera is from origin\n// rotation - about x & y axes, by left-hand screw rule, relative to camera looking along +z\n// zoom - the relative length of the lens\nvoid CamPolar( out vec3 pos, out vec3 ray, in vec3 origin, in vec2 rotation, in float distance, in float zoom, in vec2 fragCoord )\n{\n\t// get rotation coefficients\n\tvec2 c = vec2(cos(rotation.x),cos(rotation.y));\n\tvec4 s;\n\ts.xy = vec2(sin(rotation.x),sin(rotation.y)); // worth testing if this is faster as sin or sqrt(1.0-cos);\n\ts.zw = -s.xy;\n\n\t// ray in view space\n\tray.xy = fragCoord.xy - iResolution.xy*.5;\n\tray.z = iResolution.y*zoom;\n\tray = normalize(ray);\n\t\n\t// rotate ray\n\tray.yz = ray.yz*c.xx + ray.zy*s.zx;\n\tray.xz = ray.xz*c.yy + ray.zx*s.yw;\n\t\n\t// position camera\n\tpos = origin - distance*vec3(c.x*s.y,s.z,c.x*c.y);\n}\n\nvec2 Noise( in vec3 x )\n{\n    vec3 p = floor(x);\n    vec3 f = fract(x);\n\tf = f*f*(3.0-2.0*f);\n//\tvec3 f2 = f*f; f = f*f2*(10.0-15.0*f+6.0*f2);\n\n\tvec2 uv = (p.xy+vec2(37.0,17.0)*p.z) + f.xy;\n\n#if (1)\n\tvec4 rg = textureLod( iChannel0, (uv+0.5)/256.0, 0.0 );\n#else\n\t// on some hardware interpolation lacks precision\n\tvec4 rg = mix( mix(\n\t\t\t\ttextureLod( iChannel0, (floor(uv)+0.5)/256.0, 0.0 ),\n\t\t\t\ttextureLod( iChannel0, (floor(uv)+vec2(1,0)+0.5)/256.0, 0.0 ),\n\t\t\t\tfract(uv.x) ),\n\t\t\t\t  mix(\n\t\t\t\ttextureLod( iChannel0, (floor(uv)+vec2(0,1)+0.5)/256.0, 0.0 ),\n\t\t\t\ttextureLod( iChannel0, (floor(uv)+1.5)/256.0, 0.0 ),\n\t\t\t\tfract(uv.x) ),\n\t\t\t\tfract(uv.y) );\n#endif\t\t\t  \n\n\treturn mix( rg.yw, rg.xz, f.z );\n}\n\n\nfloat DistanceField( vec3 pos )\n{\n\treturn min ( pos.y+1.0, length(vec3(pos.xy,(fract(pos.z/3.0+.5)-.5)*3.0))-1.0 )\n\t\t\t+ .1*min(.5,Noise(pos*5.0+iTime*vec3(0,0,0)).x)\n\t\t\t;\n}\n\n\n// approximate a smoothed normal\nvec3 GetNormal( vec3 pos, float blur )\n{\n\tvec2 delta = vec2(0,blur+.001);\n\tvec3 grad;\n\tgrad.x = DistanceField( pos+delta.yxx )-DistanceField( pos-delta.yxx );\n\tgrad.y = DistanceField( pos+delta.xyx )-DistanceField( pos-delta.xyx );\n\tgrad.z = DistanceField( pos+delta.xxy )-DistanceField( pos-delta.xxy );\n\treturn normalize(grad);\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tfloat T = iTime;\n\t\n\tvec3 pos, ray;\n\tCamPolar( pos, ray, vec3(0), vec2(.2,-.25) + vec2(.1*sin(T/19.0),-.2*cos(T/17.0)), 8.0, 2.0, fragCoord );\n\t\n\tfloat aperture = .8;\n\tfloat focalPlane = sin((T-sin(T))*.7)*3.4 + length(pos);\n\tfloat focus = focalPlane; // todo: correct for screen-pos so flat not curved plane\n\t\n\tvec4 result = vec4(0);\n\tfloat t = 0.0;\n\tfloat oh = 0.0;\n\tfor ( int i=0; i < 100; i++ )\n\t{\n\t\tif ( result.a > .99 )\n\t\t\tbreak; //continue; // some hardware prefers continue to break\n\t\t\n\t\tfloat blur = aperture*abs(t/focus-1.0);\n\n\t\tvec3 p = pos+ray*t;\n\t\tfloat h = DistanceField( p ) + blur*.5; // shrink the \"solid\" part to be centre of the blur\n\t\t\n\t\tif ( h < blur )\n\t\t{\n\t\t\t//add blurred contribution for this sample\n\t\t\tvec3 n = GetNormal( p, blur );\n\t\t\tvec4 samplev;\n\t\t\t\n\t\t\tsamplev.rgb = mix( vec3(.2,.5,.5), vec3(.7,.5,.3), clamp((p.y+.95)/blur,0.0,1.0) );\n\n\t\t\t// lighting - this is too hard-edged, should blur\n\t\t\tsamplev.rgb *= (.3+max(dot(n,normalize(vec3(-2,3,-1))),.0));\n\t\t\t\n\t\t\tsamplev.a = pow(clamp(1.0-h/blur,0.0,1.0),2.0);\n\n\t\t\t// modulate by the length of the step\n\t\t\tsamplev.a = pow(samplev.a,(h+oh)/2.0);\n\n\t\t\tresult += vec4(samplev.rgb,1)*samplev.a*(1.0-result.a);\n\t\t}\n\t\t\n\t\tt = t+h;\n\t\toh = h;\n\t}\n\t\n\tresult.rgb *= 1.0/(result.a+.0001);\n\t\n\tresult.rgb = mix( vec3(.6,.7,.8), result.rgb, min(1.0,result.a/.99) );\n\n\tfragColor.rgb = ToGamma(result.rgb);\n}","name":"Image","description":"","type":"image"}],"flags":{"mFlagVR":false,"mFlagWebcam":false,"mFlagSoundInput":false,"mFlagSoundOutput":false,"mFlagKeyboard":false,"mFlagMultipass":false,"mFlagMusicStream":false},"info":{"id":"4dBGzw","date":"1385037212","viewed":2549,"name":"Distance Field Blur","username":"TekF","description":"Just playing with a silly idea, it looks better than I expected. Fake focal blur by marching through a softened distance field.","likes":48,"published":1,"flags":0,"usePreview":1,"tags":["raymarching","depthoffield"],"hasliked":0,"parentid":"","parentname":""}}
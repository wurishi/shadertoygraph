{"ver":"0.1","info":{"id":"msyfzw","date":"1698046203","viewed":20,"name":"RayMarch球带注释","username":"nausicaa","description":"pdcxs","likes":1,"published":1,"flags":0,"usePreview":0,"tags":["raymarch"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//t是查找的距离范围\n#define TMIN 0.1\n#define TMAX 20.\n//最大迭代次数\n#define RAYMARCH_TIME 128\n//当前距离是否小于阈值\n#define PRECISION .001\n#define AA 3\n#define PI 3.14159265\n\nvec2 fixUV(in vec2 c) {\n    return (2. * c - iResolution.xy) / min(iResolution.x, iResolution.y);\n}\n\nfloat sdfSphere(in vec3 p) {\n   //半径1 和 位移\n    return length(p) - .5;\n}\n//屏幕sdf函数\nfloat sdfPlane(in vec3 p) {\n    return p.y;\n}\nvec2 opU(vec2 a, vec2 b) {\n    return a.x < b.x ? a : b;\n}\n//合并两个物体,2个物体最小值\nfloat map(in vec3 p) {\n    float d = sdfSphere(p);\n    d = min(d, sdfPlane(p + vec3(0., 1., 0.)));\n    return d;\n}\n//输入射线源和射线方向\nfloat rayMarch(in vec3 ro, in vec3 rd) {\n   \n    float t = TMIN;\n    for(int i = 0; i < RAYMARCH_TIME && t < TMAX; i++) {\n      //当前位置\n        vec3 p = ro + t * rd;\n        //d点是否在sdf里\n        float d = map(p);\n        //小于精度返回t\n        if(d < PRECISION)\n            break;\n        t += d;\n    }\n    return t;\n}\n\n// https://iquilezles.org/articles/normalsSDF\nvec3 calcNormal(in vec3 p) {\n    const float h = 0.0001;\n    const vec2 k = vec2(1, -1);\n    return normalize(k.xyy * map(p + k.xyy * h) +\n        k.yyx * map(p + k.yyx * h) +\n        k.yxy * map(p + k.yxy * h) +\n        k.xxx * map(p + k.xxx * h));\n}\n\n//目标,摄像机位置,角度\nmat3 setCamera(vec3 ta, vec3 ro, float cr) {\n    vec3 z = normalize(ta - ro);\n    vec3 cp = vec3(sin(cr), cos(cr), 0.);\n    vec3 x = normalize(cross(z, cp));\n    vec3 y = cross(x, z);\n    return mat3(x, y, z);\n}\n\n// https://iquilezles.org/articles/rmshadows\nfloat softShadow(in vec3 ro, in vec3 rd, float k) {\n    float res = 1.0;\n    float ph = 1e20;\n    for(float t = TMIN; t < TMAX;) {\n        float h = map(ro + rd * t);\n        if(h < 0.001)\n            return 0.0;\n        float y = h * h / (2.0 * ph);\n        float d = sqrt(h * h - y * y);\n        res = min(res, k * d / max(0.0, t - y));\n        ph = h;\n        t += h;\n    }\n    return res;\n}\n\nvec3 render(vec2 uv) {\n    vec3 color = vec3(0.);\n    vec3 ro = vec3(4. * cos(iTime), 1., 4. * sin(iTime));\n    if(iMouse.z > 0.01) {\n        float theta = iMouse.x / iResolution.x * 2. * PI;\n        ro = vec3(4. * cos(theta), 1., 4. * sin(theta));\n    }\n    vec3 ta = vec3(0.);\n    mat3 cam = setCamera(ta, ro, 0.);\n    //指向屏幕的点\n    vec3 rd = normalize(cam * vec3(uv, 1.) - ro);\n    float t = rayMarch(ro, rd);\n    if(t < TMAX) {\n      //当前位置\n        vec3 p = ro + t * rd;\n        //法向量\n        vec3 n = calcNormal(p);\n        //光源方向\n        vec3 light = vec3(2. * cos(iTime - 2.0), 1., 2. * sin(iTime - 2.0) + 2.);\n        //从位置到光线,再乘当前点法向量\n        float dif = clamp(dot(normalize(light - p), n), 0., 1.);\n         p += PRECISION * n;\n        float st = rayMarch(p,normalize(light-p)); \n        if(st < TMAX)\n        {\n         dif *= .1;\n        }\n  \n         dif *= softShadow(p, normalize(light - p), 10.);\n        //环境光\n        float amb = 0.5 + 0.5 * dot(n, vec3(0., 1., 0.));\n        color = amb * vec3(0.23) + dif * vec3(1.);\n    }\n    //伽马校正\n    return sqrt(color);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec3 color = vec3(0.);\n    //平滑\n    for(int m = 0; m < AA; m++) {\n        for(int n = 0; n < AA; n++) {\n         //偏移量\n            vec2 offset = 2. * (vec2(float(m), float(n)) / float(AA) - .5);\n            vec2 uv = fixUV(fragCoord + offset);\n            color += render(uv);\n        }\n    }\n    fragColor = vec4(color / float(AA * AA), 1.);\n}\n","name":"Image","description":"","type":"image"}]}
{"ver":"0.1","info":{"id":"ld2yDh","date":"1491953731","viewed":361,"name":"2D Fourier Series Lighting","username":"slembcke","description":"An experiment in making 2D per pixel light probes.\n\nLeft side is rendered like N dot L forward diffuse lighting. Right side is creating a Fourier series approximation for the lightfield then applying all lights to the surface in a single pass.","likes":7,"published":1,"flags":0,"usePreview":0,"tags":["2d","lighting","fourierseries"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n\tForward rendering for 2D lighting doesn't seem like the best idea to me.\n\tIn particular, alpha blending means you can't reorder draw calls for better batching,\n\tand combined with a lack of z-testing it makes for a lot of overdraw.\n\n\tWhat if instead you could precalculate all the lighting, and look it up using the normal?\n\tThat's basically the idea here. You can bake a high quality lightprobe texture offline\n\tor render a realtime one in screen space.\n\n\tApplying the probe values should be pretty cheap, requiring only some basic arithmetic.\n\tHowever, it will require 6 texture samples per shaded pixel (1x albedo, 1x normal, 4x light).\n\tSeems like it shouldn't be worse than deferred, though that's not a low bar exactly.\n\t\n\tI also have an interactive MathStudio notebook I used to figure out some of the math.\n\thttp://mathstud.io/V9GLZ5\n\t\n\tI also made a version that applies the lighting to a bump map:\n\thttps://www.shadertoy.com/view/ld2cW1\n*/\n\nvec3 light(float angle, float intensity){\n \treturn vec3(normalize(vec2(cos(angle), sin(angle))), intensity);   \n}\n\nfloat NdotL(vec2 n, vec3 light){\n    return max(0.0, light.z*dot(n, light.xy));\n}\n\n// Double angle identities for cos() and sin()\nvec2 DoubleAngle(vec2 n){\n\treturn vec2(n.x*n.x - n.y*n.y, 2.0*n.x*n.y);\n}\n\n// Fourier series constants.\nconst float C0 = 0.318309886184; // 1/pi\nconst float C1 = 0.5;\nconst float C2 = 0.212206590789; // 2/(3*pi)\n\nvoid FourierApprox(\n    vec3 light,\n    inout float a0,\n    inout vec4 ab12\n){\n    vec2 g = light.xy;\n    vec2 g2 = DoubleAngle(g);\n    \n    a0 += C0*light.z;\n\tab12 += light.z*vec4(C1*g, C2*g2);\n}\n\nfloat FourierApply(vec3 n, float a0, vec4 ab12){\n    vec2 g1 = normalize(n).xy;\n    vec2 g2 = DoubleAngle(g1);\n    return a0 + ab12[0]*g1.x + ab12[1]*g1.y + ab12[2]*g2.x + ab12[3]*g2.y;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    vec2 uv = fragCoord.xy/iResolution.xy;\n    uv.x *= 2.0;\n    uv = fract(uv);\n    uv.y *= (2.0*iResolution.y)/iResolution.x;\n    \n    vec2 uv2 = 2.0*uv - 1.0;\n    vec3 n = normalize(vec3(uv2, 0));\n    float mask = step(length(2.0*uv - 1.0), 1.0);\n    \n    // Light Values\n    float ambient = 0.0;\n    vec3 l0 = light(iMouse.x/50.0, iMouse.y/iResolution.y);\n    vec3 l1 = light(iTime/5.0, 1.0);\n    \n    if(fragCoord.x < 0.5*iResolution.x){\n        // Left side works additively like forward rendering.\n\t\tfloat l = ambient;\n        l += NdotL(n.xy, l0);\n        l += NdotL(n.xy, l1);\n        fragColor = mask*vec4(l); return;\n    } else {\n        // Right side creates a light probe for the pixel then applies that.\n        float a0 = ambient;\n        vec4 ab12 = vec4(0.0);\n        \n        FourierApprox(l0, a0, ab12);\n        FourierApprox(l1, a0, ab12);\n        \n        float l = FourierApply(n, a0, ab12);\n        fragColor = mask*vec4(l); return;\n    }\n    \n    fragColor = vec4(1, 0, 0, 1); return;\n}","name":"Image","description":"","type":"image"}]}
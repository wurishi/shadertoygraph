{"ver":"0.1","info":{"id":"fsdSWj","date":"1633973893","viewed":117,"name":"Hokusai NeuroCA","username":"ax","description":"588 params NeuroCA trained with a Hokusai crop, based on the materials by Alex Mordvintsev (Znah) et al. on https://selforglive.github.io/ \nUsed Laplacian & Sobel for neighbourhood perception.\n\n*Not Quite Hokusai* XD.\n\n","likes":1,"published":1,"flags":32,"usePreview":0,"tags":["nca","neuroca"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//\n// Visualising the whole per-cell state vector\n//\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    \n  vec2 p = gl_FragCoord.xy;\n  p.y = iChannelResolution[0].y - p.y;\n  fragColor = texture( iChannel0, p/iChannelResolution[0].xy) + vec4(vec3(0.5), 1.0 );\n       \n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"vec4 hash43(in vec3 p) {\n\tvec4 p4 = fract(vec4(p.xyzx)  * vec4(.1031, .1030, .0973, .1099));\n    p4 += dot(p4, p4.wzxy+33.33);\n    return fract((p4.xxyz+p4.yzzw)*p4.zywx);\n}\n\nfloat W;   // width of band\nvec2  pos; // our shader pos.\n\n// R() to sample a pixel of different bands\n// dx: delta in x from our location\n// dy: delta in y from our location\n// b:  Band no.\n//\nvec4 R(int dx, int dy, int b) {\n    vec2 p = mod( pos + vec2(dx, dy), vec2(W, iChannelResolution[0].y) );\n    p.x   += W * float(b);\n    return texture(iChannel0, p/iChannelResolution[0].xy);\n}\n\nvec4 laplacian(int b) {\n  return R(-1, 1,b)     + R(0, 1,b)*2.   + R(1, 1,b)    +\n         R(-1, 0,b)*2.  + R(0, 0,b)*-12. + R(1, 0,b)*2. +\n         R(-1,-1,b)     + R(0,-1,b)*2.   + R(1,-1,b);\n}\n\nvec4 sobel_X(int b) {\n  return R(-1, 1,b)*1. + R(1, 1,b)*-1. +\n         R(-1, 0,b)*2. + R(1, 0,b)*-2. +\n         R(-1,-1,b)*1. + R(1,-1,b)*-1.;\n}\n\nvec4 sobel_Y(int b) {\n  return R(-1, 1,b)     + R(0, 1,b)*2.  + R(1, 1,b)     +\n         R(-1,-1,b)*-1. + R(0,-1,b)*-2. + R(1,-1,b)*-1.;\n}\n\n//\n// Weights & Bias (588 params) trained using selforglive notebook\n// https://selforglive.github.io/\n// Code generated by export_glsl() in the notebook\n//\nvec4 update_Hokusai(float band, vec4 y[6]) {\n\n  #define M mat4\n  #define F(i,_a,_b) {M a=_a,b=_b; vec4 yi=y[i]; dx+=G(0)+G(1)+G(2)+G(3);}\n  #define G(i) yi[i]*((yi[i]>0.0)?a[i]:b[i])\n  vec4 dx;\n  if (band == 0.) { dx = vec4(-2,4,15,6);\n    F(0, M(-42,6,-31,41,54,-42,-1,-35,14,23,-60,-53,-9,-11,-1,-27), M(-31,33,20,-31,-34,-110,40,-8,-91,-57,-63,22,-23,-13,11,-50));\n    F(1, M(-20,-14,-9,8,-55,-36,-9,18,-3,-26,7,54,-14,-27,-10,28), M(-1,-12,-9,10,36,34,-4,-52,53,42,29,-13,13,40,39,-71));\n    F(2, M(15,12,4,-30,3,7,14,-14,18,15,-19,-17,-8,8,8,-20), M(7,8,5,-14,-5,-9,19,-9,1,-6,9,21,-13,0,6,11));\n    F(3, M(12,-5,-8,-7,-4,7,-4,-8,3,1,23,4,36,28,24,21), M(9,-2,-6,-4,-7,5,-4,-2,-2,-4,20,0,-5,0,25,56));\n    F(4, M(2,0,2,-11,-9,-10,-5,-1,-5,-1,4,-9,-18,-16,-6,5), M(-6,-5,11,9,8,5,-5,5,7,-3,-2,4,11,15,4,-8));\n    F(5, M(16,13,-4,-20,-17,-16,-7,22,9,10,7,-17,-5,-4,1,8), M(-15,-9,2,15,2,5,-2,0,-7,-9,-7,13,-15,-21,-8,8));\n  } else if (band == 1.) { dx = vec4(-10,16,-6,3);\n    F(0, M(-19,-37,53,-21,-1,-56,63,-59,6,-8,-29,4,14,12,0,3), M(2,-12,-23,-21,24,19,-22,9,16,45,-59,53,5,31,-4,11));\n    F(1, M(-91,-13,5,-44,14,-52,0,11,13,-5,-104,8,28,5,0,-35), M(-86,-2,3,-28,21,-67,35,-21,23,-33,-50,-41,34,-2,-4,-112));\n    F(2, M(-22,-29,9,-14,-3,13,-3,4,-11,-1,38,0,-12,4,1,17), M(-4,9,0,9,11,-7,7,-19,18,-12,9,-2,-16,13,6,5));\n    F(3, M(4,-2,-1,-2,0,-1,-1,-2,7,-4,0,-3,-6,-39,33,-37), M(-6,-1,-1,-2,-2,0,0,1,-1,-5,11,-6,22,13,1,3));\n    F(4, M(13,-19,-16,-3,-8,-19,-11,13,-32,-1,-21,2,9,19,-12,6), M(29,-3,-24,-2,-15,-8,3,8,0,-15,-11,8,-2,0,20,-13));\n    F(5, M(0,-12,8,-9,2,3,0,8,8,-15,4,-4,-6,21,5,-5), M(-5,10,-10,16,-11,-4,3,-1,-8,2,-12,10,3,6,-32,-8));\n  } else { dx = vec4(-6,12,-14,19);\n    F(0, M(28,3,25,13,44,-19,11,5,40,-12,-30,21,-1,18,-1,-4), M(24,-17,-20,47,-5,-14,-26,15,-30,-10,-31,13,-51,20,-3,6));\n    F(1, M(4,-5,3,0,-23,3,-3,-13,-28,3,-1,0,-14,18,-8,-8), M(4,-11,14,1,19,6,-6,-2,14,29,0,11,23,-9,-17,-33));\n    F(2, M(-72,20,31,12,7,-90,-21,6,43,41,-93,-12,-4,6,-1,-89), M(-108,3,6,18,9,-51,-14,-16,-36,8,-70,7,-20,-7,7,-30));\n    F(3, M(-5,-8,0,3,2,-5,-8,6,10,6,-5,-2,-10,6,3,2), M(3,2,1,3,5,0,2,3,8,1,6,5,-11,-14,19,-9));\n    F(4, M(5,13,7,5,-8,-1,3,4,-6,2,-6,9,-15,-6,23,-1), M(2,-11,11,-7,19,-2,-2,-4,-1,-6,-5,-2,11,9,7,7));\n    F(5, M(4,12,-1,-8,-6,11,10,8,10,2,0,-1,-27,2,8,15), M(10,-4,1,-32,-2,-25,3,-6,2,1,2,-4,-17,-21,-2,-44));\n  }\n  #undef M\n  #undef F\n  #undef G\n  return dx/500.0;\n\n}\n\n\n// The 588-param model NCA uses a 12-element per-cell state vector and these elements\n// are stored as 3 groups of vec4 on pixels in screen-space (3 bands in X-direction).\n// \n// NeuroCA is natively tileable, so one may always visualize them in the end quickly.\n//\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n  W     = floor(iChannelResolution[0].x / 3.);  // (W)idth of a band\n  pos   = fragCoord.xy;             \n  pos.x = mod(pos.x, W);\n\n  float band = floor(gl_FragCoord.x / W);  // Identify our Band #\n\n  vec4 y[6];  // the per-cell state vector\n  y[0] = R(0,0,0);\n  y[1] = R(0,0,1);\n  y[2] = R(0,0,2);\n\n  // The following ones are 'perception' component\n  // provides information of the 1-pixel neighbourhood\n  y[3] = laplacian(0);\n  y[4] = sobel_X(1);\n  y[5] = sobel_Y(2);\n\n  vec4 x = (band == 0.) ? y[0] : ((band==1.) ? y[1] : y[2]);\n  vec4 dx;\n\n  dx = update_Hokusai(band, y);\n  vec4 mask = floor( hash43( vec3(gl_FragCoord.xy, iFrame) ) + 0.5 );\n\n  fragColor = clamp( floor( (x + dx * mask) * 128. + vec4(0.5) )/128., -1., 1.);\n}","name":"Buffer A","description":"","type":"buffer"}]}
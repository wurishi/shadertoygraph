{"ver":"0.1","info":{"id":"mtjfWG","date":"1694456972","viewed":48,"name":"Ray-Segment Intersection","username":"Envy24","description":"Just experiment)\nHere better variants for modeling lines, rays, segments:\nhttps://www.shadertoy.com/view/ctXyWX\nhttps://www.shadertoy.com/view/Dl2yzz\nhttps://www.shadertoy.com/view/dl2yWD","likes":1,"published":1,"flags":0,"usePreview":0,"tags":["raytracing","ray","intersection","segment"],"hasliked":0,"parentid":"dlSyzt","parentname":"Ray-Torus Intersection"},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/* https://www.shadertoy.com/view/DdsGDj */\n#define MOUSE_OFFSET ( iMouse.z > 0. ? iMouse.xy - iResolution.xy * 0.5 : vec2(0) )\nvec2 map_to_centered_ndc(in vec2 SC, in float scale, in vec2 origin, in bool mouse_drag)\n{\n    vec2 M = MOUSE_OFFSET * (mouse_drag == true ? 1. : 0.);\n    return ((2. * (SC - M) - iResolution.xy) / iResolution.y) * scale + origin;\n}\n\nvec3 get_background() { return vec3(.1, .4, .6); }\n\n#define NUM_OF_OBJECTS ( 2 )\nmat4 fwd_model[NUM_OF_OBJECTS]; // per object forward model transformations.\nmat4 bwd_model[NUM_OF_OBJECTS]; // per object backward model transformations.\nmat4 bwd_view = mat4(1);        // or backward transformation for camera (should be applyed once).\n\nvoid init_transformations()\n{   \n    //\n    // Model transformations.\n    //\n    for (int i = 0; i < NUM_OF_OBJECTS; ++i)\n        fwd_model[i] = mat4(1);\n\n    vec2 M = iMouse.xy == vec2(0) ? vec2(0) : (2.*iMouse.xy/iResolution.xy) - 1.,\n         R = vec2( M.x, M.y );\n    fwd_model[0] = fwd_srt_transform(vec3(1), vec3(-R.y*6.,R.x*6.,0.), vec3(0));\n    fwd_model[1] = fwd_srt_transform(vec3(1), vec3(-R.y*6.,R.x*6.,0.), vec3(0)); \n   \n    for (int i = 0; i < NUM_OF_OBJECTS; ++i)\n        bwd_model[i] = inverse(fwd_model[i]);\n     \n    //\n    // View transformation.\n    //\n    //float s = (1.+sin(iTime))*.5, T = iTime;\n    //bwd_view = bwd_srt_transform(vec3(s+0.1), T*vec3(1,.3,.6), vec3(0,0,-10));\n    //bwd_view = bwd_srt_transform(vec3(1), vec3(0), vec3(0));\n}\n\nHIT find_closest_intersection(RAY ray)\n{\n    HIT c_hit; c_hit.hit_dist = 9e5;\n    int hit_something = 0; // Set only once, when firts hit occurs.\n    int hitted_idx = 0;\n    float min_sq_d = 9e5;\n    \n    for (int i = 0; i < NUM_OF_OBJECTS; ++i)\n    {\n        HIT hit;\n                        \n        // Apply inverse transform.\n        RAY r = apply_transform_to_ray(ray, bwd_model[i]);\n        \n        // Intersect with simplified primitives.\n        switch (i)\n        {\n        case 0: hit = ray_line_int(r, vec3(-1,-1,0), vec3(0,1,0)); break;\n        case 1: hit = ray_line_int(r, vec3(0,1,0), vec3(1,-1,0)); break;\n        }\n        \n        if (hit.hit_something == 1) // Hit i-th object?\n        {\n            // Recover hit point in world coordinates.\n            hit.hit_point = apply_transformation_to_point(hit.hit_point, fwd_model[i]);\n            \n            // Calculate squared distance in world coordinates.\n            vec3 CAMtoHP = hit.hit_point - ray.position;\n            float sq_d = dot(CAMtoHP, CAMtoHP);\n            \n            if (min_sq_d > sq_d) // Find closer hit-point?\n            {\n                // Update distance.\n                min_sq_d = sq_d;\n                \n                // Save hit data.\n                c_hit = hit;\n                c_hit.hitted_idx = i;\n            }\n        }\n        \n        // If we find any hit, then this value will be set to 1, and not changed before the function exits.\n        hit_something = max(hit.hit_something, hit_something);\n    }\n\n    // Save global hit flag.\n    c_hit.hit_something = hit_something;\n\n    // Recover normal (cheap, so i don't use branch here).\n    c_hit.hp_normal = apply_transformation_to_normal(c_hit.hp_normal, bwd_model[c_hit.hitted_idx]);\n\n    return c_hit;\n}\n\nvec3 lambert(RAY ray, HIT hit) // lambert reflectance model\n{\n    vec3 light_pos = vec3(2, 2, 2),\n         hp_to_l = normalize(light_pos - hit.hit_point),\n         obj_col = 1.-get_background();\n         \n    float diffuse = max(dot(hp_to_l, hit.hp_normal), 0.);\n    \n    return hit.hit_something == 1 ?\n        obj_col * diffuse :\n        get_background();\n}\n\nvec3 scene(vec2 SC)\n{\n    init_transformations();\n\n    // Generate primary ray.\n    vec2 MP = iMouse.xy == vec2(0) ?\n        vec2(0) :\n        map_to_centered_ndc(iMouse.xy, 1., vec2(0), false);\n        \n    RAY ray = perspective_camera(SC, vec3(0,0,6), vec3(0,0,1), iResolution.xy);\n\n    // View transformation only for B variant.\n    ray = apply_transform_to_ray(ray, bwd_view);   \n    \n    // Trace scene.\n    HIT hit = find_closest_intersection(ray);\n    \n    // Process lights.\n    return lambert(ray, hit);\n}\n\n// Basic anti-aliasing (supersample).\nvec3 OSSAA(in vec2 SC)\n{\n    vec3 col = vec3(0);\n    float order = 1., inv = 1./(2.*order + 1.), blur = 1.;\n\n    for (float y = -order; y <= order; y += 1.0)\n        for (float x = -order; x <= order; x += 1.0)\n        {\n            vec2 offset = (blur*vec2(x, y)) * inv;\n            col += scene(SC + offset);\n        }\n        \n    order = 2.*order + 1.;\n    return col / (order*order);  \n}\n\nvoid mainImage( out vec4 O, in vec2 SC )\n{\n    //O = vec4(scene(SC),1.0);\n    O = vec4(OSSAA(SC), 1.0);\n    \n    // Camera look_at.\n    O = mix(O, vec4(0,1,0,1), smoothstep(3., 0., length(SC - 0.5*iResolution.xy) - 0.5));\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"// Structures.\nstruct RAY\n{\n    vec3 position;\n    vec3 direction;\n};\nstruct HIT\n{\n    int hit_something;\n    float hit_dist;\n    vec3 hit_point;\n    vec3 hp_normal;\n    int hitted_idx;\n};\n// Cameras.\nRAY perspective_camera(vec2 SC, vec3 position, vec3 look_at, vec2 resolution)\n{\n    float zFocalLength = 50.0; // mm.\n    vec3 camera = position;\n\n    vec3 f = normalize(look_at - camera);               // forward\n    vec3 r = normalize(cross(vec3(0.0, -1.0, 0.0), f)); // right\n    vec3 u = normalize(cross(r, f));                    // up\n        \n    float size = 36.0;        // Sensor Fit: Mode = Auto.    \n    float aspectRatio = resolution.x / resolution.y;\n    float vpWidth = size;\n    float vpHeight = vpWidth / aspectRatio;\n           \n    // Before uv=[0;1][0;1]\n    vec2 uv = SC / resolution.xy;\n    uv.x = (uv.x * vpWidth) - vpWidth * 0.5;\n    uv.y = (uv.y * vpHeight) - vpHeight * 0.5;\n    // After uv=[-vpWidth*0.5; vpWidth*0.5][-vpHeight*0.5; vpHeight*0.5]\n\n    return RAY(\n        camera,\n        normalize(uv.x * r + uv.y * u + f * zFocalLength));\n}\nRAY orthographic_camera(vec2 SC, vec3 pos, vec3 look_at, vec2 resolution)\n{\n    vec3 vp = pos;                 // viewport and camera position\n    \n    vec3 f = normalize(look_at - vp);                   // forward\n    vec3 r = normalize(cross(vec3(0.0, -1.0, 0.0), f)); // right\n    vec3 u = normalize(cross(r, f));                    // up\n    \n    float aspectRatio = resolution.x / resolution.y;\n    float orthographicScale = 6.8;\n    float vpWidth = orthographicScale;\n    float vpHeight = vpWidth / aspectRatio;\n   \n    vec2 uv = SC / resolution.xy;\n    uv.x = (uv.x * vpWidth) - vpWidth * 0.5;\n    uv.y = (uv.y * vpHeight) - vpHeight * 0.5;\n     \n    RAY ray;\n    return RAY(\n        vp + uv.x * r + uv.y * u,\n        f);\n}\n\n// Ray-Object intersection routines.\nHIT ray_line_int(RAY ray, vec3 b1, vec3 e1)\n{\n    vec3 b0 = ray.position, e0 = b0 + ray.direction * 1000.,\n         r = e0 - b0, s = e1 - b1, q = b1 - b0;\n    float a = dot(s, r), b = dot(r, r), c = dot(q, r),\n          d = dot(s, s), e = a,         g = dot(q, s);\n    \n    float t = (c*d - g*a) / (b*d - e*a),\n          v = (t*b - c) / a;\n          \n    vec3 b2 = b0 + r * t,\n         e2 = b1 + s * v;\n    \n    HIT hit;\n     \n    if (v < 0. || v > 1. || t < 0. || t > 1. || // Not on segment ?\n        normalize(r) == normalize(s) ||         // Parallel lines?\n        length(e2 - b2) > 2e-3)                 // No intersection?\n    {\n        hit.hit_something = 0;\n        hit.hit_dist = 9e5;\n        return hit;\n    }\n    \n    hit.hit_something = 1;\n    hit.hit_point = b2;\n    hit.hit_dist = t;\n    hit.hp_normal = -normalize(e2 - b2);\n    return hit;\n}\n\n/*\n    Matricies for column vectors and row major matricies,\n    because i prefer this variant)\n    \n    Multiplication order:\n    T2 * T1 * T0 * V;\n    \n    Representation for points and directions\n    in homogeneous coordinates:\n        Points     p = vec4(p.xyz, 1),\n        Direction  d = vec4(p.xyz, 0).\n*/\nmat4 scale(vec3 s)\n{\n    mat4 M = mat4(\n        s.x,   0,   0, 0,\n          0, s.y,   0, 0,\n          0,   0, s.z, 0,\n          0,   0,   0, 1);\n    return transpose(M);\n}\nmat4 rotX(float rad)\n{\n    float s = sin(rad), c = cos(rad);\n    mat4 M = mat4(\n         1, 0,  0, 0,\n         0, c, -s, 0,\n         0, s,  c, 0,\n         0, 0,  0, 1);\n    return transpose(M);\n}\nmat4 rotY(float rad)\n{\n    float s = sin(rad), c = cos(rad);\n    mat4 M = mat4(\n         c, 0, s, 0,\n         0, 1, 0, 0,\n        -s, 0, c, 0,\n         0, 0, 0, 1);\n    return transpose(M);\n}\nmat4 rotZ(float rad)\n{\n    float s = sin(rad), c = cos(rad);\n    mat4 M = mat4(\n         c, -s, 0, 0,\n         s,  c, 0, 0,\n         0,  0, 1, 0,\n         0,  0, 0, 1);\n    return transpose(M);\n}\nmat4 translate(vec3 t)\n{\n    mat4 M = mat4(\n        1, 0, 0, t.x,\n        0, 1, 0, t.y,\n        0, 0, 1, t.z,\n        0, 0, 0,   1);\n    return transpose(M);\n}\nmat4 fwd_srt_transform(vec3 s, vec3 r, vec3 t) // scale, rotate, translate\n{\n    return translate(t) * rotX(r.x) * rotY(r.y) * rotZ(r.z) * scale(s);\n}\nmat4 bwd_srt_transform(vec3 s, vec3 r, vec3 t) // scale, rotate, translate\n{\n    return inverse(translate(t) * rotX(r.x) * rotY(r.y) * rotZ(r.z) * scale(s));\n}\nRAY apply_transform_to_ray(RAY ray, mat4 T)\n{\n    vec4 P = vec4(ray.position + ray.direction, 1);   \n         P = T * P;\n         \n    RAY res;\n    res.position = (T * vec4(ray.position, 1.)).xyz;\n    res.direction = normalize(P.xyz - res.position);\n    return res;\n}\nvec3 apply_transformation_to_normal(vec3 normal, mat4 T)\n{\n    mat3 SR = mat3(T[0].xyz, T[1].xyz, T[2].xyz);\n    // https://paroj.github.io/gltut/Illumination/Tut09%20Normal%20Transformation.html\n    normal = normal * transpose(inverse(SR));\n    \n    return normalize(normal);\n}\nvec3 apply_transformation_to_point(vec3 p, mat4 T)\n{\n    vec4 P = vec4(p, 1.); \n    return (T * P).xyz;\n}","name":"Common","description":"","type":"common"}]}
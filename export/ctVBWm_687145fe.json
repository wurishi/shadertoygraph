{"ver":"0.1","info":{"id":"ctVBWm","date":"1702165813","viewed":30,"name":"Video Processing - Motion","username":"berelium","description":"Based on a frame accumulator. Used for a realtime video-processing pipeline. Due to how the buffering works, data input gets downscaled significantly, resulting in data loss. Regardless, the result is pretty neat. Here, I implemented motion detection.","likes":0,"published":1,"flags":34,"usePreview":0,"tags":["2d","simple","video","webcam","motion","multipass","backbuffer","frames"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[],"code":"// Fork of \"Frame Slide\" by anastadunbar. https://shadertoy.com/view/4syGDR\n// 2023-12-09 19:24:53\n\n// Modified anastadunbar's frame slide shader to act as a frame processing pipeline.\n// Far from perfect, but gets the job done.\n// Works by diving the screen space of a buffer and saving frames from the video to Buffer A.\n// Then any frame can be fetched later on from within the buffered frames...\n// Buffer B holds a previous frame, chosen by offset from the current frame.\n// Number of divisions can be changed in Common, and previous frame for comparison in Buffer B.\n// Because of the divisions, some quality may be lost... Fullscreen is recommended!\n\n//#define SHOW_ALL_FRAMES\n//#define SHOW_CURR_FRAME\n\n// Whether to use Posy's motion implementation or a color mix\n#define POSY_MOTION\n#define MIX_COLOR 0.075\n\n// Reduce noise by thresholding the average pixel color after grayscale\n#define REDUCE_NOISE 0.02\n#define GAMMA 1.0\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalize screen space [0,1]\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n    \n    // Display buffered frames\n    #ifdef SHOW_ALL_FRAMES\n        fragColor = vec4(getAllFrames(uv), 1.0);\n        return;\n    #endif\n    \n    \n    // Grab 2 frames\n    vec3 col = vec3(0);\n    vec3 prevFrame = getPrevFrame(uv);\n    vec3 currFrame = getFrame(0, ALL_FRAMES, fragCoord, iResolution.xy).rgb;\n    \n    #ifdef SHOW_CURR_FRAME\n        fragColor = vec4(prevFrame, 1.0);\n        return;\n    #endif\n    \n    // Add smooth denoise\n    \n    // Apply motion extraction\n    vec3  diff = currFrame - prevFrame;\n    float dAvg = (diff.r + diff.g + diff.b) / 3.0;\n    diff = grayscale(diff);\n    \n    \n    // Multiply mask with current frame to reduce noise, only in darker places of the mask\n    #ifdef REDUCE_NOISE\n        if(dAvg < REDUCE_NOISE) diff *= currFrame;\n    #endif\n    \n    // Output to color\n    #ifdef POSY_MOTION\n        col += (vec3(1.0) - diff) * 0.5;\n    #else\n        // Should come up with something different\n        col += mix(diff, currFrame, MIX_COLOR);\n    #endif\n\n    // Display mask\n    //col = diff;\n\n    if(GAMMA > 1.0) col = pow(col, vec3(1./GAMMA));\n    \n    // Render pixel\n\tfragColor = vec4(col, 1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4sf3zn","filepath":"/presets/webcam.png","previewfilepath":"/presets/webcam.png","type":"webcam","channel":1,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"#define backbuffer(uv) (texture(iChannel0, uv).rgb)\n#define feed(uv) (texture(iChannel1, uv).rgb)\n\n// Frame Accumulator\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec3 outc = vec3(0);\n    vec2 uv   = fragCoord.xy / iResolution.xy;\n    \n    vec2 uv2  = vec2(uv.x - CX, uv.y); // Take the picture from one step left\n    if (uv.x < CX) { // At left\n        uv2 = vec2(uv.x, uv.y - CY);   // Take the right to left and one step up\n    }\n    \n    if(uv.x < CX && uv.y < CY) {\n        outc = feed(uv * GRID);\n    } else {\n        outc = backbuffer(uv2);\n    }\n   \n    fragColor = vec4(outc, 1.0);\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"#define ROW (DIV*1)\n#define COL (DIV*0)\n#define FRAME ROW + COL\n\n// Fetch a previous frame to work with later. FRAME being the previous offset to use before the current frame.\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = getFrame(FRAME, ALL_FRAMES, fragCoord, iResolution.xy);\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"// Buffer the current and last ((DIV x DIV) - 1.0) frames in a grid format\n#define DIV 3\n#define GRID vec2(DIV,DIV)\n#define CELLS GRID.x * GRID.y\n#define CX 1. / GRID.x\n#define CY 1. / GRID.y\n\n#define PREV_FRAME iChannel1\n#define ALL_FRAMES iChannel0\n\n#define getPrevFrame(uv) (texture(PREV_FRAME, uv).rgb)\n#define getAllFrames(uv) (texture(ALL_FRAMES, uv).rgb)\n\n\n// This isnt perfect... Could use refinement\n// Get a frame from currentFrame - n (depends on how many buffered in A)\nvec4 getFrame( in int f, in sampler2D buffer, in vec2 coord, in vec2 resolution ) {\n    vec2 uv   = coord.xy / (resolution * GRID);\n    int frame = float(f+1) >= CELLS ? int(CELLS-1.) : (f < 0 ? 0 : f);  \n    \n    // Reproject UV space to single frame\n    uv.x += float(frame % DIV) * CX;\n    uv.y += ceil(float(frame/DIV)) * CY;\n    \n    // Sample the texture at the frames coordinates\n    return texture(buffer, uv);\n}\n\n\nvec3 grayscale(vec3 color) {\n    return vec3(dot(color, vec3(0.299, 0.587, 0.114)));\n}","name":"Common","description":"","type":"common"}]}
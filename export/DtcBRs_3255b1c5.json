{"ver":"0.1","info":{"id":"DtcBRs","date":"1701457317","viewed":74,"name":"SURFACE INSPECTION WITH FILTERS","username":"LUISAZNAGASC","description":"- SHADER NAME : SURFACE INSPECTION WITH FILTERS\n\n- SHADER TAGS : RAY MARCHING SURFACE, PHONG REFLECTION MODEL, GAUSSIAN BLUR FILTER, EDGE DETECTION FILTER, ...","likes":1,"published":1,"flags":32,"usePreview":0,"tags":["gaussianblurfilter","raymarchingsurface","phongreflectionmodel","edgedetectionfilter"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"const uint FragmentOriginalFilterState = 0u;\nconst uint FragmentGaussianBlurFilterState = 1u;\nconst uint FragmentEdgeDetectionFilterState = 2u;\n\nuint fragmentDesiredFilterState = FragmentOriginalFilterState;\n\nvec4 getFragmentOriginalColorUsing(in vec2 sampleFragmentInputCoordinates)\n{\n    vec2 sampleFragmentTextureCoordinates = sampleFragmentInputCoordinates.xy / iChannelResolution[0].xy;\n    \n    vec4 finalFragmentOriginalColor = texture(iChannel0, sampleFragmentTextureCoordinates.xy).rgba;\n    \n    return finalFragmentOriginalColor.rgba;\n}\n\nvec4 getFragmentGaussianBlurColorUsing(in vec2 sampleFragmentInputCoordinates)\n{\n    vec2 sampleFragmentTextureCoordinates = sampleFragmentInputCoordinates.xy / iChannelResolution[0].xy;\n    vec2 sampleFragmentTexturePixelSize = vec2(25.0, 25.0).xy / iChannelResolution[0].xy;\n    \n    vec4 totalFragmentGaussianBlurColor = vec4(0.0, 0.0, 0.0, 0.0).rgba;\n    totalFragmentGaussianBlurColor.rgba += 001.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-2.0, -2.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 004.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, -2.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 006.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, -2.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 004.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, -2.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 001.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+2.0, -2.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 004.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-2.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 016.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 024.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 016.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 004.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+2.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 006.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-2.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 024.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 036.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 024.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 006.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+2.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 004.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-2.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 016.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 024.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 016.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 004.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+2.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 001.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-2.0, +2.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 004.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, +2.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 006.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, +2.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 004.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, +2.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentGaussianBlurColor.rgba += 001.0 / 256.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+2.0, +2.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    \n    vec4 finalFragmentGaussianBlurColor = totalFragmentGaussianBlurColor.rgba;\n    \n    return finalFragmentGaussianBlurColor.rgba;\n}\n\nvec4 getFragmentEdgeDetectionColorUsing(in vec2 sampleFragmentInputCoordinates)\n{\n    vec2 sampleFragmentTextureCoordinates = sampleFragmentInputCoordinates.xy / iChannelResolution[0].xy;\n    vec2 sampleFragmentTexturePixelSize = vec2(1.0, 1.0).xy / iChannelResolution[0].xy;\n    \n    vec4 totalFragmentXEdgeDetectionColor = vec4(0.0, 0.0, 0.0, 0.0).rgba;\n    totalFragmentXEdgeDetectionColor.rgba += -1.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentXEdgeDetectionColor.rgba += +0.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentXEdgeDetectionColor.rgba += +1.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentXEdgeDetectionColor.rgba += -2.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentXEdgeDetectionColor.rgba += +0.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentXEdgeDetectionColor.rgba += +2.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentXEdgeDetectionColor.rgba += -1.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentXEdgeDetectionColor.rgba += +0.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentXEdgeDetectionColor.rgba += +1.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    \n    vec4 totalFragmentYEdgeDetectionColor = vec4(0.0, 0.0, 0.0, 0.0).rgba;\n    totalFragmentYEdgeDetectionColor.rgba += +1.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentYEdgeDetectionColor.rgba += +2.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentYEdgeDetectionColor.rgba += +1.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, -1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentYEdgeDetectionColor.rgba += +0.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentYEdgeDetectionColor.rgba += +0.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentYEdgeDetectionColor.rgba += +0.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, +0.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentYEdgeDetectionColor.rgba += -1.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(-1.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentYEdgeDetectionColor.rgba += -2.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+0.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    totalFragmentYEdgeDetectionColor.rgba += -1.0 * texture(iChannel0, sampleFragmentTextureCoordinates.xy + vec2(+1.0, +1.0).xy * sampleFragmentTexturePixelSize.xy).rgba;\n    \n    vec4 totalFragmentEdgeDetectionColor = sqrt(totalFragmentXEdgeDetectionColor.rgba * totalFragmentXEdgeDetectionColor.rgba + totalFragmentYEdgeDetectionColor.rgba * totalFragmentYEdgeDetectionColor.rgba).rgba;\n    float totalFragmentEdgeDetectionGrayScale = (totalFragmentEdgeDetectionColor.r + totalFragmentEdgeDetectionColor.g + totalFragmentEdgeDetectionColor.b) / 3.0;\n    \n    vec4 finalFragmentEdgeDetectionColor = vec4(vec3(totalFragmentEdgeDetectionGrayScale, totalFragmentEdgeDetectionGrayScale, totalFragmentEdgeDetectionGrayScale).rgb, totalFragmentEdgeDetectionColor.a).rgba;\n    \n    return finalFragmentEdgeDetectionColor.rgba;\n}\n\nvec4 getFragmentOutputColorUsing(in vec2 sampleFragmentInputCoordinates)\n{\n    vec4 finalFragmentOutputColor = vec4(0.0, 0.0, 0.0, 0.0).rgba;\n    \n    if (fragmentDesiredFilterState == FragmentOriginalFilterState)\n    {\n        vec4 sampleFragmentOriginalColor = getFragmentOriginalColorUsing(sampleFragmentInputCoordinates.xy).rgba;\n        \n        finalFragmentOutputColor.rgba = sampleFragmentOriginalColor.rgba;\n        \n        return finalFragmentOutputColor.rgba;\n    }\n    \n    if (fragmentDesiredFilterState == FragmentGaussianBlurFilterState)\n    {\n        vec4 sampleFragmentGaussianBlurColor = getFragmentGaussianBlurColorUsing(sampleFragmentInputCoordinates.xy).rgba;\n        \n        finalFragmentOutputColor.rgba = sampleFragmentGaussianBlurColor.rgba;\n        \n        return finalFragmentOutputColor.rgba;\n    }\n    \n    if (fragmentDesiredFilterState == FragmentEdgeDetectionFilterState)\n    {\n        vec4 sampleFragmentEdgeDetectionColor = getFragmentEdgeDetectionColorUsing(sampleFragmentInputCoordinates.xy).rgba;\n        \n        finalFragmentOutputColor.rgba = sampleFragmentEdgeDetectionColor.rgba;\n        \n        return finalFragmentOutputColor.rgba;\n    }\n    \n    vec4 sampleFragmentNotFoundColor = vec4(0.0, 0.0, 0.0, 1.0).rgba;\n    \n    finalFragmentOutputColor.rgba = sampleFragmentNotFoundColor.rgba;\n    \n    return finalFragmentOutputColor.rgba;\n}\n\nvoid mainImage(out vec4 sampleFragmentOutputColor, in vec2 sampleFragmentInputCoordinates)\n{\n    sampleFragmentOutputColor.rgba = getFragmentOutputColorUsing(sampleFragmentInputCoordinates.xy).rgba;\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"const int RayMarchSurfaceComponentStepIteration = 3000;\nconst float RayMarchSurfaceComponentEpsilon = 0.0001;\nconst float RayMarchSurfaceComponentMinimumDistance = 0.0;\nconst float RayMarchSurfaceComponentMaximumDistance = 3000.0;\n\nconst vec2 NormalRayDirectionEpsilon = vec2(0.0001, 0.0).xy;\n\nconst float FragmentPhongColorShininessAmount = 6.0;\n\nconst vec4 FragmentOutputColorBackgroundColor = vec4(0.25, 0.25, 0.25, 1.0).rgba;\n\nstruct rayComponent\n{\n    vec3 rayPosition;\n    vec3 rayDirection;\n};\n\nstruct materialComponent\n{\n    vec4 materialAmbientColor;\n    vec4 materialDiffuseColor;\n    vec4 materialSpecularColor;\n};\n\nstruct surfaceComponent\n{\n    float surfaceSignedDistance;\n    materialComponent surfaceMaterialComponent;\n};\n\nmat3 getTransformOrientationUsing(in vec3 sampleTransformRotation)\n{\n    vec3 sampleTransformRotationInRadians = radians(sampleTransformRotation.xyz).xyz;\n    vec3 sineTransformRotation = sin(sampleTransformRotationInRadians.xyz).xyz;\n    vec3 cosineTransformRotation = cos(sampleTransformRotationInRadians.xyz).xyz;\n    \n    mat3 xTransformOrientation = mat3(vec3(1.0, 0.0, 0.0).xyz, vec3(0.0, cosineTransformRotation.x, -sineTransformRotation.x).xyz, vec3(0.0, sineTransformRotation.x, cosineTransformRotation.x).xyz);\n    mat3 yTransformOrientation = mat3(vec3(cosineTransformRotation.y, 0.0, sineTransformRotation.y).xyz, vec3(0.0, 1.0, 0.0).xyz, vec3(-sineTransformRotation.y, 0.0, cosineTransformRotation.y).xyz);\n    mat3 zTransformOrientation = mat3(vec3(cosineTransformRotation.z, -sineTransformRotation.z, 0.0).xyz, vec3(sineTransformRotation.z, cosineTransformRotation.z, 0.0).xyz, vec3(0.0, 0.0, 1.0).xyz);\n    \n    mat3 finalTransformOrientation = xTransformOrientation * yTransformOrientation * zTransformOrientation;\n    \n    return finalTransformOrientation;\n}\n\nmat3 getLookAtOrientationUsing(in vec3 originTransformPosition, in vec3 targetTransformPosition)\n{\n    vec3 desiredForwardDirection = normalize(targetTransformPosition.xyz - originTransformPosition.xyz).xyz;\n    vec3 desiredRightwardDirection = normalize(cross(vec3(0.0, 1.0, 0.0).xyz, desiredForwardDirection.xyz).xyz).xyz;\n    vec3 desiredUpwardDirection = normalize(cross(desiredRightwardDirection.xyz, desiredForwardDirection.xyz).xyz).xyz;\n    \n    mat3 finalLookAtOrientation = mat3(-desiredRightwardDirection.xyz, -desiredUpwardDirection.xyz, -desiredForwardDirection.xyz);\n    \n    return finalLookAtOrientation;\n}\n\nmaterialComponent getRedMaterialComponent()\n{\n    materialComponent finalRedMaterialComponent;\n    finalRedMaterialComponent.materialAmbientColor.rgba = vec4(0.375, 0.0, 0.0, 1.0).rgba;\n    finalRedMaterialComponent.materialDiffuseColor.rgba = vec4(1.0, 0.0, 0.0, 1.0).rgba;\n    finalRedMaterialComponent.materialSpecularColor.rgba = vec4(0.625, 0.375, 0.375, 1.0).rgba;\n    \n    return finalRedMaterialComponent;\n}\n\nmaterialComponent getGreenMaterialComponent()\n{\n    materialComponent finalGreenMaterialComponent;\n    finalGreenMaterialComponent.materialAmbientColor.rgba = vec4(0.0, 0.375, 0.0, 1.0).rgba;\n    finalGreenMaterialComponent.materialDiffuseColor.rgba = vec4(0.0, 1.0, 0.0, 1.0).rgba;\n    finalGreenMaterialComponent.materialSpecularColor.rgba = vec4(0.375, 0.625, 0.375, 1.0).rgba;\n    \n    return finalGreenMaterialComponent;\n}\n\nmaterialComponent getBlueMaterialComponent()\n{\n    materialComponent finalBlueMaterialComponent;\n    finalBlueMaterialComponent.materialAmbientColor.rgba = vec4(0.0, 0.0, 0.375, 1.0).rgba;\n    finalBlueMaterialComponent.materialDiffuseColor.rgba = vec4(0.0, 0.0, 1.0, 1.0).rgba;\n    finalBlueMaterialComponent.materialSpecularColor.rgba = vec4(0.375, 0.375, 0.625, 1.0).rgba;\n    \n    return finalBlueMaterialComponent;\n}\n\nsurfaceComponent getCombinedSurfaceComponentUsing(in surfaceComponent firstSurfaceComponent, in surfaceComponent secondSurfaceComponent, float smoothnessBlendAmount)\n{\n    float smoothnessBlendFactor = clamp(0.5 + 0.5 * (secondSurfaceComponent.surfaceSignedDistance - firstSurfaceComponent.surfaceSignedDistance) / smoothnessBlendAmount, 0.0, 1.0);\n    \n    float smoothnessBlendInterpolation = smoothnessBlendAmount * smoothnessBlendFactor * (1.0 - smoothnessBlendFactor);\n    float combinedSurfaceSignedDistance = mix(secondSurfaceComponent.surfaceSignedDistance, firstSurfaceComponent.surfaceSignedDistance, smoothnessBlendFactor) - smoothnessBlendInterpolation;\n    \n    materialComponent firstSurfaceMaterialComponent = firstSurfaceComponent.surfaceMaterialComponent;\n    materialComponent secondSurfaceMaterialComponent = secondSurfaceComponent.surfaceMaterialComponent;\n    materialComponent combinedSurfaceMaterialComponent;\n    combinedSurfaceMaterialComponent.materialAmbientColor.rgba = mix(secondSurfaceMaterialComponent.materialAmbientColor.rgba, firstSurfaceMaterialComponent.materialAmbientColor.rgba, smoothnessBlendFactor).rgba;\n    combinedSurfaceMaterialComponent.materialDiffuseColor.rgba = mix(secondSurfaceMaterialComponent.materialDiffuseColor.rgba, firstSurfaceMaterialComponent.materialDiffuseColor.rgba, smoothnessBlendFactor).rgba;\n    combinedSurfaceMaterialComponent.materialSpecularColor.rgba = mix(secondSurfaceMaterialComponent.materialSpecularColor.rgba, firstSurfaceMaterialComponent.materialSpecularColor.rgba, smoothnessBlendFactor).rgba;\n    \n    surfaceComponent finalCombinedSurfaceComponent;\n    finalCombinedSurfaceComponent.surfaceSignedDistance = combinedSurfaceSignedDistance;\n    finalCombinedSurfaceComponent.surfaceMaterialComponent = combinedSurfaceMaterialComponent;\n    \n    return finalCombinedSurfaceComponent;\n}\n\nsurfaceComponent getSphereSurfaceComponentUsing(in vec3 sampleTransformPosition, in float sampleTransformRadius, in materialComponent sampleMaterialComponent)\n{\n    float sphereSurfaceSignedDistance = length(sampleTransformPosition.xyz) - sampleTransformRadius;\n    materialComponent sphereSurfaceMaterialComponent = sampleMaterialComponent;\n    \n    surfaceComponent finalSphereSurfaceComponent;\n    finalSphereSurfaceComponent.surfaceSignedDistance = sphereSurfaceSignedDistance;\n    finalSphereSurfaceComponent.surfaceMaterialComponent = sphereSurfaceMaterialComponent;\n    \n    return finalSphereSurfaceComponent;\n}\n\nsurfaceComponent getComplexSurfaceComponentUsing(in vec3 sampleTransformPosition, in mat3 sampleTransformRotation)\n{\n    vec3 complexFullTransformation = sampleTransformRotation * sampleTransformPosition.xyz;\n    \n    surfaceComponent redSphereSurfaceComponent = getSphereSurfaceComponentUsing(complexFullTransformation.xyz - vec3(-3.0, -3.0, 0.0).xyz, 6.0, getRedMaterialComponent());\n    surfaceComponent greenSphereSurfaceComponent = getSphereSurfaceComponentUsing(complexFullTransformation.xyz - vec3(0.0, 3.0, 0.0).xyz, 6.0, getGreenMaterialComponent());\n    surfaceComponent blueSphereSurfaceComponent = getSphereSurfaceComponentUsing(complexFullTransformation.xyz - vec3(3.0, -3.0, 0.0).xyz, 6.0, getBlueMaterialComponent());\n    \n    surfaceComponent finalComplexSurfaceComponent;\n    finalComplexSurfaceComponent = getCombinedSurfaceComponentUsing(redSphereSurfaceComponent, greenSphereSurfaceComponent, 1.5);\n    finalComplexSurfaceComponent = getCombinedSurfaceComponentUsing(finalComplexSurfaceComponent, blueSphereSurfaceComponent, 1.5);\n    \n    return finalComplexSurfaceComponent;\n}\n\nsurfaceComponent getSceneSurfaceComponentUsing(in vec3 sampleTransformPosition)\n{\n    surfaceComponent complexSurfaceComponent = getComplexSurfaceComponentUsing(sampleTransformPosition.xyz, getTransformOrientationUsing(vec3(45.0 * iTime, 45.0 * iTime, 0.0).xyz));\n    \n    surfaceComponent finalSceneSurfaceComponent;\n    finalSceneSurfaceComponent = complexSurfaceComponent;\n    \n    return finalSceneSurfaceComponent;\n}\n\nsurfaceComponent getRayMarchSurfaceComponentUsing(in rayComponent sampleRayComponent)\n{\n    float rayMarchSurfaceSignedDistance = RayMarchSurfaceComponentMinimumDistance;\n    surfaceComponent finalRayMarchSurfaceComponent;\n    finalRayMarchSurfaceComponent.surfaceSignedDistance = rayMarchSurfaceSignedDistance;\n    \n    for (int rayMarchSurfaceStepIndex = 0; rayMarchSurfaceStepIndex < RayMarchSurfaceComponentStepIteration; rayMarchSurfaceStepIndex++)\n    {\n        vec3 rayMarchRayPosition = sampleRayComponent.rayPosition.xyz + rayMarchSurfaceSignedDistance * sampleRayComponent.rayDirection.xyz;\n        \n        finalRayMarchSurfaceComponent = getSceneSurfaceComponentUsing(rayMarchRayPosition.xyz);\n        rayMarchSurfaceSignedDistance += finalRayMarchSurfaceComponent.surfaceSignedDistance;\n        \n        if (abs(finalRayMarchSurfaceComponent.surfaceSignedDistance) < RayMarchSurfaceComponentEpsilon || rayMarchSurfaceSignedDistance > RayMarchSurfaceComponentMaximumDistance)\n        {\n            finalRayMarchSurfaceComponent.surfaceSignedDistance = rayMarchSurfaceSignedDistance;\n            \n            break;\n        }\n    }\n    \n    finalRayMarchSurfaceComponent.surfaceSignedDistance = rayMarchSurfaceSignedDistance;\n    \n    return finalRayMarchSurfaceComponent;\n}\n\nvec3 getNormalRayDirectionUsing(in vec3 sampleRayPosition)\n{\n    float normalXGradient = getSceneSurfaceComponentUsing(NormalRayDirectionEpsilon.xyy + sampleRayPosition.xyz).surfaceSignedDistance - getSceneSurfaceComponentUsing(-NormalRayDirectionEpsilon.xyy + sampleRayPosition.xyz).surfaceSignedDistance;\n    float normalYGradient = getSceneSurfaceComponentUsing(NormalRayDirectionEpsilon.yxy + sampleRayPosition.xyz).surfaceSignedDistance - getSceneSurfaceComponentUsing(-NormalRayDirectionEpsilon.yxy + sampleRayPosition.xyz).surfaceSignedDistance;\n    float normalZGradient = getSceneSurfaceComponentUsing(NormalRayDirectionEpsilon.yyx + sampleRayPosition.xyz).surfaceSignedDistance - getSceneSurfaceComponentUsing(-NormalRayDirectionEpsilon.yyx + sampleRayPosition.xyz).surfaceSignedDistance;\n    \n    vec3 finalNormalRayDirection = normalize(vec3(normalXGradient, normalYGradient, normalZGradient).xyz).xyz;\n    \n    return finalNormalRayDirection.xyz;\n}\n\nvec4 getFragmentPhongColorUsing(in rayComponent sampleRayComponent, in surfaceComponent sampleSurfaceComponent)\n{\n    float sampleSurfaceSignedDistance = sampleSurfaceComponent.surfaceSignedDistance;\n    materialComponent sampleMaterialComponent = sampleSurfaceComponent.surfaceMaterialComponent;\n    \n    rayComponent normalRayComponent;\n    normalRayComponent.rayPosition.xyz = sampleRayComponent.rayPosition.xyz + sampleSurfaceSignedDistance * sampleRayComponent.rayDirection.xyz;\n    normalRayComponent.rayDirection.xyz = getNormalRayDirectionUsing(normalRayComponent.rayPosition.xyz).xyz;\n    \n    rayComponent lightRayComponent;\n    lightRayComponent.rayPosition.xyz = vec3(6.0, 6.0, -12.0).xyz;\n    lightRayComponent.rayDirection.xyz = normalize(lightRayComponent.rayPosition.xyz - normalRayComponent.rayPosition.xyz).xyz;\n    \n    vec4 sampleMaterialAmbientColor = sampleMaterialComponent.materialAmbientColor.rgba;\n    \n    float sampleMaterialDiffuseAmount = clamp(dot(lightRayComponent.rayDirection.xyz, normalRayComponent.rayDirection.xyz), 0.25, 1.0);\n    \n    rayComponent shadowRayComponent;\n    shadowRayComponent.rayPosition.xyz = normalRayComponent.rayPosition.xyz + 2.0 * RayMarchSurfaceComponentEpsilon * normalRayComponent.rayDirection.xyz;\n    shadowRayComponent.rayDirection.xyz = lightRayComponent.rayDirection.xyz;\n    \n    float shadowRaySignedDistance = getRayMarchSurfaceComponentUsing(shadowRayComponent).surfaceSignedDistance;\n    \n    if (shadowRaySignedDistance < length(lightRayComponent.rayPosition.xyz - shadowRayComponent.rayPosition.xyz))\n    {\n        sampleMaterialDiffuseAmount *= 0.25;\n    }\n    \n    vec4 sampleMaterialDiffuseColor = sampleMaterialDiffuseAmount * sampleMaterialComponent.materialDiffuseColor.rgba;\n    \n    float sampleMaterialSpecularAmount = clamp(dot(normalize(reflect(lightRayComponent.rayDirection.xyz, normalRayComponent.rayDirection.xyz).xyz).xyz, sampleRayComponent.rayDirection.xyz), 0.25, 1.0);\n    sampleMaterialSpecularAmount = pow(sampleMaterialSpecularAmount, FragmentPhongColorShininessAmount);\n    vec4 sampleMaterialSpecularColor = sampleMaterialSpecularAmount * sampleMaterialComponent.materialSpecularColor.rgba;\n    \n    vec4 finalFragmentPhongColor = sampleMaterialAmbientColor.rgba + sampleMaterialDiffuseColor.rgba + sampleMaterialSpecularColor.rgba;\n    \n    return finalFragmentPhongColor.rgba;\n}\n\nvec4 getFragmentOutputColorUsing(in rayComponent sampleRayComponent)\n{\n    vec4 finalFragmentOutputColor = FragmentOutputColorBackgroundColor.rgba;\n    \n    surfaceComponent rayMarchSurfaceComponent = getRayMarchSurfaceComponentUsing(sampleRayComponent);\n    \n    if (rayMarchSurfaceComponent.surfaceSignedDistance <= RayMarchSurfaceComponentMaximumDistance)\n    {\n        vec4 sampleFragmentPhongColor = getFragmentPhongColorUsing(sampleRayComponent, rayMarchSurfaceComponent).rgba;\n        \n        finalFragmentOutputColor.rgba = sampleFragmentPhongColor.rgba;\n    }\n    else\n    {\n        finalFragmentOutputColor.rgba = FragmentOutputColorBackgroundColor.rgba;\n    }\n    \n    return finalFragmentOutputColor.rgba;\n}\n\nvoid mainImage(out vec4 sampleFragmentOutputColor, in vec2 sampleFragmentInputCoordinates)\n{\n    vec2 sampleFragmentNormalizedCoordinates = (sampleFragmentInputCoordinates.xy * 2.0 - iResolution.xy).xy / iResolution.y;\n    \n    vec3 lookAtRayPosition = vec3(0.0, 0.0, 0.0).xyz;\n    \n    rayComponent cameraRayComponent;\n    cameraRayComponent.rayPosition.xyz = vec3(0.0, 12.0, -18.0).xyz;\n    cameraRayComponent.rayDirection.xyz = getLookAtOrientationUsing(cameraRayComponent.rayPosition.xyz, lookAtRayPosition.xyz) * normalize(vec3(vec2(sampleFragmentNormalizedCoordinates.xy), -2.0).xyz).xyz;\n    \n    sampleFragmentOutputColor.rgba = getFragmentOutputColorUsing(cameraRayComponent).rgba;\n}","name":"Buffer A","description":"","type":"buffer"}]}
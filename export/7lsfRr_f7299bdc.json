{"ver":"0.1","info":{"id":"7lsfRr","date":"1650485247","viewed":893,"name":"Zetsubo (絶望)","username":"noby","description":"Zetsubō (ぜつぼう) was a 4k intro I released in 2018 at Revision, and placed 2nd in the compo. This version is just for instructional purposes.\n\nOriginal: https://www.pouet.net/prod.php?which=75720\nVideo: https://youtube.com/watch?v=ncdA3t_vzF8\n","likes":38,"published":1,"flags":96,"usePreview":1,"tags":["intro","4k","demoscene","cubes","abstract","pathtracing"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Copyright © 2018–2022 Prismbeings.\n// All rights to the likeness of the visuals and audio reserved.\n\n// Any individual parts of the code that produces the visuals is\n// available in the public domain or licensed under the MIT license,\n// whichever suits you best under your local legislation.\n// (This applies to Buffer A, Buffer B, and Image).\n\n// This is to say: you can NOT use the code as a whole or the visual\n// output it produces for any purposes without an explicit permission,\n// nor can you remix or adapt the work itself without a permission.*\n// You absolutely CANNOT mint any NFTs based on the Work or part of it.\n// You CAN however use any individual algorithms or parts of the Code\n// for any purpose, commercial or otherwise, without attribution.\n// You may also NOT use any part of the visual output for training\n// any neural networks or image generation algortihms.\n\n// *(In practice, for most reasonable requests, I will gladly grant\n//   any wishes to remix or adapt this work :)).\n\n// WARNING: Buffer B compilation likely will take several seconds!**\n// Please rewind back to the start once compilation is finished\n// if the music playback doesn't automatically restart!\n\n// **(On Windows using ANGLE).\n\n// If the music playback doesn't start at all, please reload the page\n// and click around randomly a few times immediately as it loats.\n// This is because modern browsers prevent audio auto playback if the\n// user hasn't \"interacted\" with the page.\n\n// I understand the way this code is presented is far from ideal for\n// shadertoy or any sort of public presentation. It is simply provided\n// here on as-is basis for demonstration purposes, and as a simply way\n// to \"open source\" the relevant parts of the original work.\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\tfragColor=vec4(0);\n\tvec2 uv = gl_FragCoord.xy / iResolution.xy;\n\tif(uv.y > 0.875 || uv.y < 0.125) return;\n\tfloat rf=1.,gf=1.,bf=1.;\n\tfor(int i=0;i<12;++i){\n\t\tfragColor.r+=texture(iChannel0,.5+.5*((-1.+2.*uv)*rf)).r/12.;\n\t\tfragColor.g+=texture(iChannel0,.5+.5*((-1.+2.*uv)*gf)).g/12.;\n\t\tfragColor.b+=texture(iChannel0,.5+.5*((-1.+2.*uv)*bf)).b/12.;\n\t\trf*=.9983;\n\t\tgf*=.9979;\n        bf*=.9958;\n\t}\n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Copyright © 2018–2022 Prismbeings.\n// All rights to the likeness of the visuals and audio reserved.\n\n// Any individual parts of the code that produces the visuals is\n// available in the public domain or licensed under the MIT license,\n// whichever suits you best under your local legislation.\n// (This applies to Buffer A, Buffer B, and Image).\n\n// See \"Image\" for more detail.\n\n// This texture doesn't look exactly as the original...\n// Not sure why, but close enough.\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    // Original texture was 512×512 GL_MIRRORED_REPEAT.\n    // This is not available on shadertoy, so instead I just\n    // set it to correct scale and change the sampling in the\n    // main shader (Buffer B) so that it doesn't really repeat.\n    // Not an issue since this texture is effectively rendered\n    // at higher resolution anyway.\n\tvec2 s=512.0*fragCoord.xy*.025 / (iResolution.xy);\n\tfloat r=0.;\n\tfragColor=vec4(0);\n\tfor(float g=0.;g<8.;++g){\n    \tr+=.5+.5*sin(1.5*s.x)*cos(1.5*s.y);\n    \ts=mat2(.8,.6,-.6,.8)*s*2.01;\n    \tr+=.25*sin(2.1*s.x)*sin(2.1*s.y);\n    \ts=mat2(.5,.8,-.6,.8)*s*2.02;\n    \tr+=.125*sin(2.9*s.x)*cos(2.9*s.y);\n    \ts=mat2(.7,-.7,0.1,0.5)*s*2.03;\n    \tr+=.0625*sin(3.5*s.x)*cos(3.5*s.y);\n    \tfragColor+=1.+r;\n    \ts=vec2(fragColor.x);\n    }\n    \n    // NOTE: This was originally raised to the 6th power,\n    // but that looks completely wrong here for some reason.\n    // Leaving the pow out entirely looks the most correct\n    // to my eyes.\n\tfragColor=pow(fragColor*.03,vec4(1.0));\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"MtBXzz","filepath":"https://soundcloud.com/noby/zetsubo","previewfilepath":"https://soundcloud.com/noby/zetsubo","type":"musicstream","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":0}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// Copyright © 2018–2022 Prismbeings.\n// All rights to the likeness of the visuals and audio reserved.\n\n// Any individual parts of the code that produces the visuals is\n// available in the public domain or licensed under the MIT license,\n// whichever suits you best under your local legislation.\n// (This applies to Buffer A, Buffer B, and Image).\n\n// See \"Image\" for more detail.\n\nmat3 cubes[8];\nvec3 colors[4] = vec3[4](\n    vec3(0.7,0.5,0.4),\n    vec3(0.75),\n    vec3(0.7,0.4,0.8),\n    vec3(0.5,0.75,0.8)\n);\nfloat pi = 3.14159;\n\nfloat box(vec3 ro, vec3 rd){\n    return min((sign(rd.x)-ro.x)/rd.x,min((sign(rd.y)-ro.y)/rd.y,(sign(rd.z)-ro.z)/rd.z));\n}\n\nvec2 box2(vec3 ro, vec3 rd){\n    return vec2(max((-sign(rd.x)-ro.x)/rd.x,max((-sign(rd.y)-ro.y)/rd.y,(-sign(rd.z)-ro.z)/rd.z)),\n                min((sign(rd.x)-ro.x)/rd.x,min((sign(rd.y)-ro.y)/rd.y,(sign(rd.z)-ro.z)/rd.z)));\n}\n\nfloat seed;\nfloat hash(){return fract(sin(seed+=0.1)*54531.2322578);}\n\n// Global non-constant initializations are forbidden.\n// Instead these are set in mainImage.\nfloat bt;\nfloat tt;\nfloat anim8;\nfloat anim1;\nfloat anim2;\nfloat anim3;\nfloat anim7;\nfloat anim4;\nfloat anim6;\nfloat anim5;\nmat3 bounding;\n\nmat3 trace(vec3 ro, vec3 rd, inout float d){\n    mat3 closest = bounding;\n    d = box((ro - bounding[1]) / bounding[2], rd / bounding[2]);\n    for(int i = 0; i < 8; ++i){\n        vec2 bp = box2((ro - cubes[i][1]) / cubes[i][2], rd / cubes[i][2]);\n        float v = bp.y < bp.x ? 9e9 : bp.x;\n        if(v>1e-4 && v < d){\n            d = v;\n            closest = cubes[i];\n        }\n    }\n    return closest;\n}\n\nmat3 trac2(vec3 ro, vec3 rd, inout float d){\n    mat3 closest = mat3(0);\n    for(int i = 0; i < 8; ++i){\n        vec2 bp = box2((ro - cubes[i][1]) / cubes[i][2], rd / cubes[i][2]);\n        float v = mix(bp.x, bp.y, (0.5+0.5*sign(ro.x))*(0.5+0.5*sign(ro.z)) );\n        if(v>1e-4 && v < d){\n            d = v;\n            closest = cubes[i];\n        }\n    }\n    return closest;\n}\n\nvec3 lambert(in vec3 normal, in vec2 uv){\n   uv.y = 2.0 * uv.y - 1.0;\n   return normalize(normal + vec3(sqrt(1.0 - uv.y * uv.y) * vec2(cos(2.*pi*uv.x), sin(2.*pi*uv.x)), uv.y));\n}\n\nvec3 render(vec3 ro, vec3 rd, vec2 uv){\n    vec3 color = vec3(0), absorption = vec3(1);\n    for(int b = 0; b < 3; b++){\n        float d = 9e9;\n        mat3 tmat = anim5<1.?trace(ro, rd, d):trac2(ro, rd, d);\n        if(tmat[2] != vec3(0)) {\n            vec3 pos = ro + d*rd, nor = (pos-tmat[1])/tmat[2];\n            nor=sign(nor)*step(abs(nor).yzx,abs(nor))*step(abs(nor).zxy,abs(nor));\n            \n            float li = 1.0, rm = 1.0;\n            if(tmat == bounding){\n                tmat[0].x = mod(tmat[0].x+(anim4+anim7)*(max(0.,dot(nor,vec3(1,0,0)))+2.*max(0.,dot(nor,vec3(1,0,0)))+3.*max(0.,dot(nor,vec3(1,0,0)))+4.*max(.0,dot(nor,vec3(1,0,0)))),4.0);\n                li = mix(li,smoothstep(1.-.21*anim1,1.-.2*anim1,sin(5.0*tt+pos.y*0.5)),anim1);\n                // Texture sampling slightly changed here, was texture(iChannel0, pos.xz*0.05+0.5) originally.\n                rm=mix((rm-1.0*pow(min(1.,texture(iChannel0, pos.xz*0.05+0.5).r),3.0)*min(0.,dot(nor, vec3(0,1,0))))/1.45,\n                    rm-0.5*step(.5,fract(length(pos)))*min(0.,dot(nor, vec3(0,1,0))),anim4);\n            }\n            li = mix(li,smoothstep(0.99,1.0,sin(pos.y*9.)),anim5);\n\n            li += (1.-anim5)*0.02*max(0.0,dot(nor,normalize(vec3(1))));\n            color += absorption * li*tmat[0].y*colors[int(tmat[0].x)];\n\n            absorption *= colors[int(tmat[0].x)]/pi;\n            rd = normalize(mix(lambert(nor, vec2(hash(),hash())), reflect(rd, nor), rm*tmat[0].z));\n            ro = pos+nor*0.001;\n        } else {\n            return color+absorption*90.;\n        }\n    }\n    return color;\n}\n\nvec3 tonemap(vec3 c){\n    return (((c*(.15*c+.1*.5)+.004)/(c*(.15*c+.5)+.067))-.067)/(((15.*(.15*15.+.05)+.004)/(15.*(2.75)+.067))-.067);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    vec2 uv = fragCoord.xy / iResolution.xy;\n    if(uv.y > 0.875 || uv.y < 0.125) return;\n    \n    // Setting animation variables here.\n    bt  = floor(.5+2.*iTime*12.1/6.);\n    anim8 = smoothstep(190.,193.,iTime);\n    anim1 = smoothstep(30.,32.,iTime)-anim8;\n    anim2 = smoothstep(0.,9.,iTime)-smoothstep(200.,215.,iTime);\n    anim3 = smoothstep(63.,65.,iTime)-anim8;\n    anim7 = smoothstep(124.,127.85,iTime)-anim8;\n    anim4 = smoothstep(80.,82.,iTime)-anim7-anim8;\n    anim6 = pow(smoothstep(90.,94.,iTime),9.0)-anim8;\n    \n    // NOTE: the original constant here was 54531.2322578. I modified it slightly to make the behavior a bit more like\n    // the original intro. This is a really bad fix though, since you shouldn't rely on random camera cuts seeded from\n    // a really poor hash like this. Driver updates can and will break things.\n    // Lesson learned...\n    anim5 = step(.5+pow(anim8,.5),step(95.,iTime)*round(fract(sin(floor(bt/2.))*54535.2322578)));\n    bounding = mat3(vec3(mix(1.0,mod(bt/4.,4.0),anim3), 50.+20.*anim1, 1.5-0.5*anim4), vec3(0,2.-2.*anim4,0), (2.-anim4)*vec3(4,2,4));\n    \n    bt = mix(bt,floor(2.+4.*iTime*12.1/6.),anim5);\n    float A = mix(0.,60.,anim5);\n    float B = 9.-8.*anim5*anim7;\n    float C = 1.+anim7*(1.-anim5);\n    cubes = mat3[8](\n        mat3(vec3(1,A+99.*(1.-anim5)*anim6*pow(fract(sin(911.*floor(4.*iTime*12.1/6.))),99.),B*min(B,A+anim7*.2)), vec3(-1,-1,-1),C*vec3(0.5+0.5*fract(sin(900.*floor(9.+step(1.,anim1)*bt/.13))))),\n        mat3(vec3(1,A+99.*(1.-anim5)*anim6*pow(fract(sin(922.*floor(4.*iTime*12.1/6.))),99.),B*min(B,A+anim7*.2)), vec3( 1,-1,-1),C*vec3(0.5+0.5*fract(sin(901.*floor(9.+step(1.,anim1)*bt/.13))))),\n        mat3(vec3(1,A+99.*(1.-anim5)*anim6*pow(fract(sin(933.*floor(4.*iTime*12.1/6.))),99.),B*min(B,A+anim7*.2)), vec3(-1, 1,-1),C*vec3(0.5+0.5*fract(sin(902.*floor(9.+step(1.,anim1)*bt/.13))))),\n        mat3(vec3(1,A+99.*(1.-anim5)*anim6*pow(fract(sin(944.*floor(4.*iTime*12.1/6.))),99.),B*min(B,A+anim7*.2)), vec3(-1,-1, 1),C*vec3(0.5+0.5*fract(sin(903.*floor(9.+step(1.,anim1)*bt/.13))))),\n        mat3(vec3(1,A+99.*(1.-anim5)*anim6*pow(fract(sin(955.*floor(4.*iTime*12.1/6.))),99.),B*min(B,A+anim7*.2)), vec3( 1, 1,-1),C*vec3(0.5+0.5*fract(sin(904.*floor(9.+step(1.,anim1)*bt/.13))))),\n        mat3(vec3(1,A+99.*(1.-anim5)*anim6*pow(fract(sin(966.*floor(4.*iTime*12.1/6.))),99.),B*min(B,A+anim7*.2)), vec3( 1,-1, 1),C*vec3(0.5+0.5*fract(sin(905.*floor(9.+step(1.,anim1)*bt/.13))))),\n        mat3(vec3(1,A+99.*(1.-anim5)*anim6*pow(fract(sin(977.*floor(4.*iTime*12.1/6.))),99.),B*min(B,A+anim7*.2)), vec3(-1, 1, 1),C*vec3(0.5+0.5*fract(sin(906.*floor(9.+step(1.,anim1)*bt/.13))))),\n        mat3(vec3(1,A+99.*(1.-anim5)*anim6*pow(fract(sin(988.*floor(4.*iTime*12.1/6.))),99.),B*min(B,A+anim7*.2)), vec3( 1, 1, 1),C*vec3(0.5+0.5*fract(sin(907.*floor(9.+step(1.,anim1)*bt/.13)))))\n    );\n    float camanim = sqrt(anim7)*(1.-anim5);\n    float focushift = anim1*pow(((0.5+0.5*sin(iTime))*(0.5+0.5*sin(iTime*1.29))*(0.5+0.5*sin(iTime*1.63))),6.)/280.;\n    seed = (uv.x + uv.y * 1.43121412313 + fract(1.2345314312*iTime))*9.;\n    for(int s = 0; s < 125; s++){\n        tt = iTime + 0.042*(-0.5+hash());\n\n        float offset = mix(0.5,0.065*clamp(-cos(tt*1.3),-0.5,0.5)-1.3*clamp(sin(tt*0.9),-0.5,0.5),anim5);\n\n        vec3 ropos = mix(vec3(sin(tt*(0.21+.5*step(1.,anim7))),(0.4+0.3*cos(tt*(0.13+.5*step(1.,anim7)))),-cos(tt*(0.39+.5*step(1.,anim7)))),\n                         vec3(sin(tt*1.21),cos(tt*1.13),-cos(tt*1.39)),\n                         anim5);\n        ropos = mix(ropos, vec3(-1,.5,1), smoothstep(198., 203., iTime));\n        vec3 ro = mix(ropos, normalize(ropos),1.0-0.5*anim5+0.2*anim7)*140.0*mix(1.,0.1,camanim);\n        vec3 ww = normalize(vec3(0,-0.2+offset,0)-ro);\n        vec3 uu = normalize(cross(normalize(mix(vec3(0,1,0),vec3(.1,1,.1),anim1) ),ww));\n        vec3 vv = normalize(cross(ww,uu));\n        vec2 rand = vec2(hash(),hash()), p = -1.0 + 2.0 * (uv + 1.0*(-1.0+2.0*rand)/vec2(1280,720));\n        p.x *= 1.77;\n        vec2 lens_sample = vec2(cos(rand.x*pi*2.0),sin(rand.x*pi*2.0))*sqrt(rand.y);\n        vec3 lens_pos = ro + (lens_sample.x*uu + lens_sample.y*vv) * mix(4.5+anim4-4.2*anim7,0.25,anim5);\n        float d = mix(139.+20.*anim7,distance(ro, vec3(0)),anim5);\n        fragColor.rgb += render(lens_pos, normalize(ro+(p.x*uu + p.y*vv + mix(1.,0.07,camanim)*sqrt(0.5+0.5*anim2)*32.0*ww)*(0.0311+focushift)*d-lens_pos),p);\n    }\n    fragColor.rgb = pow(mix(vec3(1),smoothstep(-0.03, .9+anim2*.2, tonemap(mix(fragColor.rgb,vec3(length(fragColor.rgb)),anim7)/166.)), anim2), vec3(0.4545));\n}   \n","name":"Buffer B","description":"","type":"buffer"}]}
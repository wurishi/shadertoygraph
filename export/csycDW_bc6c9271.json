{"ver":"0.1","info":{"id":"csycDW","date":"1696093237","viewed":62,"name":"InteractiveMandelbrot Dementia  ","username":"shaderwho","description":"The shader calculates the audio amplitude from the provided song and uses it to modulate various effects and parameters, such as zoom, sensitivity, color complexity, and more. Audio made by me as well to go with the project.","likes":0,"published":1,"flags":64,"usePreview":0,"tags":["mandelbrot"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"ldd3D7","filepath":"https://soundcloud.com/who-625920136/fractured-eternity-across-all-boundaries","previewfilepath":"https://soundcloud.com/who-625920136/fractured-eternity-across-all-boundaries","type":"musicstream","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":0}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"vec3 lightPos = vec3(2.0, 2.0, 1.0); \nvec3 lightColor = vec3(1.1, 1.0, 1.0);\nfloat ambientStrength = 1.0;\nfloat specularStrength = 0.5; \nfloat shininess = 32.0; \n\n\nvec3 phongLighting(vec3 color, vec3 normal, vec3 fragPos, vec3 viewPos) {\n    vec3 ambient = ambientStrength * color;\n    vec3 lightDir = normalize(lightPos - fragPos);\n    float diff = max(dot(normal, lightDir), 0.0);\n    vec3 diffuse = diff * color;\n    vec3 viewDir = normalize(viewPos - fragPos);\n    vec3 reflectDir = reflect(-lightDir, normal);\n    float spec = pow(max(dot(viewDir, reflectDir), 0.0), shininess);\n    vec3 specular = specularStrength * spec * lightColor;\n    return ambient + diffuse + specular;\n}\n\nvec3 computeNormal(vec2 c) {\n    const float eps = 0.0001;\n    float base = length(vec2(c.x*c.x - c.y*c.y + c.x, 2.0 * c.x * c.y + c.y));\n    float dx = length(vec2(c.x+eps*c.x*c.x - c.y*c.y + c.x, 2.0 * (c.x+eps) * c.y + c.y));\n    float dy = length(vec2(c.x*c.x - (c.y+eps)*c.y + c.x, 2.0 * c.x * (c.y+eps) + c.y));\n    return normalize(vec3(dx - base, dy - base, eps));\n}\nvec3 adjustSaturation(vec3 color, float adjustment) {\n    float grey = dot(color, vec3(.599, 0.587, 0.014));\n    return mix(vec3(grey), color, adjustment);\n}\n\nvec3 butterflyEffect(vec3 color, float scaledN, vec2 uv, float time, float audioAmplitude) {\n    uv = abs(uv);\n    float banding = fract(scaledN * (1.0 + audioAmplitude) + sin(uv.x * (11.0 + audioAmplitude) + time) * 2.0);\n    color = mix(color, vec3(2.6 + audioAmplitude, 0.1, 1.2 - audioAmplitude), banding); // Modified color based on audioAmplitude\n    return color;\n}\nvec3 getColor(vec2 uv, vec2 center, float zoom, int numSamples, float time, float audioAmplitude) { // audioAmplitude parameter\n    vec2 c = center + uv / zoom;\n    vec2 z = c;\n    int n = 0; \n    float colorTransitionSpeed = 0.0001; \n\n    int maxIter = int(235.0 + 65.0 * sin(time * 1.14 / 6.0)); \n\n    for(int i = 1; i < maxIter; i++) { \n        if(dot(z, z) > 50.0) break;\n        z = vec2(z.x * z.x - z.y * z.y, 2.0 * z.x * z.y) + c + vec2(.0, -1.0);\n        n++;\n    }\n\n    float scaledN = float(n) * .15 + sin(time * colorTransitionSpeed) * 10.1; \n    \n    if(float(n) < float(maxIter)) {\n        float nu = log(log(length(z))) / log(15.0); \n        scaledN = scaledN + -3.1 - 3.9 * nu;\n        float angle = atan(z.y, z.x);\n\n        float intricatePattern = sin(angle * 2.0 + cos(scaledN * 4.0 + time * 2.0) * 9.0 + time * 13.0) * 10.5 + 10.5;\n\n        float rippleEffect = sin(scaledN * 3.0 + angle * 6.0 + time * .01 + cos(angle * 29.0 + scaledN * 2.0 + audioAmplitude * -11230.0) * .005 + intricatePattern * 1.0) * 0.9 + 0.6; // Modified to include audioAmplitude\n\n        float colorComplexity = sin(angle * 1.0 + time * 2.0) * cos(scaledN * 2.0 + time) * 0.5 + 0.5;\n        vec3 baseColor = vec3(\n        fract(sin(scaledN * colorComplexity + audioAmplitude) * 43758.5453), // Modified with audioAmplitude\n        fract(cos(scaledN * colorComplexity + audioAmplitude) * 12345.6789), // Modified with audioAmplitude\n        fract(sin(scaledN * colorComplexity + audioAmplitude) * 78901.2345)  // Modified with audioAmplitude\n    );\n        vec3 color = mix(baseColor, vec3(0.2, 0.1, 0.0), rippleEffect * intricatePattern) * (1.0 + sin(intricatePattern * 20.0) * 0.05);\n        \n        color = butterflyEffect(color, scaledN, uv, time, audioAmplitude); // Modified to include audioAmplitude\n\n        float fragmentedEffect = fract(sin(dot(uv * (rippleEffect + audioAmplitude * 0.1), vec2(12.9898, 78.233))) * 43758.5453); // Modified to include audioAmplitude\n        float whitePointsEffect = step(0.995 - audioAmplitude * 0.005, fragmentedEffect) * (1.0 + sin(intricatePattern * 20.0) * 10.05); // Modified to include audioAmplitude\n\n        color = mix(color, vec3(.5, 0.5, 0.6), whitePointsEffect);\n\n        float saturationAdjustment = sin(time * 1.5 + scaledN) * 0.3 + 0.0;\n        color = adjustSaturation(color, saturationAdjustment);\n\n        return color;\n    } else {\n        return vec3(0.0, 0.0, 0.0);\n    }\n}\n\nvec3 getSuperSampledColor(vec2 uv, vec2 center, float zoom, int numSamples, float time, float audioAmplitude) { \n    const int superSamples = 2; \n    float brightness = mix(-19.0, -9.9, audioAmplitude); // Mix between -19.0 and -9.9 based on audioAmplitude\n    vec3 color = vec3(brightness); // this controls the brightness\n    for(int i = -superSamples; i <= superSamples; i++) {\n        for(int j = -superSamples; j <= superSamples; j++) {\n            vec2 offset = vec2(float(i) / float(superSamples), float(j) / float(superSamples)) / iResolution.xy;\n            color += getColor(uv + offset, center, zoom, numSamples, time, audioAmplitude); \n        }\n    }\n    color /= float((2 * superSamples + 1) * (2 * superSamples + 1));\n    return color;\n}\n\nvec3 getReflection(vec2 uv, vec2 center, float zoom, int numSamples, float time, float audioAmplitude) { // Added audioAmplitude parameter\n    vec3 reflectedColor = vec3(0.0);\n    float offset = .06; // \n    reflectedColor += getColor(uv + vec2(offset, 0.0), center, zoom, numSamples, time, audioAmplitude); // Modified to include audioAmplitude\n    reflectedColor += getColor(uv + vec2(-offset, 0.0), center, zoom, numSamples, time, audioAmplitude);\n    reflectedColor += getColor(uv + vec2(0.0, offset), center, zoom, numSamples, time, audioAmplitude);\n    reflectedColor += getColor(uv + vec2(0.0, -offset), center, zoom, numSamples, time, audioAmplitude);\n    reflectedColor /= 1100.0; \n    return reflectedColor;\n}\nfloat getAudioAmplitude() {\n    float amplitude = -200.0;\n    const int numSamples = 250; // Number of samples to take from the audio\n    for(int i = -222; i < numSamples; i++) {\n        float audioSample = texture(iChannel0, vec2(float(i) / float(numSamples), 1230.5)).r; \n        amplitude += abs(audioSample); \n    }\n    return amplitude / float(numSamples);\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    vec2 resolution = iResolution.xy;\n    float time = iTime; \n    \n    float audioAmplitude = getAudioAmplitude();\n\n    float startZoom = 0.00000001; \n    float endZoom = 90000.0;\n    float zoomInDuration = 22.0;\n    float zoomOutDuration = zoomInDuration * 16.0;\n    float totalDuration = zoomInDuration + zoomOutDuration;\n    float normalizedTime = mod(time, totalDuration) / totalDuration;\n    float elapsed = normalizedTime < (zoomInDuration / totalDuration) ? normalizedTime * (totalDuration / zoomInDuration) : 1.0 - ((normalizedTime - (zoomInDuration / totalDuration)) * (totalDuration / zoomOutDuration));\n    \n    float z = time; \n    float zoom = startZoom * pow(endZoom / startZoom, elapsed) * z;  \n    vec2 center = vec2(0.109754, 0.362283);\n    float sensitivity = 41.0;\n    \n    // Adjust the shader parameters based on the amplitude\n    float adjustedZoom = zoom * (1.0 + audioAmplitude);\n    float adjustedSensitivity = sensitivity * (10.0 + audioAmplitude);\n    int adjustedNumSamples = int(mix(1.0, 1.5 + audioAmplitude * 122.0, smoothstep(11.0, 1.5, elapsed)));\n    \n    if(iMouse.z > 0.0) {\n        vec2 mouseDelta = (iMouse.xy - resolution * 0.5);\n        center += adjustedSensitivity * mouseDelta / (adjustedZoom * resolution.y); // Use adjustedSensitivity and adjustedZoom\n    }\n    \n    vec2 uv = (2.0 * fragCoord.xy - resolution) / min(resolution.y, resolution.x);\n    float frequency = 1.7 * (.1 + audioAmplitude); // Modified to include audioAmplitude\n    float amplitude = 0.09 * (.1 + audioAmplitude); // Modified to include audioAmplitude\n    float speed = .59 * (.1 + audioAmplitude); // Modified to include audioAmplitude\n    \n    uv.y += sin(uv.x * frequency + time * speed) * amplitude;\n    float angle = time * 0.09;\n    float s = sin(angle);\n    float c = cos(angle);\n    uv = vec2(c * uv.x - s * uv.y, s * uv.x + c * uv.y);\n    \n    vec3 color = vec3(0.0);\n    int numSamples = int(mix(1.0, 1.5, smoothstep(1.0, 1.5, elapsed))); \n    for(int i = -numSamples; i <= numSamples; i++) {\n        float offset = float(i) * mix(.0001, .0023, audioAmplitude); // audioAmplitude should be in the range [0, 1]\n        vec2 sampleUv = uv + offset * (uv - center);\n        color += getSuperSampledColor(sampleUv, center, zoom, numSamples, time, audioAmplitude); // Modified to include audioAmplitude\n    }\n\n\n    color /= float(2 * numSamples + 1);\n    vec3 fragPos = vec3(fragCoord.xy, 1.0);\n    vec3 viewPos = vec3(.0, 300.0, 21.0); \n    vec3 normal = computeNormal(center + uv / zoom); \n\n    vec3 reflection = getReflection(uv, center, zoom, numSamples, time, audioAmplitude); // Modified to include audioAmplitude\n    vec3 finalColor = mix(color, reflection, .0); \n\n    vec3 lightingColor = phongLighting(finalColor, normal, fragPos, viewPos);\n    fragColor = vec4(lightingColor, 1.0);\n}","name":"Image","description":"","type":"image"}]}
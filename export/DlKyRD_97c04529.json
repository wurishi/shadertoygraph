{"ver":"0.1","info":{"id":"DlKyRD","date":"1699998536","viewed":26,"name":"Random Distribution Testing 2D","username":"chronos","description":"Simple test of the distributions of hash or prng functions.\nBe careful to make sure the samples changes for each frame, and for each step and subsample pass, but does not vary per pixel!","likes":1,"published":1,"flags":32,"usePreview":0,"tags":["test","testing","random","normal","box","gaussian","limit","distribution","boxmuller","central","theorem","probability","muller"],"hasliked":0,"parentid":"DtGyz1","parentname":"Random Distribution Testing"},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n\nThis shader:\n\n2D variant of the previous shader. Uses the Box-Muller transform.\n\n-----------------------------------------------------------------\n\nForked shader description:\n\nSimple test of the distributions of hash or prng functions.\n\nMade this just for my own use, since I haven't made one like this before (... that I can remember :) )\nI'm sure there are hundreds of better ones on this site :P\n\nMade it mainly to quickly test approximate uniformity of hash functions that I may make ( or \"borrow\" ) in the future.\n\nAlso wanted to test the viability of sampling gaussians via adding uniform distributions together after reading\n(most of) this post:\nhttps://medium.com/mti-technology/how-to-generate-gaussian-samples-1cbf46b49751\n\nThis was pretty quicly hacked together. Use at own risk!\n\n-----------------------------------------------------------------\n\n// See Buffer A\n\n*/\n\nfloat sRGBencode(float C_linear)\n{\n    return C_linear > 0.0031308 ? (1.055 * pow(C_linear, 1./2.4) - 0.055) : (12.92 * C_linear);\n}\n\nvec3 sRGBencode(vec3 C_linear)\n{\n    return vec3(sRGBencode(C_linear.x), sRGBencode(C_linear.y), sRGBencode(C_linear.z));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    vec3 color = texture(iChannel0, uv).rgb;\n    \n    // Optional tone-mapping, since the values can get higher than 1 for certain distribution parameters\n    // In theory this may mess up the comparison a bit, since tanh isn't linear, so the brightness\n    // from two pixels at 50% each fed through a tanh would not have the same brightness as\n    // Two pixels at 0% and 100% each fed through a tanh:\n    // {tanh(.5) + tanh(.5)) , (tanh(0) + tanh(1)} = {0.924234, 0.761594}\n    #if 0\n    color = tanh(color);\n    #endif\n    \n    // This is one of the cases where you should clearly be able to see the difference between\n    // a simple gamma 2.2 encode curve and the actual sRGB encoding function.\n    // It should be most prominent in the outermost part of the gaussian in the very dark grays.\n    // gamma 2.2 curve encoding makes it brighter than it should be.\n    #if 1\n    color = sRGBencode(color);\n    #else\n    color = pow(color, vec3(1./2.2));\n    #endif\n    \n    fragColor = vec4(color, 1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"const float PI = 3.14159265;\n\n// Just yanked this from one of my previous shaders.\n// Idk how I came up with this. I think it may just be repeated xorshift star or PCG hash that I repeated three times,\n// to incorporate all the channels, where the bits are just shoved into the mantissa of a float at the end.\nfloat hash(vec3 uv)\n{\n    uint x = floatBitsToUint(uv.x) | 1u; // 0 is a fixed point so we remove it. although this introduces duplicate 1\n    uint y = floatBitsToUint(uv.y);\n    uint z = floatBitsToUint(uv.z);\n    \n    y ^= y >> 13;\n    y ^= y << 17;\n    y ^= y >> 5;\n    y *= 0x2545F491u;\n\n    x ^= y;\n    x ^= x >> 13;\n    x ^= x << 17;\n    x ^= x >> 5;\n    x *= 0x4F6CDD1Du;\n    \n    z ^= x;\n    z ^= z >> 13;\n    z ^= z << 17;\n    z ^= z >> 5;\n    z *= 0x1D6C45F4u;\n    \n    // Shift down by 9 to use top 23 bits in mantissa\n    // Use exponent and sign bits from 0.5\n    // floatBitsToUint(.5) is a constant so that part can be pre-computed. (0x3f000000)\n    // Since the top 23 bits are shifted right, the rest (top bits) are zero and do not need to be masked out\n    // uint w = ((z>>9) & 0x007FFFFFu) | (0xFF800000u & floatBitsToUint(.5));\n    \n    uint w = (z>>9) | 0x3f000000u; // simplified version of the above commented out line\n    \n    // re-normalize from [0.5, 1) to [0, 1)\n    // This probably loses some bits, but should still be ok\n    return 2. * uintBitsToFloat(w) - 1.;\n}\n\n\nfloat normal_dist(vec2 x, vec2 mean, float variance)\n{\n    return exp(-.5 * dot(x-mean, x-mean)/variance) / sqrt(pow(variance * 2. * PI, 2.));\n}\n\nfloat normal_dist(vec2 x, vec2 mean, mat2 covariance)\n{\n    return exp(-.5 * dot(x-mean,inverse(covariance)*(x-mean))) / sqrt(determinant(covariance) * pow(2. * PI, 2.));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = (2.*fragCoord-iResolution.xy)/iResolution.y;\n    vec2 mouse = (2.*iMouse.xy-iResolution.xy)/iResolution.y;\n    \n    if(length(iMouse.xy) < 10.)\n        mouse = vec2(sin(iTime), 0);\n    \n    // Just to bucket values in each pixel\n    vec2 uv_lower = (2. * floor(fragCoord) - iResolution.xy) / iResolution.y;\n    vec2 uv_upper = (2. *  ceil(fragCoord) - iResolution.xy) / iResolution.y;\n\n    vec3 color = vec3(0);\n\n    float count = texelFetch(iChannel0, ivec2(fragCoord), 0).a;\n    // Or could do: count = texelFetch(iChannel0, ivec2(fragCoord.x, 0), 0).a;\n    \n    // I didn't implement reset yet. feel free to drop a code snippet in the comments, and I'll add it :)\n    int reset_frame = 0;\n    if (iFrame == reset_frame)\n        count = 0.;\n    \n    int samples_per_frame = 500;\n    int steps_per_sample = 10;\n    \n    // Target variance for the distribution\n    //float variance = 1./PI;\n    vec2 mean = vec2(0, 0);\n    \n    float angle = PI / 8.;\n    mat2 Rotate = mat2(cos(angle), sin(angle), -sin(angle), cos(angle));\n    mat2 Scale  = mat2(.5/PI, 0, 0, 1./PI);\n    \n    mat2 RS = Rotate * Scale;\n    \n    mat2 covariance = RS * transpose(RS);\n    \n    for(int i = 0; i < samples_per_frame; i++)\n    {\n        vec2 smp = vec2(0); // sample \n        \n        #if 0\n        \n        // Using Central Limit Theorem method, i.e just add together a bunch of samples from another continuous distribution.\n        // In this case just a uniform distribution\n        \n        for(int j = 0; j < steps_per_sample; j++)\n        {\n            // subtracting 1/5 gives zero mean, but does not change variance\n            // If we did not do this we would have to subtract a different mean later to rescale\n            // e.g n/2 for [0,1]\n            \n            smp += -.5 + \n            vec2(\n                hash(vec3(2.*float(j), float(i), iFrame)),\n                hash(vec3(2.*float(j) + 1., float(i), iFrame))\n                );\n        }\n        \n        // Rescale gaussian to N(0, 1), i.e zero mean, unit variance\n        // Using mean and variance from https://en.wikipedia.org/wiki/Continuous_uniform_distribution#Moments\n        \n        float uniform_variance = float(steps_per_sample)/12.;\n        smp = (smp - mean)/sqrt(uniform_variance);\n        \n        #else\n        \n        // Using Box-Muller transform\n        float U0 = hash(vec3(0., float(i), iFrame));\n        float U1 = hash(vec3(1., float(i), iFrame));\n        smp = sqrt(\n            -2. * log(U0)\n        ) * vec2(cos(2. * PI * U1), sin(2.*PI*U1));\n        \n        #endif\n        \n        // Rescale normal gaussian to some other mean / variance:\n        \n        smp = RS * smp + mean;\n        \n        // Put the sample in its bucket\n        if(\n            uv_lower.x <= smp.x\n            &&\n            smp.x < uv_upper.x\n            &&\n            uv_lower.y <= smp.y\n            &&\n            smp.y < uv_upper.y\n            )\n        {\n            count += 1.;\n        }\n    }\n    \n    \n    // Normalize to average number of samples per frame scaled by screen area.\n    \n    // I didn't think this so much through, so be warned that it could be bogus. Looks correct though :)\n    // These are multiplied together to compute the area of the screen in UV coordinates\n    float width  = 2. * iResolution.x/iResolution.y;\n    float height = 2.;\n    \n    float screen_area = (iResolution.x / width) * (iResolution.y / height);\n    float total_sample_count = float((iFrame+1-reset_frame) * samples_per_frame);\n    \n    color.rgb += screen_area * count / total_sample_count;\n\n    float pix_size = 2./iResolution.y; // Size of a pixel in centered UV coordinates\n    \n    // Draw target distribution:\n    float g = normal_dist(uv, mean, covariance);\n    \n    if(uv.x > mouse.x)\n        color = vec3(g);\n        \n    // Draw a vertical black seperator line\n    color = mix(color, vec3(0), smoothstep(2. * pix_size, pix_size, abs(uv.x - mouse.x)));\n\n    fragColor = vec4(color, count);\n}","name":"Buffer A","description":"","type":"buffer"}]}
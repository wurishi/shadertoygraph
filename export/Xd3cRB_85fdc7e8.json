{"ver":"0.1","info":{"id":"Xd3cRB","date":"1519289993","viewed":771,"name":"Plane Parallax Disparity II","username":"KylBlz","description":"Follow up on https://www.shadertoy.com/view/Md3cWM\nThis is a better example of the application of this algorithm. Used OpenCV to calculate my matrices for me.","likes":5,"published":3,"flags":32,"usePreview":0,"tags":["parallax","stereo","motion","structure","disparity"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n\nPlane Parallax Disparity\n\nThis buffer just draws the animations and labels\n\nThe goal here is to do 3D reconstruction with AR markers.\nAfter two keyframes are registered to a common plane (the marker) using a perspective\ntransform what remains is a shear effect along the epipoles of the essential matrix.\nMeasuring the disparity gives you dense signed distance from the marker plane!\n\n*/\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    float time = fract(iTime * .05) * 5.;\n    vec2 uv = fragCoord / iResolution.xy - vec2(cos(clamp(time, 0., 1.) * pi) * -.05 + .05, 0.),\n         uv2 = (vec3(uv, 1.) * inverse(perspectiveMat)).xy;\n    // view the stereo pair getting perspective transformed\n    if (time < 1.) fragColor = mix(textureLod(iChannel0, mix(uv, uv2, cos(time * pi) * -.5 + .5), 0.), textureLod(iChannel1, uv, 0.), .5) + (.25 - .25 * cos(clamp(uv.y + time, 1., 1.5) * pi4)) * float(int(fragCoord.y) % 10 == 0);\n\t// fade to parallax disparity\n    else if (time < 2.) fragColor = mix(mix(textureLod(iChannel0, uv2, 0.), textureLod(iChannel1, uv, 0.), .5), spectrum(textureLod(iChannel2, uv, 0.).r), cos(time * pi) * .5 + .5);\n\t// fade to depth\n    else if (time < 3.) fragColor = mix(spectrum(textureLod(iChannel2, uv, 0.).r), textureLod(iChannel3, uv, 0.), cos(time * pi) * -.5 + .5);\n    // just view depth for a bit\n    else\n        fragColor = textureLod(iChannel3, uv, 0.);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"// rendering tools and constants\n#define GAMMA\t\t.6\n#define EXPOSURE\t.5\n\n// Reflect, Transmit, Emit rgb wavelengths, Surface scatter, sUbsurface scatter, Refractive index, Emission Uniformity, unique iDentifier\nstruct mat { vec3 r, t, e; float s, u, f, eu; int d; };\n// 1D line segment with signed IDs for each end point\nstruct seg { vec2 t; ivec2 d; };\n// Location, Normal, Distance, Object id, current Material\nstruct hit { vec3 l, n; seg s; int o, m; };\n// Location, Normal, Distance, Object id\nstruct sdf { float d; int o; };\n// Origin, Direction, Color, current Material\nstruct ray { vec3 o, d, c; mat m; };\n// center Location, Radius, Material, iDentifier\nstruct sph { vec3 l; float r; int m, d; };\n// Location, Normal, size, Material, iDentifier\nstruct pln { vec3 l; mat3 o; int m, d; };\n// Center, Size, Orientation, Material, iDentifier\nstruct box { vec3 c, s; mat3 o; int m, d; };\n\n// Some shortcuts\n#define v20 vec2(0.)\n#define v21 vec2(1.)\n#define v30 vec3(0.)\n#define v31 vec3(1.)\n#define v40 vec4(0.)\n#define v41 vec4(1.)\n#define vec3max(a) max(a.x, max(a.y, a.z))\n#define vec3min(a) min(a.x, min(a.y, a.z))\n#define vec4max(a) max(max(a.x, a.y), max(a.z, a.w))\n#define vec4min(a) min(min(a.x, a.y), min(a.z, a.w))\n#define inRange(a,x,b) step(a,x)*step(x,b)\n#define tex(a,b) textureLod(a,b,0.)\n#define texComp(a,b,c) vec4max((tex(a, b) * c))\n\nconst float\tsml = .001, isml = .999, zfar = 50.,\n\t\t\tpi_rcp = .3183098, pi2_rcp = .1591549, pi4_rcp = .0795775,\n    \t\tpi_5 = 1.5707963, pi = 3.1415926, pi2 = 6.2831853, pi4 = 12.56637,\n\t\t\tsc45 = .7071067, s60 = .866025, sqrt2 = 1.4142135, sqrt3 = 1.732050808;\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nconst float eps = .00001525878,\n           ieps = .99998474122,\n           reps = 65535.;\n#else\nconst float eps = .00390625,\n           ieps = .99609375,\n           reps = 255.;\n#endif\n\nconst mat nullMat = mat(v30, v31, v30, 0., 0., 0., 0., -1);\nconst seg nullSeg = seg(vec2(zfar), ivec2(0));\nconst hit nullHit = hit(v30, v30, nullSeg, 0, -1);\nconst sdf nullSdf = sdf(zfar, -1);\nconst vec2 nullT = vec2(zfar, 0.);\n// transforms gound plane on image 1 to image 2 calculated with opencv\nmat3 perspectiveMat = mat3(\n    .977339, .927661, -.456725,\n    .0,      .970588,  .012812,\n    .0,     -.038336, 1.\n);\n\n////////////////////////////////// Text rendering thanks to Fabrice //////////////////////////////////\n#define tex(a,b) textureLod(a,b,0.)\n#define C(c) U.x-=.425; T+= U.x<.0||U.x>1.||U.y<0.||U.y>1. ?vec4(0): tex( iChannel, U/16. + fract( floor(vec2(c, 15.999-float(c/16))) / 16.))\n#define initMsg vec4 T = vec4(0)\n#define endMsg return length(T.yz)==0. ? 0. : T.x\n#define inRange(a,x,b) step(a,x)*step(x,b)\n\nfloat msg_stereo(sampler2D iChannel, vec2 U) { initMsg; C(83);C(116);C(101);C(114);C(101);C(111); endMsg; }\nfloat msg_parallax(sampler2D iChannel, vec2 U) { initMsg; C(80);C(97);C(114);C(97);C(108);C(108);C(97);C(120); endMsg; }\nfloat msg_depth(sampler2D iChannel, vec2 U) { initMsg; C(68);C(101);C(112);C(116);C(104); endMsg; }\nfloat msg_error(sampler2D iChannel, vec2 U) { initMsg; C(69);C(114);C(114);C(111);C(114); endMsg; }\n\n//////////////////////////////////////////// Materials //////////////////////////////////////////////\nconst int _air = 0, _mFeature = 1, _mPlane = 2;\nconst mat[] matLib = mat[] (\n    mat(vec3(.01), vec3(0.99), v30, .01, .01, 1.0003, 0., _air),\n    mat(v31, v30, v30, 0., 0., -1., 0., _mPlane),\n    mat(v31, v30, v30, 0., 0., -1., 0., _mFeature)\n);\n\n//////////////////////////////////////// Raytrace Primitives ////////////////////////////////////////\nconst int _box1 = 1, _box2 = 2, _sph1 = 3, _sph2 = 4;\nsph sph1 = sph(vec3(-2., 1., -3.), .5, _mFeature, _sph1),\n\tsph2 = sph(vec3( 2., 1., 3.), .5, _mFeature, _sph2);\nbox box1 = box(vec3(0., 0., 0.), vec3(3., .001, 3.), mat3(0.), _mPlane, _box1),\n    box2 = box(vec3(0., 2., 1.), vec3(.5, 2., .5), mat3(0.), _mFeature, _box2);\n\n////////////////////////////////////// Function Implementations /////////////////////////////////////\nvoid basis(in vec3 n, out vec3 f, out vec3 r) {\n    float a = 1. / (1. + n.z);\n    float b = -n.x*n.y*a;\n    f = vec3(1. - n.x*n.x*a, b, -n.x);\n    r = vec3(b, 1. - n.y*n.y*a, -n.y);\n}\nvec3 hash33(in vec3 p) {\n\tvec3 h = vec3(dot(p,vec3(47.127, 11.311, 51.521)),\n                  dot(p,vec3(7.101, 81.683, 83.331)),\n                  dot(p,vec3(63.331, 71.101, 13.127)));\n    return fract(sin(h)*47.281);\n}\n// input is normalized visible spectrum wavelength (0. = 400nm violet/uv, 1. = 700nm red/ir)\nvec4 spectrum(float _l) {\n    float t, l = _l *300.+400.;\n    float[] fr1 = float[] (400.,410.,545.,595.,650.,415.,475.,585.,400.,475.),\n\t\t\tfr2 = float[] (410.,475.,595.,650.,700.,475.,585.,639.,475.,560.),\n        \tdv1 = float[] (10., 65., 50., 55., 50., 60., 115.,54., 75., 85.);\n    vec3[] c = vec3[] (vec3(0.,.33,-.2),vec3(.14,0.,-.13),vec3(0.,1.98,-1.),\n        vec3(.98,.06,-.4),vec3(.65,-.84,.2),vec3(0.,0.,.8), vec3(.8,.76,-.8),\n        vec3(.84,-.84,0.),vec3(0.,2.2,-1.5),vec3(.7,-1.,.3));\n    vec3 r = vec3(0.);\n    for (int i=0; i < 5; i++) { t = (l-fr1[i])/dv1[i];\n        r.r += inRange(fr1[i],l,fr2[i])*(c[i].x + c[i].y*t + c[i].z*t*t); }\n    for (int i=5; i < 8; i++) { t = (l-fr1[i])/dv1[i];\n        r.g += inRange(fr1[i],l,fr2[i])*(c[i].x + c[i].y*t + c[i].z*t*t); }\n    for (int i=8; i < 10; i++) { t = (l-fr1[i])/dv1[i];\n        r.b += inRange(fr1[i],l,fr2[i])*(c[i].x + c[i].y*t + c[i].z*t*t); }\n    return vec4(r, 1.);\n}\n// Operators\n#define len(a) (a.t.y - a.t.x)\n#define valid(a) (a.t.y < zfar)\n#define minT(a) ((a.y<a.x)? zfar: (a.x<0.)? (a.y<0.)? zfar: a.y: a.x)\nvec2 lt(in seg s) {\n    if (s.t.x < s.t.y && s.t.x > 0.) return vec2(s.t.x, float(s.d.x));\n    else if (s.t.y > 0.) return vec2(s.t.y, float(s.d.y));\n    return nullT;\n}\nvoid lt(inout seg o, in seg s) {\n    if (minT(s.t) < minT(o.t)) o = s;\n}\nvoid lt(inout sdf l, in sdf r) {\n    if (r.d < l.d && r.d > 0.) l = r;\n}\nvoid lt(inout hit o, in hit h) {\n    if (minT(h.s.t) < minT(o.s.t)) o = h;\n}\n// Signed distance (thanks IQ)\nsdf sd(in vec3 l, in box b) {\n\tvec3 d = abs(l - b.c) - b.s;\n\treturn sdf(min(vec3max(d), 0.) + length(max(d, 0.)), b.d);\n}\nsdf sd(in vec3 l, in sph s) {\n    vec3 oc = l - s.l;\n    return sdf(dot(oc, oc) - s.r * s.r, s.d);\n}\nsdf sd(in vec3 l, in pln p) {\n    return sdf(dot(p.o[1], l - p.l), p.d);\n}\n// normal functions\nvec3 nrm(in vec3 l, in box b) {\n\tvec3 a = l - b.c;\n\treturn step(b.s*ieps, abs(a)) * sign(a);\n}\nvec3 nrm(in vec3 l, in sph s) {\n    return (l - s.l) / s.r;   \n}\nvec3 nrm(in vec3 l, in pln p) {\n    return p.o[1];\n}\n// surface UV map functions\nvec2 map(in vec3 l, in box b) {\n\tmat3 o = mat3(v30, nrm(l, b) + eps, v30);\n    basis(o[1], o[0], o[2]);\n    vec3 r = l * o;\n    return r.xz;\n}\nvec2 map(in vec3 l, in sph s) {\n    vec3 n = nrm(l, s);\n    return vec2(atan(n.z, n.x) + pi, acos(-n.y)) / vec2(pi2, pi);\n}\nvec2 map(in vec3 l, in pln p) {\n    return vec2(dot(l, p.o[0]), dot(l, p.o[2]));\n}\n// intersection Segment functions\nseg rs(in ray r, in box b) {\n    vec3 t0 = b.c - r.o,\n         t1 = (t0 - b.s)/r.d,\n         t2 = (t0 + b.s)/r.d;\n    float tn = vec3max(min(t1, t2)),\n          tx = vec3min(max(t1, t2));\n    if (tx<tn || tx<0.) return nullSeg;\n    return seg(vec2(tn, tx), ivec2(b.d, -b.d));\n}\nseg rs(in ray r, in sph s) {\n    vec3 oc = r.o - s.l;\n    float c = dot(oc, oc) - s.r * s.r,\n          b = -dot(oc, r.d), h = b*b - c;\n    if (h < 0.) return nullSeg;\n    h = sqrt(h);\n    return seg(vec2(b-h,b+h), ivec2(s.d, -s.d));\n}\nseg rs(in ray r, in pln p) {\n    float t = dot(p.o[1], p.l - r.o) / dot(p.o[1], r.d);\n\treturn seg(vec2(t, t + eps), ivec2(p.d, -p.d));\n}\n// Hit functions\n#define _trc seg s = rs(r, o); vec3 l = r.o + r.d * minT(s.t); hit h = hit(l, nrm(l, o), s, o.d, o.m)\nhit trace(in ray r, in box o) { _trc; return h; }\nhit trace(in ray r, in sph o) { _trc; return h; }\nhit trace(in ray r, in pln o) { _trc; return h; }\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"Xsf3zn","filepath":"/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"/media/ap/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":0,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// render keyframe 1\n\n// p1 325 266\n// p2 240 314\n// p3 718 314\n// p4 549 266\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 uv = fragCoord / iResolution.xy;\n    \n    // update scene\n    sph1.l.xz += vec2(cos(iTime) * .5, sin(iTime) + 1.);\n\tsph2.r += .25 * cos(iTime) + .25;\n    box2.s.x += sin(iTime) * .25;\n\n    // trace scene\n    ray r = ray(vec3(-1., 2., -8.), normalize(vec3(uv * 2. - 1., 1.)), v31, nullMat);\n    seg s = nullSeg;\n    lt(s, rs(r, box1));\n    lt(s, rs(r, box2));\n    lt(s, rs(r, sph1));\n    lt(s, rs(r, sph2));\n    \n    // give spacially unique texture where possible to represent a good feature descriptor\n    float d = minT(s.t);\n    vec3 l = r.d * d;\n    vec2 smp = vec2((l.x + r.o.x) * iResolution.x * .00015, step(-1.99, l.y));\n    if (d < zfar) fragColor = vec4(textureLod(iChannel0, smp + ceil(l.y*.1+.199) * .5, 0.).rgb, 1.);\n\t// no message on this channel\n    else fragColor = vec4(0.);\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"Xsf3zn","filepath":"/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"/media/ap/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":0,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGzr","filepath":"/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","previewfilepath":"/media/ap/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","type":"texture","channel":1,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// render keyframe 2\n\n// p1 250 266\n// p2 83 314\n// p3 559 314\n// p4 474 266\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 uv = fragCoord / iResolution.xy;\n\n    // update scene\n    sph1.l.xz += vec2(cos(iTime) * .5, sin(iTime) + 1.);\n\tsph2.r += .25 * cos(iTime) + .25;\n    box2.s.x += sin(iTime) * .25;\n    \n    // trace scene\n    ray r = ray(vec3( 1., 2., -8.), normalize(vec3(uv * 2. - 1., 1.)), v31, nullMat);\n    seg s = nullSeg;\n    lt(s, rs(r, box1));\n    lt(s, rs(r, box2));\n    lt(s, rs(r, sph1));\n    lt(s, rs(r, sph2));\n    \n    // give spacially unique texture where possible to represent a good feature descriptor\n    float d = minT(s.t);\n    vec3 l = r.d * d;\n    vec2 smp = vec2((l.x + r.o.x) * iResolution.x * .00015, step(-1.99, l.y));\n    if (d < zfar) fragColor = vec4(textureLod(iChannel0, smp + ceil(l.y*.1+.199) * .5, 0.).rgb, 1.);\n    // draw stereo message on just one so it translates in all cool\n    else fragColor = vec4(0., .4, .8, 1.) * vec4(msg_stereo(iChannel1, uv * 5.)) * 2.;\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4dXGzr","filepath":"/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","previewfilepath":"/media/ap/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","type":"texture","channel":2,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"\n// marches an image transformed to have horizontal epipolar lines to compute disparity; simple diff squared matcher\nfloat disparity(in sampler2D iChannel, in vec2 uv, in vec2 px, in vec3 targetFeat) {\n    int STEPS = int(iResolution.x * .333333);\n    vec2 smp = vec2(0.);\n    for (int i = 0; i < STEPS; ++i) {\n        vec3 curFeat = textureLod(iChannel, uv + smp, 0.).rgb - targetFeat;\n        // compare the squared difference\n        if (dot(curFeat, curFeat) < eps) return float(i);\n        smp += px;\n    }\n    // should have to do with delta transform between two frames instead of steps\n    return 0.;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 uv = fragCoord / iResolution.xy,\n         uv1 = (vec3(uv, 1.) * inverse(perspectiveMat)).xy,\n         px = vec2(1. / iResolution.x, 0.);\n    // the feature we are trying to match\n    vec3 f0 = textureLod(iChannel1, uv, 0.).rgb;\n    // if we have a feature\n    if (dot(f0, f0) > eps) {\n    \t// compute parallax disparity to get signed distance from image plane\n    \tfloat parallax = disparity(iChannel0, uv1, px, f0),\n        \t  // compute stereo disparity to estimate depth\n        \t  stereo = disparity(iChannel0, uv, px, f0),\n        \t  rSTEPS = 3. / iResolution.x;\n    \tfragColor = vec4(parallax, stereo, 0., 1.) * rSTEPS;\n\t}\n    // add message\n    fragColor += msg_parallax(iChannel2, uv * 5. + vec2(.4, 0.)) * .2;\n    \n}","name":"Buffer C","description":"","type":"buffer"},{"inputs":[{"id":"4dXGzr","filepath":"/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","previewfilepath":"/media/ap/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","type":"texture","channel":1,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XdfGR8","channel":0}],"code":"// calculate depth from stereo disparity\n// additional constraint of parallax (being signed distnace from registered plane)\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    vec2 uv = fragCoord / iResolution.xy,\n         disparity = textureLod(iChannel0, uv, 0.).rg;\n    vec3 camLoc = vec3( 1., 2., -8.),\n         rd = normalize(vec3(uv * 2. - 1., 1.)),\n         markerNorm = vec3(0.,1.,0.);\n    float time = fract(iTime * .05) * 5. + .5,\n          invNormTerm = iResolution.x * .333333,\n    \n    //DEPTH CALC: stereo depth\n    baseline = distance(camLoc, vec3(-1., 2., -8.)),\n    //focal length\n    focal = iResolution.x * (iResolution.y / iResolution.x) * .885,\n    //get the actual stereo disparity back, get depth to image plane instead of focal point with * rd.z\n    stereo = disparity.y * invNormTerm * rd.z,\n    //to depth if we have disparity\n    d = step(.2, uv.y) * step(eps, disparity.y) * (baseline * focal) / stereo,\n    \n    // hard coded for 800x450 sorry im lazy\n    para = disparity.x * invNormTerm;\n    \n    // add 'depth' message\n    if (time < 4.) fragColor = max(vec4(d  * .1 - .4),\n                                   vec4(0., .4, .8, 1.) * msg_depth(iChannel1, uv * 5. - vec2(.3, 0.)));\n    else {\n        // Calculate ground truth\n        sph1.l.xz += vec2(cos(iTime) * .5, sin(iTime) + 1.);\n        sph2.r += .25 * cos(iTime) + .25;\n        box2.s.x += sin(iTime) * .25;\n        ray r = ray(camLoc, rd, v31, nullMat);\n        seg s = nullSeg;\n        lt(s, rs(r, box1));\n    \tlt(s, rs(r, box2));\n        lt(s, rs(r, sph1));\n        lt(s, rs(r, sph2));\n        float groundTruthD = minT(s.t),\n              // convert from camera space to marker space to compare\n              groundTruthParallax = dot(markerNorm, (camLoc + rd * groundTruthD) - box1.c);\n        \n        // 5 times magnified difference between calculated depth 'd' and groundTruthD\n        if (uv.y > .2 && d > 0.) fragColor = mix(vec4(d  * .1 - .4),\n                                                 vec4(d - groundTruthD, 0., groundTruthD - d, 0.) * 5.,\n                                                 cos(time * pi * .9 + .9) * -.5 + .5);\n\t\t// add messages\n        fragColor = mix(max(fragColor, vec4(0., .4, .8, 1.) * msg_error(iChannel1, uv * 5. - vec2(.3, 0.))),\n                        max(fragColor, vec4(0., .4, .8, 1.) * msg_depth(iChannel1, uv * 5. - vec2(.3, 0.))),\n                        cos(time * pi * .9 + .9) * .5 + .5);\n    }\n}","name":"Buffer D","description":"","type":"buffer"}]}
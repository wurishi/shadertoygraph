{"ver":"0.1","info":{"id":"ltXyzM","date":"1504032912","viewed":990,"name":"reprojection AA","username":"Daedelus","description":"minimal implementation of temporal anti aliasing","likes":17,"published":1,"flags":32,"usePreview":0,"tags":["aliasingantialiasreprojectiontaatemporal"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = texelFetch(iChannel0, ivec2(fragCoord), 0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// #define IDLE_CAMERA // define to remove camera animation and reveal jitter on borders\n// #define WARP // define to mess up the tunnel\n#define ANIMATE // define to move the pillars\n\n/**\nReprojection AA\n\nFor a static scene/camera:\n\nrandomly jitter pixels over time so that each pixel in every frame has a slight offset (less than 1 pixel)\nblend over about 6 frames and you'll get smooth edges due to the jittering\n\n\nFor camera motion only:\n\ntrace a ray -> get intersection point\nuse previous camera position, rotation, fov to see at what pixel that point would've been if drawn by that camera\nsample previous frame at that position to get basically the same data and crossfade\n\n\nFor more moving shapes:\n\nShapes put out their motion vector in 3D so we can take that into account when reprojecting for the previous frame.\n\n\nTODO:\n- Problems arise for animating textures (leaving trails). Possibly need a texture space motion vector?\n- Currently outputting velocities for all the shapes, \nwhich is quite cumbersome, and becomes impossible if we are \n(for example) warping the distance field with an animated noise..\nWhat to do?\n\n\nI found it fairly difficult to find decent resources on this but I think this is how TAA should work...\nhttps://de45xmedrsdbp.cloudfront.net/Resources/files/TemporalAA_small-59732822.pdf\nhttps://hardforum.com/threads/looking-for-white-papers-on-temporal-anti-aliasing.774606/#post-1026279053\n**/\n\nstruct Camera\n{\n    vec3 translate;\n    vec3 rotate; // 3 angles in radians\n    float fov; // vertical FOV in radians\n};\n\nstruct Ray\n{\n    vec3 origin;\n    vec3 direction;\n};\n\n\nmat3 RotationMatrix(float x, float y, float z)\n{\n    /* Creates a matrix from euler angles in X Y Z order */\n\tfloat sx = sin(x);\n\tfloat sy = sin(y);\n\tfloat sz = sin(z);\n\tfloat cx = cos(x);\n\tfloat cy = cos(y);\n\tfloat cz = cos(z);\n    \n\treturn mat3((cz*cy + sz*sx*sy), sz*cx, (cz*-sy + sz*sx*cy),\n\t\t(-sz*cy + cz*sx*sy), cz*cx, (-sz*-sy + cz*sx*cy),\n\t\tcx*sy, -sx, cx*cy);\n}\n\nfloat halton(int i, int b)\n{\n    /* Creates a halton sequence of values between 0 and 1.\n\thttps://en.wikipedia.org/wiki/Halton_sequence\n\tUsed for jittering based on a constant set of 2D points. */\n    float f = 1.0;\n    float r = 0.0;\n    while(i > 0)\n    {\n        f = f / float(b);\n        r = r + f * float(i % b);\n        i = i / b;\n    }\n    return r;\n}\n\nvec2 Jitter(vec2 fragCoord, int frame)\n{\n    /* Get pixel offset for a given frame */\n    return (vec2(\n    \thalton(frame%8+int(fragCoord.x)%8+1,2),\n    \thalton(frame%8+int(fragCoord.y)%8+1,3)) - 0.5);\n}\n\nRay ScreenRay(vec2 view, Camera cam)\n{\n    /* Given a camera transform and a view-space coordinate \n\te.g. (fragCoord/resolution*2-1)*vec2(aspectRatio,1)\n\treturns a ray origin and direction */\n    return Ray(cam.translate, \n               normalize(RotationMatrix(cam.rotate.x, cam.rotate.y, cam.rotate.z) * \n                         vec3(view, 1.0 / tan(cam.fov)) ));\n}\n\nCamera Cam(float time)\n{\n    /* Returns the camera transform at a certain time. */\n    const float fov = 0.464;\n    #ifdef IDLE_CAMERA\n\treturn Camera(vec3(0.0), vec3(0.0), fov);\n    #else\n    if(fract(time*0.1)<0.5) time = -time; // alternate back and forth\n    return Camera(vec3(0.0, 0.0, time), \n                  vec3(0.0, sin(time) * 0.25, time * 0.125),\n                  fov);\n    #endif\n}\n\nvec2 UVFromViewSpace(vec2 view)\n{\n    /* Invert aspect corrected coordinate to uv coordinate */\n    view.x *= iResolution.y / iResolution.x;\n    return view * 0.5 + 0.5;\n}\n\nvec2 WorldToViewSpace(vec3 pos, Camera cam)\n{\n    /* Multiply the position by the view/projection matrix of the camera transform. \n\tThen does a perspective divide to result in a 2D view-space coordinate. */\n    vec3 local = (pos - cam.translate) * RotationMatrix(cam.rotate.x, cam.rotate.y, cam.rotate.z);\n    return local.xy / (local.z * tan(cam.fov));\n}\n\n// some utilities for the distance function\nvoid pR(inout vec2 p,float a){p=cos(a)*p+sin(a)*vec2(p.y,-p.x);}\nvec4 hash4(vec4 p4)\n{\n\tp4 = fract(p4 * vec4(1031, .1030, .0973, .1099));\n    p4 += dot(p4, p4.wzxy + 19.19);\n    return fract((p4.xxyz + p4.yzzw) * p4.zywx);\n}float hash1(vec4 p){return hash4(p).x;}\nfloat hash1(float p){return hash1(vec4(p));}\nfloat snoise(float x)\n{\n    float n = floor(x);\n    float f = fract(x);\n    f = f * f * (3.0 - 2.0 * f);\n    return mix(hash1(n), hash1(n + 1.0), f);\n}\n// end utils\n\nfloat Map(vec3 point, out vec3 motion)\n{\n\t/* Distance function */\n    #ifdef WARP\n    pR(point.xy, snoise(point.z * 0.25) * 4.0 + point.z * 0.125);\n    #endif\n    motion = vec3(0.0);\n    float result = 0.5 - abs(point.y);\n    #ifdef ANIMATE\n    point.z += iTime;\n    #endif\n   \tpoint.z = fract(point.z) - 0.5;\n    point.x = abs(point.x) - 1.0;\n    vec3 q = abs(point) - vec3(0.2, 0.5, 0.2);\n    float r = max(q.x, max(q.y, q.z));\n    if(r<result)\n    {\n        result=r;\n    \t#ifdef ANIMATE\n        motion.z = 1.0;\n    \t#endif\n    }\n    return result;\n}\nfloat Map(vec3 point){vec3 motion;return Map(point, motion);}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{   \n    // get jittered view coordinate\n    vec2 jitter = Jitter(fragCoord, int(iFrame));\n\tvec2 view = ((fragCoord.xy + jitter) * 2.0 - iResolution.xy) / iResolution.y;\n    \n    // get ray at current time\n    Ray ray = ScreenRay(view, Cam(iTime));\n    \n    /*\n\tray marching\n\t*/\n    vec3 intersection, motion;\n    float sampl, totalDistance = 0.1;\n    const float far = 12.0;\n    for(int i = 0 ; i < 100 ; ++i )\n    {\n        intersection = ray.origin + ray.direction * totalDistance;\n        sampl = Map(intersection, motion);\n        totalDistance += sampl;\n        if(sampl<0.0005||totalDistance>far)break;\n    }\n    \n    // determine foreground color\n    vec2 e = vec2(0.001, 0.0);\n    vec3 n=normalize(vec3(Map(intersection+e.xyy),Map(intersection+e.yxy),Map(intersection+e.yyx))-sampl);\n   \t\n    vec3 ip = floor(fract((intersection + motion * iTime)*2.0)*2.0);\n    vec3 an = abs(n);\n    vec3 cl;\n    if(an.y > an.x && an.y > an.z)\n\t\tcl = vec3((ip.x != ip.z));\n    else if(an.z > an.x)\n\t\tcl = vec3((ip.x != ip.y));\n    else\n\t\tcl = vec3((ip.y != ip.z));\n\t\n\t// determine background color and weight\n    float fog = clamp(totalDistance/far, 0.0, 1.0);\n    vec3 bg = vec3(1.0);\n    \n    /*\n\treprojection AA\n\t*/\n    // Convert intersection to the previous viewSpace (using camera at previous frame)\n    vec2 prevFragCoord = (((WorldToViewSpace(intersection + motion * iTimeDelta, Cam(iTime - iTimeDelta)) * iResolution.y) + iResolution.xy) * 0.5);\n    // why is using jitter instead of prev jitter more stable?\n    vec2 prevJitter = Jitter(prevFragCoord, int(iFrame-1));\n    prevFragCoord -= jitter;\n    vec2 prevUV = prevFragCoord / iResolution.xy;\n    // ignore samples that were not on-screen in the previous frame\n   \tvec2 _edge = abs(prevUV * 2.0 - 1.0);\n    float weight = smoothstep(0.99, 1.01, max(_edge.x, _edge.y));\n    vec4 prev = texture(iChannel0, prevUV);\n    // ignore samples that were from a closer object (e.g. this point was occluded in the previous frame)\n    if(prev.a < fog - fog * 0.05 - 0.001) // subtracing an arbitrary epsilon, larger over distance to reduce moire\n        weight = 1.0;\n    // ignore samples with luminance difference\n    cl = mix(cl,bg,fog);\n    float prevLuma = dot(prev.xyz, vec3(0.2126, 0.715, 0.0722));\n    float clLuma = dot(cl.xyz, vec3(0.2126, 0.715, 0.0722));\n    weight = min(weight + abs(clLuma - prevLuma) * 0.2, 1.0);\n    // mix prev frame and current frame\n    fragColor = mix(prev, vec4(cl, 1.0), mix(1.0 / 6.0, 1.0, weight));\n    fragColor.a = fog;\n}\n","name":"Buf A","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"3sVXWw","date":"1574179278","viewed":124,"name":"Dithery Test","username":"spalmer","description":"test of screen 2D noise function for dithering, supports zoom.\nmouse splitscreen shows the severe color banding that 8-bit buffer quantization would otherwise do to the image.\nApparently, blue noise is ideal for this purpose.","likes":2,"published":1,"flags":0,"usePreview":0,"tags":["noise","random","dithering"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGzn","filepath":"/media/a/0c7bf5fe9462d5bffbd11126e82908e39be3ce56220d900f633d58fb432e56f5.png","previewfilepath":"/media/ap/0c7bf5fe9462d5bffbd11126e82908e39be3ce56220d900f633d58fb432e56f5.png","type":"texture","channel":2,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"Xdf3zn","filepath":"/media/a/85a6d68622b36995ccb98a89bbb119edf167c914660e4450d313de049320005c.png","previewfilepath":"/media/ap/85a6d68622b36995ccb98a89bbb119edf167c914660e4450d313de049320005c.png","type":"texture","channel":0,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsBSR3","filepath":"/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","previewfilepath":"/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","type":"texture","channel":1,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// test of screen dithering strategies\n\n// I give up!  I don't care anymore, especially about temporal change.\n// All the ALU hashes I have tried just fail or look bad,\n// to the point where I am convinced the standard Bayer table\n// ordered dither produces superior results.\n// It's so much simpler (if you have the table handy)\n// that there's no point wasting futher time on it.\n\n// ok, seems 2d blue noise actually does work better than white\n\n// uses a novel local-contiguity-preserving oscillator\n// to eliminate visual popping when animated\n\n// makes an even-integer-frequency triangle wave; like fract but preserves g0 contiguity.\nfloat osctri(float x) \n{\n\tfloat i = floor(x); \n\tx -= i; // now mirror the odd ones to preserve local contiguity\n\tfloat o = mod(i, 2.); //step(1., mod(i, 2.)); //float(int(i) & 1); //\n    return o + x - 2.*o*x; // branchless, eval to either 0 + x - 2*0*x = x, or 1 + x - 2*1*x = 1 - x; one conversion\n}\n\n// I gave it another crack.  Turned out better, I guess, since was using mod intrinsic anyhow.\n// relies on CMOV though.\nfloat osctri2(float x)\n{\n//    x -= 20.; // DEBUG stress negative range a bit\n    x = mod(abs(x), 2.); // DO NOT trust mod intrinsic!!  various systems give different results for negative numbers\n    return x > 1. ? 2.-x : x; // could use step but every gpu now has select/conditional move\n}\n\n// a scaled version of smoothstep\n// = ((3 - 2*x)*x + 3)*x/4;\n// It looks like an almost-triangle-wave.  If you want to graph it in Graphmatica:\n// y = ((.75 - .5*x)*x + .75)*x { x : [0,1) } ; y = ((.75 - .5*(2-x))*(2-x) + .75)*(2-x) { x : [1,2) }\n// btw Horner reduction is *not* the most efficient way to evaluate these polynomials\nfloat bentstep(float x)\n{\n\treturn ((.75 - .5*x)*x + .75)*x;\n}\n\n// this oscrand function has a few important qualities:\n// it's locally g0 contiguous everywhere to reduce visual pops when animated slowly;\n// it remaps the mantissa nonlinearly to reduce correlation to the argument, \n// but does so gently so its derivative isn't flat anywhere;\n// the result is a lot like a very sharp sinusoid function\n// but hopefully cheaper to compute than actual sine\n\n// similar to rand(x) but preserves local g0 contiguity; \n// also decorrelates output from input\nfloat oscrand(float x)\n{\n\tx = osctri(x); // fract(x) would destroy contiguity (a little bit)\n\tx = bentstep(x); // *gentle* nonlinear remapping; smoothstep is too much!\n \tx *= 47918.; // tile an even bunch of times after bending\n\tx = osctri(x);\n    return x;\n}\n//\tx *= 1.618034; // involving another mul by Phi; idk, seems unnecessary\n\n// omg Dithery is bad, I don't recall it being quite so pathetic.  but it is!\nfloat Dithery(vec2 p)\n{\n    const float rate = 1e-5; // noise animation speed\n    const float scale = .127;\n    float t = osctri(iTime) * rate;\n    return oscrand(dot(vec2(p), vec2(1.0, 2.017)) * scale + t); // rand has too many discontinuities\n} // result 0..1\n\n// Hoskins hash without sine from http://shadertoy.com/view/4djSRW\n// best all-FP white noise I've ever found!  Clever and elegant.\n// you're not going to beat Dave.\nfloat hashHoskins(vec2 p)\n{\n\tvec3 q = fract(vec3(p.xyx) * .1031);\n    q += dot(q, q.yzx + 19.19);\n    return fract((q.x + q.y) * q.z);\n}\n\n// returns unsigned (for use by violet & blue noises)\nfloat hash21(vec2 p)\n{\n    return hashHoskins(p);\n//    return fract(sin(dot(p, vec2(17.1,13.7)))*23456.) * 2. - 1.; // good 'nuff\n//    return Dithery(p); // meh\n}\n\n// see https://shadertoy.com/view/Wtfczs\nfloat violetnoise3(vec2 p)\n{\n    return .5*(hash21(p+vec2(1,0)) + hash21(p+vec2(0,1)) - hash21(p));\n}\n\nfloat violetnoise4(vec2 p)\n{\n    p *= 2.; // looks better with?\n    return (hash21(p+vec2(1,0)) + hash21(p+vec2(0,1))\n          - hash21(p-vec2(1,0)) + hash21(p-vec2(0,1))) * .5;\n}\n\nfloat bluenoise5(vec2 p)\n{\n    return hash21(p)\n        - .25 * (\n\t\t\thash21(p + vec2( 1,0))\n\t\t+\thash21(p + vec2(-1,0))\n\t\t+\thash21(p + vec2(0, 1))\n\t\t+\thash21(p + vec2(0,-1))\n        );\n}\n\nfloat Dither1(vec2 p) // signed wrapper around Dithery\n{\n    float g = Dithery(p);\n\tg = g * 2. - 1.; // unsigned -> signed only needed for Dithery, not Dither2\n    return g;\n}\n\n// A simple dither that works quite a lot better\n// (sorry, based on sine!! haha)\n// actually it's quite directionally biased\n// but tuned in such a way that it lines up\n// well on screen coordinates and\n// produces a hexagonal lattice of sorts\nfloat DitherB(vec2 p)\n{\n//    p.x += step(mod(p.y, 2.), 1.);\n    return sin(osctri(dot(p, vec2(1./6., 4.99/iResolution.x))) * 33.);\n}\n\n// originally from Fly Camera, iirc; works better than most others I've tried!\n// but if you zoom in, it has a severe doubled-pixels problem!\nfloat Dither(vec2 p)\n{\n    return sin(dot(p, vec2(1./3., 1./22.)) * 23456.);\n}\n\nfloat Dither2(vec2 p)\n{\n    return Dither(p + osctri(iTime * 1e-3));\n}\n\n// http://wikipedia.org/wiki/Halton_sequence\n// Van der Corput sequence translator\n// from https://shadertoy.com/view/tdffWS\nfloat H1(int i, int m)\n{\n\tfloat h = 0., r = 1. / float(m), recip = 1.;\n\tint digit;\n\twhile (i != 0) {\n        int k = i / m;\n        digit = i - k * m; //i % m; //\n\t\ti = k;\n\t\th += float(digit) * (recip *= r);\n\t}\n\treturn h;\n}\n\nfloat Dither3(vec2 p)\n{\n    //ivec2 q = ivec2(p);\n     //+ osctri(iTime * 1e-3)\n    int i = int(p.x + 3.*p.y); //q.x + 5*q.y;\n    return H1(i, 5) * 2. - 1.;\n}\n\nuint ReverseBits32(uint n) // reverses the bit pattern, i.e. 1101 becomes 1011\n{\n\tn = ((n >>  1u) & 0x55555555u) | ((n & 0x55555555u) <<  1u);\n\tn = ((n >>  2u) & 0x33333333u) | ((n & 0x33333333u) <<  2u);\n\tn = ((n >>  4u) & 0x0f0f0f0fu) | ((n & 0x0f0f0f0fu) <<  4u);\n\tn = ((n >>  8u) & 0x00ff00ffu) | ((n & 0x00ff00ffu) <<  8u);\n\tn = ((n >> 16u) & 0x0000ffffu) | ((n & 0x0000ffffu) << 16u);\n\treturn n;\n}\n// simple bit reversal actually does a surprisingly good job of hashing\n// but is computationally very expensive without access to a hardware supported intrinsic\n// even with this clever bit shuffling method\n\nfloat Dither4(vec2 p)\n{\n    uint x = uint(p.x + iResolution.x * p.y);\n    uint y = ReverseBits32(x);\n    x ^= (y ^ (y >> 16)); // ^ (y << 16));\n    return float(x & 0xffffu) / exp2(16.) * 2.-1.; //exp2(23.) / float(x >> 9); //\n}\n// an extremely simple bit-munging PRNG\nuint XorSmash(uint x)\n{\n//    x = ReverseBits32(x);\n    for (int i = 11; i-- > 0; x = ((x >> 6) ^ 5u) ^ (x << 3) ^ (x << 1));\n    return x;\n}\n\nfloat Dither5(vec2 p)\n{\n    uint x = uint(p.x + iResolution.x * p.y);\n    x = XorSmash(x);\n    return float(x & 0xffffu) / exp2(16.) * 2.-1.; //exp2(23.) / float(x >> 9); //\n}\n/*\n// it's way too obvious a pattern, looking at it again now.\n// I \"adjusted\" it and now it's trash.  :(\nfloat DitherJimenez2(vec2 p)\n{\n    // Jorge Jimenez called this interleaved gradient noise;  see slide 123 in:\n\t//  http://iryoku.com/downloads/Next-Generation-Post-Processing-in-Call-of-Duty-Advanced-Warfare-v18.pptx\n\t// from Siggraph 2014, but he never explains how they chose the magic constants.\n\t// works great, but it's not mine, and since I didn't build it or pick the constants,\n\t// idk what situations it's really appropriate for or how to adjust it when needed.\n    // osctri seems better than fract in many ways, but brings its own issues :(\n\treturn osctri(108. * osctri(dot(p, vec2(.06711056, .00583715)))) * 2. - 1.; // 1/14.9007846, 1/171.316482\n}\n// older copy just uses fract but I don't like it; the pattern is very linear and obvious.\n// I think I must have botched it somehow.\nfloat DitherJimenez1(vec2 p)\n{\n\treturn fract(52.9829189 * fract(dot(p, vec2(0.06711056, 0.00583715)))) * 2. - 1.; // 1/14.9007846, 1/171.316482\n}\n*/\n\n// Dammit, at this point I can't even find the old thing I thought was awesome before,\n// or if I did, I no longer think it's quite so awesome?  \n\n// At this point I don't even care anymore, I'm just using the bluenoise texture!  ;)\n\n// shaders work much better with data from buffers or images, not const arrays!\n// besides this is only 4x4\nfloat DitherBayerLUT(vec2 q)\n{\n    // 4x4 Bayer ordered dither pattern, floats\n\t// TODO try unorm float type\n\tconst float[16] ditherTable = float[16] ( \n\t\t.05885815, .52972337, .17657446, .64743967,\n\t\t.76515597, .29429076, .88287228, .41200706,\n\t\t.23543261, .70629782, .11771630, .58858152,\n\t\t.94173043, .47086521, .82401413, .35314891\n\t);\n\tivec2 p = ivec2(q) & 3; return ditherTable[p.x + 4 * p.y] * 2. - 1.;\n}\n\n// the standard Shadertoy.com Bayer texture is 8x8\nfloat DitherBayerTex(vec2 p) // of course must know the texture channel!\n{\n    return texture(iChannel0, p / iChannelResolution[0].xy).x * 2. - 1.;\n}\n// simple, works well, only problem is that it occupies a sampler!\n\nfloat BlueNoiseTex(vec2 p)\n{\n    return texture(iChannel1, p / iChannelResolution[1].xy).x * 2. - 1.;\n}\n\nfloat BlueNoiseTexAnim(vec2 p)\n{\n    return texture(iChannel1, p / iChannelResolution[1].xy)[iFrame&3] * 2. - 1.;\n    //return texelFetch(iChannel1, ivec2(p)&1023, 0)[iFrame&3] * 2. - 1.;\n}\n\nfloat WhiteNoiseTex(vec2 p)\n{\n    return texture(iChannel2, p / iChannelResolution[2].xy).x * 2. - 1.;\n}\n\n// theoretically, blue noise is ideal for dithering\n// due to its propensity toward high frequencies\n// especially if it's gaussian value distributed\n// and signed!\n// tempting to use 3D blue noise for attempted temporal dithering\n// but first see this https://momentsingraphics.de/3DBlueNoise.html\n// For ShaderToy, the supplied precomputed 1024x1024 \n// blue noise RGBA texture is clearly the best practical choice.\n// But almost anything seems better than nothing.\n// Low frequencies will be noticeable though,\n// and any pattern *will* be noticed by the human eye.\n// violet noise is pretty cheap and easy to compute in a pinch,\n// and though not quite blue, is still way better than white noise.\n#define ChooseDither \\\nBlueNoiseTex //BlueNoiseTexAnim //DitherBayerTex //WhiteNoiseTex //DitherBayerLUT //\n//bluenoise5 //violetnoise3 //violetnoise4 //\n//hashHoskins //DitherJimenez //hash2_idk //\n//Dither5(p); //Dither4(p); //Dither3(p); //Dither2(p); //Dither1(p); //\n\n// TODO might try some kind of scrolling or other animating noise over time,\n// but strangely that adds little value in many applications and contributes\n// obvious motion artifacts as your eye magically sees such large-scale motion.\n// Since 3D blue noise was basically debunked and any precomputed 3d table basically\n// inefficient use of cache and memory, any other way to do noise over time\n// results in some kind of whitish noise over time, or just destroys the 2d blue properties.\n// I personally find keeping the pattern still and using it as a sort of\n// screen door filter works fairly well so long as the pixels are small enough\n// anyway since blue noise texture has 4 channels, it's easy enough to animate that, see BlueNoiseTexAnim.\n// alternately each frame one could compute a random offset within the 1024*1024 image and shift that to origin.\n\nvoid mainImage(out vec4 c, vec2 p)\n{\n    const float zoom = 4.; //8.; //2.; //1.; //16.; // zoom - only used for the PiP showing the noise now\n    // use amp of zero if you want to watch the bands crawl by\n    float amp = .6/256.; //.5; //.0; //.5/127.; //.25; //1.; // should be nigh imperceptible at around .7/256.\n    vec2 uv = p / iResolution.xy;\n//    p /= zoom;\n//    p = floor(p) + .5; // pixellate - be careful not to break the 1:1 case!  round() does not work!\n    c.rgb = vec3(.5); // grey\n    // color gradient designed to exhibit banding, which the dithering is expected to be able to counter.\n    c.rgb += .5 * cos(.1*iTime + .125 * uv.xyx + vec3(0,2,4)); // hue cycle\n    float divider = (dot(iMouse,iMouse) < 2.5) ? .085 : iMouse.x / iResolution.x;\n    c += exp2(-1024.*abs(uv.x-divider));\n    c.rgb = pow(c.rgb, vec3(1./2.2)); // gamma correct to srgb gamut\n\t// dithering works best in output gamma, as the quanta are more equally spaced perceptually.\n    if (uv.x >= divider) {\n\t    float g = ChooseDither(p);\n        // show pattern in PiP window at bottom left, divider hides it by default\n        if (all(lessThan(uv, vec2(1,2)/5.)))\n            amp = .5, g = ChooseDither(floor(p / zoom) + .5);\n        g = fract(g); // enforce 0..1\n        g = g * 2. - 1.; // to signed\n\t    g *= amp; // dither scale\n\t    c.rgb += g;\n    }\n    c.a = 1.;\n}","name":"Image","description":"","type":"image"}]}
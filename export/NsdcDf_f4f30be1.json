{"ver":"0.1","info":{"id":"NsdcDf","date":"1654181970","viewed":91,"name":"RGBW part2","username":"stduhpf","description":"Matching \"unbound\" RGB colors as best as possible with RGBW output.\nfork of https://shadertoy.com/view/NsjBzt (the same algorithms, without image)\nthe bottom slider changes targeted usage of white \"subpixel\"\npart1: https://www.shadertoy.com/view/7sBfWW","likes":2,"published":1,"flags":32,"usePreview":0,"tags":["ui","blackbody","rgbw"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dfGRn","filepath":"/media/a/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","previewfilepath":"/media/ap/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsBSR3","filepath":"/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","previewfilepath":"/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","type":"texture","channel":2,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Fork of \"RGBW playground\" by stduhpf. https://shadertoy.com/view/NsjBzt\n// 2022-06-02 13:46:58\n\n// This assumes your display is perfectly calibtated to track sRGB EOTF. \n// If it's not, you can try using simple gamma transform to match your display characteristics as close as possible\n// But you will likely see color errors with the \"sub-pixelated\" version of the render\n// that would not happen on an ideal display\n// The \"normal\" version should not cause any issue\n\n//#define GAMMA_EOTF //assume sRGB EOTF if disabled\n#define GAMMA 2.2 // 2. and 2.4 are also common\n\n// linear luminance boost compared to virtual RGB subpixels, 1. is normal brightness \nconst float image_brightness = 5.; \n\nconst mat3 xyz = mat3(\n\t3.240479, -1.537150, -0.498535,\n    -0.969256, 1.875992, 0.041556,\n    0.055648, -0.204043, 1.057311);\n\nvec3 rgblackbodyUv(float x){\n    vec3 col = texture(iChannel0,vec2(x,1.)).rgb;\n    \n    col=col*xyz;\n    {// slightly adjust xyz to rec.709 transform so that the computed 6500K blackbody correspond exactly to rec.709 white point (D65)\n        //otherwise there's a slight difference (maybe due to the precision of the xyz matrix)\n        float x = TTouv(6500.); // == 0.5\n        vec3 d65=texture(iChannel0,vec2(x,1.5)).rgb*xyz;\n        col.rgb/=d65; \n    }\n    \n    return col/max(col.r,max(col.g,col.b)); //could also normalize using luminance instead of max\n}\n\n\n\n\n// rec.709/sRGB primaries relative luminance (or luma)\nconst vec3 lum = vec3(0.2126,0.7152,0.0722);\n\n\nfloat getWhiteInt(){\n    return texture(iChannel0,vec2(3.5)/iChannelResolution[0].xy).r;\n}\n\nfloat getTempC(){\n    return texture(iChannel0,vec2(5.5)/iChannelResolution[0].xy).r;\n}\n\nfloat getW_alg(){\n    float phase = texture(iChannel0,vec2(7.5)/iChannelResolution[0].xy).r;\n    return phase>=0.?phase:.5+.5*sin(iTime*.25);\n}\n\n\n/*\n    This Algorithm maximises the utilisation of the white channel\n    It could be usefull for applications where higher CRI is better\n    The downside is that if the white lightsource stops working,\n    the colors will look completely different\n*/\nvec4 RGBW_max(vec3 t, vec3 W){\n    bool noW = dot(W,W)==0.;\n\n\n    float lW = noW?1.:dot(W,lum);\n\n  \n    vec3 tn = t/W; //colors mapped to a similar colorspace, but with W as whitepoint (kinda like a color temperature change)\n    \n    \n    float w=noW?1.:min(min(tn.r,min(tn.g,tn.b)),1.); //baseline amount of W\n    \n    vec3 c = t-w*W; //remaining colors after removing the baseline\n    \n    //the following only changes anything if some component of c is gerater than 1.\n    //this means that the input color has at least one component above 1+w*W\n    \n    //this is the part that \"desaturates\" colors that still overshoot the RGB space after removing baseline,towards W\n    //the luminance of the output will match the input as long as the original input is within the [vec3(0),1+W] range \n    \n    //a slight tint shift will also happen during this process\n    //(not the same as the min algorithm), that's a possible future improvement \n    \n    w+=dot(max(c,1.)-1.,lum)/lW; //anything above 1. is converted to white while preserving luminance\n    c=min(c,1.); // removes the extra colors that got converted to white\n    \n    // \"refinement\" step, where the extra white gets converted back to colors if there is still some non-full channels\n    float w2=max(w,1.)-1.;\n    c+=(1.-c)*min(w2*lW/dot(lum,1.-c),1.);\n    w=min(w,1.);\n    \n    return vec4(c,w);\n}\n\n/*\n    This Algorithm minimises the utilisation of the white channel\n    It could be usefull for applications where putting too much \n    strain on a silngle source might damage it. Plus the colors stay\n    close to the original colors if the white lightsource breaks\n    The downside is that the CRI is typically worse\n*/\nvec4 RGBW_min(vec3 t, vec3 W){\n    bool noW = dot(W,W)==0.;\n    float lW = noW?1.:dot(W,lum);\n\n    vec3 tn = max(t-1.,0.)/W; //overshoot of colors mapped to a similar colorspace, but with W as whitepoint (kinda like a color temperature change)\n    \n    \n    float w = max(max(tn.r,tn.g),tn.b);//baseline amount of W\n    \n    vec3 c=t-w*W;\n    \n    //the following only changes anything if some component of c is lower than 0.\n    //this means that the input color has at least one component under 1-w*W\n    \n    //this is the part that \"desaturates\" colors that still overshoot the RGB space after removing baseline,towards W\n    //the luminance of the output will match the input as long as the original input is within the [vec3(0),1+W] range\n    \n    //a slight tint shift will also happen during this process\n    //(not the same as the max algorithm), that's a possible future improvement \n    \n    vec3 cn = min(c,0.); // negative channels only\n    float ln = dot(cn,lum);  // negative luminance of the negative channels\n    \n    w+=ln/lW; // remove some white according to the luminance requirements\n    c=max(c,0.);// adds back the missing colors that got removed from white\n    \n    // \"refinement\" step, where the extra white gets converted back to colors if there is still some non-full channels\n    float w2=max(w,1.)-1.;\n    c+=(1.-c)*min(w2*lW/dot(lum,1.-c),1.);\n    w=min(w,1.);\n    \n    return vec4(c,w);\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    float wi = getWhiteInt();\n    float Tc = getTempC();\n    float T = uvToT(Tc);\n    \n                        \n    float ma = image_brightness; //Lower this value to decrease the max brightness of target image (maybe I should add a slider for that)\n    \n    float q = 4.; //size of the fake pixels (subpixels are half (or quarter) of this size)\n    float ppt = 1.; //pixels per texel\n    vec3 t0 = srgb_to_rgb(texture(iChannel1,(ppt*floor(fragCoord/(q*ppt))*q+.5)/iResolution.xy).rgb)*ma;\n    \n    vec3 W = rgblackbodyUv(Tc)*wi*.5; //varying the white max brightness over time\n    \n    //this algorithm breaks if W is outside the RGB gamut (even in cases where there is a solution), so we force positive coordinates\n    //otherwise whites under 1900K would not work\n    W=max(W,.000030517578125);\n    \n    \n    // If there is a way to reproduce input with RGBW\n    // then all the possible outputs are a linear mix of the outputs with\n    // the lowest value of w, and the one with highest w\n    \n    //a 50%-50% mix of both results tends to give less visible noise in \"subpixel\" view,\n    //because the luminance is more evenly spread across the subpixels  \n    float W_usage = getW_alg(); \n    vec4 result = mix(RGBW_min(t0,W),RGBW_max(t0,W),W_usage);\n    \n    result = clamp(result,0.,1.);//should not change anything\n    \n    vec3 c = result.rgb;\n    float w = result.w;\n    \n    vec3 t1 = c+w*W;//final reconstructed color\n    \n    \n    \n    vec2 ar = vec2(10,1.15)/iResolution.xy;\n    vec2 uv0 = fragCoord.xy/iResolution.xy;\n    vec2 uv = ar*fragCoord.xy-vec2(0.,.05);\n    \n\n\n    vec2 id = floor(uv);\n    if(id.y>0.){\n    //top sliders\n        float idy = floor((uv.y-1.)*20.);\n        if(idy==0.){\n        // white relative intensityintensity\n            float d =abs(uv.x-wi);\n            fragColor.rgb = 2.*uv0.x*W/wi;\n            if(d<.075)\n               fragColor=vec4(step(.025,d));\n        }else{\n        //color temperature\n            fragColor.rgb=rgblackbodyUv(uv0.x)*wi*.1;\n            float d = abs(uv0.x-Tc);\n            if(d<.0075)\n               fragColor=vec4(step(.0025,d));\n        }\n    }else{\n        if(id.y<0.){\n        //normal rendering\n            float d = abs(uv0.x-W_usage);\n            if(d<.0075)\n               fragColor=vec4(step(.0025,d));\n        }else{\n        //fake sub-pixels\n            //randomly \"rotate\" the fake subpixels for less artifacts (but more noise) (remove \"*0.\" to enable)\n            vec2 noise =texture(iChannel2,floor(fragCoord/q)/iChannelResolution[2].xy).xy*0.; \n            vec2 uuvv = mod(floor(fragCoord*2./q)+step(noise,vec2(.5)),2.);\n            fragColor.rgb = c*vec3(uuvv.x< 1.&& uuvv.y>=1.,\n                                   uuvv.x>=1.&& uuvv.y>=1.,\n                                   uuvv.x>=1.&& uuvv.y< 1.) / ma\n                           + float(uuvv.x< 1.&& uuvv.y< 1.) * W * w / (ma);\n           \n           /*\n           // other subpixel layout (needs q=4. or more)\n            vec2 uuvv = mod(floor(fragCoord*4./q),4.);\n            fragColor.rgb = c*vec3(uuvv.x==1.,\n                                   uuvv.x==0.,\n                                   uuvv.x==3.) / ma\n                           + float(uuvv.x==2.) * W * w / (ma);\n                           \n           */\n                           \n           if(mod(iTime,5.)<2.5)fragColor.rgb = .25 * t1 / ma;\n           // if the colors look different when using the \"dithered\" view and the composite,\n           // maybe your monitor use the wrong EOTF (by that I mean not sRGB),try different gamma values to mitigate this\n        }\n    }\n    \n    if(iMouse.z<.1*iResolution.x && iMouse.z>0. && floor(iMouse.y*ar.y-.05)==0.)\n        fragColor=vec4(dot(fragColor.rgb,lum)); //grayscale when clicking left\n    #ifdef GAMMA_EOTF\n        fragColor = pow(fragColor,vec4(1./2.2));\n    #else\n        fragColor.rgb = rgb_to_srgb(fragColor.rgb);\n    #endif \n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//black-body radiation\n\nfloat blackbody(float wl, float T){\n    float h = 6.6e-34; // Planck constant\n    float k = 1.4e-23; // Boltzmann constant\n    float c = 3e8;// Speed of light\n   \twl*=1e-9;\n    return  2.*h*(c*c)/(wl*wl*wl*wl*wl*(exp(h*c/(T*wl*k))-1.));\n}\n\n\nfloat gaussian(float x,float al, float mu, float s1, float s2){\n    float y = x-mu;\n    y/=y<0.?s1:s2;\n    return al*exp(-y*y*.5);\n}\n\n\nvec3 lambdatoXYZ(float wl){\n    return vec3( gaussian(wl, 1.056, 599.8, 37.9, 31.0)+gaussian(wl, 0.362, 442.0, 16.0, 26.7)+ gaussian(wl, -0.065, 501.1, 20.4, 26.2)\n                ,gaussian(wl, 0.821, 568.8, 46.9, 40.5)+gaussian(wl,0.286, 530.9, 16.3, 31.1)\n                ,gaussian(wl, 1.217, 437.0, 11.8, 36.0)+gaussian(wl, 0.681, 459.0, 26.0, 13.8));\n}\n\n\n\n\n#define lmin 300.\n#define lmax 800.\n\nvec3 blackbody(float t,float h, int samples){\n    float l = lmin;\n    float lstep = (lmax-lmin)/(float(samples));\n    l+=lstep*h;\n    vec3 col = vec3(0);\n    float s=0.;\n    for(int i=0;i<samples;i++){\n        col+=lambdatoXYZ(l)*blackbody(l,t);\n        l+=lstep;\n        s++;\n    }\n    return col/s;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = texture(iChannel0,fragCoord/iResolution.xy);\n    ivec2 pixel = ivec2(floor(fragCoord.xy));\n    vec2 ar = vec2(10,1.15)/iResolution.xy;\n    vec4 m = iMouse*vec4(ar,ar)-vec4(0,.05,0,.05);\n    \n    if(iMouse.w>0.){\n        // keep last click coordinates\n        if(pixel==ivec2(9)){\n            fragColor.xy = m.zw;\n        }\n    }else{\n        m.zw = texture(iChannel0,vec2(9.5)/iChannelResolution[0].xy).xy;\n    }\n    \n    if(iMouse.xy!=vec2(0.)){\n    \n        vec4 id = floor(m);\n        if(id.w==0.){\n\n        }else{\n            if(id.w<0.){\n                 if(pixel==ivec2(7)){\n                     fragColor.r = m.x*.1;\n                 }\n            }else{\n                float idy = floor((m.w-1.)*20.);\n\n                if(pixel==ivec2(3)&&idy==0.){\n                    fragColor.r = m.x;\n                }\n                if(pixel==ivec2(5)&&idy!=0.){\n                    fragColor.r = m.x*.1;\n                }\n            }\n        }\n    }\n   \n    if(iFrame<1){\n        fragColor=vec4(0);\n        if(pixel==ivec2(1)){\n            fragColor.rgb=vec3(.25,.1,.6);\n            fragColor.a=-1.;\n            }else{\n             if(pixel==ivec2(7)){\n                 fragColor.r = -0.5;\n             }\n            if(pixel==ivec2(3)){\n                fragColor.r = 2.;\n            }\n            if(pixel==ivec2(5)){\n                fragColor.r = TTouv(6500.);\n            }\n        }\n    }\n     if(int(floor(iResolution.y))-1==pixel.y&&iFrame<10){\n        fragColor += vec4(blackbody(uvToT(fragCoord.x/iResolution.x),fract((.5+.5*sqrt(5.))*float(iFrame)),16),1);\n    }\n\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"const float Tstart = 2000.; //500. for a very wide choice\nconst float Tmid = 6500.;\nfloat Tscale = 2.*log(Tmid/Tstart);//1.*log(Tend/Tstart)\n\nfloat TTouv(float x){\n    return log(x/Tstart)/Tscale;\n} \n\n\nfloat uvToT(float x){\n    return Tstart*exp(Tscale*x);\n} \n\n\nconst float SRGB_GAMMA = 1.0 / 2.4;\nconst float SRGB_INVERSE_GAMMA = 2.4;\nconst float SRGB_ALPHA = 0.055;\n\n\n// Converts a single linear channel to srgb\nfloat linear_to_srgb(float channel) {\n    if(channel <= 0.0031308)\n        return 12.92 * channel;\n    else\n        return (1.0 + SRGB_ALPHA) * pow(channel, 1.0/2.4) - SRGB_ALPHA;\n}\n\n// Converts a single srgb channel to rgb\nfloat srgb_to_linear(float channel) {\n    if (channel <= 0.04045)\n        return channel / 12.92;\n    else\n        return pow((channel + SRGB_ALPHA) / (1.0 + SRGB_ALPHA), 2.4);\n}\n\n// Converts a linear rgb color to a srgb color (exact, not approximated)\nvec3 rgb_to_srgb(vec3 rgb) {\n    return vec3(\n        linear_to_srgb(rgb.r),\n        linear_to_srgb(rgb.g),\n        linear_to_srgb(rgb.b)\n    );\n}\n\n// Converts a srgb color to a linear rgb color (exact, not approximated)\nvec3 srgb_to_rgb(vec3 srgb) {\n    return vec3(\n        srgb_to_linear(srgb.r),\n        srgb_to_linear(srgb.g),\n        srgb_to_linear(srgb.b)\n    );\n}","name":"Common","description":"","type":"common"}]}
{"ver":"0.1","info":{"id":"tsXBDS","date":"1601129820","viewed":617,"name":"KNITTED TEDDY","username":"alro","description":"A modelled teddy with texture synthesis, normal mapping and PBR for a knitted wool look.\n\nLong compilation time on some platforms.","likes":33,"published":1,"flags":32,"usePreview":1,"tags":["texture","heightmap","sphericalharmonics","pbr","triplnar","teddy"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\t\n    Normal mapping arbitrary shapes with synthesized pattern texture. \n\n\tLong compilation times on some platforms.\n\n\tEdit: \tSpherical harmonics for diffuse IBL\n\t\t \tTo change the environment, swap the cubemap in Buffer C.\n            \n    Based on:\n\thttps://learnopengl.com/PBR/Theory\n\thttps://tinyurl.com/y5ebd7w7\n\thttps://google.github.io/filament/Filament.md.html\n\thttps://graphics.pixar.com/library/OrthonormalB/paper.pdf\n\n\t\n\tWe raymarch the union of simple shapes and apply a heightfield texture from Buffer B to \n\tadjust the surface normals using triplanar mapping. We create an orthonormal coordinate \n\tsystem based on the surface normal of the unrotated shape. This basis has a discontinuity\n\tat the z-plane where one of the coordinate axes is flipped. As we sample the neighbourhood\n\tsymmetrically across the origin, this should  not cause visual artefacts, however, we need\n\tto clamp the z value as very small values break the basis construction.\n\t\n\tColour is calculated using PBR with diffuse IBL using spherical harmonics. There is no \n\tspecular IBL.\n\t\n\tNormal mapping will lead to an impossible surface where the view ray and normal dot \n\tproduct is negative. Using PBR, this leads to negative radiance and black artefacts at \n\tdetail fringes. See \"Microfacet-based Normal Mapping for Robust Monte Carlo Path Tracing\"\n\tby SchÃ¼ssler et al. for a discussion of a physically correct solution. We just clamp the\n\tdot product with a normal to some small\tvalue.\n\n*/\n\n#define HEAD 0\n#define EARS 1\n#define SNOUT 2\n#define BODY 3\n#define ARMS 4\n#define LEGS 5\n#define NOSE 6\n#define EYES 7\n#define TAIL 8\n\n//#define ANIMATE_LIGHT\n\n// Variable iterator initializer to stop loop unrolling\n#define ZERO (min(iFrame,0))\n\n// azimuth\nfloat sunLocation = 2.05;\n\n// 0: horizon, 1: zenith\nfloat sunHeight = 0.5;\n\nconst int MAX_STEPS = 64;\nconst float MIN_DIST = 0.01;\nconst float MAX_DIST = 10.0;\nconst float EPSILON = 1e-4;\nconst float DETAIL_EPSILON = 1e-2;\nconst float SHADOW_SHARPNESS = 2.0;\nconst float DETAIL_HEIGHT = 0.02;\nconst vec3 DETAIL_SCALE = vec3(3.0);\nconst vec3 BLENDING_SHARPNESS = vec3(16.0);\n\nconst float AMBIENT_STRENGTH = 2.8;\nconst float EXPOSURE = 0.65;\n\n// Minimum dot product value\nconst float minDot = 1e-5;\n\n// Clamped dot product\nfloat dot_c(vec3 a, vec3 b){\n\treturn max(dot(a, b), minDot);\n}\n\nvec3 rayDirection(float fieldOfView, vec2 fragCoord) {\n    vec2 xy = fragCoord - iResolution.xy / 2.0;\n    float z = (0.5 * iResolution.y) / tan(radians(fieldOfView) / 2.0);\n    return normalize(vec3(xy, -z));\n}\n\n// https://www.geertarien.com/blog/2017/07/30/breakdown-of-the-lookAt-function-in-OpenGL/\nmat3 lookAt(vec3 camera, vec3 at, vec3 up){\n  vec3 zaxis = normalize(at-camera);    \n  vec3 xaxis = normalize(cross(zaxis, up));\n  vec3 yaxis = cross(xaxis, zaxis);\n\n  return mat3(xaxis, yaxis, -zaxis);\n}\n\n//---------------------------- Rotations ----------------------------\n\nvec3 rotate(vec3 p, vec4 q){\n  return 2.0 * cross(q.xyz, p * q.w + cross(q.xyz, p)) + p;\n}\n\nvec3 rotateX(vec3 p, float angle){\n    return rotate(p, vec4(sin(angle/2.0), 0.0, 0.0, cos(angle/2.0)));\n}\n\nvec3 rotateY(vec3 p, float angle){\n\treturn rotate(p, vec4(0.0, sin(angle/2.0), 0.0, cos(angle/2.0)));\n}\n\nvec3 rotateZ(vec3 p, float angle){\n\treturn rotate(p, vec4(0.0, 0.0, sin(angle), cos(angle)));\n}\n\n\n//---------------------------- Positioning ----------------------------\n\n// Rotate and translate part for SDF depending on the id.\nvoid setPosition(inout vec3 p, inout vec3 n, int id){\n    float angleX;\n    float angleZ;\n    \n    vec3 globalOffset = vec3(0, -1 , 0);\n    \n    vec3 offset = globalOffset;\n\n    // GPUs love branching!\n    if(id == HEAD){\n\t\tp = p + offset;\n        return;\n        \n    }else if(id == EARS){\n        angleZ = -2.35;\n        offset += vec3(0.0, -0.5, -0.5);\n        if(p.z > 0.0){\n            p = rotateZ(p+offset, angleZ);\n            n = rotateZ(n, angleZ);\n            return;\n        }else{\n            p = rotateZ(p+offset*vec3(1,1,-1), angleZ);\n            n = rotateZ(n, angleZ);\n            return;\n        }\n        \n    }else if(id == SNOUT){\n        angleZ = -0.25;\n        p = rotateZ(p+offset, angleZ)+vec3(0.55, 0.0, 0.0);\n        n = rotateZ(n, angleZ);\n        return;\n        \n    }else if(id == BODY){\n        offset += vec3(0.0, 1.4, -0.0);\n    \tp = p + offset;\n        return;\n        \n    }else if(id == ARMS){\n        angleX = -1.0;\n        angleZ = -1.0;\n        offset += vec3(0.0, 0.95, -0.38);\n        if(p.z > 0.0){\n            p = rotateX(rotateZ(p+offset, angleZ), angleX);\n            n = rotateX(rotateZ(n, angleZ), angleX);\n            return;\n        }else{\n            p = rotateX(rotateZ(p+offset * vec3(1,1,-1), angleZ), -angleX);\n            n = rotateX(rotateZ(n, angleZ), -angleX);\n            return;\n        }\n\n    }else if(id == LEGS){\n        angleX = -0.5;\n        angleZ = -1.2;\n        offset += vec3(0.05, 2.05, -0.3);\n        if(p.z > 0.0){\n            p = rotateX(rotateZ(p+offset, angleZ), angleX);\n            n = rotateX(rotateZ(n, angleZ), angleX);\n            return;\n        }else{\n            p = rotateX(rotateZ(p+offset * vec3(1,1,-1), angleZ), -angleX);\n            n = rotateX(rotateZ(n, angleZ), -angleX);\n            return;\n        }\n    \n    }else if(id == NOSE){\n        offset += vec3(0.7, 0.18, 0.0);\n        p = p + offset;\n        return;\n        \n    }else if(id == EYES){\n        offset += vec3(0.55, 0.0, -0.25);\n    \tp = p + offset;\n        return;\n\n    }else if(id == TAIL){\n        offset += vec3(-0.5, 1.9, 0.0);\n    \tp = rotateZ(p + offset, -0.2);\n        n = rotateZ(n, -0.2);\n        return;\n    }\n}\n\n//---------------------------- Distance functions ----------------------------\n\nvec4 opElongate( in vec3 p, in vec3 h ){ \n    vec3 q = abs(p)-h;\n    return vec4( max(q,0.0), min(max(q.x,max(q.y,q.z)),0.0) );\n}\n\nfloat sphereSDF(vec3 p, float radius) {\n    return length(p) - radius;\n}\n\nfloat torusSDF(vec3 p, float smallRadius, float largeRadius) {\n\treturn length(vec2(length(p.xz) - largeRadius, p.y)) - smallRadius;\n}\n\nfloat sdRoundCone( vec3 p, float r1, float r2, float h ){\n  vec2 q = vec2( length(p.xz), p.y );\n    \n  float b = (r1-r2)/h;\n  float a = sqrt(1.0-b*b);\n  float k = dot(q,vec2(-b,a));\n    \n  if( k < 0.0 ) return length(q) - r1;\n  if( k > a*h ) return length(q-vec2(0.0,h)) - r2;\n        \n  return dot(q, vec2(a,b) ) - r1;\n}\n\n// Update part id when smallest distance has changed.\nvoid trackMaterial(inout float oldDist, float dist, inout int oldId, int id){\n    if(dist != oldDist){\n    \toldDist = dist;\n        oldId = id;\n    }\n}\n\n// Get the combined SDF of the body. Arms, legs, ears and eyes are evaluated once by using\n// the absolute value of Z to mirror them across the plane, reducing overall work. Keep track\n// of which body part is the closest to determine texture rotation later.\nfloat getSDF(vec3 position, inout int id) {\n    float dist = 1e10;\n    float oldDist = dist;\n\n    // Two variables for temporary position manipulation\n    vec3 q;\n    vec4 w;\n\n    // Unused here\n    vec3 n;\n    \n    // Head\n    q = position;\n   \tsetPosition(q, n, HEAD);\n    w = opElongate(q, vec3(-0.08, 0, 0));\n    dist = min(dist, sphereSDF(w.xyz, 0.7));\n    trackMaterial(oldDist, dist, id, HEAD);\n    \n    // Ears, mirrored\n    q = position;\n    q.z = abs(q.z);\n    setPosition(q, n, EARS);\n    dist = min(dist, torusSDF(q, 0.12, 0.12));\n    trackMaterial(oldDist, dist, id, EARS);\n   \n    // Snout\n    q = position;\n    setPosition(q, n, SNOUT);\n    w = opElongate(q, vec3(-0.08, 0, 0));\n    dist = min(dist, sphereSDF(w.xyz, 0.3));\n    trackMaterial(oldDist, dist, id, SNOUT);\n    \n    // Body\n    q = position;\n    setPosition(q, n, BODY);\n    w = opElongate(q, vec3(-0.2, 0.2, -0.08));\n    dist = min(dist, sphereSDF(w.xyz, 0.75));\n    trackMaterial(oldDist, dist, id, BODY);\n    \n    // Arms, mirrored\n    q = position;\n    q.z = abs(q.z);\n    setPosition(q, n, ARMS);\n    dist = min(dist, sdRoundCone(q, 0.3, 0.28, 0.7));\n    trackMaterial(oldDist, dist, id, ARMS);\n\t\n    // Legs, mirrored\n    q = position;\n    q.z = abs(q.z);\n    setPosition(q, n, LEGS);\n    dist = min(dist, sdRoundCone(q, 0.3, 0.3, 0.7));\n    trackMaterial(oldDist, dist, id, LEGS);\n    \n    // Nose\n    q = position;\n    setPosition(q, n, NOSE);\n\tw = opElongate(q, vec3(-0.04,0.0, 0.02) );\n    dist = min(dist, sphereSDF(w.xyz, 0.08));\n    trackMaterial(oldDist, dist, id, NOSE);\n    \n    // Eyes, mirrored\n    q = position;\n    q.z = abs(q.z);\n    setPosition(q, n, EYES);\n    dist = min(dist, sphereSDF(q, 0.05));\n    trackMaterial(oldDist, dist, id, EYES);\n    \n    // Tail\n    q = position;\n    setPosition(q, n, TAIL);\n    dist = min(dist, sphereSDF(q, 0.15));\n    trackMaterial(oldDist, dist, id, TAIL);\n\n    return dist;\n}\n\nfloat distanceToScene(vec3 cameraPos, vec3 rayDir, float start, float end, out int id) {\n\t\n    // Start at a predefined distance from the camera in the ray direction\n    float depth = start;\n    \n    // Variable that tracks the distance to the scene \n    // at the current ray endpoint\n    float dist;\n    \n    // For a set number of steps\n    for (int i = ZERO; i < MAX_STEPS; i++) {\n        \n        // Get the sdf value at the ray endpoint, giving the maximum \n        // safe distance we can travel in any direction without hitting a surface\n        dist = getSDF(cameraPos + depth * rayDir, id);\n        \n        // If it is small enough, we have hit a surface\n        // Return the depth that the ray travelled through the scene\n        if (dist < EPSILON){\n            return depth;\n        }\n        \n        // Else, march the ray by the sdf value\n        depth += dist;\n        \n        // Test if we have left the scene\n        if (depth >= end){\n            id = -1;\n            return end;\n        }\n    }\n\n    return depth;\n}\n\n//---------------------------- Normal mapping ----------------------------\n\n// https://tinyurl.com/y5ebd7w7\nvec3 getTriplanar(vec3 position, vec3 normal, int id){\n\n    setPosition(position, normal, id);\n\n    vec3 xaxis;\n    vec3 yaxis;\n    vec3 zaxis;\n\n    xaxis = texture(iChannel1, DETAIL_SCALE.x*(position.zy)).rgb;\n    yaxis = texture(iChannel1, DETAIL_SCALE.y*(position.zx)).rgb;\n    zaxis = texture(iChannel1, DETAIL_SCALE.z*(position.xy)).rgb;\n\n\n    if(id == EYES || id == NOSE){\n    \txaxis = xaxis.ggg;\n    \tyaxis = yaxis.ggg;\n    \tzaxis = zaxis.ggg;\n    }else{\n    \txaxis = xaxis.rrr;\n    \tyaxis = yaxis.rrr;\n    \tzaxis = zaxis.rrr;\n    }\n\n    vec3 blending = abs(normal);\n\tblending = normalize(max(blending, 0.00001));\n    blending = pow(blending, BLENDING_SHARPNESS);\n\tfloat b = (blending.x + blending.y + blending.z);\n\tblending /= b;\n\n    return\txaxis * blending.x + \n       \t\tyaxis * blending.y + \n        \tzaxis * blending.z;\n}\n\n//Return the position of p extruded in the normal direction by normal map\nvec3 getDetailExtrusion(vec3 p, vec3 normal, int id){\n    float detail = DETAIL_HEIGHT*length(getTriplanar(p, normal, id));\n    return p + detail * normal;\n}\n\n// Get surface normal from the gradient of the surrounding sdf field\n// by sampling the values in the neighbouring area\n/*\nvec3 getNormal(vec3 p) {\n    int id;\n    return normalize(vec3(\n        getSDF(vec3(p.x + EPSILON, p.y, p.z), id) - \n        getSDF(vec3(p.x - EPSILON, p.y, p.z), id),\n        getSDF(vec3(p.x, p.y + EPSILON, p.z), id) - \n        getSDF(vec3(p.x, p.y - EPSILON, p.z), id),\n        getSDF(vec3(p.x, p.y, p.z + EPSILON), id) - \n        getSDF(vec3(p.x, p.y, p.z - EPSILON), id)\n    ));\n}*/\n\n// Tetrahedral normal technique with a loop to avoid inlining getSDF()\n// This should improve compilation times\n// https://iquilezles.org/articles/normalsSDF\nvec3 getNormal(vec3 p){\n    vec3 n = vec3(0.0);\n    int id;\n    for(int i = ZERO; i < 4; i++){\n        vec3 e = 0.5773*(2.0*vec3((((i+3)>>1)&1),((i>>1)&1),(i&1))-1.0);\n        n += e*getSDF(p+e*EPSILON, id);\n    }\n    return normalize(n);\n}\n\n// Get orthonormal basis from surface normal\n// https://graphics.pixar.com/library/OrthonormalB/paper.pdf\nvoid pixarONB(vec3 n, out vec3 b1, out vec3 b2){\n\tfloat sign_ = n.z >= 0.0 ? 1.0 : -1.0;\n\tfloat a = -1.0 / (sign_ + n.z);\n\tfloat b = n.x * n.y * a;\n\tb1 = vec3(1.0 + sign_ * n.x * n.x * a, sign_ * b, -sign_ * n.x);\n\tb2 = vec3(b, sign_ + n.y * n.y * a, -n.y);\n}\n\n// Return the the normal after applying a normal map\nvec3 getDetailNormal(vec3 p, vec3 normal, float t, int id){\n    vec3 tangent;\n    vec3 bitangent;\n    // Construct orthogonal directions tangent and bitangent to sample detail gradient in\n    pixarONB(normal, tangent, bitangent);\n    \n    tangent = normalize(tangent);\n    bitangent = normalize(bitangent);\n    \n    float EPS = DETAIL_EPSILON * 0.2;\n    \n    vec3 delTangent = vec3(0);\n    vec3 delBitangent = vec3(0);\n    \n    for(int i = ZERO; i < 2; i++){\n        \n        // i ->  s\n        // 0 ->  1\n        // 1 -> -1\n        float s = 1.0 - 2.0 * float(i&1);\n    \n        delTangent += s * getDetailExtrusion(p + s * tangent * EPS, normal, id);\n\n        delBitangent += s * getDetailExtrusion(p + s * bitangent * EPS, normal, id);\n\n    }\n    \n    return normalize(cross(delTangent, delBitangent));\n}\n\n//---------------------------- Shadows ----------------------------\n\n// https://iquilezles.org/articles/rmshadows\nfloat softShadow(vec3 pos, vec3 rayDir, float start, float end, float k ){\n    float res = 1.0;\n    float depth = start;\n    int id;\n    for(int counter = ZERO; counter < MAX_STEPS; counter++){\n        float dist = getSDF(pos + rayDir * depth, id);\n        if( abs(dist) < EPSILON){ return 0.0; }       \n        if( depth > end){ break; }\n        res = min(res, k*dist/depth);\n        depth += dist;\n    }\n    return res;\n}\n\n// Ambient occlusion reduces the ambient light strength in areas which are closely shielded \n// by other objects\n// https://www.youtube.com/watch?v=22PZF7fWLqI\nfloat ambientOcclusion(vec3 position, vec3 normal){\n\n\tfloat ao = 0.0;\n    // step size\n    float del = 0.08;\n    float weight = 0.1;\n    \n    // Travel out from point with fixed step size and accumulate proximity to other surfaces\n    // iq slides include 1.0/pow(2.0, i) factor to reduce the effect of farther objects\n    // but Peer Play uses just 1.0/dist\n    int id;\n    for(int i = ZERO; i < 5; i++){\n        float dist = float(i+1) * del;\n    \t// Ignore measurements from inside objects\n    \tao += max(0.0, (dist - getSDF(position + normal * dist, id))/dist);\n    }\n    // Return a weighted occlusion amount\n    return 1.0 - weight * ao;\n}\n\n\n//---------------------------- PBR ----------------------------\n\n// Trowbridge-Reitz\nfloat distribution(vec3 n, vec3 h, float roughness){\n    float a_2 = roughness * roughness;\n\treturn a_2/(PI * pow(pow(dot_c(n, h), 2.0) * (a_2 - 1.0) + 1.0, 2.0));\n}\n\n// GGX and Schlick-Beckmann\nfloat geometry(float cosTheta, float k){\n\treturn (cosTheta) / (cosTheta * (1.0 - k) + k);\n}\n\nfloat smiths(float NdotV, float NdotL, float roughness){\n    float k = pow(roughness + 1.0, 2.0) / 8.0; \n\treturn geometry(NdotV, k) * geometry(NdotL, k);\n}\n\n// Fresnel-Schlick\nvec3 fresnel(float cosTheta, vec3 F0){\n    return F0 + (1.0 - F0) * pow(1.0 - cosTheta, 5.0);\n} \n\n// Cook-Torrance BRDF\nvec3 BRDF(vec3 p, vec3 n, vec3 viewDir, vec3 lightDir,\n          vec3 albedo, vec3 F0, float roughness, float metalness){\n          \n    vec3 h = normalize(viewDir + lightDir);\n    float NdotL = dot_c(lightDir, n);\n    float NdotV = dot_c(viewDir, n);\n\n    float cosTheta = dot_c(h, viewDir);\n    vec3 lambertian = albedo / PI;\n\n    float D = distribution(n, h, roughness);\n    vec3 F = fresnel(cosTheta, F0);\n\n    float G = smiths(NdotV, NdotL, roughness);\n    \n    vec3 specular =  D * F * G / max(0.0001, (4.0 * NdotV * NdotL));\n   \n    vec3 kD = (1.0 - F) * (1.0 - metalness);\n    return kD * lambertian + specular;\n}\n\nvec3 getSPHIrradiance(vec3 normal){\n\n    vec4 n = vec4(normal, 1.0);\n    \n    mat4 redMatrix = mat4(\n        texelFetch(iChannel2, ivec2(0,0), 0),\n        texelFetch(iChannel2, ivec2(0,1), 0),\n        texelFetch(iChannel2, ivec2(0,2), 0),\n        texelFetch(iChannel2, ivec2(0,3), 0));\n    \n    \n    mat4 grnMatrix = mat4(\n        texelFetch(iChannel2, ivec2(1,0), 0),\n        texelFetch(iChannel2, ivec2(1,1), 0),\n        texelFetch(iChannel2, ivec2(1,2), 0),\n        texelFetch(iChannel2, ivec2(1,3), 0));\n    \n    \n    mat4 bluMatrix = mat4(\n        texelFetch(iChannel2, ivec2(2,0), 0),\n        texelFetch(iChannel2, ivec2(2,1), 0),\n        texelFetch(iChannel2, ivec2(2,2), 0),\n        texelFetch(iChannel2, ivec2(2,3), 0));\n    \n    float r = dot(n, redMatrix * n);\n    float g = dot(n, grnMatrix * n);\n    float b = dot(n, bluMatrix * n);\n    \n    return vec3(r, g, b);\n}\n\nvec3 getEnvironment(vec3 rayDir){\n    vec2 texCoord = vec2((atan(rayDir.z, rayDir.x) / TWO_PI) + 0.5, acos(rayDir.y) / PI);\n    return texture(iChannel2, texCoord).rgb;\n}\n\nvec3 getIrradiance(vec3 p, vec3 n, vec3 rayDir, vec3 geoNormal, int id){\n    vec3 I = vec3(0);\n    \n#ifdef ANIMATE_LIGHT\n    sunLocation = mod(iTime, 6.28);\n#endif\n\n    vec3 albedo = 0.25 * vec3(0.75,0.4,0.2);\n    vec3 F0 = vec3(0.01);\n    float roughness = 1.0;\n    float metalness = 0.0;\n\n    if(id == NOSE || id == EYES){\n        albedo = vec3(0.02);\n    }\n\n    vec3 lightPosition = 10.0*normalize(vec3(cos(sunLocation), sunHeight, sin(sunLocation)));\n    vec3 lightColour = vec3(5);\n\n    vec3 vectorToLight = lightPosition - p;\n   \tvec3 lightDir = normalize(vectorToLight);\n    vec3 radiance = lightColour;\n    float shadow = softShadow(p + n * EPSILON * 2.0, lightDir, MIN_DIST,\n                              length(vectorToLight), SHADOW_SHARPNESS);\n    I += shadow \n        * BRDF(p, n, -rayDir, lightDir, albedo, F0, roughness, metalness) \n        * radiance \n        * dot_c(n, lightDir);\n\n\n    // Ambient occlusion from geometry. Use texture heightmap for detail ao.\n    float ao = ambientOcclusion(p, geoNormal)\n        \t * length(getTriplanar(p, normalize(geoNormal), id));\n\n    // Ignore kS until specular irradiance is implemented\n\tvec3 kD = vec3(1.0 - metalness);\n\tvec3 irradiance = AMBIENT_STRENGTH * getSPHIrradiance(n);\n\tvec3 diffuse    = irradiance * albedo / PI;\n\tvec3 ambient    = kD * diffuse * ao; \n    \n    return ambient + I;\n}\n\n//---------------------------- Render ----------------------------\n\n// https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/\nvec3 ACESFilm(vec3 x){\n    return clamp((x * (2.51 * x + 0.03)) / (x * (2.43 * x + 0.59) + 0.14), 0.0, 1.0);\n}\n\nvec3 getColour(vec3 cameraPos, vec3 rayDir, float dist, int id){\n    \n    // If the ray endpoint is not at a surface\n    if (dist > MAX_DIST - EPSILON) {\n        return getEnvironment(rayDir);\n    }\n\n    // Else, determine the surface colour\n    vec3 position = cameraPos + rayDir * dist;\n    vec3 normal = getNormal(position);\n    \n    // Avoid artefacts when trying to sample detail normals across Z-plane. Shape deformation\n    // increases the region where visible errors occur.\n    if(abs(normal.z) < 1e-5){\n    \tnormal.z = 1e-5;\n    }\n    \n    normal = normalize(normal);\n    vec3 detailNormal = normalize(getDetailNormal(position, normal, dist, id));\n    return getIrradiance(position, detailNormal, rayDir, normal, id);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n    \n\t//----------------- Define a camera -----------------\n    \n    vec3 rayDir = rayDirection(60.0, fragCoord);\n\n    vec3 cameraPos = texelFetch(iChannel0, ivec2(0.5, 1.5), 0).xyz;\n\n    vec3 targetDir = -cameraPos;\n\n    vec3 up = vec3(0.0, 1.0, 0.0);\n\n    // Get the view matrix from the camera orientation\n    mat3 viewMatrix = lookAt(cameraPos, targetDir, up);\n\n    // Transform the ray to point in the correct direction\n    rayDir = normalize(viewMatrix * rayDir);\n\n    //---------------------------------------------------\n\t\n    // Track which part was hit.\n    int id = -1;\n    \n    // Find the distance to where the ray stops\n    float dist = distanceToScene(cameraPos, rayDir, MIN_DIST, MAX_DIST, id);\n    vec3 col = vec3(0);\n    \n    if (dist < MAX_DIST) {\n        vec3 position = cameraPos + rayDir * dist;\n        vec3 normal = getNormal(position);\n\n        // Avoid artefacts when trying to sample detail normals across Z-plane. Shape \n        // deformation increases the region where visible errors occur.\n        if(abs(normal.z) < 1e-5){\n            normal.z = 1e-5;\n        }\n\n        normal = normalize(normal);\n        vec3 detailNormal = normalize(getDetailNormal(position, normal, dist, id));\n        col = getIrradiance(position, detailNormal, rayDir, normal, id);\n\n        // Tonemapping\n        col = ACESFilm(EXPOSURE * col);\n\n    }else{\n        col = getEnvironment(rayDir);\n    }\n\n    // Gamma\n    col = pow(col, vec3(0.4545));\n    \n    \n    // col = texture(iChannel1, fragCoord.xy/iChannelResolution[1].xy).rrr;\n\n\n    fragColor = vec4(col, 1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//Track mouse movement and resolution change between frames and set camera position.\n\n#define PI 3.14159\n#define EPS 1e-4\n#define CAMERA_DIST 3.5\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    \n    //Work with just the first four pixels.\n    if((fragCoord.x == 0.5) && (fragCoord.y < 4.0)){\n        \n        vec4 oldMouse = texelFetch(iChannel0, ivec2(0.5), 0).xyzw;\n        vec4 mouse = (iMouse / iResolution.xyxy); \n        vec4 newMouse = vec4(0);\n\n        float mouseDownLastFrame = texelFetch(iChannel0, ivec2(0.5, 3.5), 0).x;\n        \n        //If mouse button is down and was down last frame\n        if(iMouse.z > 0.0 && mouseDownLastFrame > 0.0){\n            \n            //Difference between mouse position last frame and now.\n            vec2 mouseMove = mouse.xy-oldMouse.zw;\n            newMouse = vec4(oldMouse.xy + vec2(5.0, 3.0)*mouseMove, mouse.xy);\n        }else{\n            newMouse = vec4(oldMouse.xy, mouse.xy);\n        }\n        newMouse.x = mod(newMouse.x, 2.0*PI);\n        newMouse.y = min(0.99, max(-0.99, newMouse.y));\n\n        //Store mouse data in the first pixel of Buffer B.\n        if(fragCoord == vec2(0.5, 0.5)){\n            //Set value at first frames\n            if(iFrame < 5){\n                newMouse = vec4(-2.0, -0.2, 0.0, 0.0);\n            }\n            fragColor = vec4(newMouse);\n        }\n\n        //Store camera position in the second pixel of Buffer B.\n        if(fragCoord == vec2(0.5, 1.5)){\n            //Set camera position from mouse information.\n            vec3 cameraPos = CAMERA_DIST * vec3(sin(newMouse.x), -sin(newMouse.y), -cos(newMouse.x));\n            fragColor = vec4(cameraPos, 1.0);\n        }\n        \n        //Store resolution change data in the third pixel of Buffer B.\n        if(fragCoord == vec2(0.5, 2.5)){\n            float resolutionChangeFlag = 0.0;\n            //The resolution last frame.\n            vec2 oldResolution = texelFetch(iChannel0, ivec2(0.5, 2.5), 0).yz;\n            \n            if(iResolution.xy != oldResolution){\n            \tresolutionChangeFlag = 1.0;\n            }\n            \n        \tfragColor = vec4(resolutionChangeFlag, iResolution.xy, 1.0);\n        }\n           \n        //Store whether the mouse button is down in the fourth pixel of Buffer A\n        if(fragCoord == vec2(0.5, 3.5)){\n            if(iMouse.z > 0.0){\n            \tfragColor = vec4(vec3(1.0), 1.0);\n            }else{\n            \tfragColor = vec4(vec3(0.0), 1.0);\n            }\n        }\n        \n    }\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"Xsf3Rr","filepath":"/media/a/79520a3d3a0f4d3caa440802ef4362e99d54e12b1392973e4ea321840970a88a.jpg","previewfilepath":"/media/ap/79520a3d3a0f4d3caa440802ef4362e99d54e12b1392973e4ea321840970a88a.jpg","type":"texture","channel":2,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// Heightmap for a knitted texture.\n\nfloat saturate(float x){\n\treturn clamp(x, 0.0, 1.0);\n}\n\nfloat remap(float x, float low1, float high1, float low2, float high2){\n\treturn low2 + (x - low1) * (high2 - low2) / (high1 - low1);\n}\n\nvec2 rotate(vec2 p, float angle){\n\treturn mat2(cos(angle), sin(angle), -sin(angle), cos(angle)) * p;\n}\n\nfloat circularOut(float f){\n  return sqrt((2.0 - f) * f);\n}\n\nfloat getCellHeight(vec2 p, vec2 id){\n    \n    vec2 height;\n    \n    float d = circularOut(1.0-length(p.x));\n    float detail;\n    float angle;\n    \n    float theta = sin(7.38);\n\tfloat detailTheta = sin(1.68);\n    \n    float repeat = 4.0;\n    float threadRepeat = 30.0;\n    \n    if(mod(id.x, 2.0) == 0.0){\n        detail = 0.85*abs(cos(repeat*(rotate(p, theta)).x));\n        angle = detailTheta;\n    }else{\n        detail = 0.85*abs(cos(-repeat*(rotate(p, -theta)).x));\n        angle = -detailTheta;\n    }\n    \n    d = pow(d, 2.0) * saturate(remap(d, detail, 1.1, 0.0, 1.0));\n    detail = 0.12 * sin(threadRepeat*(rotate(p, angle)).x);\n  \n    return saturate(remap(d, detail, 1.0, 0.0, 1.0));\n\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){    \n    \n    bool resolutionChanged = (texelFetch(iChannel0, ivec2(0.5, 2.5), 0).x == 1.0);\n    \n    // Draw map at the first frame or when the resolution has changed.\n    if(iFrame < 1 || resolutionChanged || length(texture(iChannel2, vec2(0)).rgb) > 0.0){\n    \tvec2 scale = vec2(10.0, 4.0);\n        vec2 uv;\n        float height;\n        uv = fragCoord.xy/iResolution.xy;\n        uv *= scale;\n        vec2 p = fract(uv)-0.5;\n        vec2 id = floor(uv);\n\n        height = getCellHeight(p, id);\n        fragColor = vec4(height, \n                         length(texture(iChannel2, (fragCoord/iResolution.xy)).rgb), \n                         0.0, \n                         1.0);\n    }else{\n        fragColor = texelFetch(iChannel1, ivec2(fragCoord), 0);\n    }\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"XsX3zn","filepath":"/media/a/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","previewfilepath":"/media/ap/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","type":"cubemap","channel":2,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"//\n//\tDiffuse IBL using spherical harmonics\n//\n// \tRead the environment map and calculate 9 spherical harmonics coefficients for each channel.\n//\tThe coefficients will describe the low frequency data of the environment. We can use them\n//\tto construct a matrix which, when multiplied with a view vector, will give the data in \n//\tthat direction. The low frequency data is similar to a convoluted irradiance map and is \n//\tused for diffuse image based lighting, which gives us the ambient colour for shading. \n//\n//\tBased on:\n//\t[1] https://cseweb.ucsd.edu/~ravir/papers/envmap/envmap.pdf\n//\t[2] http://orlandoaguilar.github.io/sh/spherical/harmonics/irradiance/map/2017/02/12/SphericalHarmonics.html\n//\t[3] https://metashapes.com/blog/realtime-image-based-lighting-using-spherical-harmonics/\n//\t[4]\thttps://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere/26127012#26127012\n//\t[5] https://bduvenhage.me/geometry/2019/07/31/generating-equidistant-vectors.html\n//  [6] https://andrew-pham.blog/2019/08/26/spherical-harmonics/\n//\n//\tThis tab writes the matrix from equaton 12 of [1] used in lighting calculations later.\n\n//Constants cn from equation 12 in [1]\nconst float c1 = 0.429043;\nconst float c2 = 0.511664;\nconst float c3 = 0.743125;\nconst float c4 = 0.886227;\nconst float c5 = 0.247708;\n\n//First 9 spherical harmonic coefficients from equation 3 in [1]\nconst float Y00 = 0.282095;\nconst float Y1n = 0.488603; // 3 direction dependent values\nconst float Y2n = 1.092548; // 3 direction dependent values\nconst float Y20 = 0.315392;\nconst float Y22 = 0.546274;\n\nvec3 getRadiance(vec3 dir){\n    //Shadertoy textures are gamma corrected. Undo for lighting calculations.\n    vec3 col = inv_gamma(texture(iChannel2, dir).rgb);\n    // Add some bloom to the environment\n    col += 0.5 * pow(col, vec3(2));\n    return col;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n    vec3 currentColour = texture(iChannel2, vec3(1,1,1)).rgb;\n\n    bool cubemapChangedFlag = texelFetch(iChannel1, ivec2(4.5, 4.5), 0).rgb != currentColour;\n    bool resolutionChanged = texelFetch(iChannel0, ivec2(0.5, 2.5), 0).r > 0.0;\n    bool run = iFrame == 0 || cubemapChangedFlag || resolutionChanged;\n     \n    //Cubemap load may take a while. Run code first frame and while last frame flag was 0\n    if(run){\n    \n    vec4 col = vec4(0);\n        \n        //  Store an equirectangular projection of the environment map. Subsequent code will\n        //  overwrite specific pixels to store the SPH matrices and state flags but this \n        //  should not be visible in the final redner.\n        vec2 texCoord = fragCoord.xy / iResolution.xy;\n        vec2 thetaphi = ((texCoord * 2.0) - vec2(1.0)) * vec2(PI, HALF_PI); \n        vec3 rayDir = vec3( cos(thetaphi.y) * cos(thetaphi.x), \n                           -sin(thetaphi.y), \n                            cos(thetaphi.y) * sin(thetaphi.x));\n\n        col = vec4(getRadiance(rayDir), 1.0);\n        //Ensure radiance is not 0\n        col.x = max(col.x, 1e-5);\n        col.y = max(col.y, 1e-5);\n        col.z = max(col.z, 1e-5);\n\n        //Coefficient values to accumulate\n        vec3 L00 = vec3(0);\n        vec3 L1_1 = vec3(0);\n        vec3 L10 = vec3(0);\n        vec3 L11 = vec3(0);\n\n        vec3 L2_2 = vec3(0);\n        vec3 L2_1 = vec3(0);\n        vec3 L20 = vec3(0);\n        vec3 L21 = vec3(0);\n        vec3 L22 = vec3(0);\n\n        //To make the sampling rate scalable and independent of the cubemap dimensions, we can \n        //sample a set number of equidistant directions on a sphere. While this is not doable \n        //for all number of directions, a good approximation is the Fibonacci spiral on a \n        //sphere.\n\n        //From [4]\n        //Golden angle in radians\n        float phi = PI * (3.0 - sqrt(5.0));\n        float pointCount;\n        \n        if(run){\n            pointCount = 1024.0;\n        }else{\n            pointCount = 1.0;\n            return;\n        }\n\n        for(float i = 0.0; i < pointCount; i++){\n\n            float y = 1.0 - (i / pointCount) * 2.0;\n            //Radius at y\n            float radius = sqrt(1.0 - y * y);  \n\n            //Golden angle increment\n            float theta = phi * i;\n\n            float x = cos(theta) * radius;\n            float z = sin(theta) * radius;\n\n            //Sample directiion\n            vec3 dir = normalize(vec3(x, y, z));\n\n            //Envronment map value in the direction (interpolated)\n            vec3 radiance = getRadiance(dir);\n\n            //Accumulate value weighted by spherical harmonic coefficient in the direction\n            L00 += radiance * Y00;\n            L1_1 += radiance * Y1n * dir.y;\n            L10 += radiance * Y1n * dir.z;\n            L11 += radiance * Y1n * dir.x;\n            L2_2 += radiance * Y2n * dir.x * dir.y;\n            L2_1 += radiance * Y2n * dir.y * dir.z;\n            L20 += radiance * Y20 * (3.0 * pow(dir.z, 2.0) - 1.0);\n            L21 += radiance * Y2n * dir.x * dir.z;\n            L22 += radiance * Y22 * (pow(dir.x, 2.0) - pow(dir.y, 2.0));\n        }\n\n        //Scale the sum of coefficents on a sphere\n        float factor = 4.0*PI / pointCount;\n        \n        L00 *= factor;\n        L1_1 *= factor;\n        L10 *= factor;\n        L11 *= factor;\n        L2_2 *= factor;\n        L2_1 *= factor;\n        L20 *= factor;\n        L21 *= factor;\n        L22 *= factor;\n\n        //Write 4x4 matrix to bufferB\n        //GLSL matrices are column major\n        if(fragCoord.x < 3.0 && fragCoord.y < 4.0){\n\n            int idxM = int(fragCoord.y-0.5);\n\n            if(fragCoord.x == 0.5){\n                mat4 redMatrix;\n                redMatrix[0] = vec4(c1*L22.r, c1*L2_2.r, c1*L21.r, c2*L11.r);\n                redMatrix[1] = vec4(c1*L2_2.r, -c1*L22.r, c1*L2_1.r, c2*L1_1.r);\n                redMatrix[2] = vec4(c1*L21.r, c1*L2_1.r, c3*L20.r, c2*L10.r);\n                redMatrix[3] = vec4(c2*L11.r, c2*L1_1.r, c2*L10.r, c4*L00.r-c5*L20.r);\n                col = redMatrix[idxM];\n            }\n\n            if(fragCoord.x == 1.5){\n                mat4 grnMatrix;\n                grnMatrix[0] = vec4(c1*L22.g, c1*L2_2.g, c1*L21.g, c2*L11.g);\n                grnMatrix[1] = vec4(c1*L2_2.g, -c1*L22.g, c1*L2_1.g, c2*L1_1.g);\n                grnMatrix[2] = vec4(c1*L21.g, c1*L2_1.g, c3*L20.g, c2*L10.g);\n                grnMatrix[3] = vec4(c2*L11.g, c2*L1_1.g, c2*L10.g, c4*L00.g-c5*L20.g);\n                col = grnMatrix[idxM];\n            }\n\n            if(fragCoord.x == 2.5){\n                mat4 bluMatrix;\n                bluMatrix[0] = vec4(c1*L22.b, c1*L2_2.b, c1*L21.b, c2*L11.b);\n                bluMatrix[1] = vec4(c1*L2_2.b, -c1*L22.b, c1*L2_1.b, c2*L1_1.b);\n                bluMatrix[2] = vec4(c1*L21.b, c1*L2_1.b, c3*L20.b, c2*L10.b);\n                bluMatrix[3] = vec4(c2*L11.b, c2*L1_1.b, c2*L10.b, c4*L00.b-c5*L20.b);\n                col = bluMatrix[idxM];\n            }\n        }\n        \n                //Store a sample colour of the cubemap to detect load and change\n        if(fragCoord.x == 4.5 && fragCoord.y == 4.5){\n              col = vec4(texture(iChannel2, vec3(1,1,1)).rgb, 1.0);\n        }\n        \n        fragColor = col;\n    }else{\n        //Reuse SH matrices\n        fragColor = texture(iChannel1, fragCoord.xy/iResolution.xy);\n    }\n}","name":"Buffer C","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"/*\n    Copyright (c) 2020 al-ro\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in all\n    copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    SOFTWARE.\n*/\n\n#define PI 3.14159\n#define HALF_PI (0.5 * PI)\n#define TWO_PI (2.0 * PI)\n#define GAMMA 2.2\n#define INV_GAMMA 1.0/GAMMA\n\nvec3 gamma(vec3 col){\n\treturn pow(col, vec3(INV_GAMMA));\n}\n\nvec3 inv_gamma(vec3 col){\n\treturn pow(col, vec3(GAMMA));\n}\n","name":"Common","description":"","type":"common"}]}
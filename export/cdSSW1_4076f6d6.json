{"ver":"0.1","info":{"id":"cdSSW1","date":"1670194409","viewed":155,"name":"Kuwahara Filter Inspiration","username":"trancor","description":"(WIP)\nSuch a long standing \"noise reduction\" concept, the Kuwahara Filter\nYet looks so much better as style and vibe","likes":2,"published":1,"flags":32,"usePreview":0,"tags":["filter","kuwahara","sampling","stylize","augment"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Work In Progress\n//\n// Mostly making this to test methods of detail smoothing & edge detection\n//   I normally do two passes or funcs, smoothing in one, edge in another\n//   Yet seems Kuwahara's quadrant based filtering\n//     Would be able to determine edges easily enough while filtering\n//\n// Some kuwahara inspired filter testing and other tests inspired by it\n// Kuwahara Filter -\n//   https://en.wikipedia.org/wiki/Kuwahara_filter\n\n// -- -- -- -- --\n\n// Filter Functions and Info Links in `Common`\n\n// Available Filters Below-\n//   Default Kuwahara ; Quadrants with Equal Weighting\n//    - 0 ; Quadrant Sampling\n//    - 1 ; Sampling with Edge detection\n//    - 2 ; Sampling with Limited Distance Edge detection (-- Currently Active --)\n//    - 3 ; Sampling with Edge Normal/Direction detection\n//            With animated 'light' source and edge shading..ish\n// Set filter # below to display -\n#define DISPLAY_FILTER 2\n\n// When Edges available, how much of each section draw edges (0-1)\n#define EDGE_DRAW_RANGE 0.4\n\n// -- -- -- -- --\n// -- -- -- -- --\n// -- -- -- -- --\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 resRatio = 1.0 / iResolution.xy;\n    vec2 pixelRatio = vec2( 1.0, iResolution.y/iResolution.x );\n    vec2 uv = fragCoord * resRatio;\n\n    float time = iTime ;\n    float sinTime = sin(time);\n    float cosTime = sin(time);\n    float absTime = abs(sinTime);\n\n\n    // Time varying pixel color\n    vec4 outCd = vec4( uv, 0.0, 1.0 );\n\n    outCd = texture(iChannel0, uv);\n    \n    // Each section separated by a red bar\n    //   The filter ammount, or how far it searches to blend like colors, is -\n    //     Current Section Number * filterBandsMaxStep\n    //   So default reach values, left to right, are - 5, 10, 15\n    \n    float filterBandCount = 3.0;\n    float filterBandsMaxStep = 5.0;\n    float invStepBands = .1; // 1.0/filterStepBands;\n    \n    // Per Filter Visualization Section\n    //   From bottom of section up, draw found edges overlay\n    float edgeBlender = step( fract(uv.y*4.0), EDGE_DRAW_RANGE );\n    \n    \n    // -- -- -- -- --\n    \n    vec2 stepSize = vec2( resRatio )  ;\n    float separators = step( abs(fract(uv.x*filterBandCount)), .005) * .5 * step(.005,uv.x);\n    vec2 baseStepCount = vec2( floor(uv.x*filterBandCount + 1.0) * filterBandsMaxStep );\n    \n    vec2 stepCount = mix( baseStepCount, vec2( baseStepCount.x*(absTime) + 1.0), 1.0);\n    \n    vec4 kuwFilterCd = outCd;\n    float kuwFilterEdges = 0.0;\n    vec3 kuwFilterEdgeNorms = vec3(0.0);\n    float edgeDetectionDistance = 1.0;\n    \n    \n    // User Interaction Data & GUI\n    //  ( Work In Progress )\n    //outCd.xyz = texture(iChannel1, uv).xyz;\n    \n    \n    // -- -- -- -- --\n    // -- -- -- -- --\n    // -- -- -- -- --\n    //\n    // Filter 1 -\n    //   Default Kuwahara Filter, No edge detection\n#if (DISPLAY_FILTER == 0)\n    kuwFilterCd = kuwaharaFilter(  iChannel0, uv, stepSize, stepCount );\n#endif\n    \n    // -- -- -- -- --\n    //\n    // Filter 2 -\n    //   Default Kuwahara Filter, with edge-falloff detection\n#if (DISPLAY_FILTER == 1)\n    kuwaharaEdgeFilter(  iChannel0, uv, stepSize, stepCount, kuwFilterCd, kuwFilterEdges );\n    \n    // Tighten edge value\n    kuwFilterEdges = 1.0-(1.0-kuwFilterEdges)*(1.0-kuwFilterEdges);\n    //kuwFilterEdges *= kuwFilterEdges;\n    kuwFilterEdges = step(.65, kuwFilterEdges);\n#endif\n    \n    // -- -- -- -- --\n    //\n    // Filter 3 -\n    // Kuwahara Filter, with edge detection limited to a given distance from UV\n#if (DISPLAY_FILTER == 2)\n    // Distance from current UV for edge-falloff detection influence\n    //   Edge thickness, more or less\n    edgeDetectionDistance = 2.0 ;\n    \n    kuwaharaEdgeLimitFilter(  iChannel0, uv, stepSize, stepCount, edgeDetectionDistance, kuwFilterCd, kuwFilterEdges );\n    // Edge output is 0-max difference between current pixel and average\n    //   Currently in manhattan distance, not length()\n    kuwFilterEdges = step(0.19, kuwFilterEdges);\n#endif\n    \n    // -- -- -- -- --\n    //\n    // Filter 4 -\n    // Kuwahara Filter, with edge tangent normal\n#if (DISPLAY_FILTER == 3)\n    // Distance from current UV for edge-falloff detection influence\n    //   Edge thickness, more or less\n    edgeDetectionDistance = .0 ;\n    \n    vec2 normalStepCount = vec2( 5.0 );\n    kuwaharaEdgeNormalFilter(  iChannel0, uv, stepSize, normalStepCount, edgeDetectionDistance, kuwFilterCd, kuwFilterEdgeNorms );\n    kuwFilterEdges = kuwFilterEdgeNorms.x;\n    edgeBlender = 0.0; // Wont draw edges\n    separators = 0.0; // Wont draw red separators\n    vec2 edgeNormal = ( vec2(-kuwFilterEdgeNorms.y, kuwFilterEdgeNorms.z) );\n    \n    vec2 lightSource = vec2(0.0,1.0);\n    lightSource.x = sinTime*.45+.5;\n    lightSource.y = cos(time*.5)*.45+.5;\n    \n    vec2 lightDir = (lightSource-uv)*pixelRatio*1.5;\n    float lightDist = min(1.0, length(lightDir)); // * kuwFilterEdgeNorms.x);\n    lightDir = normalize(lightDir);\n    \n    float lightDot = dot( lightDir, edgeNormal )*.85+.85;\n    lightDot = mix( lightDot, 0.0, lightDist);\n    kuwFilterCd.xyz *= lightDot;\n    //kuwFilterCd.xyz = vec3( normalize(edgeNormal), 0.0 );\n    \n    vec4 lightColor = vec4(0.8,0.95,1.0,0.5);\n    vec2 distVec = 25.0*pixelRatio.xy; // Higher is smaller light :/\n    drawRadialGradient( kuwFilterCd, uv, lightSource, distVec, lightColor ); \n#endif\n\n    // -- -- -- -- --\n    // -- -- -- -- --\n    // -- -- -- -- --\n    \n    outCd = kuwFilterCd;\n    \n    // Draw Edges Overlay\n    outCd.xyz = mix( outCd.xyz, vec3(1.0,0.0,1.0), edgeBlender * kuwFilterEdges );\n    \n    // Add Seperators\n    outCd = mix( outCd, vec4(1,0,0,1), separators);\n    \n\n    // Output to screen\n    fragColor = outCd;\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"XsXGRn","filepath":"/media/a/cd4c518bc6ef165c39d4405b347b51ba40f8d7a065ab0e8d2e4f422cbc1e8a43.jpg","previewfilepath":"/media/ap/cd4c518bc6ef165c39d4405b347b51ba40f8d7a065ab0e8d2e4f422cbc1e8a43.jpg","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGRn","filepath":"/media/a/e6e5631ce1237ae4c05b3563eda686400a401df4548d0f9fad40ecac1659c46c.jpg","previewfilepath":"/media/ap/e6e5631ce1237ae4c05b3563eda686400a401df4548d0f9fad40ecac1659c46c.jpg","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dfGRn","filepath":"/media/a/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","previewfilepath":"/media/ap/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","type":"texture","channel":2,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"Xsf3zn","filepath":"/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"/media/ap/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":3,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// A \"source image\" I guess\n//   Just some sort of input for the filters\n\n#define DRAW_SQUARE_RES 0\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 resRatio = 1.0 / iResolution.xy;\n    \n    // Center uv sampling on screen\n    //   Res Height determinate \n#if ( DRAW_SQUARE_RES > 0 )\n    float uShift = ((iResolution.y - iResolution.x) * .5) * resRatio.y;\n    resRatio.x=resRatio.y; // Eh, make it square\n    vec2 uv = vec2( ( fragCoord.x*resRatio.x + uShift), fragCoord.y * resRatio.y );\n#else\n    vec2 uv = fragCoord * resRatio;\n#endif\n\n    \n    vec3 cdA = texture(iChannel0, uv).xyz;\n    vec3 cdB = texture(iChannel1, uv).xyz;\n    vec3 cdC = texture(iChannel2, uv).xyz;\n    vec3 cdD = texture(iChannel3, uv).xyz;\n    \n    vec3 outCd = mix( cdA, cdB, step(.25, uv.y) );\n    outCd = mix( outCd, cdC, step(.5, uv.y) );\n    outCd = mix( outCd, cdD, step(.75, uv.y) );\n    \n    //outCd.xyz = cdA.xyz;\n    \n    fragColor = vec4( outCd, 1.0 );\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"// Kuwahara Filter Wiki\n//   https://en.wikipedia.org/wiki/Kuwahara_filter\n//\n// Info for advancements to the original Kuwahara filter from the 1970s\n//   Points to note in the paper linked below -\n//     Ansitropic weighting logic\n//     N sampling regions, not just 4\n//     Rotation/Scaling/Skewing of sampling regions for better edge retention\n//     Using polynomial fall off logic for better performance\n//       Rather than blending based on a gaussian weighted falloff\n//   http://www.umsl.edu/~kangh/Papers/kang-tpcg2010.pdf\n//\n// --\n//\n//  Kuwahara Filter logic -\n//    Box blur, but per quadrant around the  frag\n//      (1,1), (-1,1), (-1,-1), (1,-1)\n//    Gather average color of each quadrant\n//      Then use the quadrant average value with the lowest delta to the current pixel's color\n//    This will blur noise yet \"retain\" edges in the image\n//\n// --\n// \n// Findings\n//   Edges arn't as free as expected\n//   But allows for emboss and edge normal direction\n//   Color to Normal Vector possible\n//     Within reason and some pre-set assumptions\n//\n// \n// --\n//\n// List of Filters below -\n//  - Default Kuwahara Filter, square quadran\n//\n\n\n// -- -- -- --\n// Helper Functions\n//   ( Filter functions below )\n// Not all are used, leaving for easy copy'pasta\n\n// Manhattan Length of Vectors\nfloat manhattan(vec3 val){\n    val = abs(val);\n    return val.x+val.y+val.z;\n}\nfloat manhattan(vec4 val){\n    val = abs(val);\n    return val.x+val.y+val.z+val.w;\n}\nfloat manhattan(vec3 v1, vec3 v2){\n    vec3 val = abs(v2-v1);\n    return val.x+val.y+val.z;\n}\nfloat manhattan(vec4 v1, vec4 v2){\n    vec4 val = abs(v2-v1);\n    return val.x+val.y+val.z+val.w;\n}\n\n// Distance as float, no pixel ratio consideration\nvoid drawRadialGradient( inout vec4 kuwFilterCd, vec2 uv, vec2 lightSource, float dist, vec4 lightColor ){\n    vec3 outCd = kuwFilterCd.xyz;\n    float deltaLen = 1.0 - min( 1.0, length( lightSource - uv ) / dist );\n    deltaLen = 1.0-(1.0-deltaLen)*(1.0-deltaLen);\n    //deltaLen = min(1.0, deltaLen*1.2);\n    deltaLen *= lightColor.a;\n    kuwFilterCd.xyz = mix( outCd.xyz, lightColor.xyz, deltaLen);\n}\n// Distance as vec2 to allow for oblong gradients; pixel ratio correction mostly\nvoid drawRadialGradient( inout vec4 kuwFilterCd, vec2 uv, vec2 lightSource, vec2 dist, vec4 lightColor ){\n    vec3 outCd = kuwFilterCd.xyz;\n    float deltaLen = 1.0 - min( 1.0, length( (lightSource - uv ) * dist ));\n    deltaLen = 1.0-(1.0-deltaLen)*(1.0-deltaLen);\n    //deltaLen = min(1.0, deltaLen*1.2);\n    deltaLen *= lightColor.a;\n    kuwFilterCd.xyz = mix( outCd.xyz, lightColor.xyz, deltaLen);\n}\n\n// -- -- -- -- -- -- -- -- -- -- --\n// -- -- -- -- -- -- -- -- -- -- --\n// -- -- -- -- -- -- -- -- -- -- --\n\n\n// Default Kuwahara Filter\n//\n// Default Kuwahara; Quadrant Sampling\nvoid kuwaharaSample( sampler2D tex, vec2 baseUv, vec2 stepSize, ivec2 stepCount,\n                     vec4 baseCd, vec2 quadrant, inout vec4 baseAvgCd, inout float baseMinDelta ){\n  vec4 curAvgCd, curCd = vec4(0,0,0,0);\n  vec2 curUvOffset;\n  int x,y;\n  for( x=0; x < stepCount.x; ++x ){\n      for( y=0; y < stepCount.y; ++y ){\n          curUvOffset = stepSize * vec2( x, y ) * quadrant;\n          curCd = texture(tex, baseUv + curUvOffset);\n          curAvgCd += curCd;\n      }\n  }\n  \n  curAvgCd /= float(stepCount.x * stepCount.y);\n  float curCdDelta = length( curAvgCd - baseCd );\n  baseAvgCd = mix( curAvgCd, baseAvgCd, step( baseMinDelta, curCdDelta ) );\n  baseMinDelta = min( baseMinDelta, curCdDelta );\n}\n//\n// baseUv - current uv\n// stepSize - pixel ratio; 1.0/uv\n// stepCount - iteration steps per axis in quadrant\n//\nvec4 kuwaharaFilter(  sampler2D tex, vec2 baseUv, vec2 stepSize, vec2 stepCount ){\n\n  vec2 curUv, curUvOffset;\n  vec4 curCd;\n  float curCdDelta;\n  vec4 baseCd = texture(tex, baseUv);\n  vec4 curAvgCd = vec4(0,0,0,0);\n  \n  vec2 reachMult = stepSize;\n  float blend = 1.0;\n  \n  ivec2 iStepCount = ivec2( int(stepCount) );\n  \n  int x,y;\n  float avgCount = 0.0;\n  vec2 quadrant;\n  \n  float minDelta = 999.0;\n  vec4 minAvgCd = baseCd;\n  \n  // One quadrant at a time\n  \n  quadrant = vec2( 1, 1 );\n  kuwaharaSample( tex, baseUv, stepSize, iStepCount, baseCd, quadrant, minAvgCd, minDelta );\n  \n  quadrant = vec2( -1, 1 );\n  kuwaharaSample( tex, baseUv, stepSize, iStepCount, baseCd, quadrant, minAvgCd, minDelta );\n  \n  quadrant = vec2( -1, -1 );\n  kuwaharaSample( tex, baseUv, stepSize, iStepCount, baseCd, quadrant, minAvgCd, minDelta );\n  \n  quadrant = vec2( 1, -1 );\n  kuwaharaSample( tex, baseUv, stepSize, iStepCount, baseCd, quadrant, minAvgCd, minDelta );\n  \n  // -- -- -- --\n  \n  vec4 blendCd = minAvgCd;\n  return blendCd;\n}\n\n\n// -- -- -- -- -- -- -- -- -- -- --\n// -- -- -- -- -- -- -- -- -- -- --\n// -- -- -- -- -- -- -- -- -- -- --\n\n\n// Default Kuwahara Filter\n//\n// Default Kuwahara; Sampling with Edge consideration\nvoid kuwaharaEdgeSample( sampler2D tex, vec2 baseUv, vec2 stepSize, ivec2 stepCount,\n                         vec4 baseCd, vec2 quadrant, inout vec4 baseAvgCd, inout float baseMinDelta, inout float baseMaxDelta ){\n  vec4 curAvgCd, curCd = vec4(0,0,0,0);\n  vec2 curUvOffset;\n  int x,y;\n  for( x=0; x < stepCount.x; ++x ){\n      for( y=0; y < stepCount.y; ++y ){\n          curUvOffset = stepSize * vec2( x, y ) * quadrant;\n          curCd = texture(tex, baseUv + curUvOffset);\n          curAvgCd += curCd;\n      }\n  }\n  \n  curAvgCd /= float(stepCount.x * stepCount.y);\n  float curCdDelta = length( curAvgCd - baseCd );\n  baseAvgCd = mix( curAvgCd, baseAvgCd, step( baseMinDelta, curCdDelta ) );\n  baseMinDelta = min( baseMinDelta, curCdDelta );\n  baseMaxDelta = max( baseMaxDelta, curCdDelta );\n}\n//\n// baseUv - current uv\n// stepSize - pixel ratio; 1.0/uv\n// stepCount - iteration steps per axis in quadrant\nvoid kuwaharaEdgeFilter(  sampler2D tex, vec2 baseUv, vec2 stepSize, vec2 stepCount, inout vec4 filterCd, inout float foundEdges ){\n\n  vec2 curUv, curUvOffset;\n  vec4 curCd;\n  float curCdDelta;\n  vec4 baseCd = texture(tex, baseUv);\n  vec4 curAvgCd = vec4(0,0,0,0);\n  \n  vec2 reachMult = stepSize;\n  \n  ivec2 iStepCount = ivec2( int(stepCount) );\n  \n  int x,y;\n  float avgCount = 0.0;\n  vec2 quadrant;\n  \n  float minDelta = 999.0; // Determines average color output\n  float maxDelta = 0.0; // Edge value output\n  \n  vec4 minAvgCd = baseCd;\n  \n  // One quadrant at a time\n  \n  quadrant = vec2( 1, 1 );\n  kuwaharaEdgeSample( tex, baseUv, stepSize, iStepCount, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  quadrant = vec2( -1, 1 );\n  kuwaharaEdgeSample( tex, baseUv, stepSize, iStepCount, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  quadrant = vec2( -1, -1 );\n  kuwaharaEdgeSample( tex, baseUv, stepSize, iStepCount, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  quadrant = vec2( 1, -1 );\n  kuwaharaEdgeSample( tex, baseUv, stepSize, iStepCount, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  // -- -- -- --\n  \n   filterCd = minAvgCd;\n   foundEdges = maxDelta;\n  \n}\n\n\n// -- -- -- -- -- -- -- -- -- -- --\n// -- -- -- -- -- -- -- -- -- -- --\n// -- -- -- -- -- -- -- -- -- -- --\n\n\n// Default Kuwahara Filter with Edge Sampling\n//   Edge Detection limited to a single step\n//     To aid with getting a desired style but also sharp edge detections\n//\n// Default Kuwahara; Sampling with limited Edge consideration\n//   baseMaxDelta - Current edge detection value\nvoid kuwaharaEdgeLimitSample( sampler2D tex, vec2 baseUv, vec2 stepSize, ivec2 stepCount, float edgeReach,\n                         vec4 baseCd, vec2 quadrant, inout vec4 baseAvgCd, inout float baseMinDelta, inout float baseMaxDelta ){\n  vec4 curAvgCd, curCd = vec4(0,0,0,0);\n  vec2 curUvOffset;\n  float curCdDelta;\n  float doEdgeSample=0.0;\n  float maxSampledDelta=0.0;\n  int x,y;\n  for( x=0; x < stepCount.x; ++x ){\n      for( y=0; y < stepCount.y; ++y ){\n          curUvOffset = stepSize * vec2( x, y ) * quadrant;\n          curCd = texture(tex, baseUv + curUvOffset);\n          curAvgCd += curCd;\n          \n          // Edge detection offset, should sample be desired outside of x == y == 0\n          //   Sampling all quadrants, no matter weighting\n          doEdgeSample = step( float(x+y), edgeReach+.1 );\n          curCdDelta = min(1.0, manhattan( curCd.xyz - baseCd.xyz ) );\n          maxSampledDelta = mix( maxSampledDelta, max( maxSampledDelta, curCdDelta ), doEdgeSample );\n      }\n  }\n  \n  curAvgCd /= float(stepCount.x * stepCount.y);\n  curCdDelta = length( curAvgCd - baseCd );\n  baseAvgCd = mix( curAvgCd, baseAvgCd, step( baseMinDelta, curCdDelta ) );\n  \n  curCdDelta = min(1.0, manhattan( curAvgCd.xyz - baseCd.xyz ) );\n  // Agh... This is wrong, this is putting edge preference on lowest delta not highest\n  //   I'll fix later, cause would be two different results\n  doEdgeSample = step( .1, curCdDelta ) * step( curCdDelta, baseMinDelta );\n  baseMaxDelta = mix( baseMaxDelta, maxSampledDelta, doEdgeSample );\n  \n  baseMinDelta = min( baseMinDelta, curCdDelta );\n\n}\n//\n// baseUv - current uv\n// stepSize - pixel ratio; 1.0/uv\n// stepCount - iteration steps per axis in quadrant\nvoid kuwaharaEdgeLimitFilter(  sampler2D tex, vec2 baseUv, vec2 stepSize, vec2 stepCount, float edgeReach, inout vec4 filterCd, inout float foundEdges ){\n\n  vec2 curUv, curUvOffset;\n  vec4 curCd;\n  float curCdDelta;\n  vec4 baseCd = texture(tex, baseUv);\n  vec4 curAvgCd = vec4(0,0,0,0);\n  \n  vec2 reachMult = stepSize;\n  \n  ivec2 iStepCount = ivec2( int(stepCount) );\n  \n  int x,y;\n  float avgCount = 0.0;\n  vec2 quadrant;\n  \n  float minDelta = 999.0; // Determines average color output\n  float maxDelta = 0.0; // Edge value output\n  \n  vec4 minAvgCd = baseCd;\n  \n  // One quadrant at a time\n  \n  quadrant = vec2( 1, 1 );\n  kuwaharaEdgeLimitSample( tex, baseUv, stepSize, iStepCount, edgeReach, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  quadrant = vec2( -1, 1 );\n  kuwaharaEdgeLimitSample( tex, baseUv, stepSize, iStepCount, edgeReach, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  quadrant = vec2( -1, -1 );\n  kuwaharaEdgeLimitSample( tex, baseUv, stepSize, iStepCount, edgeReach, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  quadrant = vec2( 1, -1 );\n  kuwaharaEdgeLimitSample( tex, baseUv, stepSize, iStepCount, edgeReach, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  // -- -- -- --\n  \n   filterCd = minAvgCd;\n   foundEdges = maxDelta;\n  \n}\n\n\n// -- -- -- --\n\n\n\n\n// -- -- -- -- -- -- -- -- -- -- --\n// -- -- -- -- -- -- -- -- -- -- --\n// -- -- -- -- -- -- -- -- -- -- --\n\n// Default Kuwahara Filter with Edge Normal Calculations\n//   ( Work in Progress )\n//\n// Default Kuwahara; Sampling with Edge direction consideration\n//   baseMaxDelta - vec3( Current edge detection value, Edge X Direction, Edge Y Direction )\nvoid kuwaharaEdgeNormalSample( sampler2D tex, vec2 baseUv, vec2 stepSize, ivec2 stepCount, float edgeReach,\n                         vec4 baseCd, vec2 quadrant, inout vec4 baseAvgCd, inout float baseMinDelta, inout vec3 baseMaxDelta ){\n  vec4 curAvgCd, curCd = vec4(0,0,0,0);\n  vec2 curUvOffset;\n  float curCdDelta;\n  float doEdgeSample=0.0;\n  float maxSampledDelta=0.0;\n  int x,y;\n  for( x=0; x < stepCount.x; ++x ){\n      for( y=0; y < stepCount.y; ++y ){\n          curUvOffset = stepSize * vec2( x, y ) * quadrant;\n          curCd = texture(tex, baseUv + curUvOffset);\n          curAvgCd += curCd;\n          \n          // Edge detection offset, should sample be desired outside of x == y == 0\n          //   Sampling all quadrants, no matter weighting\n          doEdgeSample = step( float(x+y), edgeReach+.1 );\n          curCdDelta = min(1.0, manhattan( curCd.xyz - baseCd.xyz ) );\n          maxSampledDelta = mix( maxSampledDelta, max( maxSampledDelta, curCdDelta ), doEdgeSample );\n      }\n  }\n  \n  curAvgCd /= float(stepCount.x * stepCount.y);\n  curCdDelta = length( curAvgCd - baseCd );\n  baseAvgCd = mix( curAvgCd, baseAvgCd, step( baseMinDelta, curCdDelta ) );\n  \n  \n  curCdDelta = min(1.0, manhattan( curAvgCd.xyz - baseCd.xyz ) );\n  doEdgeSample = step( .1, curCdDelta ) * step( baseMaxDelta.x, curCdDelta );\n  \n  float normalBoost = 1.0;\n  float doNormalBlend = min(1.0, abs( baseMaxDelta.x - maxSampledDelta ) * normalBoost ) * doEdgeSample;\n  baseMaxDelta.yz = ( mix( baseMaxDelta.yz, (quadrant), doNormalBlend ) );\n  \n  baseMaxDelta.x = mix( baseMaxDelta.x, maxSampledDelta, doEdgeSample );\n  \n  baseMinDelta = min( baseMinDelta, curCdDelta );\n\n}\n//\n// baseUv - current uv\n// stepSize - pixel ratio; 1.0/uv\n// stepCount - iteration steps per axis in quadrant\nvoid kuwaharaEdgeNormalFilter(  sampler2D tex, vec2 baseUv, vec2 stepSize, vec2 stepCount, float edgeReach, inout vec4 filterCd, inout vec3 foundEdges ){\n\n  vec2 curUv, curUvOffset;\n  vec4 curCd;\n  float curCdDelta;\n  vec4 baseCd = texture(tex, baseUv);\n  vec4 curAvgCd = vec4(0,0,0,0);\n  \n  vec2 reachMult = stepSize;\n  \n  ivec2 iStepCount = ivec2( int(stepCount) );\n  \n  int x,y;\n  float avgCount = 0.0;\n  vec2 quadrant;\n  \n  float minDelta = 999.0; // Determines average color output\n  vec3 maxDelta = vec3( 0.0 ); // vec3( Edge value, Edge Direction X, Edge Direction Y ) output\n  \n  vec4 minAvgCd = baseCd;\n  \n  // One quadrant at a time\n  \n  quadrant = vec2( 1, 1 );\n  kuwaharaEdgeNormalSample( tex, baseUv, stepSize, iStepCount, edgeReach, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  quadrant = vec2( -1, 1 );\n  kuwaharaEdgeNormalSample( tex, baseUv, stepSize, iStepCount, edgeReach, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  quadrant = vec2( -1, -1 );\n  kuwaharaEdgeNormalSample( tex, baseUv, stepSize, iStepCount, edgeReach, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  quadrant = vec2( 1, -1 );\n  kuwaharaEdgeNormalSample( tex, baseUv, stepSize, iStepCount, edgeReach, baseCd, quadrant, minAvgCd, minDelta, maxDelta );\n  \n  // -- -- -- --\n  \n   filterCd = minAvgCd;\n   foundEdges = maxDelta;\n  \n}\n\n\n// -- -- -- --\n\n\n// -- -- -- -- -- -- -- -- -- -- --\n// -- -- -- -- -- -- -- -- -- -- --\n// -- -- -- -- -- -- -- -- -- -- --\n\n\n// Not used at the moment\n//   Going to set up some compare contrasts with filter tests\n// Default box blur with added per pixel blending\n//   Cheaper than gaussian ... sorta, but better than default box\n//     Still not as good as 2-pass box blur for look and performance\nvec4 boxSample( sampler2D tex, vec2 uv, vec2 reachMult, float blend ){\n  vec2 curUVOffset;\n  vec4 curCd;\n  \n  vec4 blendCd = texture(tex, uv);\n  \n  curUVOffset = reachMult * vec2( -1.0, -1.0 );\n  curCd = texture(tex, uv+curUVOffset);\n  blendCd = mix( blendCd, curCd, blend);\n  curUVOffset = reachMult * vec2( -1.0, 0.0 );\n  curCd = texture(tex, uv+curUVOffset);\n  blendCd = mix( blendCd, curCd, blend);\n  curUVOffset = reachMult * vec2( -1.0, 1.0 );\n  curCd = texture(tex, uv+curUVOffset);\n  blendCd = mix( blendCd, curCd, blend);\n  \n  curUVOffset = reachMult * vec2( 0.0, -1.0 );\n  curCd = texture(tex, uv+curUVOffset);\n  blendCd = mix( blendCd, curCd, blend);\n  curUVOffset = reachMult * vec2( 0.0, 1.0 );\n  curCd = texture(tex, uv+curUVOffset);\n  blendCd = mix( blendCd, curCd, blend);\n  \n  curUVOffset = reachMult * vec2( 1.0, -1.0 );\n  curCd = texture(tex, uv+curUVOffset);\n  blendCd = mix( blendCd, curCd, blend);\n  curUVOffset = reachMult * vec2( 1.0, 0.0 );\n  curCd = texture(tex, uv+curUVOffset);\n  blendCd = mix( blendCd, curCd, blend);\n  curUVOffset = reachMult * vec2( 1.0, 1.0 );\n  curCd = texture(tex, uv+curUVOffset);\n  blendCd = mix( blendCd, curCd, blend);\n  \n  return blendCd;\n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGzr","filepath":"/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","previewfilepath":"/media/ap/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// Mouse/Interaction Data Storage and Functions\n//   With GUI Draws\n// (WIP)\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 resRatio = 1.0 / iResolution.xy;\n    vec2 uv = fragCoord * resRatio;\n    \n    vec3 outCd = vec3( 0.0, 0.0, 0.0 );\n    //outCd = texture(iChannel1, uv).xyz; // Prior Data\n    \n    //vec2 mouseUV = iMouse.xy * resRatio;\n    \n    //outCd = texture(iChannel0, uv).xyz; // Font\n    \n    outCd.xyz = vec3(step(0.0, iMouse.z+iMouse.w));\n    \n    fragColor = vec4( outCd, 1.0 );\n}","name":"Buffer B","description":"","type":"buffer"}]}
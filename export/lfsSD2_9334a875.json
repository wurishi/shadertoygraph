{"ver":"0.1","info":{"id":"lfsSD2","date":"1707732405","viewed":27,"name":"[inspirnathan] 00 - introduction","username":"hrst4","description":"[inspirnathan] 00 - introduction","likes":0,"published":1,"flags":0,"usePreview":0,"tags":["inspirnathan"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// This a french translation of the highly educational Nathan Vaughn's tutorials.\n// Un grand merci à lui !\n// his website: https://inspirnathan.com/\n// original:\n// from https://inspirnathan.com/posts/47-shadertoy-tutorial-part-1\n\n/*\nSalutations, chers amis ! J'ai récemment été fasciné par les shaders et \nleur incroyable qualité. Aujourd'hui, je vais vous expliquer comment créer \ndes shaders de pixels à l'aide d'un outil en ligne extraordinaire appelé Shadertoy, \ncréé par Inigo Quilez et Pol Jeremias, deux personnes extrêmement talentueuses.\n\nQu'est-ce qu'un shader ?\n\nLes shaders sont des programmes puissants qui, à l'origine, étaient destinés à \nl'ombrage d'objets dans une scène 3D. De nos jours, les shaders ont de multiples fonctions.\nLes programmes de shaders s'exécutent généralement sur le processeur graphique (GPU) \nde votre ordinateur, où ils peuvent fonctionner en parallèle.\n\n\nIl est extrêmement important de comprendre que les shaders s'exécutent en parallèle \nsur votre GPU. \nVotre programme s'exécutera indépendamment pour chaque pixel dans Shadertoy en même temps.\n\n\nLes langages de shaders tels que le High-Level Shading Language (HLSL)\net l'OpenGL Shading Language (GLSL) sont les langages les plus couramment utilisés\npour programmer le pipeline de rendu du GPU. \n\nCes langages ont une syntaxe similaire au langage de programmation C.\n\nLorsque vous jouez à un jeu tel que Minecraft, les shaders sont utilisés pour donner\nl'impression que le monde est en 3D lorsque vous le regardez à partir d'un écran en 2D \n(c'est-à-dire le moniteur de votre ordinateur ou l'écran de votre téléphone).\nLes shaders peuvent également modifier radicalement l'aspect d'un jeu en ajustant\nla façon dont la lumière interagit avec les objets ou la façon dont les objets sont\nrendus à l'écran. \n\nCette vidéo YouTube présente 10 shaders qui peuvent donner à Minecraft un aspect\ntotalement différent et démontrer la beauté des shaders.\nhttps://www.youtube.com/watch?v=1BnNAu_L4FA\n\n\nLes shaders se présentent généralement sous deux formes : \nles vertex shaders et les fragment shaders.\nLe vertex shader est utilisé pour créer les sommets des maillages 3D \nde toutes sortes d'objets tels que des sphères, des cubes, des éléphants,\nles protagonistes d'un jeu en 3D, etc. \n\nLes informations fournies par le nuanceur de sommets sont transmises au nuanceur géométrique,\nqui peut alors manipuler ces sommets ou effectuer des opérations supplémentaires \navant le nuanceur de fragments. \n\nVous n'entendrez généralement pas beaucoup parler des nuanceurs de géométrie. \nLa dernière partie du pipeline est le fragment shader.\n\nLe fragment shader calcule la couleur finale du pixel et détermine si un pixel doit\nêtre montré à l'utilisateur ou non.\n\nSupposons par exemple que nous ayons un nuanceur de vertex qui dessine\ntrois points/vertices à l'écran sous la forme d'un triangle. \nUne fois que ces sommets sont transmis au nuanceur de fragment, \nla couleur du pixel entre chaque sommet peut être remplie automatiquement.\n\nLe GPU sait très bien comment interpoler les valeurs.\nEn supposant qu'une couleur soit attribuée à chaque sommet dans le nuanceur de sommet, \nle GPU peut interpoler les couleurs entre chaque sommet pour remplir le triangle.\n\nDans les moteurs de jeu comme Unity ou Unreal, les vertex shaders et les fragment shaders \nsont largement utilisés pour les jeux en 3D.\nUnity fournit une abstraction au-dessus des shaders appelée ShaderLab,\nqui est un langage qui se superpose à HLSL pour faciliter l'écriture des shaders \npour vos jeux. En outre, Unity fournit un outil visuel appelé Shader Graph \nqui vous permet de construire des shaders sans écrire de code. \n\nSi vous cherchez \"Unity shaders\" sur Google, vous trouverez des centaines de shaders\nqui exécutent de nombreuses fonctions différentes. Vous pouvez créer des shaders qui \nfont briller les objets, rendent les personnages translucides, et même créer des \"effets\nd'image\" qui appliquent un shader à l'ensemble de la vue de votre jeu. \nIl existe un nombre infini de façons d'utiliser les shaders.\n\nVous entendrez souvent parler des nuanceurs de fragments comme des nuanceurs de pixels.\nLe terme \"nuanceur de fragment\" est plus exact, car les nuanceurs peuvent empêcher \nles pixels d'être dessinés à l'écran. Dans certaines applications telles que Shadertoy, \nvous devez dessiner chaque pixel à l'écran, il est donc plus logique de les appeler\nnuanceurs de pixels dans ce contexte.\n\nLes shaders sont également responsables du rendu de l'ombrage et de l'éclairage\ndans votre jeu, mais ils peuvent être utilisés à d'autres fins. \nUn programme de shaders peut être exécuté sur le GPU, alors pourquoi ne pas profiter \nde la parallélisation qu'il offre ? Vous pouvez créer un shader de calcul \nqui exécute des calculs lourds sur le GPU plutôt que sur le CPU. \nEn fait, Tensorflow.js tire parti du GPU pour former des modèles \nd'apprentissage automatique plus rapidement dans le navigateur.\n\nLes shaders sont des programmes puissants !\n\n\n# Qu'est-ce que Shadertoy ?\n\nDans la prochaine série de billets, je parlerai de Shadertoy. \nShadertoy est un site web qui aide les utilisateurs à créer des shaders de pixels et à\nles partager avec d'autres, un peu comme Codepen avec HTML, CSS et JavaScript.\n\nShadertoy s'appuie sur l'API WebGL pour effectuer un rendu graphique dans le navigateur\nà l'aide du GPU. WebGL vous permet d'écrire des shaders en GLSL et prend en charge \nl'accélération matérielle. \nEn d'autres termes, vous pouvez exploiter le GPU pour manipuler les pixels de \nl'écran en parallèle afin d'accélérer le rendu. \nVous souvenez-vous que vous deviez utiliser ctx.getContext('2d') lorsque vous \ntravailliez avec l'API HTML Canvas ? \nShadertoy utilise un canevas avec le contexte webgl au lieu de 2d, \nde sorte que vous pouvez dessiner des pixels à l'écran avec de meilleures \nperformances en utilisant WebGL.\n\nBien que Shadertoy utilise le GPU pour améliorer les performances de rendu,\nvotre ordinateur peut ralentir un peu lorsqu'il ouvre un shader Shadertoy \nde quelqu'un qui effectue des calculs lourds. Assurez-vous que le GPU de votre ordinateur\npeut le supporter et comprenez que cela peut épuiser la batterie de \nvotre appareil assez rapidement.\n\nLes moteurs de jeux 3D modernes tels que Unity et Unreal Engine et les logiciels de modélisation 3D tels que Blender fonctionnent très rapidement parce qu'ils utilisent à la fois un vertex shader et un fragment shader, et qu'ils effectuent de nombreuses optimisations pour vous. Dans Shadertoy, vous n'avez pas accès à un vertex shader. Vous devez vous appuyer sur des algorithmes tels que le ray marching et les champs/fonctions de distance signés (SDF) pour rendre les scènes 3D, ce qui peut s'avérer coûteux en termes de calcul.\n\nVeuillez noter que l'écriture de shaders dans Shadertoy ne garantit pas \nqu'ils fonctionneront dans d'autres environnements tels que Unity.\nIl se peut que vous deviez traduire le code GLSL en une syntaxe \nsupportée par votre environnement cible, telle que HLSL. \nShadertoy fournit également des variables globales qui peuvent ne pas être prises\nen charge dans d'autres environnements. \nQue cela ne vous arrête pas pour autant ! Il est tout à fait possible de modifier\nvotre code Shadertoy et de l'utiliser dans vos jeux ou vos logiciels de modélisation. \nCela demande juste un peu de travail supplémentaire. \nEn fait, Shadertoy est un excellent moyen d'expérimenter les shaders avant de\nles utiliser dans votre moteur de jeu ou votre logiciel de modélisation préféré.\n\nShadertoy est un excellent moyen de s'entraîner à la création de shaders \navec GLSL et vous aide à penser de manière plus mathématique. \nDessiner des scènes en 3D nécessite beaucoup d'arithmétique vectorielle. \nC'est un exercice intellectuellement stimulant et un excellent moyen de montrer \nses compétences à ses amis. \nSi vous naviguez sur Shadertoy, vous verrez des tonnes de créations magnifiques\nqui ont été dessinées uniquement à l'aide de mathématiques et de code ! Une fois\nque tu auras pris en main Shadertoy, tu verras que c'est vraiment amusant !\n\n# Introduction à Shadertoy\n(...)\n\n# Comprendre le code d'un shader\n\nWhen you first start a new shader in Shadertoy, you will find the following code:\n*/\n\n/*\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n  // Normalized pixel coordinates (from 0 to 1)\n  vec2 uv = fragCoord/iResolution.xy;\n\n  vec3 col = 0.5 + 0.5*cos(iTime+uv.xyx+vec3(0,2,4));\n\n  // Output to screen\n  fragColor = vec4(col,1.0);\n}\n*/\n\n/*\nVous pouvez exécuter le code en appuyant sur la petite flèche comme indiqué dans\nla section 8 de l'image ci-dessus ou en appuyant sur Alt+Enter ou Option+Enter\ncomme raccourci clavier.\n\nSi vous n'avez jamais travaillé avec des shaders auparavant, ce n'est pas grave ! \nJe vais faire de mon mieux pour vous expliquer la syntaxe GLSL que vous utilisez \npour écrire des shaders dans Shadertoy. \nD'emblée, vous remarquerez qu'il s'agit d'un langage à typage statique comme C, C++, Java\net C#. GLSL utilise également le concept de types. \nCertains de ces types sont : bool (booléen), int (entier), float (décimal) et vec (vecteur).\nGLSL exige également que des points-virgules soient placés à la fin de chaque ligne.\nDans le cas contraire, le compilateur émettra une erreur.\n\n\nDans l'extrait de code ci-dessus, nous définissons une fonction mainImage \nqui doit être présente dans notre shader Shadertoy.\nElle ne renvoie rien, le type de retour est donc void. \nElle accepte deux paramètres : fragColor et fragCoord.\n\nIl se peut que vous vous grattiez la tête à propos des entrées et sorties.\nPour Shadertoy, vous n'avez généralement à vous soucier de ces mots-clés \nqu'à l'intérieur de la fonction mainImage. Vous vous souvenez que j'ai dit\nque les shaders nous permettent d'écrire des programmes pour le pipeline \nde rendu du GPU ? Pensez à l'entrée et à la sortie comme à l'entrée et à la sortie.\nShadertoy nous donne une entrée, et nous écrivons une couleur en sortie.\n\nAvant de continuer, changeons le code en quelque chose d'un peu plus simple :\n*/\n\n/*\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n  // Normalized pixel coordinates (from 0 to 1)\n  vec2 uv = fragCoord/iResolution.xy;\n\n  vec3 col = vec3(0., 0., 1.); // RGB values\n\n  // Output to screen\n  fragColor = vec4(col,1.0);\n}\n\n*/\n\n/*\nLorsque nous exécutons le programme de nuanceur, \nnous devrions obtenir une toile entièrement bleue.\nLe programme de nuanceur s'exécute pour chaque pixel de la toile EN PARALLÈLE. \nIl est extrêmement important de garder cela à l'esprit. Vous devez réfléchir à \nla manière d'écrire un code qui changera la couleur du pixel en fonction de la \ncoordonnée du pixel. \n\nIl s'avère que nous pouvons créer des œuvres d'art étonnantes en utilisant\nuniquement les coordonnées des pixels !\n\nDans les shaders, nous spécifions les valeurs RVB (rouge, vert, bleu) \nen utilisant une plage comprise entre zéro et un. \nSi vos valeurs de couleur sont comprises entre 0 et 255, vous pouvez les normaliser\nen les divisant par 255.\n\nNous avons donc vu comment modifier la couleur de la toile, \nmais que se passe-t-il à l'intérieur de notre programme d'ombrage ? \n\nLa première ligne de la fonction mainImage déclare une variable appelée uv de type vec2.\nSi vous vous souvenez de votre arithmétique vectorielle à l'école, cela signifie \nque nous avons un vecteur avec une composante \"x\" et une composante \"y\". \nUne variable de type vec3 aurait une composante \"z\" supplémentaire.\n\nVous avez peut-être appris à l'école l'existence du système de coordonnées 3D. \nIl nous permet de représenter graphiquement des coordonnées 3D sur des feuilles \nde papier ou toute autre surface plane. Il est évidemment difficile de visualiser les\n3D sur une surface 2D. \n\nC'est pourquoi les mathématiciens les plus brillants ont créé un système de coordonnées\n3D pour nous aider à visualiser les points dans l'espace 3D.\n\nCependant, dans le code des shaders, les vecteurs doivent être considérés comme \ndes \"tableaux\" pouvant contenir entre une et quatre valeurs.\nLes vecteurs peuvent contenir des informations sur les coordonnées XYZ dans\nl'espace 3D ou des informations sur les valeurs RVB. \nPar conséquent, les éléments suivants sont équivalents dans les programmes de shaders :\n\ncolor.r = color.x\ncolor.g = color.y\ncolor.b = color.z\ncolor.a = color.w\n\nOui, il peut y avoir des variables de type vec4, et la lettre w ou a est utilisée\npour représenter une quatrième valeur. \nLe a signifie \"alpha\", puisque les couleurs peuvent avoir un canal alpha en plus \ndes valeurs RVB normales. \nJe suppose qu'ils ont choisi w parce qu'il se trouve avant x dans l'alphabet,\net qu'ils ont déjà atteint la dernière lettre 🤷.\n\nLa variable uv ne représente pas vraiment un acronyme.\nElle fait référence au sujet de la cartographie UV qui est couramment utilisée \npour cartographier des morceaux d'une texture (comme une image)bsur des objets 3D.\nLe concept de cartographie UV est plus applicable aux environnements qui vous donnent \naccès à un vertex shader contrairement à Shadertoy, mais vous pouvez toujours exploiter\nles données de texture dans Shadertoy.\n\nLa variable fragCoord représente les coordonnées XY du canevas.\nLe coin inférieur gauche commence à (0, 0) et le coin supérieur droit est \n(iResolution.x, iResolution.y). \n\nEn divisant fragCoord par iResolution.xy, nous pouvons normaliser les coordonnées\ndes pixels entre zéro et un.\n\nRemarquez que nous pouvons effectuer des opérations arithmétiques assez facilement\nentre deux variables de même type, même s'il s'agit de vecteurs.\nC'est la même chose que d'effectuer des opérations sur les composants individuels :\n\nuv = fragCoord/iResolution.xy\n\n// The above is the same as:\nuv.x = fragCoord.x/iResolution.x\nuv.y = fragCoord.y/iResolution.y\n\nLorsque nous disons quelque chose comme iResolution.xy,la partie .xy se réfère uniquement\nà la composante XY du vecteur. Cela nous permet de ne retirer que les composantes\ndu vecteur qui nous intéressent, même si iResolution est de type vec3.\n\nSelon cet article de Stack Overflow \n(https://stackoverflow.com/questions/27888323/what-does-iresolution-mean-in-a-shader), \nla composante z représente le rapport d'aspect des pixels, qui est généralement de 1,0. \nUne valeur de 1 signifie que les pixels de votre écran sont carrés.\nVous ne verrez généralement pas les gens utiliser la composante z de iResolution très\nsouvent, voire pas du tout.\n\nNous pouvons également effectuer des raccourcis lors de la définition des vecteurs.\nL'extrait de code suivant définit la couleur de l'ensemble de la toile en noir.\n\n*/\n\n/*\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n  // Normalized pixel coordinates (from 0 to 1)\n  vec2 uv = fragCoord/iResolution.xy;\n\n  vec3 col = vec3(0); // Same as vec3(0, 0, 0)\n\n  // Output to screen\n  fragColor = vec4(col,1.0);\n}\n\n*/\n\n/*\nLorsque nous définissons un vecteur, le code du shader est suffisamment intelligent\npour appliquer la même valeur à toutes les valeurs du vecteur si vous ne spécifiez \nqu'une seule valeur. Par conséquent, vec3(0) est étendu à vec3(0,0,0).\n\nSi vous essayez d'utiliser des valeurs inférieures à zéro comme couleur de fragment\nde sortie, elles seront limitées à zéro. \nDe même, toute valeur supérieure à un sera limitée à un. \nCela ne s'applique qu'aux valeurs de couleur dans la couleur finale du fragment.\n\nIl est important de garder à l'esprit que le débogage dans Shadertoy et \ndans la plupart des environnements de shaders, en général, est principalement visuel. \nVous n'avez rien comme console.log pour venir à votre secours. \nVous devez utiliser la couleur pour vous aider à déboguer.\n\nEssayons de visualiser les coordonnées des pixels sur l'écran avec le code suivant :\n*/\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n  // Normalized pixel coordinates (from 0 to 1)\n  vec2 uv = fragCoord/iResolution.xy;\n\n  vec3 col = vec3(uv, 0); // This is the same as vec3(uv.x, uv.y, 0)\n\n  // Output to screen\n  fragColor = vec4(col,1.0);\n}\n\n\n\n/*\nNous devrions obtenir une toile composée d'un mélange de noir, de rouge, de vert \net de jaune.\n\nC'est joli, mais en quoi cela nous aide-t-il ? \nLa variable uv représente les coordonnées normalisées de la toile entre zéro et un \nsur l'axe des x et l'axe des y. Le coin inférieur gauche de la toile a pour coordonnées\n(0, 0). Le coin supérieur droit de la toile a pour coordonnées (1, 1).\n\n\nDans la variable col, nous la fixons à (uv.x, uv.y, 0), \nce qui signifie que nous ne devrions pas nous attendre à une couleur bleue dans le canevas.\nLorsque uv.x et uv.y sont égaux à zéro, nous obtenons du noir. \nLorsqu'ils sont tous deux égaux à un, nous obtenons du jaune, car en infographie,\nle jaune est une combinaison de valeurs rouges et vertes. Le coin supérieur gauche \nde la toile est (0, 1), ce qui signifie que la variable col serait égale à (0, 1, 0), \nce qui correspond à la couleur verte. Le coin inférieur droit a pour coordonnées (1, 0),\nce qui signifie que la variable col est égale à (1, 0, 0), ce qui correspond \nà la couleur rouge.\n\nLaissez les couleurs vous guider dans votre processus de débogage !\n\n# Conclusion\n\nOuf ! J'ai couvert pas mal de choses sur les shaders et Shadertoy dans cet article.\nJ'espère que vous êtes toujours avec moi ! \nLorsque j'ai appris les shaders pour la première fois, j'ai eu l'impression \nd'entrer dans un tout nouveau domaine de la programmation.\nC'est complètement différent de ce à quoi je suis habitué,\nmais c'est excitant et stimulant ! Dans la prochaine série d'articles,\nje parlerai de la façon dont nous pouvons créer des formes sur le canevas \net faire des animations !\n*/\n\n\n\n","name":"Image","description":"","type":"image"}]}
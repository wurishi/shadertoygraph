{"ver":"0.1","info":{"id":"WlcGDj","date":"1577548359","viewed":862,"name":"Cubemap Projection","username":"Tara","description":"Ray marching within a cubemap (or a spherically warped 2D texture).\nThis is a proof of concept for a novel parallax correction algorithm that can be applied to image-based lighting.\nThis is unfinished, because I continued developmed within my engine.","likes":20,"published":1,"flags":0,"usePreview":0,"tags":["raymarching","parallax","cubemap","projection","correction"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XdXGzn","filepath":"/media/a/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","previewfilepath":"/media/ap/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","type":"texture","channel":3,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4df3Rr","filepath":"/media/a/3871e838723dd6b166e490664eead8ec60aedd6b8d95bc8e2fe3f882f0fd90f0.jpg","previewfilepath":"/media/ap/3871e838723dd6b166e490664eead8ec60aedd6b8d95bc8e2fe3f882f0fd90f0.jpg","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4df3Rr","filepath":"/media/a/3871e838723dd6b166e490664eead8ec60aedd6b8d95bc8e2fe3f882f0fd90f0.jpg","previewfilepath":"/media/ap/3871e838723dd6b166e490664eead8ec60aedd6b8d95bc8e2fe3f882f0fd90f0.jpg","type":"texture","channel":2,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sf3Rr","filepath":"/media/a/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","previewfilepath":"/media/ap/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","type":"texture","channel":1,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// You are free to change these:\nconst float depth_scale = 0.6;\nconst float depth_offset = 1.0;\n//const vec3 light_color = vec3(3.6, 3.3, 3.0);\nconst vec3 light_color = vec3(3.6, 2.5, 1.5) * 0.25;\n\n// Fog settings:\nconst vec3 fog_air_color = vec3(0.8, 0.6, 0.6);\nconst vec3 fog_water_color = vec3(0.5, 0.325, 0.25) * 0.65;\nconst float fog_air_extinction_coefficient = -0.05;\nconst float fog_water_extinction_coefficient = -20.0;\n\n#define ANIMATE_CAMERA\n//#define DEMO_MODE\n//#define DITHER_SECONDARY_RAYS\t// WIP\n\n// Debug tools:\n//#define DEBUG_NORMALS\n\n// TODO: Improve normal mapping.\n// Here's a reference: https://stackoverflow.com/questions/21210774/normal-mapping-on-procedural-sphere\n// TODO: Rotate the view direction correctly!\n// TODO: Diffuse term doesn't match shadows!\n\nvec3 light_position = vec3(0.0);\n\nfloat get_distance(vec2 uv)\n{\n    // Fix the aspect ratio:\n    uv.x *= 2.0;\n    \n    // Small adjustment to create a hole at the top.\n    // This should be baked into the texture.\n    float y_scale = smoothstep(0.8, 1.0, uv.y);\n    return(depth_offset - texture(iChannel1, uv).r * depth_scale + y_scale);\n}\n\nfloat compute_ao(vec3 origin, vec3 n_normal)\n{\n    // TODO: PERFORMANCE: Calculate AO in texture space?\n    \n    // TODO: Improve sample coordinates!\n    const vec2 coordinates[24] = vec2[](\n        vec2(0.1345339, 0.9776062),\n        vec2(0.4509954, 0.711735),\n        vec2(0.7675728, 0.5708129),\n        vec2(0.7562704, 0.226492),\n        vec2(0.797026, -0.1188121),\n        vec2(0.5915386, -0.4101292),\n        vec2(0.2672587, -0.5891874),\n        vec2(0.560896, -0.7683676),\n        vec2(0.2602177, -0.9483843),\n        vec2(-0.2098463, -0.8336008),\n        vec2(-0.09346788, -0.4964156),\n        vec2(-0.4253753, -0.312667),\n        vec2(-0.1753666, 0.02664107),\n        vec2(0.1650871, -0.1864996),\n        vec2(0.299685, 0.1578036),\n        vec2(0.0109844, 0.3367841),\n        vec2(-0.102881, 0.6622637),\n        vec2(-0.4101768, 0.848845),\n        vec2(-0.6571413, 0.6137035),\n        vec2(-0.4172723, 0.3342704),\n        vec2(-0.7731495, 0.2193842),\n        vec2(-0.7416561, -0.1416828),\n        vec2(-0.8618071, -0.4668948),\n        vec2(-0.6076193, -0.7025846)\n    );\n    \n    const vec3 coordinates2[24] = vec3[24](\n        vec3(0.1, 0.45, -0.62),\n        vec3(-0.9, 0.01, 0.5),\n        vec3(-0.4, -0.57, 0.64),\n        vec3(0.47, 0.756, -0.541),\n        vec3(0.1, -0.45, 0.62),\n        vec3(0.39, 0.01, 0.5),\n        vec3(-0.74, -0.57, -0.64),\n        vec3(0.47, -0.756, -0.541),\n        vec3(0.1, -0.45, -0.62),\n        vec3(-0.79, -0.21, 0.5),\n        vec3(0.4, 0.57, -0.464),\n        vec3(0.47, -0.1756, -0.541),\n\n        -vec3(0.1, 0.45, -0.62),\n        -vec3(-0.9, 0.01, 0.5),\n        -vec3(-0.4, -0.57, 0.64),\n        -vec3(0.47, 0.756, -0.541),\n        -vec3(0.1, -0.45, 0.62),\n        -vec3(0.39, 0.01, 0.5),\n        -vec3(-0.74, -0.57, -0.64),\n        -vec3(0.47, -0.756, -0.541),\n        -vec3(0.1, -0.45, -0.62),\n        -vec3(-0.79, -0.21, 0.5),\n        -vec3(0.4, 0.57, -0.464),\n        -vec3(0.47, -0.1756, -0.541)\n    );\n    \n    /*\n    float samples = 0.0;\n    float sample_weights = 0.0;\n    \n\t// World space version:\n    for(int i=0; i<coordinates2.length(); ++i)\n    {\n        // TODO: Orient to hemisphere?\n        vec3 sample_position = origin + n_normal * 0.1;\n        sample_position = origin + coordinates2[i] * 0.25 * (float(1 + i) / float(coordinates2.length()));\n        \n        vec3 cubemap_origin_to_sample_position = sample_position - cubemap_origin;\t// TODO: Pre-subtract this?\n        \n        float cubemap_origin_to_sample_position_length = length(cubemap_origin_to_sample_position);\n        vec3 n_cubemap_origin_to_sample_position = cubemap_origin_to_sample_position / cubemap_origin_to_sample_position_length;\n        \n        vec2 uv = compute_uv(n_cubemap_origin_to_sample_position);\n        float sample_depth = get_distance(uv);\n        if(cubemap_origin_to_sample_position_length > sample_depth)\n        {\n   \t\t\t// TODO: Take normals into account!\n            samples += 1.0;\n        }        \n    }\n    float ao = 1.0 - samples / float(coordinates.length());\n    //ao = pow(ao, 2.0);\n    ao = min(ao + 0.2, 1.0) - 0.0;\n    ao = pow(ao, 2.0);\n    return(ao);\n    */\n    \n\t// Texture space version:\n    // This approach is not 100% mathematically correct, but works good enough and is much faster.\n    float samples = 0.0;\n    //float sample_weights = 0.0;\n    \n    vec2 center_uv = compute_uv(normalize(origin - cubemap_origin));\n    float center_distance = get_distance(center_uv);\n    \n    for(int i=0; i<coordinates.length(); ++i)\n    {\n        // TODO: Orient to hemisphere?\n        //vec2 sample_coordinate = center_uv + coordinates[i].xy * 0.05 * (float(1 + i) / float(coordinates.length()));\n        vec2 sample_coordinate = center_uv + coordinates[i].xy * 0.05;\n        float sample_depth = get_distance(sample_coordinate);\n        \n        // TODO: Take normals into account! I don't think we can do that efficiently in the texture space version.\n        bool occluded = (center_distance < sample_depth);\n        //float sample_weight = 1.0 / (1.0 + dot(coordinates[i].xy, coordinates[i].xy) * 2.0);\t// TODO: Precompute?\n        \n        //sample_weights += sample_weight;\n        //samples += float(occluded) * sample_weight;\n        \n        samples += float(occluded);\n    }\n    \n    //float ao = samples / sample_weights;\n    float ao = samples / float(coordinates.length());\n    return(ao);\n}\n\nbool find_intersection(vec3 origin, vec3 n_direction, const int max_iterations,\n                       const float step_size, const int refinement_step_count, out vec3 point_of_intersection)\n{\n    vec3 sample_position = origin;\n    vec3 ray_increment = n_direction * step_size;\n    \n    for(int i=0; i<max_iterations; ++i)\n    {\n        sample_position += ray_increment;\n\n        vec3 cubemap_origin_to_sample_position = sample_position - cubemap_origin;\t// TODO: Pre-subtract this?\n        float cubemap_origin_to_sample_position_length = length(cubemap_origin_to_sample_position);\n        vec3 n_cubemap_origin_to_sample_position = cubemap_origin_to_sample_position / cubemap_origin_to_sample_position_length;\n        vec2 uv = compute_uv(n_cubemap_origin_to_sample_position);\n        float sample_depth = get_distance(uv);\n        \n        if(cubemap_origin_to_sample_position_length > sample_depth)\n        {\n            // Refine intersection by tracing backwards:\n            vec3 refinement_increment = ray_increment / float(refinement_step_count);\n            for(int j=0; j<refinement_step_count; ++j)\n            {\n                sample_position -= refinement_increment;\n\n                vec3 cubemap_origin_to_sample_position = sample_position - cubemap_origin;\n                float cubemap_origin_to_sample_position_length = length(cubemap_origin_to_sample_position);\n                vec3 n_cubemap_origin_to_sample_position = cubemap_origin_to_sample_position / cubemap_origin_to_sample_position_length;\n       \t\t\tvec2 uv = compute_uv(n_cubemap_origin_to_sample_position);\n                float sample_depth = get_distance(uv);\n                \n                if(cubemap_origin_to_sample_position_length <= sample_depth)\n                {\n                    break;\n                }\n            }\n            \n            point_of_intersection = sample_position;\n            return(true);\n        }        \n    }\n    \n    return(false);\n}\n\nfloat compute_shadows(vec3 origin, vec3 n_light_direction, vec3 light_position)\n{\n    // TODO: Stop marching once light has been passed.\n    // TODO: Use a point light or something!\n    \n    origin += n_light_direction * 0.005;\t// Offset to avoid self-intersection\n    \n    vec3 point_of_intersection;\n    if(find_intersection(origin, n_light_direction, 16, 0.05, 0, point_of_intersection))\n    {\n        return(0.0);\n    }\n    \n    return(1.0);\n}\n\nvec3 uv_to_direction(void)\n{\n    return(vec3(0.0));\n}\n\nvec3 calculate_normal(vec2 uv, float radius, float noise_strength)\t// TODO: Check if this function produces good normals.\n{\n    // TODO: Smooth the normals?\n    vec2 right_uv = uv + vec2(radius / iChannelResolution[1].x);\n    vec2 top_uv = uv + vec2(0.0, radius / iChannelResolution[1].y);\n    \n    float center_distance = get_distance(uv);\n    float right_distance = get_distance(right_uv);\n    float top_distance = get_distance(top_uv);\n    \n    \n    const float noise_scale = 7.0 * 4.0;\n    vec3 noise = texture(iChannel3, uv * noise_scale).rgb;\n    center_distance += (noise.x * 2.0 - 0.5) * noise_strength;\n    right_distance += (noise.y * 2.0 - 0.5) * noise_strength;\n    top_distance += (noise.z * 2.0 - 0.5) * noise_strength;\n    \n    \n    // Smooth out the normals a little bit:\n    //right_distance = mix(right_distance, center_distance, 0.75);\n    //top_distance = mix(top_distance, center_distance, 0.75);\n    \n    vec3 tangent_space_normal;\n    tangent_space_normal.x = right_distance - center_distance;\n    tangent_space_normal.y = top_distance - center_distance;\n    tangent_space_normal.xy *= 35.0;\n    tangent_space_normal.z = 1.0 - sqrt(tangent_space_normal.x * tangent_space_normal.x + tangent_space_normal.y * tangent_space_normal.y);\t// TODO: Use cross product and stuff!\n    \n    \n    // More accurate version:\n    vec3 x_axis = normalize(vec3(right_uv - uv, right_distance - center_distance));\n    vec3 y_axis = normalize(vec3(top_uv - uv, top_distance - center_distance));\n    vec3 z_axis = normalize(cross(y_axis, x_axis));\t// TODO: Why do we need to normalize this??\n    tangent_space_normal = z_axis;\n    tangent_space_normal.z = -tangent_space_normal.z;\n    //return(tangent_space_normal);\n   // tangent_space_normal.yx = tangent_space_normal.xy;\n    \n    // TODO: Try this approach:\n    // https://www.opengl.org/discussion_boards/showthread.php/186332-Need-help-normal-mapping-a-cube-mapped-sphere\n    mat3 tbn_matrix;\n    vec2 signed_uv = 2.0 * uv - vec2(1.0);\n    float d = sqrt(uv.x * uv.x + uv.y * uv.y + 1.0);\n    \n    tbn_matrix[0] = vec3(    d,    0,  uv.x/d);\n    tbn_matrix[1] = vec3(    0,    d,  uv.y/d );\n    tbn_matrix[2] = vec3( -d*uv.x, -d*uv.y,  1.0 / d);\n    \n    /*\n    tbn_matrix[0] = vec3(    d,    0,  -d*uv.x);\n    tbn_matrix[1] = vec3(    0,    d,  -d*uv.y );\n    tbn_matrix[2] = vec3( uv.x/d, uv.y/d,  1.0 / d);\n    */\n    //return(tbn_matrix * tangent_space_normal);\n    //return(tangent_space_normal * tbn_matrix);\n    \n    \n    vec3 normal = tangent_space_normal;\n    \n    vec3 n_normal = normalize(normal);\n    vec3 forward;\n    forward.x = cos(uv.x * two_pi + pi / 2.0) * sin(uv.y * pi);\n    forward.y = cos(uv.y * pi);\n    forward.z = sin(uv.x * two_pi + pi / 2.0) * sin(uv.y * pi);\n    \n    vec3 up = vec3(0.0, 1.0, 0.0);\n    vec3 right = normalize(cross(up, forward));\t// TODO: Use sphere normal!\n    //vec3 forward = cross(up, normal);\n    vec3 up_corrected = cross(right, forward);\n    \n    mat3 tangent_matrix;\n    tangent_matrix[0] = right;\n    tangent_matrix[1] = up;\n    tangent_matrix[2] = forward;\n        \n    n_normal = normalize(n_normal * tangent_matrix);\n    \n    \n    // Angle offset approach:\n    //uv.x += tangent_space_normal.x;\n    //uv.y += tangent_space_normal.y;\n    n_normal.x = cos(uv.x * two_pi + half_pi + (half_pi * tangent_space_normal.x)) * sin(uv.y * pi);\n    n_normal.y = cos(uv.y * pi - (half_pi * tangent_space_normal.y));\n    n_normal.z = sin(uv.x * two_pi + half_pi + (half_pi * tangent_space_normal.x)) * sin(uv.y * pi);\n    \n    // Sphere normals:\t// TODO: Still not 100% accurate!\n    float sin_y = sin(uv.y * pi);\n    n_normal.x = sin(uv.x * two_pi) * sin_y;\n    n_normal.y = cos(uv.y * pi);\n    n_normal.z = cos(uv.x * two_pi) * sin_y;\n    \n    // Normap map normals in world space:\n    {\n        float sin_y = sin(uv.y * pi - (half_pi * tangent_space_normal.y));\n        n_normal.x = sin(uv.x * two_pi + (half_pi * tangent_space_normal.x)) * sin_y;\n        n_normal.y = cos(uv.y * pi - (half_pi * tangent_space_normal.y));\n        n_normal.z = cos(uv.x * two_pi + (half_pi * tangent_space_normal.x)) * sin_y;\n    }\n    //n_normal = normalize(n_normal);\n    \n    // TODO: Convert from uv to direction for all 3 samples.\n    //       Then calculate vectors towards each other and do cross product.\n    \n    \n    return(n_normal);\n    \n    // TODO: PERFORMANCE: Is there a faster way to calculate world space normals?\n    /*\n    // Convert each sample to world space:\n    vec3 center_position;\n    center_position.x = cos(uv.x * two_pi) * sin(uv.y * two_pi - pi);\n    //center_position.y = cos(uv.y * two_pi);\n    center_position.y = cos(uv.y * two_pi - pi);\n    center_position.z = sin(uv.x * two_pi) * sin(uv.y * two_pi - pi);\n                              \n    vec3 right_position;\n    right_position.x = cos(right_uv.x * two_pi) * sin(right_uv.y * two_pi - pi);\n    right_position.y = cos(right_uv.y * two_pi - pi);\n    right_position.z = sin(right_uv.x * two_pi) * sin(right_uv.y * two_pi - pi);\n                              \n    vec3 top_position;\n    top_position.x = cos(top_uv.x * two_pi) * sin(top_uv.y * two_pi - pi);\n    top_position.y = cos(top_uv.y * two_pi - pi);\n    top_position.z = sin(top_uv.x * two_pi) * sin(top_uv.y * two_pi - pi);\n    \n    normal = cross(normalize(right_position - center_position),\n                   normalize(top_position - center_position));\n    */\n    \n    /*\n    vec2 uv;\n    uv.x = (pi + atan(n_direction.x, n_direction.z)) / (2.0 * pi);\n    uv.x *= 2.0;\n    uv.y = n_direction.y * 0.5 + 0.5;\n    */\n    \n    vec3 vector;\n    /*\n    uv.x = (pi + atan(n_direction.x, n_direction.z)) / (2.0 * pi);\n    uv.x * (2.0 * pi) = pi + atan(n_direction.x, n_direction.z);\n    uv.x * (2.0 * pi) - pi = atan(n_direction.x, n_direction.z);\n    tan(uv.x * (2.0 * pi) - pi) = n_direction.x, n_direction.z;\n    */\n    \n    /*\n    vector.x = tan(uv.x * two_pi - pi);\n    vector.y = uv.y * 2.0 - 1.0;\n    vector.z = tan(uv.x * two_pi - pi - 0.5 * pi);\n    \n    vector.x = cos(uv.x * two_pi - pi);\n    vector.y = uv.y * 2.0 - 1.0;\n    vector.z = sin(uv.x * two_pi - pi);\n    \n    return(normalize(vector));\n    */\n    \n    /*\n    vector.x = cos(uv.x * two_pi - pi);\n    vector.y = cos(uv.y * two_pi);\n    vector.z = sin(uv.x * two_pi - pi);\n    //vector = normalize(vector + normal * 0.25);\n    vector = normalize(vector * normal);\n    return(vector);\n    */\n        \n    // TODO: Convert back to world space!\n    return(normalize(normal));\n}\n\nvec2 get_reflection_uv(vec3 p, vec3 n_reflection)\n{\n    const float reflection_distane = 1.0;\n    \n    p += n_reflection * reflection_distane;\n    return(compute_uv(normalize(p - cubemap_origin)));\n}\n\nvec3 get_specular(vec3 p, vec3 n_normal_smooth, vec3 n_direction)\n{\n    vec3 n_reflection_vector = reflect(n_direction, n_normal_smooth);\n    vec2 reflection_uv = get_reflection_uv(p, n_reflection_vector);\n    \n    // Approximate the reflection:\n    vec3 reflection = to_linear_space(texture(iChannel0, reflection_uv * albedo_texture_scale).rgb);\n\n    return(reflection);\n}\n\nvec3 shade_pixel(vec3 point_of_intersection, vec3 n_direction, vec2 uv)\n{\n    vec3 linear_color = to_linear_space(texture(iChannel2, uv * albedo_texture_scale).rgb);\n    \n    // This needs to be read from a mipmapped texture:\n    vec3 indirect_light_color = to_linear_space(textureLod(iChannel0, uv * albedo_texture_scale, 7.0).rgb);\n    \n    // TODO: Attenuate lighting?\n    vec3 sample_to_light = light_position - point_of_intersection;\n    float sample_to_light_length = length(sample_to_light);\n    vec3 n_sample_to_light = sample_to_light / sample_to_light_length;\n    //n_sample_to_light = -normalize(point_of_intersection - 0.5 * vec3(sin(iTime), 0.5, cos(iTime)));\t// Directional light\n    \n    vec3 n_normal = calculate_normal(uv, 1.5, 0.002);\n    float shadows = compute_shadows(point_of_intersection, n_sample_to_light, light_position);\n    float ao = compute_ao(point_of_intersection, n_normal);\n      \n    float distance_attenuation = 1.0 / (sample_to_light_length * sample_to_light_length);\n    float lambert_term = max(0.0, dot(n_normal, n_sample_to_light));\n    vec3 diffuse_light = light_color * lambert_term;\n    diffuse_light *= distance_attenuation;\n    \n    vec3 diffuse = linear_color * shadows * diffuse_light;\n    vec3 indirect = linear_color * ao * indirect_light_color * (0.75 + 0.25 * lambert_term * shadows);\n    \n    // Apply wetness-based reflections: ///////////////////////////////////////////\n    \n    // Calculate a smoother normal because the surface is coated in water:\n    vec3 n_normal_smooth = calculate_normal(uv, 2.0, 0.0);\n    \n    // Make rocks close to the water wet:\n    float height_wetness = smoothstep(0.1, 0.0, point_of_intersection.y);\n    float height_wetness_diffuse = smoothstep(0.03, 0.08, point_of_intersection.y);\n\n    // Make rocks sticking out more wet:\n    float depth_wetness = smoothstep(0.9, 0.7, get_distance(uv));\n\n    float wetness_mask = (depth_wetness * 0.5 + 0.5) * pow(1.0 - mix(0.0, depth_wetness, 1.0 - height_wetness), 3.0) * height_wetness;\n    \n    // Reflection ray pointing downwards means it's gonna hit the water surface. \n    vec3 n_reflection_vector = reflect(n_direction, n_normal_smooth);\n    float blend_factor = smoothstep(0.0, -0.2, n_reflection_vector.y);\n    \n    // Change specular to fog color if under water:\n    float height_blend_factor = smoothstep(-0.05, 0.05, point_of_intersection.y);\n    blend_factor *= height_blend_factor;\n \n    float fresnel = get_fresnel_term(n_normal_smooth, -n_direction);\n    vec3 specular = get_specular(point_of_intersection, n_normal_smooth, n_direction);\n    specular = mix(fog_water_color * 0.25, specular * light_color * 0.25, blend_factor);\n    specular *= fresnel * wetness_mask;\n    \n    float diffuse_darkening = (1.0 - height_wetness) * pow(1.0 - mix(0.0, depth_wetness * depth_wetness, 1.0 - height_wetness_diffuse), 5.0);\n    diffuse *= diffuse_darkening * 0.9 + 0.1;\t// Darken diffuse cuz it's wet.\n    indirect *= (diffuse_darkening * 0.25 + 0.75);\n    /////////////////////////////////////////////////////////////////////////\n    \n    vec3 shaded_color = diffuse + indirect + specular; \n    \n    \n#ifdef DEMO_MODE\n    float slice_width = iResolution.x / 5.0;\n    float coordinate = gl_FragCoord.x - gl_FragCoord.y * 0.1 + slice_width / 5.0;\n    if(coordinate < slice_width)\n    {\n    \treturn(vec3(diffuse_light * shadows));\n    }\n    \n    //if(coordinate < slice_width * 2.0 + sin(iTime) * iResolution.x)\t// Animated\n    if(coordinate < slice_width * 2.0)\n    {\n    \treturn(vec3(ao));\n    }\n    \n    //if(coordinate < slice_width * 3.0 + sin(iTime + pi) * iResolution.x)\t// Animated\n    if(coordinate < slice_width * 3.0)\n    {\n    \treturn(n_normal);\n    }\n    \n    if(coordinate < slice_width * 4.0)\n    {\n    \treturn(linear_color);\n    }\n    \n    return(indirect_light_color);\n#endif\n    \n#ifdef DEBUG_NORMALS\n    {\n        float slice_width = iResolution.x / 5.0;\n        float coordinate = gl_FragCoord.x - gl_FragCoord.y * 0.1 + slice_width * 0.5;\n        if(coordinate < slice_width)\n        {\n            return(vec3(n_normal.x, 0.0, 0.0));\n        }\n\n        if(coordinate < slice_width * 2.0)\n        {\n            return(vec3(0.0, n_normal.y, 0.0));\n        }\n\n        if(coordinate < slice_width * 3.0)\n        {\n            return(vec3(0.0, 0.0, n_normal.z));\n        }\n\n        if(coordinate < slice_width * 4.0)\n        {\n            return(n_normal);\n        }\n        \n    \treturn(normalize(cubemap_origin - point_of_intersection));\t// Guaranteed to be correct normals!\n    }\n#endif\n    \n    return(shaded_color);\n}\n\nvec3 trace_ray(vec3 origin, vec3 n_direction, out vec3 point_of_intersection)\n{\n    if(find_intersection(origin, n_direction, 32, 0.1, 10, point_of_intersection))\n    {\n        vec2 uv = compute_uv(normalize(point_of_intersection - cubemap_origin));\t// TODO: Normalization required?\n        vec3 color = shade_pixel(point_of_intersection, n_direction, uv);\n\n        return(shade_pixel(point_of_intersection, n_direction, uv));\n    }     \n\n    return(vec3(0.0, 1.0, 0.0));  \n}\n\n// This function assumes the plane always gets hit.\nfloat intersect_plane(vec3 ray_origin, vec3 n_ray_direction, vec3 plane_origin, vec3 n_plane_normal)\n{\n    float denominator = dot(n_ray_direction, n_plane_normal);\n    float t = dot(plane_origin - ray_origin, n_plane_normal) / denominator;\n    return(t);\n}\n\nvec3 get_water_normal(vec3 water_plane_point_of_intersection)\n{\n    vec3 noise = texture(iChannel3, water_plane_point_of_intersection.xz * 0.2).rgb;\t// TODO: Why can't we use \"water_plane_point_of_intersection\"???\n    \n    // TODO: This time-based code has numerical precision issues:\n    float water_time = iTime * 9.0;\n    \n    vec3 offset;\n    offset.x = sin(water_time + noise.r * two_pi);\n    offset.y = sin(water_time + noise.g * two_pi);\n    offset.z = sin(water_time + noise.b * two_pi);\n            \n    return(normalize(offset + vec3(0.0, 1.0 / 0.03, 0.0)));\n}\n\nvec3 trace_reflection(vec3 origin, vec3 n_direction, inout float travelled_distance_in_air)\n{\n    vec3 point_of_intersection;\n    vec3 reflection = trace_ray(origin, n_direction, point_of_intersection);       \n\n    travelled_distance_in_air += distance(origin, point_of_intersection);\n    reflection = apply_fog(reflection, travelled_distance_in_air,\n                           fog_air_color, fog_air_extinction_coefficient);\n    return(reflection);\n}\n\nvec3 trace_refraction(vec3 origin, vec3 n_direction)\n{\n    vec3 point_of_intersection;\n    vec3 refraction = trace_ray(origin, n_direction, point_of_intersection);\n\n    float travelled_distance_in_water = distance(origin, point_of_intersection);\n    refraction = apply_fog(refraction, travelled_distance_in_water,\n                           fog_water_color, fog_water_extinction_coefficient);\n\n    return(refraction);\n}\n\n\nvec3 render(vec3 origin, vec3 n_direction, vec2 uv)\n{\n    vec3 point_of_intersection;\n    if(find_intersection(origin, n_direction, 64, 0.04, 25, point_of_intersection))\n    {       \n        float travelled_distance_in_air = distance(origin, point_of_intersection);\n        \n        if(point_of_intersection.y < 0.0)\n        {\n            // TODO: PERFORMANCE: Stop raymarching when hitting the water.\n           \t\n            // Find ray vs water intersection:\n            const vec3 water_plane_normal = vec3(0.0, 1.0, 0.0);\n            const vec3 water_plane_origin = vec3(0.0);\n\n            float water_plane_distance = intersect_plane(origin, n_direction, water_plane_origin, water_plane_normal);\n            vec3 water_plane_point_of_intersection = origin + water_plane_distance * n_direction;\n\n            vec3 n_water_normal = get_water_normal(water_plane_point_of_intersection);\n            \n            float fresnel = get_fresnel_term(n_water_normal, -n_direction);\n            \n            //n_water_normal = n_water_plane;\n            \n#ifdef DITHER_SECONDARY_RAYS\n       \t\t//if(mod(gl_FragCoord.x, fresnel) < 0.1 || mod(gl_FragCoord.y, fresnel) < 0.1)\n            //if(mod(gl_FragCoord.x + gl_FragCoord.y, 2.0) < 0.5)\n            //if(mod(gl_FragCoord.x, 2.0) + mod(gl_FragCoord.y, 2.0) < 3.0)\n            if(fresnel + mod(gl_FragCoord.x + gl_FragCoord.y, 2.0) - 1.0 > 0.1)\n           \n    \t\t//float noise = texture(iChannel0, uv * 4.0).r;\t// iChannelResolution[4]\n            //if(noise < fresnel)\n            {\n                // Reflection:\n                vec3 n_reflection_vector = reflect(n_direction, n_water_normal);\n                vec3 reflection = trace_reflection(water_plane_point_of_intersection, n_reflection_vector, travelled_distance_in_air);\n            \treturn(reflection);\n            }\n            else\n            {\n                // Refraction:\n                vec3 n_refraction_vector = refract(n_direction, n_water_normal, ior_air / ior_water);\n                vec3 refraction = trace_refraction(water_plane_point_of_intersection, n_refraction_vector);\n\n                refraction = apply_fog(refraction, distance(origin, water_plane_point_of_intersection),\n                                       fog_air_color, fog_air_extinction_coefficient);\n\n            \treturn(refraction);\n            }\n#else\n            // Reflection:\n    \t\tvec3 n_reflection_vector = reflect(n_direction, n_water_normal);\n            vec3 reflection = trace_reflection(water_plane_point_of_intersection, n_reflection_vector, travelled_distance_in_air);\n\n            // Refraction:\n    \t\tvec3 n_refraction_vector = refract(n_direction, n_water_normal, ior_air / ior_water);\n            vec3 refraction = trace_refraction(water_plane_point_of_intersection, n_refraction_vector);\n\n            refraction = apply_fog(refraction, distance(origin, water_plane_point_of_intersection),\n                                   fog_air_color, fog_air_extinction_coefficient);\n            \n \n            return(mix(refraction, reflection, fresnel));\n#endif\n            \n        }\n        else\n        {\n            vec2 uv = compute_uv(normalize(point_of_intersection - cubemap_origin));\n            vec3 color = shade_pixel(point_of_intersection, n_direction, uv);\n            color = apply_fog(color, travelled_distance_in_air, fog_air_color, fog_air_extinction_coefficient);\n            return(color);\n        }\n        \n    }\n    \n    // This point should never be reached.\n    return(vec3(1.0, 0.0, 0.0));\n}\n\nvec3 get_view_direction(vec2 uv)\n{\n    const float fov_factor = 0.75;\n    \n    //vec3 n_direction = vec3(uv * 2.0 - 1.0, 2.0);\n    vec3 n_direction = vec3(uv * fov_factor * 2.0 - fov_factor, 1.0);\n    \n    \n#ifdef ANIMATE_CAMERA\n    n_direction.y += sin(iTime * 0.75) * 0.25;\t// Look up and down\n#endif\n    \n    // Correct the aspect ration:\n    n_direction.x *= iResolution.x / iResolution.y;\n    \n    n_direction = normalize(n_direction);\n    \n#ifndef ANIMATE_CAMERA\n    return(n_direction);\n#endif\n    \n    float angle = iTime * 0.25;\n    vec3 n_rotated_direction = n_direction;\n    n_rotated_direction.x = n_direction.x * cos(-angle) - n_direction.z * sin(-angle);\n    n_rotated_direction.z = n_direction.x * sin(-angle) + n_direction.z * cos(-angle);\n    \n    return(normalize(n_rotated_direction));\n}\n\nvec3 get_view_origin(void)\n{\n#ifndef ANIMATE_CAMERA\n    return(vec3(0.0, 0.1, 0.0));\n#endif\n    vec3 origin = vec3(0.0) + vec3(cos(iTime * 0.5) * 0.05,\n                                   0.035 + sin(iTime * 0.25 - 2.1) * 0.02,\n                                   sin(iTime * 0.5) * 0.01);\n    origin *= vec3(5.0, 3.0, 5.0);\n    return(origin);\n}\n\nvoid update_light_position(void)\n{\n    float sn = sin(iTime * 3.0);\n    float cs = cos(iTime * 3.0);\n    light_position = vec3(sn * 0.2,\n                          0.9 + cs * cs * 0.2,\n                          cs * 0.1);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord / iResolution.xy;\n\n    vec3 n_direction = get_view_direction(uv);\n    vec3 origin = get_view_origin();\n    \n    update_light_position();\n    \n    // Do the raymarching and shading:\n    fragColor.rgb = render(origin, n_direction, uv);\n\tfragColor.rgb = to_srgb(fragColor.rgb);\n    fragColor.a = 1.0;\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"const float gamma = 2.2;\nconst float pi = 3.14159265359;\nconst float two_pi = 2.0 * pi;\nconst float r_two_pi = 1.0 / two_pi;\nconst float half_pi = pi / 2.0;\nconst float ior_water = 1.333;\nconst float ior_air = 1.0;\nconst float albedo_texture_scale = 4.0;\n\n// This would correspond to the world position of your reflection probe:\nconst vec3 cubemap_origin = vec3(0.0);\n    \nvec3 to_linear_space(vec3 color)\n{\n\treturn(pow(color, vec3(gamma)));  \n}\n\nvec3 to_srgb(vec3 color)\n{\n\treturn(pow(color, vec3(1.0 / gamma)));\n}\n\nvec2 compute_uv(vec3 n_direction)\n{\n    vec2 uv;\n    uv.x = (pi + atan(n_direction.x, n_direction.z)) * r_two_pi;\n    uv.y = n_direction.y * 0.5 + 0.5;\n    return(uv);\n}\n\nfloat get_fresnel_term(vec3 n_normal, vec3 n_reflection)\n{\n\t// Implementation based on this article: https://en.wikipedia.org/wiki/Schlick's_approximation\n\tfloat n1 = ior_air;\n\tfloat n2 = ior_water;\n\tfloat r0 = (n1 - n2) / (n1 + n2);\n\tr0 *= r0;\t// We don't use \"pow()\", because it might not calculate the sign correctly (it must always end up positive!).\n\tfloat cos_theta = max(dot(n_reflection, n_normal), 0.0);\t// The angle between the direction from which the incident light is coming and the normal of the interface between the two media, hence cos_theta = dot(N, V).\n\t\n\treturn(r0 + (1.0 - r0) * pow(1.0 - cos_theta, 5.0));\n}\n\nvec3 apply_fog(vec3 color, float travelled_distance,\n               vec3 fog_color, float fog_extinction_coefficient)\n{\n    vec3 fog_factor = exp(fog_color * travelled_distance * fog_extinction_coefficient);\n    return(mix(fog_color, color, fog_factor));\n}","name":"Common","description":"","type":"common"}]}
{"ver":"0.1","info":{"id":"cdj3zm","date":"1667414659","viewed":233,"name":"GGX dielectric","username":"stduhpf","description":"Trying to understand BRDFs \nThis is a model to render opaque dielectric material with GGX microfacets, Smith masking-shadowing, and Schlick's approximation for Fresnel coefficient.\nEnergy seems to get lost at high roughness. (needs multiscattering?)","likes":8,"published":1,"flags":32,"usePreview":0,"tags":["specular","importancesampling","montecarlo","ibl","pbr"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\n#define DITHER\n\n\n//#define tonemap(x) (x)\n#define tonemap(x) ACES(x)\n//#define tonemap(x) HLG_tm(x)\n\n// anyone is free to use the code and values contained in this shader\n\nvec3 RRTAndODTFit(vec3 v) \n{\n    vec3 a = v * (v + 0.0245786);\n    vec3 b = v * (0.983729 * v + 0.4329510) + 0.238081;\n    return a / b;\n}\nvec3 ACES(vec3 color){\n    const mat3 ACESInputMat = mat3(\n        0.59719, 0.35458, 0.04823,\n        0.07600, 0.90834, 0.01566,\n        0.02840, 0.13383, 0.83777\n    );\n    const mat3 ACESOutputMat = mat3(\n         1.60475, -0.53108, -0.07367,\n        -0.10208,  1.10813, -0.00605,\n        -0.00327, -0.07276,  1.07602\n    );\n    color = color * ACESInputMat;\n    color = RRTAndODTFit(color);\n    color = color * ACESOutputMat;\n    return clamp(color, 0.0, 1.0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    vec2 m = iMouse.x>0.?iMouse.xy:vec2(iResolution.x*.5);\n\n    // left side: RGB, right side: spectral\n    vec4 col = texture(iChannel0,uv);col/=col.a;\n    \n\n    fragColor = vec4(\n        pow(\n            tonemap(col.rgb\n                   ///HLG_MAX\n                   )\n            ,vec3(1./2.2))\n    ,1.0);\n    \n   #ifdef DITHER\n   vec4 noise = texture(iChannel3,(fragCoord)/iChannelResolution[3].xy);\n    //merge channels for better noise precision;\n    noise = noise*255./256.+noise.yzwx*255./(256.*256.);\n    noise+=noise.zwxy/(256.*256.); // the two last channels\n    \n    \n    const float prec = float((1<<8)-1); //8-bit color range: 0.->255.\n        \n    vec3 l = fragColor.rgb; //gamma-space value\n    vec3 lin = pow(l,vec3(2.2)); //linear-space value\n    \n    // get quantization \"bounds\"\n    vec3 lfg = floor(l*prec)/prec;\n    vec3 lcg = ceil(l*prec)/prec;\n    \n    // convert bounts to linear\n    vec3 lfl = pow(lfg,vec3(2.2));\n    vec3 lcl = pow(lcg,vec3(2.2));\n    \n    //vec3 xg = (l  -lfg)/(lcg-lfg); // == fract(l*prec)\n    vec3 xl = (lin-lfl)/(lcl-lfl);\n    \n    vec3 dithered = mix(lfg,lcg,step(noise.xyz,xl)); \n    fragColor.rgb = dithered;\n   #endif\n    \n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"XdfGRn","filepath":"/media/a/e6e5631ce1237ae4c05b3563eda686400a401df4548d0f9fad40ecac1659c46c.jpg","previewfilepath":"/media/ap/e6e5631ce1237ae4c05b3563eda686400a401df4548d0f9fad40ecac1659c46c.jpg","type":"texture","channel":3,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dX3Rr","filepath":"/media/a//media/previz/cubemap00.png","previewfilepath":"/media/ap//media/previz/cubemap00.png","type":"cubemap","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsBSR3","filepath":"/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","previewfilepath":"/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","type":"texture","channel":1,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"void importanceSampling(bool useCubemap, inout vec4 fragColor, vec3 n, vec3 rd, vec3 ld, float r,\n    vec2 dithering, samplerCube cubemap, int iFrame,bool useLaz)\n{\n    vec3 albedo = vec3(.8,.1,.15); //diffuse color\n    vec3 f0 = vec3(0.045185,.045845,.047039); //specular color (at 0Â° of incidence)\n\n    vec3 h = h_sampleGGXVNDF(n,-rd,r,dithering,iFrame); //microfacet normal\n    float ndoti = dot(h,-rd);\n  \n    vec3 f = Schlick(f0,ndoti); //fresnel\n    //float noise = fract(dithering.r+1.618033989*float(iFrame));\n    //bool specular = f.r>noise;\n    //vec3 dir = specular?reflect(rd,h):sampleValidLambertDiffuse(n,h,dithering,iFrame);\n    {//specular\n        vec3 dir = reflect(rd,h);\n        vec3 col = vec3(0.);\n        if(dot(dir,n)>=0.){ //ignore sample if reflected vector goes inside\n            vec3 tx = texture(cubemap,dir).rgb;\n            float l = ggxMaskingShadowing(n,-rd,dir,r)/ggxMasking(n,-rd,r);\n            col = f*tx*l;\n            fragColor += vec4((col),.5);\n        }\n    }\n    {//diffuse\n        vec3 dir = sampleValidLambertDiffuse(n,h,dithering,iFrame); //this should never go inside the surface\n        vec3 col = vec3(0.);\n        vec3 tx = texture(cubemap,dir).rgb;\n        float l = ggxMaskingShadowing(n,-rd,dir,r)/ggxMasking(n,-rd,r);\n        col = albedo*(1.-f)*tx*l;\n        fragColor += vec4((col),.5);\n    }\n\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = (2.*(fragCoord)-iResolution.xy)/iResolution.x;\n\n    vec3 ro = vec3(0.,0.,-2.25);\n    vec3 rd = normalize(vec3(uv,1.));\n\n    \n    vec4 noise = texture(iChannel1,fragCoord/iChannelResolution[1].xy);\n    vec2 dithering = (noise.rg*255.+noise.ba)/256.;\n        \n    vec4 i = iSphere(vec3(0),1.,ro,rd);\n    \n    if(i.a>100000.){\n        fragColor = texture(iChannel2,rd);\n        return;\n    }\n    \n    vec3 p = ro+rd*i.a;\n    vec3 n = i.rgb;\n    float r = getRoughness(p.xzy,iChannel3);\n    r*=r;\n    fragColor = \n        //(.5-sign(iMouse.z)*.5)*\n        texture(iChannel0,fragCoord/iResolution.xy);\n    const int samples = 1;\n    for(int i = 0;i<samples;i++){\n        importanceSampling(true, fragColor,n,rd,vec3(0),r,dithering,iChannel2,(iFrame%2048)*samples+i,\n        true);\n    }\n    \n\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"const float PI = acos(-1.);\nconst float TAU = PI+PI;\n\n\nfloat getRoughness(vec3 p, sampler2D t){\n    return .2+.4*texture(t,(p.xz)).r;//sin(p.y*40.)*0.1+.3;\n}\n\n\nmat3 getBasis(vec3 nor){\n    bool t = 1.-abs(nor.z)>.00001;\n    if(!t)\n        nor=nor.zxy;\n    vec3 tc = vec3( 1.0+nor.z-nor.xy*nor.xy, -nor.x*nor.y)/(1.0+nor.z);\n    vec3 uu = vec3( tc.x, tc.z, -nor.x );\n    vec3 vv = vec3( tc.z, tc.y, -nor.y );\n    \n    return t?mat3(uu,vv,nor):mat3(uu.yzx,vv.yzx,nor.yzx);\n}\n\nvec4 iSphere(vec3 sp, float sr,vec3 ro, vec3 rd) //intersection entre une sphere et un rayon\n{\n    vec3 p = sp-ro;\n    float d = dot(-rd,p);\n    float i = d*d- dot(p,p)+sr*sr;\n    d = i>0.?-sqrt(i)-d:-1000.;\n    if(d<0.)\n        i=-abs(i);\n\treturn vec4(normalize(rd*d-p),i>0.?d:1e6); //renvoie le vecteur normal au point d'intersection et la distance\n}\t\t\t\t\t\t\t\t\t//1e6 est un nombre tres grand\n\n\nfloat ggxMaskingShadowing(vec3 n, vec3 d, vec3 l, float a){\n    a*=a;\n    float dotNL = dot(n,l);\n    float dotND = dot(n,d);\n    float denomA = dotNL * sqrt(a + (1.0f - a) * dotND * dotND);\n    float denomB = dotND * sqrt(a + (1.0f - a) * dotNL * dotNL);\n\n    return 2.0f * dotND * dotNL / (denomA + denomB);\n}\n\nfloat ggxMasking(vec3 n, vec3 l, float a){\n    a*=a;\n    float dotNL = dot(n,l);\n    float denom = sqrt((1.-a) + a/(dotNL*dotNL));\n\n    return 2.0f / (1.+denom);\n}\n\nfloat D_GGX_A(vec3 n, const vec3 h, float at, float ab) { //anisotropic\n    vec3 hh = inverse(getBasis(n))*h; //should probably be precomputed\n    float d = hh.z;\n    float ToH = hh.x;\n    float BoH = hh.y;\n    float a2 = at * ab;\n    vec3 v = vec3(ab * ToH, at * BoH, a2 * d);\n    float v2 = dot(v, v);\n    float w2 = a2 / v2;\n    return a2 * w2 * w2 * (1.0 / PI);\n}\n\n\n\nfloat hash(float p)\n{\n    p = fract(p * .1031);\n    p *= p + 33.33;\n    p *= p + p;\n    return fract(p);\n}\n\n\nvec3 Schlick(vec3 f0, float cosTheta){\n    #ifdef RENORMALZE_REFLECTANCE\n    f0 = f0/max(max(1.,f0.r),max(f0.g,f0.b));\n    #elifdef CLAMP_REFLECTANCE\n    f0 = clamp(f0,0.,1.);\n    #endif\n    return f0+(1.-f0)*pow(1.-cosTheta,5.);\n}\n\n\n// https://hal.archives-ouvertes.fr/hal-01509746/document\nvec3 sampleGGXVNDF(vec3 V_, float at, float ab, float U1, float U2)\n{\n    // stretch view\n    vec3 V = normalize(vec3(at * V_.x, ab * V_.y, V_.z));\n    // orthonormal basis\n    vec3 T1 = (V.z < 0.9999) ? normalize(cross(V, vec3(0,0,1))) : vec3(1,0,0);\n    vec3 T2 = cross(T1, V);\n    // sample point with polar coordinates (r, phi)\n    float a = 1.0 / (1.0 + V.z);\n    float r = sqrt(U1);\n    float phi = (U2<a) ? U2/a * PI : PI + (U2-a)/(1.0-a) * PI;\n    float P1 = r*cos(phi);\n    float P2 = r*sin(phi)*((U2<a) ? 1.0 : V.z);\n    // compute normal\n    vec3 N = P1*T1 + P2*T2 + sqrt(max(0.0, 1.0 - P1*P1 - P2*P2))*V;\n    // unstretch\n    N = normalize(vec3(at*N.x, ab*N.y, max(0.0, N.z)));\n    return N;\n}\n\nvec3 h_sampleGGXVNDF(vec3 n,vec3 v, float a, vec2 seed, int iFrame){\n    const float phi2=1.32471795724474602596090885447809734; //root of X^3-X-1=0.\n\tconst float phi2sq=phi2*phi2;\n    vec2 hash = fract(seed + fract(.5+float(iFrame)/vec2(phi2sq,phi2)));\n    \n    mat3 b =  getBasis(n);\n    return getBasis(n)*sampleGGXVNDF(inverse(b)*v,a,a,hash.x,hash.y);\n}\n\n\nvec3 sphereCapPoint(vec3 n, float cosa, vec2 h){ \n    //uniform mapping from square to spherical cap with angle acos(cosa)\n    \n    h.x=(1.-h.x*(1.-cosa));\n    h.y*=2.*PI;\n    \n    //conversion to cartesian space\n    return getBasis(n)*vec3(sqrt(1.-h.x*h.x)*vec2(cos(h.y),sin(h.y)),h.x);\n}\n\nvec3 sampleValidLambertDiffuse(vec3 n, vec3 h, vec2 seed, int iFrame){\n    /*\n        Samples a random direction with cosine distribution relative to microfacet normal \"h\", according to lambert's law.\n        The added constraint in this case is that the direction must not intersect the surface with normal \"n\"\n        \n        To sample cosine distribution without the constraint is pretty easy. we just need to sample a random point \n        on the unit sphere \"s\", add this to the normal vector, and finally normalize the result.\n        // return normalize(h+randomSpherePoint());\n        with this method, the output direction \"o\" will not intersect the surface if n.o>0\n        wich is equivalent to n.(h+s)>0 <=> n.h + n.s >0 <=> n.s > -n.h\n        all the points satisfying this condition are making a spherical cap (with angle>pi/2 and main direction n)\n        to avoid self-intersection, we can just sample this spherical cap instead of the whole sphere.\n    */\n    \n    const float phi2=1.32471795724474602596090885447809734; //root of X^3-X-1=0.\n\tconst float phi2sq=phi2*phi2;\n    vec2 noise = fract(seed + fract(.75645452+float(3*iFrame+5)/vec2(phi2sq,phi2)));\n    \n    float NdotH = dot(n,-h);\n    return normalize(h+sphereCapPoint(n,NdotH,noise));\n}\n\n//// Dynamic range and tonemap\nconst float HLG_MAX = 5.4; // peak brightness (>=1). Due to float precision issues, values above 5.4 can lead to invalid nubers \n// increasing past 3. will affect significantly only pixels with luninance exceeding 254./255.\n// HLG_MAX = sqrt(-log(1-HLG_SCALER*HLG_SCALER))/HLG_SCALER\n//this is an empirical fitting approximation of the solution, not the actual solution to this equation (I don't think there is a simple real solution)\nconst float HLG_SCALER = sqrt(1.-exp((1.-HLG_MAX)*3.92)); \n\nvec3 HLG(vec3 lin){ //increased dinamic range from image (assusmes color to be already in linear space)\n    if(HLG_SCALER<=0. || HLG_MAX <=1.)\n        return lin;\n    lin*=HLG_SCALER;\n    //luminance-based version(could also maybe work per channel, but it would mess with chromacity; so I perfer this way)\n    float lum = dot(lin,vec3(0.2126,.7152,.0722));\n    float l = lum;\n    if(l<=0.) return lin/HLG_SCALER;\n    l = (sqrt(-log(1.-l*l)));\n    if(isnan(l))l=lum;\n    return (lin*l/lum)/HLG_SCALER;\n}\n\n\nvec3 HLG_tm(vec3 o){ //how the HLG function assumes the HDR colors are encoded, can be used as bad tonemapping (still needs gamma correction after)\n    if(HLG_SCALER<=0. || HLG_MAX <=1.)\n        return o;\n    o=o*HLG_SCALER;\n    float l = dot(o,vec3(0.2126,.7152,.0722));\n    if(l<=0.)return vec3(0.);\n    float lum = sqrt(1.-exp(-l*l)); \n    vec3 lin = lum*o/l;\n    return lin/HLG_SCALER;\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"XsX3zn","filepath":"/media/a/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","previewfilepath":"/media/ap/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","type":"cubemap","channel":0,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dX3Rr","channel":0}],"code":"// Background image (linear colors)\n\nvoid mainCubemap( out vec4 fragColor, in vec2 fragCoord, in vec3 rayOri, in vec3 rayDir )\n{\n    fragColor = pow(texture(iChannel0,rayDir),vec4(2.2));\n\n    //increase dynamic range\n    fragColor.rgb = HLG(fragColor.rgb);\n}","name":"Cube A","description":"","type":"cubemap"}]}
{"ver":"0.1","info":{"id":"Mfc3Dr","date":"1711639592","viewed":220,"name":"3D wave simulation","username":"Nazlbit","description":"A simulation of a wave propagation in 3D space.","likes":16,"published":1,"flags":48,"usePreview":0,"tags":["3d","wave","simulation","space","field","vector","propagation"],"hasliked":0,"parentid":"MXlXWj","parentname":"Black hole (kinda)"},"renderpass":[{"inputs":[{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Press Space to pause/play the simulation\n// Press Backspace to reset the simulation\n\n// Uncomment the next line if the framerate is too low\n//#define FAST\n\nconst float fov = 35.;\nconst float camera_distance = 4.;\nconst float cube_size = 2.;\nconst float tonemapping_gamma = 0.5;\nconst float tonemapping_exposure = 0.5;\nconst float glow_intensity = 6.;\nconst float sample_mapping_coeff = 0.1; // Affects how dense the field looks.\nconst float glow_gradient_scaling = 2.; // Affects how hot the field looks.\nconst float transmittence_cutoff = 0.01; // Stop sampling deeper in the volume if less than this percentage of light reaches the viewer.\nconst float volume_absorbance = 0.5; // The constant absorbance of the volume.\nconst vec3 background_color = vec3(0.5);\nconst float step_size_multiplier = 1.;\n\n// Calculate the position and the direction of the ray based on the camera\n// orientation and the fragment coordinates.\nvec3 get_ray(const vec2 orientation, out vec3 pos)\n{\n    // Calculate the camera basis vectors.\n    vec3 right = vec3(cos(orientation.x), 0, sin(orientation.x));\n    vec3 forward = vec3(-sin(orientation.x), 0, cos(orientation.x));\n    vec3 up = vec3(0, cos(orientation.y), 0) + forward * sin(orientation.y);\n    forward = forward * cos(orientation.y) + vec3(0, -sin(orientation.y), 0);\n\n    // The camera is always looking at the center.\n    pos = -forward * camera_distance;\n\n    vec2 normalized_coords = (gl_FragCoord.xy * 2. - iResolution.xy) / iResolution.x;\n    const float fov_tan = tan(radians(fov));\n\n    vec3 ray_dir = forward +\n                   right * normalized_coords.x * fov_tan +\n                   up * normalized_coords.y * fov_tan;\n\n    return normalize(ray_dir);\n}\n\n// Calculate the intersection points of a ray with a cube.\n// x is the distance to the near point and y is the distance to the far point.\nvec2 cube_intersection(const vec3 r, const vec3 o, const float cube_size)\n{\n    vec3 t1 = (cube_size * 0.5 - o) / r;\n    vec3 t2 = -(cube_size * 0.5 + o) / r;\n    bvec3 m = greaterThan(t2, t1);\n    vec3 t_min = mix(t2, t1, m);\n    vec3 t_max = mix(t1, t2, m);\n    return vec2(max(max(t_min.x, t_min.y), t_min.z), min(min(t_max.x, t_max.y), t_max.z));\n}\n\n// A simple color gradient that goes from dark red to orange, yellow and white.\nvec3 color_gradient(float a)\n{\n    const vec3 v[] = vec3[](\n                            vec3(0.3, 0, 0),\n                            vec3(0.7, 0.05, 0),\n                            vec3(1, 0.5, 0),\n                            vec3(1, 1, 0),\n                            vec3(1));\n\n    a = clamp(a, 0., 1.) * float(v.length() - 1);\n    int a1 = int(floor(a));\n    int a2 = min(a1 + 1, v.length() - 1);\n    return mix(v[a1], v[a2], a - float(a1));\n}\n\n// Apply a tonemapping curve to the HDR value.\n// Clamping to [0, 1] range has to be done separately.\n// https://www.desmos.com/calculator/vxmtgd7kvz\nvec3 tonemap(const vec3 x, const float a, const float b)\n{\n    return a != 0. ? x * (1. + 1. / a) / (x + 1. / (a * b)) : x * b;\n}\n\n// Apply sRGB gamma correction to a linear value.\nvec3 linear2gamma(const vec3 x)\n{\n    return mix(12.92 * x, 1.055 * pow(x, vec3(1./2.4)) - 0.055, greaterThan(x, vec3(0.0031308)));\n} \n\n// https://www.shadertoy.com/view/ttc3zr\nuint murmurHash12(uvec2 src) {\n    const uint M = 0x5bd1e995u;\n    uint h = 1190494759u;\n    src *= M; src ^= src>>24u; src *= M;\n    h *= M; h ^= src.x; h *= M; h ^= src.y;\n    h ^= h>>13u; h *= M; h ^= h>>15u;\n    return h;\n}\n\n// 1 output, 2 inputs\nfloat hash12(vec2 src) {\n    uint h = murmurHash12(floatBitsToUint(src));\n    return uintBitsToFloat(h & 0x007fffffu | 0x3f800000u) - 1.0;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Calculate camera orientation.\n    vec2 orientation;\n    if(iMouse.z > 0.)\n    {\n        // The camera orientation depends on the mouse position.\n        vec2 normalized_mouse = iMouse.xy / iResolution.xy;\n        orientation = -vec2(normalized_mouse.x * radians(360.), (normalized_mouse.y - 0.5) * radians(180.) );\n    }\n    else\n    {\n        // The camera is revolving around the cube.\n        orientation = vec2(radians(20.) * iTime, radians(0.));\n    }\n\n    // Calculate the position and the direction of the ray based on the camera\n    // orientation and the fragment coordinates.\n    vec3 pos;\n    vec3 ray = get_ray(orientation, pos);\n\n    // Calculate the intersection of the ray with a cube representing the simulation volume.\n    // t[0] is the distance from the camera along the ray to the near point of the intersection\n    // and t[1] is to the far point.\n    vec2 t = cube_intersection(ray, pos, cube_size);\n\n    // The near point mustn't be behind the camera.\n    t[0] = max(t[0], 0.);\n\n    // Initialize the resulting color.\n    vec3 result = background_color * mix(0.05, 1., pow(fragCoord.y / iResolution.y, 2.));\n\n    // If the ray intersects the cube.\n    if(t[1] > t[0])\n    {\n        // Calculate the interaction of the light passing through the volume\n        // by stepping along the ray and sampling the simulation values.\n        // The idea is that each point has a density. The higher the density,\n        // the lower the chance of the light passing through without scattering.\n        // In addition, high density areas emit light.\n\n        // The dimensions of the framebuffer.\n        ivec2 real_extent = ivec2(iResolution.xy);\n\n        // Calculate the dimensions of the simulation volume 3D texture.\n        int virt_extent = real2virt_extent(real_extent);\n\n        // Calculate the step size.\n        float step_size = cube_size / float(virt_extent) * step_size_multiplier;\n        int num_steps = int((t[1] - t[0]) / step_size);\n        float actual_step_size = (t[1] - t[0]) / float(num_steps) * float(virt_extent);\n\n        // The volume always absorbs some amount of light.\n        float volume_transmittance = pow(1. - volume_absorbance, actual_step_size / float(virt_extent));\n\n        // Add a random depth offset to the ray to reduce the Moire effect.\n        float ray_z_offset = hash12(fragCoord);\n\n        // Step through the volume and calculate how it affects the light.\n        float total_transmittance = 1.;\n        vec3 sum = vec3(0);\n        for(int i = 0; i < num_steps && total_transmittance > transmittence_cutoff; ++i)\n        {\n            // Calculate the step position in the 3D space of the simulation volume.\n            float tp = mix(t[0], t[1], (float(i) + ray_z_offset) / float(num_steps));\n            vec3 p = ((pos + ray * tp) / cube_size + 0.5) * float(virt_extent);\n\n            // Sample the simulation volume at the position.\n#ifdef FAST\n            // Use nearest sampling\n            float v = fetch_3d(iChannel0, iChannel1, ivec3(p), real_extent, virt_extent);\n#else\n            // Use trilinear texture filtering\n            float v = sample_3d(iChannel0, iChannel1, p, real_extent, virt_extent);\n#endif\n            // Transform the value to limit it to a [0, 1] range.\n            // The new value represents the probability of the light scattering\n            // while passing through a unit distance of the volume.\n            v *= v;\n            v /= v + sample_mapping_coeff;\n\n            // Calculate the value of the emited light.\n            // It's a crude approximation of the black body radiation.\n            // The intensity of the emited light linearly depends on the size of the step.\n            vec3 glow = color_gradient(v * glow_gradient_scaling) * v * glow_intensity * actual_step_size;\n\n            // Now inverse the value to represent the probability of the light passing\n            // through the volume without scattering.\n            v = 1. - v;\n\n            // Compensate for the varying step size.\n            v = pow(v, actual_step_size);\n\n            // Calculate the effect of the step on the light.\n            sum += glow * total_transmittance;\n            total_transmittance *= v * volume_transmittance;\n        }\n\n        total_transmittance = total_transmittance > transmittence_cutoff ? total_transmittance : 0.;\n        result = result * total_transmittance + sum;\n    }\n\n    // Apply tonemapping to the HDR value.\n    result = tonemap(result, tonemapping_gamma, tonemapping_exposure);\n\n    // Clamp the value to the [0, 1] range.\n    result = clamp(result, vec3(0), vec3(1));\n\n    // Do gamma correction.\n    result = linear2gamma(result);\n\n    fragColor = vec4(result, 1.);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"\nvoid mainImage(out vec4 result, in vec2 uv)\n{\n    bool backspace_is_clicked = bool(texelFetch(iChannel3, ivec2(8, 1), 0).x);\n    if(iFrame % 60000 == 0 || backspace_is_clicked)\n    {\n        result = initial_state(uv, 0, 0, iResolution.xy);\n        return;\n    }\n\n    bool space_is_toggled = bool(texelFetch(iChannel3, ivec2(32, 2), 0).x);\n    if(space_is_toggled)\n    {\n        result = read_buffer(iChannel0, ivec2(uv));\n        return;\n    }\n\n    result = simulation(iChannel0, iChannel1, iChannel2, uv, 0, iResolution.xy);\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"const float c = 0.3; // Stable at up to 0.5.\nconst float damping_coeff = 0.99995;\n\n#define read_buffer(buffer, uv) texelFetch(buffer, uv, 0)\n\nint real2virt_extent(const ivec2 real_extent)\n{\n    return int(pow(float(real_extent.x * real_extent.y * 4 * 2), 1./3.));\n}\n\nivec3 real2virt_coords(const ivec4 coords, const ivec2 real_extent, const int virt_extent)\n{\n    int a = ((coords.w * real_extent.y + coords.y) * real_extent.x + coords.x) * 4 + coords.z;\n    int x = a % virt_extent;\n    int y = (a / virt_extent) % virt_extent;\n    int z = a / (virt_extent * virt_extent);\n    return ivec3(x, y, z);\n}\n\nivec4 virt2real_coords(const ivec3 coords, const ivec2 real_extent, const int virt_extent)\n{\n    int a = (coords.z * virt_extent + coords.y) * virt_extent + coords.x;\n    int x = (a / 4) % real_extent.x;\n    int y = (a / (real_extent.x * 4)) % real_extent.y;\n    int z = a % 4;\n    int w = a / (real_extent.x * real_extent.y * 4);\n    return ivec4(x, y, z, w);\n}\n\n#define boundary(virt_coords, virt_extent) (any(lessThan(virt_coords, ivec3(0))) || any(greaterThanEqual(virt_coords, ivec3(virt_extent))))\n\nfloat fetch_3d(const sampler2D buffer_a, const sampler2D buffer_b, const ivec3 virt_coords, const ivec2 real_extent, const int virt_extent)\n{\n    if(boundary(virt_coords, virt_extent))\n    {\n        return 0.;\n    }\n\n    ivec4 real_coords = virt2real_coords(virt_coords, real_extent, virt_extent);\n\n    if(bool(real_coords.w))\n        return read_buffer(buffer_b, real_coords.xy)[real_coords.z];\n    else\n        return read_buffer(buffer_a, real_coords.xy)[real_coords.z];\n}\n\nfloat sample_3d(const sampler2D buffer_a, const sampler2D buffer_b, const vec3 virt_coords, const ivec2 real_extent, const int virt_extent)\n{\n    ivec3 a = ivec3(floor(virt_coords - 0.5));\n    ivec3 b = a + 1;\n    vec3 m = virt_coords - 0.5 - vec3(a);\n\n    return mix(mix(mix(fetch_3d(buffer_a, buffer_b, a,                  real_extent, virt_extent), fetch_3d(buffer_a, buffer_b, a + ivec3(1, 0, 0), real_extent, virt_extent), m.x),\n                   mix(fetch_3d(buffer_a, buffer_b, a + ivec3(0, 1, 0), real_extent, virt_extent), fetch_3d(buffer_a, buffer_b, a + ivec3(1, 1, 0), real_extent, virt_extent), m.x), m.y),\n               mix(mix(fetch_3d(buffer_a, buffer_b, a + ivec3(0, 0, 1), real_extent, virt_extent), fetch_3d(buffer_a, buffer_b, a + ivec3(1, 0, 1), real_extent, virt_extent), m.x),\n                   mix(fetch_3d(buffer_a, buffer_b, a + ivec3(0, 1, 1), real_extent, virt_extent), fetch_3d(buffer_a, buffer_b, a + ivec3(1, 1, 1), real_extent, virt_extent), m.x), m.y), m.z);\n}\n\nvec2 pulse(const ivec3 coords, const int extent, const vec3 pos, const vec3 direction, const float wl, const float ampl, const float pulse_size)\n{\n    vec2 result;\n    float extent_f = float(extent);\n    vec3 normalized_coords = vec3(coords) / extent_f * 2. - 1.;\n\n    vec3 transformed_coords = normalized_coords - pos;\n    float offset = dot(transformed_coords, direction);\n\n    float r = length(transformed_coords / pulse_size);\n    float phase = offset * extent_f * radians(180.) / wl;\n    result.x = cos(phase) * exp(-r*r);\n\n    transformed_coords -= 2. * direction * c / extent_f;\n    offset = dot(transformed_coords, direction);\n    r = length(transformed_coords / pulse_size);\n    phase = offset * extent_f * radians(180.) / wl;\n    result.y = cos(phase) * exp(-r*r);\n    return result * ampl;\n}\n\nvec4 initial_state(const vec2 coords, const int page, const int frame, const vec2 real_extent)\n{\n    vec4 result;\n    int virt_extent = real2virt_extent(ivec2(real_extent));\n    for(int i = 0; i < 4; ++i)\n    {\n        ivec3 virt_coords = real2virt_coords(ivec4(coords, i, page), ivec2(real_extent), virt_extent);\n        result[i] = pulse(virt_coords, virt_extent, vec3(0), normalize(vec3(1)), max(float(virt_extent)*0.1, 6.), 1., 0.25)[frame % 2];\n    }\n    return result;\n}\n\nfloat f(const float a, const sampler2D buffer_a, const sampler2D buffer_b, const ivec3 virt_coords, const ivec3 b_offset, const ivec2 real_extent, const int virt_extent)\n{\n    return (fetch_3d(buffer_a, buffer_b, virt_coords + b_offset, real_extent, virt_extent) - a);\n}\n\nvec4 simulation(const sampler2D prev_buffer, const sampler2D current_buffer_a, const sampler2D current_buffer_b, const vec2 _uv, const int page, const vec2 extent)\n{\n    vec4 result;\n    ivec2 real_extent = ivec2(extent);\n    ivec2 uv = ivec2(_uv);\n    int virt_extent = real2virt_extent(real_extent);\n\n    vec4 prev = read_buffer(prev_buffer, uv);\n    vec4 current = page == 0 ? read_buffer(current_buffer_a, uv) : read_buffer(current_buffer_b, uv);\n    for(int i = 0; i < 4; ++i)\n    {\n        ivec3 virt_coords = real2virt_coords(ivec4(uv, i, page), real_extent, virt_extent);\n\n        float a = f(current[i], current_buffer_a, current_buffer_b, virt_coords, +ivec3(1, 0, 0), real_extent, virt_extent) +\n                  f(current[i], current_buffer_a, current_buffer_b, virt_coords, -ivec3(1, 0, 0), real_extent, virt_extent) +\n                  f(current[i], current_buffer_a, current_buffer_b, virt_coords, +ivec3(0, 1, 0), real_extent, virt_extent) +\n                  f(current[i], current_buffer_a, current_buffer_b, virt_coords, -ivec3(0, 1, 0), real_extent, virt_extent) +\n                  f(current[i], current_buffer_a, current_buffer_b, virt_coords, +ivec3(0, 0, 1), real_extent, virt_extent) +\n                  f(current[i], current_buffer_a, current_buffer_b, virt_coords, -ivec3(0, 0, 1), real_extent, virt_extent);\n\n        result[i] = current[i] + (current[i] - prev[i]) * damping_coeff + a * c * c;\n    }\n    return result;\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"\nvoid mainImage(out vec4 result, in vec2 uv)\n{\n    bool backspace_is_clicked = bool(texelFetch(iChannel3, ivec2(8, 1), 0).x);\n    if(iFrame % 60000 == 0 || backspace_is_clicked)\n    {\n        result = initial_state(uv, 1, 0, iResolution.xy);\n        return;\n    }\n\n    bool space_is_toggled = bool(texelFetch(iChannel3, ivec2(32, 2), 0).x);\n    if(space_is_toggled)\n    {\n        result = read_buffer(iChannel0, ivec2(uv));\n        return;\n    }\n\n    result = simulation(iChannel0, iChannel1, iChannel2, uv, 1, iResolution.xy);\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"\nvoid mainImage(out vec4 result, in vec2 uv)\n{\n    bool backspace_is_clicked = bool(texelFetch(iChannel3, ivec2(8, 1), 0).x);\n    if(iFrame % 60000 == 0 || backspace_is_clicked)\n    {\n        result = initial_state(uv, 0, 1, iResolution.xy);\n        return;\n    }\n\n    bool space_is_toggled = bool(texelFetch(iChannel3, ivec2(32, 2), 0).x);\n    if(space_is_toggled)\n    {\n        result = read_buffer(iChannel0, ivec2(uv));\n        return;\n    }\n\n    result = simulation(iChannel0, iChannel1, iChannel2, uv, 0, iResolution.xy);\n}\n","name":"Buffer C","description":"","type":"buffer"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XdfGR8","channel":0}],"code":"\nvoid mainImage(out vec4 result, in vec2 uv)\n{\n    bool backspace_is_clicked = bool(texelFetch(iChannel3, ivec2(8, 1), 0).x);\n    if(iFrame % 60000 == 0 || backspace_is_clicked)\n    {\n        result = initial_state(uv, 1, 1, iResolution.xy);\n        return;\n    }\n\n    bool space_is_toggled = bool(texelFetch(iChannel3, ivec2(32, 2), 0).x);\n    if(space_is_toggled)\n    {\n        result = read_buffer(iChannel0, ivec2(uv));\n        return;\n    }\n\n    result = simulation(iChannel0, iChannel1, iChannel2, uv, 1, iResolution.xy);\n}\n","name":"Buffer D","description":"","type":"buffer"}]}
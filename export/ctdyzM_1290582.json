{"ver":"0.1","info":{"id":"ctdyzM","date":"1699047686","viewed":275,"name":"Importance Sampled Raymarching","username":"Quinchilion","description":"A test for my optimization idea (~2.6x speedup over original). See comment for explanation.\nComment out IMPORTANCE_SAMPLED to switch to the original implementation.\nUse mouse to look around.","likes":16,"published":1,"flags":32,"usePreview":0,"tags":["raymarching","cloud","importancesampling","optimization"],"hasliked":0,"parentid":"3sffzj","parentname":"VOLUMETRIC CLOUD"},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsBSR3","filepath":"/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","previewfilepath":"/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","type":"texture","channel":3,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n    Volumetric cloud shader forked from https://www.shadertoy.com/view/ctdyzM\n    Implementing my idea of an importance sampled scattering term of the raymarching integral.\n\n    The usual raymarching algorithm involves calculating the scattering term, along with an\n    expensive shadow ray march, at every step of the main loop. However, not all steps have\n    been created equal. A sample in the middle of the cloud usually only contributes a very\n    small percentage to the final integral because of the very low transmittance at that point.\n    Similarly, a low density wisp generally contributes less than a thick cloud behind it.\n    \n    The idea is to weigh all points along the camera ray by the density and transmittance at\n    that point and importance sample them based on that. We should need fewer such high-quality\n    samples than we do during the regular marching process where we sample the scattering\n    uniformly.\n    \n    The fun is in the implementation details. To importance sample this in a performant way,\n    we first march through the cloud as usual, but instead of accumulating scattering, we\n    try to distribute N samples along the ray according to a pdf that reflects their\n    contribution.\n    \n    We keep track of the previous step's density to form trapezoidal segments between the\n    steps. Intuitively, for each segment, we compare its weight to the combined weight of all\n    segments that came before it. With a chance proportional to this ratio, we choose that\n    segment to be the host of our sample.\n    \n    Once we have chosen the segments with probability according to their contribution, we can\n    importance sample a point within each segment using the trapezoidal pdf. There is a\n    tradeoff between doing this directly within the marching loop and wasting some work on\n    determining sample positions within segments that will be thrown away, or storing the\n    entire segments and sampling them later, wasting some register space.\n    \n    Either way, we only do the expensive step of calculating the inscattered light for the\n    final set of N samples, where N can usually be smaller than the number of steps needed for\n    the main marching loop without a big loss in quality. With even fewer samples, we get\n    well-behaved noise only in the shading of the cloud, which is easier to filter than when\n    reducing samples of the marching loop. Effectively, we are separating the transmittance\n    and scattering terms of the integral.\n    \n    One small detail for trapezoidal integration to work right is to allow the cloud shaping\n    function to take on negative values. Otherwise we would be overestimating densities.\n    Segments can be clipped to only positive parts easily enough.\n    \n    There is a small difference when compared to the original implementation that I haven't\n    been I able to find the source of yet. It disappears with a higher primary step count,\n    so maybe it is due to using a different integration strategy. The original implementation\n    doesn't converge at 32 steps either.\n    \n    HOW TO USE THIS:\n    \n    The IMPORTANCE_SAMPLED macro switches between my optimization and the original\n    implementation. My version uses the same number of primary steps. The number of samples\n    for importance sampling is configurable with a separate define. 8 samples seems to be\n    enough to end up with very little noise.\n    \n    See mainRayImportanceSampled and related functions above it for the relevant bits.\n    \n    I've added an FPS counter (thanks IQ) in the corner so you can compare the performance\n    in fullscreen. On my gpu and current settings, I observe a ~2.6x speedup, with only a bit\n\tmore noise. If you are getting capped by refresh rate, increase the SUPERSAMPLING value\n    below.\n    \n    Please credit Dolkar aka Quinchilion if you wish to share this method.\n    Many thanks to alro for providing a neatly written test bed shader :)\n*/\n\n//------- Comment to switch back to original implementation\n#define IMPORTANCE_SAMPLED\n\n//------- The number of samples for scattering integration\n#define SCATTERING_SAMPLE_COUNT 8\n\n//------- Increase value if you are capped to refresh rate\n#define SUPERSAMPLING 1\n\n//------- Uncomment for fewer ray marching steps and better performance\n// #define FAST\n\n#ifdef FAST\n\t#define STEPS_PRIMARY 16\n#else\n\t#define STEPS_PRIMARY 32\n#endif\n\n#define STEPS_LIGHT 10\n\n//------- Uncomment to display noise texture atlas\n//#define NOISE_ATLAS\n\n//------- Uncomment for coloured cloud\n//#define COLOUR_SCATTERING\n\n//------- Uncomment to move the sun\n//#define ANIMATE_SUN\n\n//------- Uncomment for coloured light\n//#define COLOUR_LIGHT\n\n//------- Offset the sample point by blue noise every frame to get rid of banding\n#define DITHERING\nconst float goldenRatio = 1.61803398875;\n\n// For size of AABB\n#define CLOUD_EXTENT 100.0\n\nconst vec3 skyColour = 0.7 * vec3(0.09, 0.33, 0.81);\n\n// Scattering and absorption coefficients\n#ifdef COLOUR_SCATTERING\nconst vec3 sigmaS = vec3(0.5, 1.0, 1.0);\n#else\nconst vec3 sigmaS = vec3(1);\n#endif\nconst vec3 sigmaA = vec3(0.0);\n\n// Extinction coefficient.\nconst vec3 sigmaE = max(sigmaS + sigmaA, vec3(1e-6));\n\nconst float power = 200.0;\nconst float densityMultiplier = 0.5;\n\nconst float shapeSize = 0.4;\nconst float detailSize = 0.8;\n\nconst float shapeStrength = 0.6;\nconst float detailStrength = 0.35;\n\nconst float cloudStart = 0.0;\nconst float cloudEnd = CLOUD_EXTENT;\n\nconst vec3 minCorner = vec3(-CLOUD_EXTENT, cloudStart, -CLOUD_EXTENT);\nconst vec3 maxCorner = vec3(CLOUD_EXTENT, cloudEnd, CLOUD_EXTENT);\n\nvec3 rayDirection(float fieldOfView, vec2 fragCoord) {\n    vec2 xy = fragCoord - iResolution.xy / 2.0;\n    float z = (0.5 * iResolution.y) / tan(radians(fieldOfView) / 2.0);\n    return normalize(vec3(xy, -z));\n}\n\n// https://www.geertarien.com/blog/2017/07/30/breakdown-of-the-lookAt-function-in-OpenGL/\nmat3 lookAt(vec3 camera, vec3 targetDir, vec3 up){\n  vec3 zaxis = normalize(targetDir);    \n  vec3 xaxis = normalize(cross(zaxis, up));\n  vec3 yaxis = cross(xaxis, zaxis);\n\n  return mat3(xaxis, yaxis, -zaxis);\n}\n\n// Darken sky when looking up.\nvec3 getSkyColour(vec3 rayDir){\n    return mix(skyColour, 0.5 * skyColour, 0.5+0.5*rayDir.y);\n}\n\n// Return the near and far intersections of an infinite ray and a sphere. \n// Assumes sphere at origin. No intersection if result.x > result.y\nvec2 sphereIntersections(vec3 start, vec3 dir, float radius){\n\tfloat a = dot(dir, dir);\n\tfloat b = 2.0 * dot(dir, start);\n    float c = dot(start, start) - (radius * radius);\n\tfloat d = (b*b) - 4.0*a*c;\n\tif (d < 0.0){\n        return vec2(1e5, -1e5);\n\t}\n\treturn vec2((-b - sqrt(d))/(2.0*a), (-b + sqrt(d))/(2.0*a));\n}\n\n// https://gist.github.com/DomNomNom/46bb1ce47f68d255fd5d\n// Compute the near and far intersections using the slab method.\n// No intersection if tNear > tFar.\nvec2 intersectAABB(vec3 rayOrigin, vec3 rayDir, vec3 boxMin, vec3 boxMax) {\n    vec3 tMin = (boxMin - rayOrigin) / rayDir;\n    vec3 tMax = (boxMax - rayOrigin) / rayDir;\n    vec3 t1 = min(tMin, tMax);\n    vec3 t2 = max(tMin, tMax);\n    float tNear = max(max(t1.x, t1.y), t1.z);\n    float tFar = min(min(t2.x, t2.y), t2.z);\n    return vec2(tNear, tFar);\n}\n\nbool insideAABB(vec3 p){\n    float eps = 1e-4;\n\treturn  (p.x > minCorner.x-eps) && (p.y > minCorner.y-eps) && (p.z > minCorner.z-eps) && \n\t\t\t(p.x < maxCorner.x+eps) && (p.y < maxCorner.y+eps) && (p.z < maxCorner.z+eps);\n}\n\nbool getCloudIntersection(vec3 org, vec3 dir, out float distToStart, out float totalDistance){\n\tvec2 intersections = intersectAABB(org, dir, minCorner, maxCorner);\n\t\n    if(insideAABB(org)){\n        intersections.x = 1e-4;\n    }\n    \n    distToStart = intersections.x;\n    totalDistance = intersections.y - intersections.x;\n    return intersections.x > 0.0 && (intersections.x < intersections.y);\n}\n\n\nfloat getPerlinWorleyNoise(vec3 pos){\n    // The cloud shape texture is an atlas of 6*6 tiles (36). \n    // Each tile is 32*32 with a 1 pixel wide boundary.\n    // Per tile:\t\t32 + 2 = 34.\n    // Atlas width:\t6 * 34 = 204.\n    // The rest of the texture is black.\n    // The 3D texture the atlas represents has dimensions 32 * 32 * 36.\n    // The green channel is the data of the red channel shifted by one tile.\n    // (tex.g is the data one level above tex.r). \n    // To get the necessary data only requires a single texture fetch.\n    const float dataWidth = 204.0;\n    const float tileRows = 6.0;\n    const vec3 atlasDimensions = vec3(32.0, 32.0, 36.0);\n\n    // Change from Y being height to Z being height.\n    vec3 p = pos.xzy;\n\n    // Pixel coordinates of point in the 3D data.\n    vec3 coord = vec3(mod(p, atlasDimensions));\n    float f = fract(coord.z);  \n    float level = floor(coord.z);\n    float tileY = floor(level/tileRows); \n    float tileX = level - tileY * tileRows;\n\n    // The data coordinates are offset by the x and y tile, the two boundary cells \n    // between each tile pair and the initial boundary cell on the first row/column.\n    vec2 offset = atlasDimensions.x * vec2(tileX, tileY) + 2.0 * vec2(tileX, tileY) + 1.0;\n    vec2 pixel = coord.xy + offset;\n    vec2 data = texture(iChannel0, mod(pixel, dataWidth)/iChannelResolution[0].xy).xy;\n    return mix(data.x, data.y, f);\n}\n\n// Read cloud map.\nfloat getCloudMap(vec3 p){\n    vec2 uv = 0.5 + 0.5 * (p.xz/(1.8 * CLOUD_EXTENT));\n    return texture(iChannel2, uv).x;\n}\n\nfloat getCloudHeight(vec3 p) {\n    return saturate((p.y - cloudStart)/(cloudEnd-cloudStart));\n}\n\n// Cloud shaping function, slightly changed from the original to avoid clamping to 0\nfloat clouds(vec3 p, bool sampleNoise){\n    if(!insideAABB(p)){\n    \treturn 0.0;\n    }\n\n    float cloudHeight = getCloudHeight(p);\n    float cloud = getCloudMap(p);\n\n    // If there are no clouds, exit early.\n    if(cloud <= 0.0){\n      return densityMultiplier * cloud;\n    }\n\n    // Sample texture which determines how high clouds reach.\n    float height = pow(cloud, 0.75);\n    \n    // Round the bottom and top of the clouds. From \"Real-time rendering of volumetric clouds\". \n    cloud *= min(remap(cloudHeight, 0.0, 0.25 * (1.0-cloud), 0.0, 1.0), 1.0)\n           * min(remap(cloudHeight, 0.75 * height, height, 1.0, 0.0), 1.0);\n\n    // Animate main shape.\n    p += vec3(2.0 * iTime, 0.0, iTime);\n    \n    // Get main shape noise\n    float shape = getPerlinWorleyNoise(shapeSize * p);\n\n    // Carve away density from cloud based on noise.\n    cloud = remap(cloud, shapeStrength * (shape), 1.0, 0.0, 1.0);\n\n    // Early exit from empty space\n    if(cloud <= 0.0){\n      return densityMultiplier * cloud;    \n    }\n    \n    // Animate details.\n    p += vec3(3.0 * iTime, -3.0 * iTime, iTime);\n    \n    // Get detail shape noise\n    float detail = getPerlinWorleyNoise(detailSize * p);\n    \n\t// Carve away detail based on the noise\n\tcloud = remap(cloud, detailStrength * (detail), 1.0, 0.0, 1.0);\n    return densityMultiplier * cloud;\n}\n\nfloat HenyeyGreenstein(float g, float costh){\n\treturn (1.0 / (4.0 * 3.1415))  * ((1.0 - g * g) / pow(1.0 + g*g - 2.0*g*costh, 1.5));\n}\n\n// https://twitter.com/FewesW/status/1364629939568451587/photo/1\nvec3 multipleOctaves(float extinction, float mu, float stepL){\n\n    vec3 luminance = vec3(0);\n    const float octaves = 4.0;\n    \n    // Attenuation\n    float a = 1.0;\n    // Contribution\n    float b = 1.0;\n    // Phase attenuation\n    float c = 1.0;\n    \n    float phase;\n    \n    for(float i = 0.0; i < octaves; i++){\n        // Two-lobed HG\n        phase = mix(HenyeyGreenstein(-0.1 * c, mu), HenyeyGreenstein(0.3 * c, mu), 0.7);\n        luminance += b * phase * exp(-stepL * extinction * sigmaE * a);\n        // Lower is brighter\n        a *= 0.2;\n        // Higher is brighter\n        b *= 0.5;\n        c *= 0.5;\n    }\n    return luminance;\n}\n\n// Get the amount of light that reaches a sample point.\nvec3 lightRay(vec3 org, vec3 p, float mu, vec3 sunDirection){\n\n\tfloat lightRayDistance = CLOUD_EXTENT*0.75;\n    float distToStart = 0.0;\n    \n    getCloudIntersection(p, sunDirection, distToStart, lightRayDistance);\n        \n    float stepL = lightRayDistance/float(STEPS_LIGHT);\n\n\tfloat lightRayDensity = 0.0;\n\n\t// Collect total density along light ray.\n\tfor(int j = 0; j < STEPS_LIGHT; j++){\n\t\n\t\tbool sampleDetail = true;\n\t\tif(lightRayDensity > 0.3){\n\t\t\tsampleDetail = false;\n\t\t}\n        \n\t\tlightRayDensity += max(clouds(p + sunDirection * float(j) * stepL, sampleDetail), 0.0);\n\t}\n    \n\tvec3 beersLaw = multipleOctaves(lightRayDensity, mu, stepL);\n\t\n    // Return product of Beer's law and powder effect depending on the \n    // view direction angle with the light direction.\n\treturn mix(beersLaw * 2.0 * (1.0 - (exp( -stepL * lightRayDensity * 2.0 * sigmaE))), \n               beersLaw, \n               0.5 + 0.5 * mu);\n}\n\n// Get the colour along the main view ray.\nvec3 mainRay(vec3 org, vec3 dir, vec3 sunDirection, \n             out vec3 totalTransmittance, float mu, vec3 sunLightColour, float offset){\n    \n\t// Variable to track transmittance along view ray. \n    // Assume clear sky and attenuate light when encountering clouds.\n\ttotalTransmittance = vec3(1.0);\n\n\t// Default to black.\n\tvec3 colour = vec3(0.0);\n    \n    // The distance at which to start ray marching.\n    float distToStart = 0.0;\n    \n    // The length of the intersection.\n    float totalDistance = 0.0;\n\n    // Determine if ray intersects bounding volume.\n\t// Set ray parameters in the cloud layer.\n\tbool renderClouds = getCloudIntersection(org, dir, distToStart, totalDistance);\n\n\tif(!renderClouds){\n\t\treturn colour;\n    }\n\n\t// Sampling step size.\n    float stepS = totalDistance / float(STEPS_PRIMARY); \n    \n    // Offset the starting point by blue noise.\n    distToStart += stepS * offset;\n    \n    // Track distance to sample point.\n    float dist = distToStart;\n\n    // Initialise sampling point.\n    vec3 p = org + dist * dir;\n    \n    // Combine backward and forward scattering to have details in all directions.\n\tfloat phaseFunction = mix(HenyeyGreenstein(-0.3, mu), HenyeyGreenstein(0.3, mu), 0.7);\n    \n    vec3 sunLight = sunLightColour * power;\n\n\tfor(int i = 0; i < STEPS_PRIMARY; i++){\n\n        // Normalised height for shaping and ambient lighting weighting.\n        float cloudHeight = getCloudHeight(p);\n\n        // Get density and cloud height at sample point\n        float density = max(clouds(p, true), 0.0);\n\n        vec3 sampleSigmaS = sigmaS * density;\n        vec3 sampleSigmaE = sigmaE * density;\n\n        // If there is a cloud at the sample point.\n        if(density > 0.0 ){\n\n            //Constant lighting factor based on the height of the sample point.\n            vec3 ambient = sunLightColour * mix((0.2), (0.8), cloudHeight);\n\n            // Amount of sunlight that reaches the sample point through the cloud \n            // is the combination of ambient light and attenuated direct light.\n            vec3 luminance = 0.1 * ambient +\n               \tsunLight * phaseFunction * lightRay(org, p, mu, sunDirection);\n\n            // Scale light contribution by density of the cloud.\n            luminance *= sampleSigmaS;\n\n            // Beer-Lambert.\n            vec3 transmittance = exp(-sampleSigmaE * stepS);\n\n            // Better energy conserving integration\n            // \"From Physically based sky, atmosphere and cloud rendering in Frostbite\" 5.6\n            // by Sebastian Hillaire.\n            colour += \n                totalTransmittance * (luminance - luminance * transmittance) / sampleSigmaE; \n\n            // Attenuate the amount of light that reaches the camera.\n            totalTransmittance *= transmittance;  \n\n            // If ray combined transmittance is close to 0, nothing beyond this sample \n            // point is visible, so break early.\n            if(length(totalTransmittance) <= 0.001){\n                totalTransmittance = vec3(0.0);\n                break;\n            }\n        }\n\n        dist += stepS;\n\n\t\t// Step along ray.\n\t\tp = org + dir * dist;\n\t}\n    \n\treturn colour;\n}\n\n//------------------ The start of the scattering importance sampling code ------------------\n\n// from https://www.shadertoy.com/view/MsdGzl\n//------------------------------------------------------------------\n// oldschool rand() from Visual Studio\n//------------------------------------------------------------------\nint   seed = 1;\nint   rand(void) { seed = seed*0x343fd+0x269ec3; return (seed>>16)&32767; }\nfloat frand(void) { return float(rand())/32767.0; }\nvoid  srand( ivec2 p, int frame )\n{\n    int n = frame;\n    n = (n<<13)^n; n=n*(n*n*15731+789221)+1376312589; // by Hugo Elias\n    n += p.y;\n    n = (n<<13)^n; n=n*(n*n*15731+789221)+1376312589;\n    n += p.x;\n    n = (n<<13)^n; n=n*(n*n*15731+789221)+1376312589;\n    seed = n;\n}\n\n// Convert ray segment to 0->1 range while adjusting density, assuming unit extinction\nvoid normalizeSegment(float tStart, float tEnd, inout float rhoStart, inout float rhoEnd) {\n    float len = tEnd - tStart;\n    rhoStart *= len;\n    rhoEnd *= len;\n}\n\n// Integrates transmittance along a normalized ray segment with linearly varying density\nfloat segmentTransmittance(float rhoStart, float rhoEnd, float t) {\n    float a = (rhoEnd - rhoStart) * 0.5;\n    float b = rhoStart;\n    \n    return exp(-a * t * t - b * t);\n}\n\n// The importance pdf of a sample along a ray, chosen as a product of transmittance and density\nfloat segmentImportancePdf(float rhoStart, float rhoEnd, float t) {\n    float rho = rhoStart + (rhoEnd - rhoStart) * t;\n    return segmentTransmittance(rhoStart, rhoEnd, t) * rho;\n}\n\n// The cdf to the pdf above (not quite cdf of a segment as I(0->1) != 1, but I(0->inf) = 1)\nfloat segmentImportanceCdf(float rhoStart, float rhoEnd, float t) {\n    // We make use of this fact later, rather than calling this function\n    return 1.0 - segmentTransmittance(rhoStart, rhoEnd, t);\n}\n\n// The inverse cdf to the pdf above, normalized for the segment, outputs (0,1)\n// https://www.desmos.com/calculator/42ge4uqgid\nfloat segmentImportanceInvCdf(float rhoStart, float rhoEnd, float p) {\n    float c = log(p * (exp(-(rhoStart + rhoEnd) * 0.5) - 1.0) + 1.0);\n    float d = sqrt(rhoStart * rhoStart + 2.0 * (rhoStart - rhoEnd) * c);\n    return (rhoStart - d) / (rhoStart - rhoEnd);\n}\n\n// Trapezoid segment with unit extinction\nstruct SampledSegment {\n    float tStart;\n    float tEnd;\n    float rhoStart;\n    float rhoEnd;\n};\n\nSampledSegment segSamples[SCATTERING_SAMPLE_COUNT];\n\n// Importance sampling of segments\nvoid sampleSegment(float tStart, float rhoStart, float tEnd, float rhoEnd, inout float transmittance) {\n    // The input segment defines densities on the tStart -> tEnd range. For simplicity, scale the range\n    // to 0->1\n    normalizeSegment(tStart, tEnd, rhoStart, rhoEnd);\n    \n    // The segment may extend to negative densities, which we make use of by clamping the segment range\n    // to positive values. We do this after the normalization to preserve energy\n    if (rhoStart < 0.0) {\n        tStart += (-rhoStart) * ((tEnd - tStart) / (rhoEnd - rhoStart)); \n        rhoStart = 0.0;\n    }\n    if (rhoEnd < 0.0) {\n        tEnd += (-rhoEnd) * ((tEnd - tStart) / (rhoEnd - rhoStart)); \n        rhoEnd = 0.0;\n    }\n    \n    float prevTransmittance = transmittance;\n    transmittance *= segmentTransmittance(rhoStart, rhoEnd, 1.0);\n    \n    // Importance sample weight for this segment compared to all segments marched so far\n    // This way we don't try to sample total transmittance as that's easy to integrate\n    // and would only add to the noise. But it means we need to multiply the scattering\n    // by 1 - transmittance later on.\n    float segmentProb = 1.0 - (1.0 - prevTransmittance) / (1.0 - transmittance);\n    \n    // Use a low-discrepancy sequence to replace existing segments according to the relative\n    // sampling probability\n    float r = frand();\n    for (int i = 0; i < SCATTERING_SAMPLE_COUNT; i++) {\n        float lds = fract(r + float(i) / goldenRatio);\n        if (lds <= segmentProb) {\n            segSamples[i].tStart = tStart;\n            segSamples[i].tEnd = tEnd;\n            segSamples[i].rhoStart = rhoStart;\n            segSamples[i].rhoEnd = rhoEnd;\n        }\n    }\n}\n\n// Importance sampling inside a segment\nfloat sampleInsideSegment(SampledSegment s, float v) {\n    float x = 0.5;\n    if (abs(s.rhoStart - s.rhoEnd) > 1.0e-6)\n        x = segmentImportanceInvCdf(s.rhoStart, s.rhoEnd, v);\n        \n    return s.tStart + x * (s.tEnd - s.tStart);\n}\n\n// Get the colour along the main view ray, with added scattering importance sampling\nvec3 mainRayImportanceSampled(vec3 org, vec3 dir, vec3 sunDirection, out vec3 totalTransmittance,\n    float mu, vec3 sunLightColour, float offset){\n    \n\t// Variable to track transmittance along view ray. \n    // Assume clear sky and attenuate light when encountering clouds.\n\ttotalTransmittance = vec3(1.0);\n\n\t// Default to black.\n\tvec3 colour = vec3(0.0);\n    \n    // The distance at which to start ray marching.\n    float distToStart = 0.0;\n    \n    // The length of the intersection.\n    float totalDistance = 0.0;\n\n    // Determine if ray intersects bounding volume.\n\t// Set ray parameters in the cloud layer.\n\tbool renderClouds = getCloudIntersection(org, dir, distToStart, totalDistance);\n\n\tif(!renderClouds){\n\t\treturn colour;\n    }\n\n\t// Sampling step size.\n    float stepS = totalDistance / float(STEPS_PRIMARY); \n    \n    // Offset the starting point by blue noise.\n    distToStart += stepS * offset;\n    \n    // Track distance to sample point.\n    float dist = distToStart;\n\n    // Initialise sampling point.\n    vec3 p = org + dist * dir;\n    \n    vec3 sunLight = sunLightColour * power;\n\n    // First march through the cloud to determine scattering sample positions\n    // As an optimization, importance sample and store whole segments first\n    float transmittance = 1.0;\n    float prevSigmaE = 0.0;\n    \n    for(int i = 0; i < STEPS_PRIMARY; i++){\n        // Get density at sample point\n        // Do not clamp the density so we can utilize negative values to get more accurate segments\n        float density = clouds(p, true);\n        \n        // We don't support colored extinction for importance sampling\n        float sampleSigmaE = sigmaE.g * density;\n        \n        // Form a segment from the last step to the current one and determine sample positions\n        if (sampleSigmaE > 0.0 || prevSigmaE > 0.0)\n            sampleSegment(dist - stepS, prevSigmaE, dist, sampleSigmaE, transmittance);\n        \n        // If ray combined transmittance is close to 0, nothing beyond this sample \n        // point is visible, so break early.\n        if (transmittance <= 0.001) {\n            transmittance = 0.0;\n            break;\n        }\n        \n        prevSigmaE = sampleSigmaE;\n        dist += stepS;\n\n\t\t// Step along ray.\n\t\tp = org + dir * dist;\n    }\n\n    // Convert to colored transmittance, only works if the color was uniform\n    totalTransmittance = exp(log(transmittance) * (sigmaE / sigmaE.g));\n\n    // Now shade the samples in a separate step\n    if (transmittance != 1.0) {\n        // Combine backward and forward scattering to have details in all directions.\n        float phaseFunction = mix(HenyeyGreenstein(-0.3, mu), HenyeyGreenstein(0.3, mu), 0.7);\n        float r = frand();\n        \n        for(int i = 0; i < SCATTERING_SAMPLE_COUNT; i++){\n            // Importance sample inside the chosen segment\n            float lds = fract(r + float(i) / goldenRatio);\n            float sampleDist = sampleInsideSegment(segSamples[i], lds);\n            p = org + sampleDist * dir;\n            \n            // Normalised height for shaping and ambient lighting weighting.\n            float cloudHeight = getCloudHeight(p);\n\n            //Constant lighting factor based on the height of the sample point.\n            vec3 ambient = sunLightColour * mix((0.2), (0.8), cloudHeight);\n\n            // Amount of sunlight that reaches the sample point through the cloud \n            // is the combination of ambient light and attenuated direct light.\n            vec3 luminance = 0.1 * ambient +\n                sunLight * phaseFunction * lightRay(org, p, mu, sunDirection);\n            \n            // Since we sampled according to extinction instead of scattering amount, we need to\n            // scale the result by the difference\n            luminance *= sigmaS / sigmaE;\n\n            // Division by pdf cancels out\n            colour += luminance * (1.0 - totalTransmittance) / float(SCATTERING_SAMPLE_COUNT);\n        }\n    }\n    \n\treturn colour;\n}\n\n//------------------- The end of the scattering importance sampling code -------------------\n\n//------------- Framerate counter from https://www.shadertoy.com/view/lsKGWV ---------------\n\nfloat SampleDigit(const in float n, const in vec2 vUV)\n{\t\t\n\tif(vUV.x  < 0.0) return 0.0;\n\tif(vUV.y  < 0.0) return 0.0;\n\tif(vUV.x >= 1.0) return 0.0;\n\tif(vUV.y >= 1.0) return 0.0;\n\t\n\tfloat data = 0.0;\n\t\n\t     if(n < 0.5) data = 7.0 + 5.0*16.0 + 5.0*256.0 + 5.0*4096.0 + 7.0*65536.0;\n\telse if(n < 1.5) data = 2.0 + 2.0*16.0 + 2.0*256.0 + 2.0*4096.0 + 2.0*65536.0;\n\telse if(n < 2.5) data = 7.0 + 1.0*16.0 + 7.0*256.0 + 4.0*4096.0 + 7.0*65536.0;\n\telse if(n < 3.5) data = 7.0 + 4.0*16.0 + 7.0*256.0 + 4.0*4096.0 + 7.0*65536.0;\n\telse if(n < 4.5) data = 4.0 + 7.0*16.0 + 5.0*256.0 + 1.0*4096.0 + 1.0*65536.0;\n\telse if(n < 5.5) data = 7.0 + 4.0*16.0 + 7.0*256.0 + 1.0*4096.0 + 7.0*65536.0;\n\telse if(n < 6.5) data = 7.0 + 5.0*16.0 + 7.0*256.0 + 1.0*4096.0 + 7.0*65536.0;\n\telse if(n < 7.5) data = 4.0 + 4.0*16.0 + 4.0*256.0 + 4.0*4096.0 + 7.0*65536.0;\n\telse if(n < 8.5) data = 7.0 + 5.0*16.0 + 7.0*256.0 + 5.0*4096.0 + 7.0*65536.0;\n\telse if(n < 9.5) data = 7.0 + 4.0*16.0 + 7.0*256.0 + 5.0*4096.0 + 7.0*65536.0;\n\t\n\tvec2 vPixel = floor(vUV * vec2(4.0, 5.0));\n\tfloat fIndex = vPixel.x + (vPixel.y * 4.0);\n\t\n\treturn mod(floor(data / pow(2.0, fIndex)), 2.0);\n}\n\nfloat PrintInt(const in vec2 uv, const in float value )\n{\n\tfloat res = 0.0;\n\tfloat maxDigits = 1.0+ceil(log2(value)/log2(10.0));\n\tfloat digitID = floor(uv.x);\n\tif( digitID>0.0 && digitID<maxDigits )\n\t{\n        float digitVa = mod( floor( value/pow(10.0,maxDigits-1.0-digitID) ), 10.0 );\n        res = SampleDigit( digitVa, vec2(fract(uv.x), uv.y) );\n\t}\n\n\treturn res;\t\n}\n\nvec3 FpsCounter(vec2 uv, vec3 color)\n{\n    uv = (uv-vec2(0.0,0.9))*20.0;\n    if (uv.x <= 4.0 && uv.y >= 0.0)\n        color = max(color, vec3(PrintInt(uv, iFrameRate)));\n\n    return color;\n}\n\n//------------------------- Back to original volumetric cloud code -------------------------\n\nfloat getGlow(float dist, float radius, float intensity){\n    dist = max(dist, 1e-6);\n\treturn pow(radius/dist, intensity);\t\n}\n\n// https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/\nvec3 ACESFilm(vec3 x){\n    return clamp((x * (2.51 * x + 0.03)) / (x * (2.43 * x + 0.59) + 0.14), 0.0, 1.0);\n}\n\nvec3 drawSubpixel(in ivec2 fragCoord) {\n    srand(fragCoord, iFrame % 32);\n    \n    // Get the default direction of the ray (along the negative Z direction)\n    vec3 rayDir = rayDirection(55.0, vec2(fragCoord) / float(SUPERSAMPLING));\n   \n    //----------------- Define a camera -----------------\n    \n    vec3 cameraPos = texelFetch(iChannel1, ivec2(0.5, 1.5), 0).xyz;\n\t\n    vec3 targetDir = -cameraPos + vec3(-10.0, cloudStart + 0.5 * (cloudEnd-cloudStart), -5.0);\n    \n    vec3 up = vec3(0.0, 1.0, 0.0);\n    \n    // Get the view matrix from the camera orientation\n    mat3 viewMatrix = lookAt(cameraPos, targetDir, up);\n    \n    // Transform the ray to point in the correct direction\n    rayDir = normalize(viewMatrix * rayDir);\n    \n    //---------------------------------------------------\n\n    #ifdef COLOUR_LIGHT\n\t\tvec3 sunLightColour = 0.5 + 0.5 * cos(iTime+vec3(0,2,4));\n\t#else\n\t\tvec3 sunLightColour = vec3(1.0);\n\t#endif\n    \n    // azimuth\n\tfloat sunLocation = 1.0;\n\t// 0: horizon, 1: zenith\n\tfloat sunHeight = 0.6;\n    \n\t#ifdef ANIMATE_SUN\n    \tsunLocation = iTime * 0.3;\n\t#endif\n    \n    vec3 sunDirection = normalize(vec3(cos(sunLocation), sunHeight, sin(sunLocation)));\n    \n    vec3 background = getSkyColour(rayDir);\n\n    float mu = 0.5+0.5*dot(rayDir, sunDirection);\n    background += sunLightColour * getGlow(1.0-mu, 0.00015, 0.9);\n  \n\tvec3 totalTransmittance = vec3(1.0);\n    \n    float offset = 0.0;\n    \n    #ifdef DITHERING\n    // Sometimes the blue noise texture is not immediately loaded into iChannel3\n    // leading to jitters.\n    if(iChannelResolution[3].xy == vec2(1024)){\n        // From https://blog.demofox.org/2020/05/10/ray-marching-fog-with-blue-noise/\n        // Get blue noise for the fragment.\n        float blueNoise = texelFetch(iChannel3, fragCoord % 1024, 0).r;\n\n    \t// Blue noise texture is blue in space but animating it leads to white noise in time.\n        // Adding golden ratio to a number yields a low discrepancy sequence (apparently),\n    \t// making the offset of each pixel more blue in time (use fract() for modulo 1).\n        // https://blog.demofox.org/2017/10/31/animating-noise-for-integration-over-time/\n        offset = fract(blueNoise + float(iFrame%32) * goldenRatio);\n    }\n    #endif\n\n    float exposure = 0.5;\n    \n    #ifdef IMPORTANCE_SAMPLED\n    vec3 colour = exposure * mainRayImportanceSampled(cameraPos, rayDir, sunDirection, \n                                 totalTransmittance, dot(rayDir, sunDirection), sunLightColour, offset); \n    #else\n    vec3 colour = exposure * mainRay(cameraPos, rayDir, sunDirection, \n                                     totalTransmittance, dot(rayDir, sunDirection), sunLightColour, offset); \n    #endif\n\n    colour += background * totalTransmittance;\n   \n    return colour;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    vec3 colour = vec3(0.0);\n    \n    for (int x = 0; x < SUPERSAMPLING; x++) {\n        for (int y = 0; y < SUPERSAMPLING; y++) {\n            ivec2 subCoord = ivec2(fragCoord) * SUPERSAMPLING + ivec2(x,y);\n            colour += drawSubpixel(subCoord);\n        }\n    }\n    \n    colour /= float(SUPERSAMPLING * SUPERSAMPLING);\n    \n    // Tonemapping\n    colour = ACESFilm(colour);\n\n    // Gamma correction 1.0/2.2 = 0.4545...\n    colour = pow(colour, vec3(0.4545));\n    \n    #ifdef NOISE_ATLAS\n    colour = texture(iChannel0, 0.3 * fragCoord.xy/iResolution.xy).rgb;\n    #endif\n    \n    colour = FpsCounter(fragCoord.xy / iResolution.y, colour);\n    \n    // Output to screen\n    fragColor = vec4(colour, 1.0);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//Create a Perlin-Worley texture atlas for cloud shape carving.\n//Runs only once in the first frame.\n//Based on https://github.com/sebh/TileableVolumeNoise/blob/master/main.cpp\n\n//The atlas is a 6*6 grid of 32*32 tiles with a single layer of halo cells around each tile. \n\n//TODO: Assumes a size of at least 204 * 204. Make it work with any reasonable resolution.\n\n#define PERLIN_WORLEY 0\n#define WORLEY 1\n\nvec3 modulo(vec3 m, float n){\n  return mod(mod(m, n) + n, n);\n}\n\n// 5th order polynomial interpolation\nvec3 fade(vec3 t){\n    return (t * t * t) * (t * (t * 6.0 - 15.0) + 10.0);\n}\n\n#define SIZE 8.0\n\n// https://www.shadertoy.com/view/4djSRW\nvec3 hash(vec3 p3){\n    p3 = modulo(p3, SIZE);\n    p3 = fract(p3 * vec3(0.1031, 0.1030, 0.0973));\n    p3 += dot(p3, p3.yxz + 33.33);\n    return 2.0 * fract((p3.xxy + p3.yxx) * p3.zyx) - 1.0;\n}\n\nfloat gradientNoise(vec3 p){\n\n    vec3 i = floor(p);\n    vec3 f = fract(p);\n\t\n\tvec3 u = fade(f);\n    \n    /*\n    * For 1D, the gradient of slope g at vertex u has the form h(x) = g * (x - u), where u \n    * is an integer and g is in [-1, 1]. This is the equation for a line with slope g which \n    * intersects the x-axis at u.\n    * For N dimensional noise, use dot product instead of multiplication, and do \n    * component-wise interpolation (for 3D, trilinear)\n    */\n    return mix( mix( mix( dot( hash(i + vec3(0.0,0.0,0.0)), f - vec3(0.0,0.0,0.0)), \n              dot( hash(i + vec3(1.0,0.0,0.0)), f - vec3(1.0,0.0,0.0)), u.x),\n         mix( dot( hash(i + vec3(0.0,1.0,0.0)), f - vec3(0.0,1.0,0.0)), \n              dot( hash(i + vec3(1.0,1.0,0.0)), f - vec3(1.0,1.0,0.0)), u.x), u.y),\n    mix( mix( dot( hash(i + vec3(0.0,0.0,1.0)), f - vec3(0.0,0.0,1.0)), \n              dot( hash(i + vec3(1.0,0.0,1.0)), f - vec3(1.0,0.0,1.0)), u.x),\n         mix( dot( hash(i + vec3(0.0,1.0,1.0)), f - vec3(0.0,1.0,1.0)), \n              dot( hash(i + vec3(1.0,1.0,1.0)), f - vec3(1.0,1.0,1.0)), u.x), u.y), u.z );\n}\n\n\nfloat getPerlinNoise(vec3 pos, float frequency){\n\n\t//Compute the sum for each octave.\n\tfloat sum = 0.0;\n\tfloat weightSum = 0.0;\n\tfloat weight = 1.0;\n\n\tfor(int oct = 0; oct < 3; oct++){\n\n        vec3 p = pos * frequency;\n        float val = 0.5 + 0.5 * gradientNoise(p);\n        sum += val * weight;\n        weightSum += weight;\n\n        weight *= 0.5;\n        frequency *= 2.0;\n\t}\n\n\treturn saturate(sum / weightSum);\n}\n\nfloat worley(vec3 pos, float numCells){\n\tvec3 p = pos * numCells;\n\tfloat d = 1.0e10;\n\tfor (int x = -1; x <= 1; x++){\n\t\tfor (int y = -1; y <= 1; y++){\n\t\t\tfor (int z = -1; z <= 1; z++){\n                vec3 tp = floor(p) + vec3(x, y, z);\n                tp = p - tp - (0.5 + 0.5 * hash(mod(tp, numCells)));\n                d = min(d, dot(tp, tp));\n            }\n        }\n    }\n\treturn 1.0 - saturate(d);\n}\n\n//Return the 3D coordinate corresponding to the 2D atlas uv coordinate.\nvec3 get3Dfrom2D(vec2 uv, float tileRows){\n    vec2 tile = floor(uv);\n    float z = floor(tileRows * tile.y + tile.x);\n    return vec3(fract(uv), z);\n}\n\n\n#define NUM_CELLS 2.0\n\nfloat getTextureForPoint(vec3 p, int type){\n\tfloat res;\n    if(type == PERLIN_WORLEY){\n        \n        //Perlin-Worley.\n        float perlinNoise = getPerlinNoise(p, SIZE);\n        res = perlinNoise;\n\n        //Special weights from example code.\n        float worley0 = worley(p, NUM_CELLS * 2.0);\n        float worley1 = worley(p, NUM_CELLS * 8.0);\n        float worley2 = worley(p, NUM_CELLS * 14.0);\n\n        float worleyFBM = worley0 * 0.625 + worley1 * 0.25 + worley2 * 0.125;\n        res = remap(perlinNoise, 0.0, 1.0, worleyFBM, 1.0);\n        \n\t}else{\n\n        //Worley\n        float worley0 = worley(p, NUM_CELLS);\n        float worley1 = worley(p, NUM_CELLS * 2.0);\n        float worley2 = worley(p, NUM_CELLS * 4.0);\n        float worley3 = worley(p, NUM_CELLS * 8.0);\n\n        float FBM0 = worley0 * 0.625 + worley1 * 0.25 + worley2 * 0.125;\n\t\tfloat FBM1 = worley1 * 0.625 + worley2 * 0.25 + worley3 * 0.125;\n\t\tfloat FBM2 = worley2 * 0.75 + worley3 * 0.25;\n\n        res = FBM0 * 0.625 + FBM1 * 0.25 + FBM2 * 0.125;\n\t}\n    \n\treturn res;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    \n    if(iFrame < 1 || length(texelFetch(iChannel0, ivec2(0), 0).rgba) == 0.0){\n        vec3 col = vec3(0);\n        //32 with 1 pixel on either side.\n        float tileSize = 34.0;\n        float padWidth = 1.0;\n        float coreSize = tileSize - 2.0 * padWidth;\n        float tileRows = 6.0;\n        float tileCount = tileRows * tileRows;\n        vec2 tile = floor((fragCoord.xy - 0.5) / tileSize);\n\n        bool padCell = false;\n        if(mod(fragCoord.x, tileSize) == 0.5 || mod(fragCoord.x, tileSize) == tileSize - 0.5){\n            padCell = true;\n        }\n        if(mod(fragCoord.y, tileSize) == 0.5 || mod(fragCoord.y, tileSize) == tileSize - 0.5){\n            padCell = true;\n        }\n\n        bool startPadX = false;\n        bool endPadX = false;\n        bool startPadY = false;\n        bool endPadY = false;\n\n        if(fragCoord.x == tile.x * tileSize + 0.5){\n            startPadX = true;\n        }\n        if(fragCoord.y == tile.y * tileSize + 0.5){\n            startPadY = true;\n        }\n        if(fragCoord.x == (tile.x + 1.0) * tileSize - 0.5){\n            endPadX = true;\n        }\n        if(fragCoord.y == (tile.y + 1.0) * tileSize - 0.5){\n            endPadY = true;\n        }\n\n        vec2 padding = vec2(2.0 * padWidth) * tile;\n        vec2 pixel;\n        vec2 uv;\n        \n        if(!padCell){\n            pixel = fragCoord.xy - padWidth - padding;\n            uv = vec2(pixel.xy/coreSize);\n        }else{\n            pixel = fragCoord.xy - padWidth - padding;\n            if(startPadX){\n                pixel.x += coreSize;\t\n            }\n            if(startPadY){\n                pixel.y += coreSize;\t\n            }\n            if(endPadX){\n                pixel.x -= coreSize;\t\n            }\n            if(endPadY){\n                pixel.y -= coreSize;\t\n            }\n            uv = vec2(pixel.xy/coreSize);\n        }\n        \n        vec3 p_ = get3Dfrom2D(uv, tileRows);\n        vec3 p = p_;\n        p.z /= (tileRows*tileRows);\n\n        // Get Perlin-Worley noise for level l\n        float worleyPerlinNoise = getTextureForPoint(p, PERLIN_WORLEY);\n\n        // Get Worley noise for level l\n        float worleyNoise = getTextureForPoint(p, WORLEY);\n        col.r = saturate(remap(worleyPerlinNoise, worleyNoise, 1.0, 0.0, 1.0));\n\n        p_ = mod(p_ + 1.0, tileRows * tileRows);\n        p = p_;\n        p.z /= (tileRows*tileRows);\n\n        // Get Perlin-Worley noise for level l+1\n        worleyPerlinNoise = getTextureForPoint(p, PERLIN_WORLEY);\n\n        // Get Worley noise for level l+1\n        worleyNoise = getTextureForPoint(p, WORLEY);\n        col.g = saturate(remap(worleyPerlinNoise, worleyNoise, 1.0, 0.0, 1.0));\n\n        // Unused cells\n        if(gl_FragCoord.x > tileRows * tileSize || gl_FragCoord.y > tileRows * tileSize){\n            col = vec3(0);\n        }\n        \n    \tfragColor = vec4(col,1.0);\n        \n    }else{\n        \n    \tfragColor = texelFetch(iChannel0, ivec2(fragCoord - 0.5), 0).rgba;\n        \n    }\n\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"//Track mouse movement and resolution change between frames and set camera position.\n\n#define PI 3.14159\n#define EPS 1e-4\n#define CAMERA_DIST 180.0\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    \n    //Work with just the first four pixels.\n    if((fragCoord.x == 0.5) && (fragCoord.y < 4.0)){\n        \n        vec4 oldData = texelFetch(iChannel0, ivec2(0.5), 0).xyzw;\n\n        vec2 oldPolarAngles = oldData.xy;\n        vec2 oldMouse = oldData.zw;\n\n        vec2 polarAngles = vec2(0);\n        vec2 mouse = iMouse.xy / iResolution.xy; \n        \n        // Stop camera going directly above and below\n        float angleEps = 0.01;\n\n        float mouseDownLastFrame = texelFetch(iChannel0, ivec2(0.5, 3.5), 0).x;\n        \n        // If mouse button is down and was down last frame.\n        if(iMouse.z > 0.0 && mouseDownLastFrame > 0.0){\n            \n            // Difference between mouse position last frame and now.\n            vec2 mouseMove = mouse - oldMouse;\n            polarAngles = oldPolarAngles + vec2(5.0, 3.0) * mouseMove;\n            \n        }else{\n            polarAngles = oldPolarAngles;\n        }\n        \n        polarAngles.x = modulo(polarAngles.x, 2.0 * PI - angleEps);\n        polarAngles.y = min(PI - angleEps, max(angleEps, polarAngles.y));\n\n        // Store mouse data in the first pixel of Buffer A.\n        if(fragCoord == vec2(0.5, 0.5)){\n            // Set value at first frames.\n            if(iFrame < 10){\n                polarAngles = vec2(2.3, 1.7);\n                mouse = vec2(0);\n            }\n            fragColor = vec4(polarAngles, mouse);\n        }\n\n        // Store camera position in the second pixel of Buffer A.\n        if(fragCoord == vec2(0.5, 1.5)){\n            // Cartesian direction from polar coordinates.\n            vec3 cameraPos = normalize(vec3(-cos(polarAngles.x) * sin(polarAngles.y), \n                                             cos(polarAngles.y), \n                                            -sin(polarAngles.x) * sin(polarAngles.y)));\n\n            fragColor = vec4(vec3(-10.0, 0.0, -5.0) + CAMERA_DIST * cameraPos, 1.0);\n        }\n        \n        //Store resolution change data in the third pixel of Buffer B.\n        if(fragCoord == vec2(0.5, 2.5)){\n            float resolutionChangeFlag = 0.0;\n            //The resolution last frame.\n            vec2 oldResolution = texelFetch(iChannel0, ivec2(0.5, 2.5), 0).yz;\n            \n            if(iResolution.xy != oldResolution){\n            \tresolutionChangeFlag = 1.0;\n            }\n            \n        \tfragColor = vec4(resolutionChangeFlag, iResolution.xy, 1.0);\n        }\n           \n        //Store whether the mouse button is down in the fourth pixel of Buffer A\n        if(fragCoord == vec2(0.5, 3.5)){\n            if(iMouse.z > 0.0){\n            \tfragColor = vec4(vec3(1.0), 1.0);\n            }else{\n            \tfragColor = vec4(vec3(0.0), 1.0);\n            }\n        }\n        \n    }\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"/*\n    Copyright (c) 2020 al-ro\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in all\n    copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    SOFTWARE.\n*/\n\nfloat saturate(float x){\n\treturn clamp(x, 0.0, 1.0);\n}\n\nfloat remap(float x, float low1, float high1, float low2, float high2){\n\treturn low2 + (x - low1) * (high2 - low2) / (high1 - low1);\n}\n\nfloat modulo(float m, float n){\n  return mod(mod(m, n) + n, n);\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"//Simple cloud map to define where clouds occur.\n\nfloat circularOut(float t) {\n  return sqrt((2.0 - t) * t);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    \n    bool resolutionChanged = (texelFetch(iChannel0, ivec2(0.5, 2.5), 0).x == 1.0);\n    \n    //Draw map at the first frame or when the resolution has changed.\n    if(iFrame < 1 || resolutionChanged){\n    \tvec2 uv = fragCoord/iResolution.xy;\n        uv -= 0.5;\n\n        //Three overlapping circles.\n        uv *= 5.0;\n        float dist = circularOut(max(0.0, 1.0-length(uv)));\n        uv *= 1.2;\n        dist = max(dist, 0.8*circularOut(max(0.0, 1.0-length(uv+0.65))));\n        uv *= 1.3;\n        dist = max(dist, 0.75*circularOut(max(0.0, 1.0-length(uv-0.75))));\n\n        vec3 col = vec3(dist);\n\n        fragColor = vec4(col,1.0);\n    }else{\n        //Reuse data in buffer.\n    \tfragColor = texelFetch(iChannel1, ivec2(fragCoord - 0.5), 0).rgba;;\n    }\n}","name":"Buffer C","description":"","type":"buffer"}]}
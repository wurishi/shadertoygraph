{"ver":"0.1","info":{"id":"wdcyRS","date":"1601131200","viewed":443,"name":"Audio Channel test","username":"itgaz","description":"Test area for audio channels behaviour, to help me write a desktop shadertoy application","likes":3,"published":3,"flags":4,"usePreview":0,"tags":["audio"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XdXGRr","filepath":"/presets/mic.png","previewfilepath":"/presets/mic.png","type":"mic","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    \n#define FFT 1\n#if FFT\n    // FFT Value is stored in red channel, at y == 0.25\n    // x represents the FFT bucket, so a basic spectrum display is just x,0.25 + cutoff\n    vec4 channel0FFT = texture(iChannel0, vec2(uv.x, 0.25));\n    \n    if( uv.y > channel0FFT.r ) {\n      fragColor = vec4(0.0,0.0,0.0,1.0); //vec4(0.5 + 0.5*cos(iTime+uv.xyx+vec3(0,2,4)), 1.0);\n    } else {\n      fragColor = channel0FFT;\n    }\n#else\n    // Amplitude is stored in red channel, at y == 0.75\n    // x represents time, seems to roughly be last frame time <= x <= current frame time?\n    // (TODO) I believe each X pixel is a single sample from the input, so the texture may not\n    // contain a whole frame worth of audio\n    vec4 channel0Amplitude = texture(iChannel0, vec2(uv.x, 0.75));\n    \n    if( abs(0.5 - uv.y) > channel0Amplitude.r * 0.5 ) {\n    \tfragColor = vec4(0.0,0.0,0.0,1.0); //vec4(0.5 + 0.5*cos(iTime+uv.xyx+vec3(0,2,4)), 1.0);\n    } else {\n    \tfragColor = channel0Amplitude;\n    }\n    \n#endif\n}","name":"Image","description":"","type":"image"}]}
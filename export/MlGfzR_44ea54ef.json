{"ver":"0.1","info":{"id":"MlGfzR","date":"1547317015","viewed":65,"name":"phongplaneray","username":"caudya","description":"phong","likes":0,"published":1,"flags":0,"usePreview":0,"tags":["phong","planeray"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Photorealistic rendering course - Step 04\n// By Alan \"Latex\" Savary.\n//\n// Next step: \"[Step05] Shadow casting\"\n//\n\n//##############################################################################################\n\n// - The aim is to render a 3D sphere seen by a 3D camera with Phong illumination shading.\n// - The sphere is defined by its 3D position and its radius.\n// - The camera is defined by its 3D position, the fact that it looks towards a 3D point target,\n//   has its up vector as upward as possible, and its field of view defined by a vertical angle.\n// \n// The different space coordinates:\n//\n//                +----------------+\n//                |                |\n//                |     screen     |\n//              Y î                |\n//                |                |\n//                +->--------------+\n//                   X\n//                    \n//\n//                                +-----------------+\n//                               .|                .|\n//                               .|        +      . |\n//                               .|       .     .   |\n//                               .+------.-----.----+\n//                               ..     .    .     .\n//                               ..    .   .    .\n//                               ..   .  .    .\n//                               .   .  .    .\n//                               .  . .  .\n//                               cz.. .\n//                               ./.\n//                               /\n//                      camera  +---> cx      \n//                              |\n//                              |\n//                              v cy\n//\n//            \n//                 Y\n//                  î\n//                  |       world\n//                  +--> X  \n//                 /  \n//              Z /   \n//        \n\n//##############################################################################################\n\n// In GLSL, IEEE 754 infinity can conveniently be achieved by dividing by zero:\nconst float FLT_MAX = 1.0 / 0.0;    \n\n// We can define a structure that will contain the parameters needed\n// by an object to specify its shading according to Phong shading.\nstruct Material\n{\n    float Ka;\t// ambiant        coefficient\n    float Kd;\t// diffuse        coefficient\n    float Ks;\t// specular       coefficient\n    float Kn;\t// specular power coefficient\n};\n    \n    // ~ ~ ~ ~ ~ ~ ~ ~ \n        \n// Camera parameters\nvec3\t   cameraPos    = vec3(6,  4, -5);\nconst vec3\t   cameraTarget = vec3(3,  1, -8);\nconst float    cameraFovY   = 80.0;\t\t\t\t// NOTE: angle in degree\n\n// Sky parameters\nconst vec3     skyCol       = vec3(0);\t\t\t// black\nconst int      skyId        = 0;\n\n// Sphere parameters\nvec3     spherePos    = cameraTarget + vec3(0, 1, 2);\nconst float    sphereRadius = 1.0;\nconst vec3     sphereCol    = vec3(1,0,0);\t\t// red\nconst Material sphereMat    = Material(0.2/*Ka*/, 0.7/*Kd*/, 1.0/*Ks*/, 50.0/*Kn*/);\nconst int      sphereId     = 1;\n\n// Plane parameters\nconst vec3     planePos     = vec3(0, 0.1, 0);\nconst vec3     planeNormal  = vec3(0, 1.0, 0);\nconst vec3     planeCol1    = vec3(1.0);\t\t// white\nconst vec3     planeCol2    = vec3(0.4);\t\t// gray\nconst Material planeMat     = Material(0.2/*Ka*/, 1.0/*Kd*/, 0.2/*Ks*/,  5.0/*Kn*/);\nconst int      planeId      = 2;\n\n// Light(s) parameters\nconst vec3     ambiantCol   = vec3(0,0,1);\t\t// blue\nconst vec3     lightCol     = vec3(1,1,1);\t\t// white\nvec3     lightPos     = vec3(8, 10, -12);\n\n\nconst float eps = 0.01;\n\n    \n//##############################################################################################\n\nvoid animateScene(in float time) {\n    //animate the sphere position\n\tconst float pi = 3.1415926535;\n\tconst float rs = 2.0;\n\tconst float spr = 5.0;\n\tfloat as = 2.0*pi * time /spr;\n\n    spherePos = cameraTarget + rs * vec3(-sin(as), 0.0, cos(as)) + vec3(0, 1, 0);\n    \n    lightPos += vec3(0.0, 10.5 + 9.5 * cos(time) - 10.0, 0.0);\n    \n    float targetDist = length(cameraTarget - cameraPos);\n    cameraPos -= vec3(0, 0, targetDist);\n    cameraPos += targetDist * vec3(sin(time), max(sin(time*0.5), 0.0), cos(time));\n    \n}\n    \n\nfloat raySphere(    vec3 rayPos    ,     vec3 rayDir, vec3 spherePos, float sphereRadius,\n                out vec3 intersecPt, out vec3 normal)\n{\n    // Explanation:\n    //\n    //  Any point P(t) on the ray respect the following equation:\n    //\n    //         P(t) = rayPos + t * rayDir                            (1)\n    //\n    //  Any point on the sphere must be at sphereRadius distance from the sphere center.\n    //  Which, for a point P of space, yields to follow equation:\n    //\n    //                 distance(P - spherePos)   = sphereRadius\n    //     <=>         distance(P - spherePos)^2 = sphereRadius^2\n    //     <=> dot(P - spherePos, P - spherePos) = sphereRadius^2    (2)\n    //\n    // The intersection point(s) of the ray with the sphere must respect both equations.\n    // So, we can replace P of equation (2) with (1) to express both constraints into a\n    // single equation:\n    //\n    //      dot(rayPos+t*rayDir - spherePos, rayPos+t*rayDir - spherePos) = sphereRadius^2\n    //  <=> dot(t*rayDir + rayPos-spherePos, t*rayDir + rayPos-spherePos) = sphereRadius^2\n    //  <=> dot(t * rayDir + diff, t * rayDir + diff)                     = sphereRadius^2\n    //        ; with diff = rayPos - spherePos\n    //\n    // As we can 'distribute' additive component over a dot product, we have:\n    //\n    //      dot(t*rayDir, t*rayDir) + 2*dot(diff,t*rayDir) + dot(diff, diff) = sphereRadius^2\n    //  <=> t^2*dot(rayDir, rayDir) + t*2*dot(diff,rayDir) + dot(diff, diff) = sphereRadius^2\n    //  <=> t^2*dot(rayDir, rayDir) + t*2*dot(diff,rayDir) + dot(diff, diff)-sphereRadius^2 = 0\n    //  <=> a*t^2 + b*t + c = 0\n    //        ; with:\n    //                a =   dot(rayDir, rayDir)\n    //                b = 2*dot(diff  , rayDir)\n    //                c =   dot(diff  , diff  ) - sphereRadius^2\n    //\n    // This is a 2nd degree (quadratic) equation to solve.\n    //\n    // If discriminant di (= b^2 - 4*a*c) is negative, the ray doesn't intersect the sphere.\n    // Otherwise there are up to two solutions (t1 and t2).\n    \n    vec3 diff = rayPos - spherePos;\n    \n    float a =       dot(rayDir, rayDir);\n    float b = 2.0 * dot(diff  , rayDir);\n    float c =       dot(diff  , diff  ) - sphereRadius * sphereRadius;\n    \n    float di = b*b - 4.0*a*c;\n    \n    if (di >= 0.0)\n    {\n        float sdi = sqrt(di);\n        float den = 1. / (2.0 * a);\n        float t1  = (-b - sdi) * den;\n        float t2  = (-b + sdi) * den;\n        \n        // We can notice that 'a' (so 'den') and sdi are positive.\n        // So, we know for sure that t1 <= t2 whatever the configuration.\n\n        // We can also list all the possibilities of intersection or non-intersection:\n        //\n        //    t1...t2.....r------------>\t(t1<0 & t2<0)\t\t\tno intersection\n        //       t1t2.....r------------>\t(t1<0 & t2<0 & t1=t2)\tno intersection\n        //    t1........t2r------------>\t(t1<0 & t2=0)\t\t\tassume no intersection\n        //            t1t2r------------>\t(t1=t2=0)\t\t\t\tassume no intersection\n        //    t1..........r--------t2-->\t(t1<0 & t2>0)\t\t\tintersection at (t2, -n)\n        //              t1r--------t2-->\t(t1=0 & t2>0)\t\t\tintersection at (t2, -n)\n        //                r---t1---t2-->\t(t1>0 & t2>t1)\t\t\tintersection at (t1,  n)\n        //                r---t1t2----->\t(t1>0 & t2=t1)\t\t\tintersection at (t1,  n)\n        \n        // This can be summed up by:\n\t\t//        \n        // If t1 >  0, then the sphere is ahead of the ray, and the point we see is the\n        //             one associated to t1 with a normal pointing outward the sphere.\n        //             \n        // If t1 <= 0 and t2 >  0, then the ray starts inside the sphere, and the point we see\n        //                         is the one associated to t2 with a normal point inward the\n        //                         sphere.\n        //                         \n        // Otherwise, there is no intersection or we assume there is none.\n\n        float t = -1.0;\n        float dir = 1.0;\n        if (t1 > 0.0)\n        \tt = t1;\n        else if (t2 > 0.0)\n        {\n            t = t2;\n            dir = -1.0;\n        }\n        else\n            return t;\n        \n        // As we found the value of t, we can insert it into equation (1) to find\n        // the position of the first intersection point encountered along the ray.\n        intersecPt = rayPos + t * rayDir;\n\n        // Then, we can use the property of a sphere that the infinite line along the\n        // normal vector to a point on the sphere is passing through the center of the\n        // sphere.\n        // Then, we need to reverse the vector direction if the intersection point is\n        // seen from inside the sphere.\n        normal     = normalize(intersecPt - spherePos) * dir;\n        \n        return t;\n    }\n    \n    return -1.0;\n}\n\n//----------------------------------------------------------------------------------------------\n\n// NOTE: planeNormal must be a unit-vector!\nfloat rayPlane(    vec3 rayPos    ,     vec3 rayDir, vec3 planePos, vec3 planeNormal,\n               out vec3 intersecPt, out vec3 normal)\n{\n    // Explanation:\n    //\n    //  Any point P(t) on the ray respect the following equation:\n    //\n    //         P(t) = rayPos + t * rayDir                            (1)\n    //\n    //  The analytic equation of a plane is of the form: a * x + b * y + c * z + d = 0\n    //  That can be rewritten with a dot-product:              (a,b,c).(x,y,z) + d = 0\n    //  With (a,b,c) being the normal N to the plane which defines the orientation of the plane,\n    //  with (x,y,z) being any 3D point of space, and 'd' defining at which position the plane\n    //  is located.\n    //\n    //  NOTE: Without loss of generality (a,b,c) can be normalized and d scaled accordingly.\n    //        So, the normal is assumed here to be a unit-vector!!!\n    //\n    //  So, we have:    dot(planeNormal, P) + d = 0   for any 3D point P on the plane\n    //\n    //  We can find d because we know our plane pass through planePos point.\n    //  This means planePos also follow the above equation:\n    //      \n    //          dot(planeNormal, planePos) + d = 0\n    //      <=> d = -dot(planeNormal, planePos)\n    //\n    //  So, we now know the complete equation of the plane:\n    //\n    //          dot(planeNormal, P) + (-dot(planeNormal, planePos)) = 0\n    //      <=> dot(planeNormal, P) - dot(planeNormal, planePos) = 0\n    //      <=> dot(planeNormal, P - planePos) = 0                   (2)\n    //\n    // The intersection point(s) of the ray with the plane must respect both equations.\n    // So, we can replace P of equation (2) with (1) to express both constraints into a\n    // single equation:\n    //\n    //      dot(planeNormal, (rayPos + t * rayDir) - planePos) = 0\n    //  <=> dot(planeNormal, t * rayDir + (rayPos - planePos)) = 0\n    //\n    // As we can 'distribute' additive component over a dot product, we have:\n    //\n    //      dot(planeNormal, t * rayDir) + dot(planeNormal, (rayPos - planePos)) = 0\n    //  <=> t * dot(planeNormal, rayDir) + dot(planeNormal, rayPos - planePos) = 0\n    //  <=> t * dot(planeNormal, rayDir) = -dot(planeNormal, rayPos - planePos)\n    //  <=> t * dot(planeNormal, rayDir) =  dot(planeNormal, planePos - rayPos)\n    //\n    // We can find t if 'den = dot(planeNormal, rayDir)' is not zero.\n    // In the case it is zero, it means the ray is parallel to the plane, and there will be\n    // no interesction (or an infinity if the rayPos is on the plane. In that case, we choose\n    // to assume that we have no intersection at all).\n    //\n    // So, here after in this explanation, we assume 'den' is non zero.\n    //\n    // We can then find the value of 't' at which the intersection occurs:\n    //\n    //    t = dot(planeNormal, planePos - rayPos) / dot(planeNormal, rayDir)\n    \n    float den = dot(planeNormal, rayDir);\n    \n    if (abs(den) <= 0.000001)\t// To avoid numerical instabilities we consider the ray to be \n        return -1.0;\t\t\t// parallel if the angle between the normal and the ray is\n        \t\t\t\t\t\t// ALMOST zero.\n        \t\t\t\t\t\n    float t = dot(planeNormal, planePos - rayPos) / den;\n    \n    // As we found the value of t, we can insert it into equation (1) to find\n    // the position of the first intersection point encountered along the ray.\n    intersecPt = rayPos + t * rayDir;\n    \n    // NOTE: The normal to be returned has to be pointing 'towards' the rayPos position.\n    //       So, the angle between the ray direction and the normal must > 90°, so the\n    //       dot-product should be negative.\n    //       This can be expressed by taking the 'sign' of den\n    normal = -sign(den) * planeNormal;\n    \n    return t;\n}\n\n//----------------------------------------------------------------------------------------------\n\nvoid computeCameraRayFromPixel( in vec2 pixCoord, out vec3 rayPos, out vec3 rayDir)\n{\n    // Compute camera focal length for a height on image plane going in [-1,1] range\n    //\n    //        \n    //                     -1\n    //                  /|  \n    //                 / |\n    //                /  |\n    //               /   |\n    //              /). .|. . . . . . fovY (vertical angle field of view expressed in degrees)\n    //             /  )  |\n    //            +---)--|-----> cz\n    //            |\\  )  |           î\n    //            | \\)   |           |\n    //            v  \\   |           |\n    //           cy   \\  |           | h\n    //                 \\ |           |\n    //                  \\|           |\n    //                     1         v\n    //                         \n    //            <------>\n    //              focal length\n    //\n    //    We have that:\n    //\n    //        tan((2*Pi/180)*cameraFovY/2) = h / focal\n    //    <=> focal = h / tan(radians(cameraFovY/2))\n    //    <=> focal = 1 / tan(radians(cameraFovY/2))\n                 \n    float focal = 1.0 / tan(radians(cameraFovY) / 2.0);\n    \n    // Compute camera three main axis (X,Y,Z) expressed in world space\n    //\n    //  NOTES: - First, we compute the Z camera unit vector that goes from the camera position\n    //           and look toward the camera target.\n    \n    vec3 cz = normalize(cameraTarget - cameraPos);\n    \n    //         - Then, we use the fact that the cross-product of two vectors (even if not\n    //           perpendicular) gives a third vector that is perpendicular to the two others.\n    //           Plus, the direction given by the result is given by applying the 'right-hand'\n    //           technique by pointing the thumb along the first vector, the index finger along\n    //           the second vector, and the result will be given by the middle finger.\n    //           NOTE: the length of the resulting vector needs to be normalized if the two\n    //                 input vectors aren't perpendicular AND of unit length.\n    //         - To compute the cx vector, we can assume, temporarily, that the cy vector is the\n    //           perfect '-up' vector.\n    //           This is possible because cy must be as near as '-up' and the true cy vector\n    //           will be in the same plane than the plane defined by the cz & the 'up' vectors.\n    //         - So, as: cx = cross-product(cy, cz)\n    //                      = normalized(cross-product(-up, cz))\n    \n    vec3 up = vec3(0,1,0);\t\t\t\t\t\t\t// perfect up vector\n    vec3 cx = normalize(cross(-up, cz));\n    \n    //         - Finally, we can find the true cy by applying: cy = cross-product(cz, cx)\n\n    vec3 cy = normalize(cross( cz, cx));\n\n    // Here we apply a set of transformations to transform the coordinates range:\n    //\n    //     pixCoord.xy                  is in range [0..  iResolution.x] x [0..  iResolution.y]\n    //\n    //  2.*pixCoord.xy                  is in range [0..2*iResolution.x] x [0..2*iResolution.y]\n    //\n    //  2.*pixCoord.xy - iResolution.xy is in range\n    //                        [-iResolution.x..iResolution.x] x [-iResolution.y..iResolution.y]\n    //\n    //  pt = (2.*pixCoord.xy - iResolution.xy) / iResolution.y is in range\n    //                         [-ratio,ratio] x [-1, 1] \n    //            with ratio = iResolution.x / iResolution.y;\n    //\n    // Here the scaled applied is uniform because we divide horizontal & vertical coordinates\n    // by the same value: iResolution.y\n    \n    vec2 pt = (2.*pixCoord - iResolution.xy) / iResolution.y;\n    \n\t// We can now find the ray properties:\n    //   - The ray start position is the camera position\n    //   - The ray direction can be decomposed into 3 sub-vectors:\n    //      *            dy = (-pt.y) * cy   because pt vertical axis is going in opposite\n    //                                       direction than cy, and pt.y is in range [-1,1],\n    //                                       which matches the range spanned by vertical\n    //                                       positions (in camera space) on the image plane\n    //                                       located at the focal length distance along cz.\n    //\n    //      * similarly: dx =    pt.x * cx   NOTE: pt.x and horizontal positions (in camera\n    //                                             space) shares the same range (taking into\n    //                                             account the image ratio. Said differently,\n    //                                             image & camera have the same ratio).\n    //      * and:       dz =   focal * cz\n    //\n    //     which brings that: rayDir = pt.x * cx - pt.y * cy + focal * cz\n    //\n    //   - Finally, the ray direction is normalized because it makes it more practical later on.\n\n    rayPos = cameraPos;\n    rayDir = normalize(pt.x * cx - pt.y * cy + focal * cz);\n}\n\n//----------------------------------------------------------------------------------------------\n\n// The aim of this routine is to find the nearest intersection the ray has with ALL the objects\nfloat computeNearestIntersection(vec3 rayPos, vec3 rayDir,\n                                 out int objectId, out vec3 intersecI, out vec3 normalI)\n{\n    // Set the default value when no intersection is found: we hit the 'sky'\n    float minDist  = FLT_MAX;\n          objectId = skyId;\n    \n    // Test the sphere\n    vec3 intersecS, normalS;\n    float distS = raySphere(rayPos, rayDir, spherePos, sphereRadius, intersecS, normalS);\n    if ((distS > 0.0) && (distS < minDist))\n    {\n        objectId  =  sphereId;\n        minDist   =     distS;\n        intersecI = intersecS;\n          normalI =   normalS;\n    }\n    \n    // Test the plane\n    vec3 intersecP, normalP;\n    float distP =  rayPlane(rayPos, rayDir,  planePos,  planeNormal, intersecP, normalP);\n    if ((distP > 0.0) && (distP < minDist))\n    {\n        objectId  =   planeId;\n        minDist   =     distP;\n\t    intersecI = intersecP;\n    \t  normalI =   normalP;\n    }\n    \n    // To remain coherent with the raySphere & rayPlane function that returns -1 when no\n    // intersetion is found, we add the following two lines:\n    if (objectId == skyId)\n        minDist = -1.0;\n    \n    return minDist;\n}\n\n//----------------------------------------------------------------------------------------------\n\nvec3 getSphereColorAtPoint(vec3 pt)\n{\n    return sphereCol;\n}\n\n//----------------------------------------------------------------------------------------------\n\n// pt is assumed to be on the plane surface\nvec3 getPlaneColorAtPoint(vec3 pt)\n{\n    // As the plane is textured with a checkboard pattern, we need to define\n    // a 'texture coordinate frame'.\n    //\n    // NOTE: As this is pixel independent it could be calculated once and\n    //       defined by 'const' global value at the top of this source code.\n\t//    \n    // For that, we need first to compute the two X & Y axis of the plane that will serve with\n    // the plane position as defining fully this texture coordinate frame.\n    //\n    // We assume the plane normal is the plane Z-axis.\n    //\n    // We want to find what will be the plane X-axis if this axis is as near as possible to the\n    // world X axis.\n\n    vec3 worldX = vec3(1,0,0);\n    vec3 axisX  = normalize(worldX - dot(worldX, planeNormal) * planeNormal);\n    \n    // We then find the plane Y-axis thanks to the cross-product\n    // properties with orthonormal basis\n    vec3 axisY  = normalize(cross(planeNormal, axisX));\n\n    // Now, find the coordinate of the input point according to this texture coordinate frame\n    vec3 diff = pt - planePos; \n    float u = dot(diff, axisX);\n    float v = dot(diff, axisY);\n    \n    // Finally, apply the checkboard pattern by using this very concise formula:\n    return mod(floor(u * 0.5) + floor(v * 0.5), 2.0) < 1.0  ? planeCol1 : planeCol2;\n}\n\n//----------------------------------------------------------------------------------------------\n\nvec3 getObjectColorAtPoint(int objectId, vec3 pt, out Material objectMat)\n{\n    if (objectId == sphereId)\n    {\n        objectMat = sphereMat;\n        return getSphereColorAtPoint(pt);\n    }\n    else if (objectId == planeId)\n    {\n        objectMat = planeMat;\n        return getPlaneColorAtPoint(pt);\n    }\n        \n    return skyCol;\n}\n\n//----------------------------------------------------------------------------------------------\n\nfloat getShadowAtPoint(in vec3 I, in vec3 normalI, in Material objectMat, in vec3 L, in float Ldist)\n{\n    int object;\n    vec3 vec1, vec;\n    float dist = computeNearestIntersection(I, L, object, vec1, vec);\n    if (dist<Ldist && dist>0.0) {\n        return 0.0;\n    } else {\n        return 1.0;\n    }\n}\n\n//----------------------------------------------------------------------------------------------\n\nvec3 computePhongShading(vec3 objectCol, Material objectMat, vec3 N, vec3 L, vec3 R, vec3 V, float shadowFactor)\n{\n    // Phong shading is simplification of the 'Rendering equation' of Kajiya.\n    //\n    // It consists:\n    //  - in removing all diffuse inter-reflections and to replace them by one ambiant component\n    //  - in assuming the BRDF of material is the addition of a purely diffuse (mat, lambertian)\n    //    surface, plus a perfectly specular (mirror-like) component.\n    \n    // NOTES:\n    //  - The diffuse color is a mix of the light color and the object color.\n    //    It is logical as a light source has a spectrum that is absorbed by the object surface.\n    //    It is, then, the resulting spectrum that is diffused in all direction.\n    //\n    //    For example, a red light shining on a 'blue' (under white light) object would appear\n    //    black, because a 'blue' object is blue because it absorbs all wavelength except the\n    //    blue one that ends up diffusely reflected off the surface towards the observer.\n    //    Hence, the red spectrum part of the light would be absorbed by the object, leaving\n    //    nothing to be reflected.\n    //\n    //    So, we would thing the diffuse shading equation would be something like:\n    //            factor * max(lightCol - (1-objectCol), 0)\n    //               ; where 1-objectCol represents the color absorbed by th object.\n    //                 and max(lightCol - (1-objectCol), 0) would then represents the\n    //                 color remaining after absorbption.\n    //    But that is not what Phong shading is!\n    //\n    //  - The diffuse ammount depends first on the properties of the object to be 'mat', and\n    //    it's controlled with object Kd parameter.\n    //\n    //    It also depends on how 'frontward' the object surface is to the light.\n    //    The more 'frontward' we are, the more light the surface receive, and will then diffuse\n    //    in every direction of the hemisphere at the surface point.\n    //    This is expressed by the cosinus of the angle between the normal and the light vector,\n    //    which is expressed by the dot-product between those two vectors.\n    //\n    //    When the angle is >= 90° the light doesn't shine anymore on the point, so the\n    //    contribution of this light is zero!\n    //    To take that into account, and avoid negative value of the cosinus, we need to clamp\n    //    its value in [0,1] range. This is done by taking the max between 0 and the cosinus.\n\t//\n    //  - The ambiantCol parameter is the most 'unrealistic' parameter because if not set\n    //    properly, you can obtain a color that is totaly irrelevant of the light sources\n    //    and the surrounding diffuse objects, and more importantly the object's color itself!\n    //    Logically, the ambiant should behave like a diffuse lighting, and should be a mix\n    //    of the ambiant color and the object color.\n    //    But that is not what Phong shading is!\n    //\n    //    A good use is to set Ka to be a small value, and to set the ambiant color to a\n    //    color that is mainly the color of the light and a bit of the overall color of the\n    //    entire scene.\n    //\n    //    An improvment would be to replace the Ka and ambiantCol by a single ambiant component\n    //    associated to each object.\n    //    It would enable to emulate the reddish aspect of an object near a red wall.\n    //    Plus, the color would be blended with the object color.\n    //    We could even add a directional & distance aspect to better emulate inter-reflections.\n    //    But that would not be Phong shading anymore! :-)\n    //\n    //  - The specular works quite like the diffuse but the resulting color depends only on the\n    //    light color because specularity comes from light that did not interact much with the\n    //    micro-geometry of the object surface, hence the reflected color does not depend on the\n    //    object color.\n    //\n    //  - The specular component in Phong shading is a cheat!\n    //    As the light source is a point, the perfectly specular reflection would produce a\n    //    single dot (if not nothing because of aliasing).\n    //\n    //    To give the illusion of a light that has a size, Phong applies a kind of diffuse\n    //    principle that relate the reflection direction (from the light that bounces off the\n    //    object surface) and the observer viewing direction.\n    //    The nearer those vectors are (the smaller the angle in-between) the more reflected\n    //    light the observer is receiving.\n\t//\n    //    To control how big the light spot appears (the pseudo light-size is), a power is\n    //    applied on the cosinus of the angle (like the diffuse, it must remain in [0,1] range).\n    //    The higher the value, the smaller the spot will appears.\n    \n    vec3 ambiant  = objectMat.Ka * ambiantCol;\n    vec3 diffuse  = objectMat.Kd *  objectCol * lightCol *     max(dot(N,L), 0.);\n    vec3 specular = objectMat.Ks *              lightCol * pow(max(dot(R,V), 0.), objectMat.Kn);\n    \n    vec3 phongCol = ambiant + shadowFactor*diffuse + shadowFactor*specular;\n\n    return phongCol;\n}\n\n//##############################################################################################\n//##############################################################################################\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    float time = iTime;\n    \n    animateScene(time);\n    \n    \n    // Compute the ray to be casted through the pixel towards the 3D scene\n    vec3 rayPos, rayDir;\n    computeCameraRayFromPixel(fragCoord, rayPos, rayDir);\n    \n\t// Test ray-objetcs intersections and find the nearest one\n    // (with its associated intersection point and normal at the object surface)\n    int  objectId;\n    vec3 intersecI, normalI;\n    float distI = computeNearestIntersection(rayPos, rayDir, objectId, intersecI, normalI);\n    \n    // Apply the shading to the points that are on the sphere surface and seen by the camera\n    if (distI > 0.0)\n    {\n        // unit-vector going from the surface point toward the light\n\t    vec3 L = normalize(lightPos - intersecI);\n        \n        // unit-vector of the reflection direction of the light at the surface point\n    \tvec3 R = 2.0 * dot(normalI, L) * normalI - L;\n        \n        // unit-vector going from the surface point toward the camera \n        vec3 V = -rayDir;\n        \n        // Get the diffuse color at the intersection point\n        Material objectMat;\n        vec3 objectCol = getObjectColorAtPoint(objectId, intersecI,objectMat);\n        \n        vec3 I = intersecI + normalI*eps;\n        \n        float Ldist = length(lightPos-I);\n        \n        float shadowfactor = getShadowAtPoint(I, normalI, objectMat, L, Ldist);\n        //float shadowfactor = 1.0;\n        // Apply the Phong shading to compute the color\n        // of the surface point as seen from the camera\n    \tfragColor = vec4(computePhongShading(objectCol, objectMat, normalI, L, R, V, shadowfactor), 1);\n    }\n    else\t// We did not hit the sphere, so we have the sky color (here: black)\n     \tfragColor = vec4(skyCol, 1);\n}","name":"Image","description":"","type":"image"}]}
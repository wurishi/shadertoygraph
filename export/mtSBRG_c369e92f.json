{"ver":"0.1","info":{"id":"mtSBRG","date":"1694157734","viewed":78,"name":"3.3 Raytracer (rim light)","username":"Envy24","description":"Hold LMB to see rim light only.\nMouse.x uses control rim light spread.","likes":3,"published":1,"flags":0,"usePreview":0,"tags":["raytracing","light","rim","model","material"],"hasliked":0,"parentid":"dtSBRG","parentname":"3.2 Raytracer (blinn-phong)"},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"#define TO_RAD                      0.017453292519943295        // Convert degrees to radians\n\n/* https://www.shadertoy.com/view/DdsGDj */\n#define MOUSE_OFFSET ( iMouse.z > 0. ? iMouse.xy - iResolution.xy * 0.5 : vec2(0) )\nvec2 map_to_centered_ndc(in vec2 SC, in float scale, in vec2 origin, in bool mouse_drag)\n{\n    vec2 M = MOUSE_OFFSET * (mouse_drag == true ? 1. : 0.);\n    return ((2. * (SC - M) - iResolution.xy) / iResolution.y) * scale + origin;\n}\n\nvec3 get_background() { return vec3(.1, .4, .6); }\n\n#define NUM_OF_OBJECTS ( 2 )\nmat4 fwd_model[NUM_OF_OBJECTS]; // per object forward model transformations.\nmat4 bwd_model[NUM_OF_OBJECTS]; // per object backward model transformations.\nmat4 fwd_view = mat4(1);        // forward transformation for all objects in scene (should be applyed many times).\nmat4 bwd_view = mat4(1);        // or backward transformation for camera (should be applyed once).\nMATERIAL materials[NUM_OF_OBJECTS];\n#define NUM_OF_LIGHTS ( 3 )\nLIGHT lights[NUM_OF_LIGHTS];\n\nvoid init_scene()\n{   \n    //\n    // Model transformations.\n    //\n    for (int i = 0; i < NUM_OF_OBJECTS; ++i)\n        fwd_model[i] = mat4(1);\n\n    fwd_model[0] = fwd_srt_transform(vec3(1), vec3(0), vec3(0,-1,0));\n    fwd_model[1] = fwd_srt_transform(vec3(1), vec3(0.2,0,0), vec3(0,0,0));\n    //fwd_model[2] = fwd_srt_transform(vec3(1), vec3(0), vec3(0,1,-1));  \n   \n    for (int i = 0; i < NUM_OF_OBJECTS; ++i)\n        bwd_model[i] = inverse(fwd_model[i]);\n     \n    //\n    // View transformation.\n    //\n    float s = (1.+sin(iTime))*.5, T = iTime;\n    bwd_view = bwd_srt_transform(vec3(1), T*vec3(0,1,0), vec3(0));\n    \n    //\n    // Lights.\n    //\n    lights[0].pos = (rotY(0.*TO_RAD) * vec4(0,10,10,1)).xyz;\n    lights[0].diffuse_Id = vec3(1,0,0);\n    lights[0].ambient_Ia = 0.1 * lights[0].diffuse_Id;\n    lights[0].specular_Is = lights[0].diffuse_Id;\n    \n    lights[1].pos = (rotY(120.*TO_RAD) * vec4(0,10,10,1)).xyz;\n    lights[1].diffuse_Id = vec3(0,1,0);\n    lights[1].ambient_Ia = 0.1 * lights[1].diffuse_Id;\n    lights[1].specular_Is = lights[1].diffuse_Id;\n    \n    lights[2].pos = (rotY(240.*TO_RAD) * vec4(0,10,10,1)).xyz;\n    lights[2].diffuse_Id = vec3(0,0,1);\n    lights[2].ambient_Ia = 0.1 * lights[2].diffuse_Id;\n    lights[2].specular_Is = lights[2].diffuse_Id;\n    \n    //\n    // Materials.\n    //\n    materials[0].diffuse_Kd = 1. * vec3(1);\n    materials[0].ambient_Ka = 0.1 * materials[0].diffuse_Kd;\n    materials[0].specular_Ks = 2.8 * materials[0].diffuse_Kd;\n    materials[0].spec_exp = 64.;\n    materials[0].rim_amount = 0.1;\n    \n    materials[1].diffuse_Kd = 1. * vec3(1);\n    materials[1].ambient_Ka = 0.1 * materials[1].diffuse_Kd;\n    materials[1].specular_Ks = 0.2 * materials[1].diffuse_Kd;\n    materials[1].spec_exp = 64.;\n    materials[1].rim_amount = 0.9;\n}\n\nHIT find_closest_intersection(RAY ray)\n{\n    HIT c_hit; c_hit.hit_dist = 9e5;\n    int hit_something = 0; // Set only once, when firts hit occurs.\n    int hitted_idx = 0;\n    float min_sq_d = 9e5;\n    \n    for (int obj_idx = 0; obj_idx < NUM_OF_OBJECTS; ++obj_idx)\n    {\n        HIT hit;\n                        \n        // Apply inverse transform.\n        RAY r = apply_transform_to_ray(ray, bwd_model[obj_idx]);\n        \n        // Intersect with simplified primitives.\n        switch (obj_idx)\n        {\n        case 0: hit = ray_infinite_plane_XZ_int(r); break;\n        case 1: hit = ray_unit_sphere_int(r); break;\n        //case 1: hit = ray_aabb_int(r, vec3(1)); break;\n        }\n        \n        if (hit.hit_something == 1) // Hit i-th object?\n        {\n            // Recover hit point in world coordinates.\n            hit.hit_point = apply_transformation_to_point(hit.hit_point, fwd_model[obj_idx]);\n            \n            // Calculate squared distance in world coordinates.\n            vec3 CAMtoHP = hit.hit_point - ray.position;\n            float sq_d = dot(CAMtoHP, CAMtoHP);\n            \n            if (min_sq_d > sq_d) // Find closer hit-point?\n            {\n                // Update distance.\n                min_sq_d = sq_d;\n                \n                // Save hit data.\n                c_hit = hit;\n                c_hit.hitted_idx = obj_idx;\n            }\n        }\n        \n        // If we find any hit, then this value will be set to 1, and not changed before the function exits.\n        hit_something = max(hit.hit_something, hit_something);\n    }\n\n    // Save global hit flag.\n    c_hit.hit_something = hit_something;\n\n    // Recover normal (cheap, so i don't use branch here).\n    c_hit.hp_normal = apply_transformation_to_normal(c_hit.hp_normal, bwd_model[c_hit.hitted_idx]);\n\n    return c_hit;\n}\n\n\nvec3 rim_light(RAY ray, HIT hit, int light_idx)\n{\n    // Fetch metarial data.\n    int idx = hit.hitted_idx;\n    vec3 Kd = materials[idx].diffuse_Kd;\n\n    // Calculate directions.\n    vec3 inv_view_dir = -ray.direction; \n\n    /* Rim light. */\n    float rim_intensity = max(1. - dot(hit.hp_normal, inv_view_dir), 0.);\n          rim_intensity = smoothstep(iMouse.x/iResolution.x, 1., rim_intensity);\n    \n    vec3 total_color = Kd * lights[light_idx].diffuse_Id * rim_intensity;\n    vec3 result = materials[idx].rim_amount * total_color;\n    /* !Rim light. */\n        \n    return result;\n}\n\nvec3 blinn_phong(RAY ray, HIT hit, int light_idx)\n{\n    // Fetch metarial data.\n    int idx = hit.hitted_idx;\n    vec3 Ka = materials[idx].ambient_Ka; \n    vec3 Kd = materials[idx].diffuse_Kd;\n    vec3 Ks = materials[idx].specular_Ks;\n    float se = materials[idx].spec_exp;\n    \n    // Calculate directions.\n    vec3 hp_to_l_dir = normalize(lights[light_idx].pos - hit.hit_point); \n    vec3 h = -ray.direction + hp_to_l_dir;\n         h /= length(h);\n\n    /* Blinn-Phong reflection model. */\n    // Calculate diffuse and specular components, and their sum for shadows.\n    float diffuse = max(dot(hit.hp_normal, hp_to_l_dir), 0.), \n          specular = pow(max(dot(hit.hp_normal, h), 0.0), se);\n\n    vec3 ambient_color = Ka * lights[light_idx].ambient_Ia;\n    vec3 total_color =\n        ambient_color +\n        Kd * lights[light_idx].diffuse_Id * diffuse +\n        Ks * lights[light_idx].specular_Is * specular;\n    /* !Blinn-Phong reflection model. */\n        \n    return total_color;\n}\n\nvec3 process_lights(RAY ray, HIT hit)\n{\n    vec3 accumulated_color = vec3(0);\n    \n    for (int light_idx = 0; light_idx < NUM_OF_LIGHTS; ++light_idx)\n    {       \n        accumulated_color += rim_light(ray, hit, light_idx);\n        if (!(iMouse.z > 0.)) \n            accumulated_color += blinn_phong(ray, hit, light_idx);      \n    }\n    \n    return accumulated_color;\n}\n\nvec3 exposure_tone_mapping(vec3 HDR, float exposure)\n{\n    return vec3(1.0) - exp(-HDR * exposure);\n}\nvec3 ACES(const vec3 x) \n{\n    // Narkowicz 2015, \"ACES Filmic Tone Mapping Curve\"\n    const float a = 2.51; const float b = 0.03; const float c = 2.43;\n    const float d = 0.59; const float e = 0.14;\n    return (x * (a * x + b)) / (x * (c * x + d) + e);\n}\n\nvec3 scene(vec2 SC)\n{\n    // Generate primary ray.\n    vec2 MP = iMouse.xy == vec2(0) ?\n        vec2(0) :\n        map_to_centered_ndc(iMouse.xy, 1., vec2(0), false);\n        \n    RAY ray;\n        //ray = orthographic_camera(SC, vec3(0,0,0), vec3(0,0,-1), iResolution.xy);\n        ray = perspective_camera(SC, vec3(0,1.5,10), vec3(0,0,0), iResolution.xy);\n\n    // View transformation.\n    ray = apply_transform_to_ray(ray, bwd_view);  \n    \n    // Trace scene.\n    HIT hit = find_closest_intersection(ray);\n    \n    vec3 color = hit.hit_something == 1 ?\n        process_lights(ray, hit) :\n        get_background();\n     \n    //return exposure_tone_mapping(color, 1.1);\n    return ACES(color);\n    //return color;\n}\n\n// Basic anti-aliasing (supersample).\nvec3 OSSAA(in vec2 SC)\n{\n    vec3 col = vec3(0);\n    float order = 1., inv = 1./(2.*order + 1.), blur = 1.;\n\n    for (float y = -order; y <= order; y += 1.0)\n        for (float x = -order; x <= order; x += 1.0)\n        {\n            vec2 offset = (blur*vec2(x, y)) * inv;\n            col += scene(SC + offset);\n        }\n        \n    order = 2.*order + 1.;\n    return col / (order*order);  \n}\n\nvoid mainImage( out vec4 O, in vec2 SC )\n{\n    init_scene();\n\n    //O = vec4(scene(SC),1.0);\n    O = vec4(OSSAA(SC), 1.0);\n    \n    // Camera look_at.\n    O = mix(O, vec4(0,1,0,1), smoothstep(3., 0., length(SC - 0.5*iResolution.xy) - 0.5));\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"// Structures.\nstruct RAY\n{\n    vec3 position;\n    vec3 direction;\n};\nstruct HIT\n{\n    int hit_something;\n    float hit_dist;\n    vec3 hit_point;\n    vec3 hp_normal;\n    vec2 uv;\n    int hitted_idx;\n    float is_inside;\n};\nstruct LIGHT\n{\n    vec3 pos;\n    vec3 ambient_Ia;\n    vec3 diffuse_Id;\n    vec3 specular_Is;\n};\nstruct MATERIAL\n{\n    vec3 ambient_Ka;\n    vec3 diffuse_Kd;\n    vec3 specular_Ks;\n    float spec_exp;\n    float rim_amount;\n};\n// Cameras.\nRAY perspective_camera(vec2 SC, vec3 position, vec3 look_at, vec2 resolution)\n{\n    float zFocalLength = 50.0; // mm.\n    vec3 camera = position;\n\n    vec3 f = normalize(look_at - camera);               // forward\n    vec3 r = normalize(cross(vec3(0.0, -1.0, 0.0), f)); // right\n    vec3 u = normalize(cross(r, f));                    // up\n        \n    float size = 36.0;        // Sensor Fit: Mode = Auto.    \n    float aspectRatio = resolution.x / resolution.y;\n    float vpWidth = size;\n    float vpHeight = vpWidth / aspectRatio;\n           \n    // Before uv=[0;1][0;1]\n    vec2 uv = SC / resolution.xy;\n    uv.x = (uv.x * vpWidth) - vpWidth * 0.5;\n    uv.y = (uv.y * vpHeight) - vpHeight * 0.5;\n    // After uv=[-vpWidth*0.5; vpWidth*0.5][-vpHeight*0.5; vpHeight*0.5]\n\n    return RAY(\n        camera,\n        normalize(uv.x * r + uv.y * u + f * zFocalLength));\n}\nRAY orthographic_camera(vec2 SC, vec3 pos, vec3 look_at, vec2 resolution)\n{\n    vec3 vp = pos;                 // viewport and camera position\n    \n    vec3 f = normalize(look_at - vp);                   // forward\n    vec3 r = normalize(cross(vec3(0.0, -1.0, 0.0), f)); // right\n    vec3 u = normalize(cross(r, f));                    // up\n    \n    float aspectRatio = resolution.x / resolution.y;\n    float orthographicScale = 6.8;\n    float vpWidth = orthographicScale;\n    float vpHeight = vpWidth / aspectRatio;\n   \n    vec2 uv = SC / resolution.xy;\n    uv.x = (uv.x * vpWidth) - vpWidth * 0.5;\n    uv.y = (uv.y * vpHeight) - vpHeight * 0.5;\n     \n    RAY ray;\n    return RAY(\n        vp + uv.x * r + uv.y * u,\n        f);\n}\n\n// Ray-Object intersection routines.\nHIT ray_infinite_plane_XZ_int(RAY ray)\n{\n    // Plane definition:\n    // Equation: Ax + By + Cz + D = 0\n    // Primitive constrains:\n    //   N = vec3(A, B, C) = vec3(0, 1, 0)\n    //   D = 0\n\n    HIT hit;\n    float root = -ray.position.y/ray.direction.y;\n\n    if (dot(vec3(0,1,0), ray.direction) > .0 || // back face?    \n        root < 0.)                              // behind camera?\n    { \n        hit.hit_something = 0; \n        hit.hit_dist = 9e5;\n        return hit; \n    }\n    \n    hit.hit_something = 1;\n    hit.hit_dist = root;\n    hit.hit_point = ray.position + ray.direction * root;\n    hit.hp_normal = vec3(0,1,0);\n    \n    return hit;\n}\nHIT ray_unit_sphere_int(RAY ray) // sphere_pos always equals vec3(0), and sphere_r equals to 1.\n{\n    float half_b = dot(ray.position, ray.direction),\n          c = dot(ray.position, ray.position) - 1.,\n          discriminant = (half_b * half_b - c),\n          sqrtDiscriminant = sqrt(discriminant),\n          root = min(-half_b - sqrtDiscriminant, -half_b + sqrtDiscriminant);\n    \n    HIT hit;\n    \n    if (discriminant < 0. || // no real roots?\n        root < 0.)           // behind camera?\n    { \n        hit.hit_something = 0;\n        hit.hit_dist = 9e5;\n        return hit; \n    }\n    \n    hit.hit_something = 1;\n    hit.hit_dist = root;\n    hit.hit_point = ray.position + ray.direction * root;\n    hit.hp_normal = normalize(hit.hit_point);\n    \n    return hit;\n}\nHIT ray_aabb_int(RAY ray, vec3 size)\n{\n    HIT hit;\n    \n    vec3 m = vec3(1.0) / ray.direction,\n         n = m * ray.position,\n\t     k = abs(m) * size,\n\t     t1 = -n - k,\n\t     t2 = -n + k;\n         \n\tfloat tN = max(max(t1.x, t1.y), t1.z),\n\t      tF = min(min(t2.x, t2.y), t2.z);\n\n\tif (tN > tF || tF < 0.0) // no hit?\n    {\n        hit.hit_something = 0;\n        hit.hit_dist = 9e5;\n        return hit;\n    }\n\n    vec3 yzx = vec3(t1.y, t1.z, t1.x),\n\t     zxy = vec3(t1.z, t1.x, t1.y);\n\n    hit.hit_something = 1;\n    hit.hit_dist = min(tN, tF);\n    hit.hit_point = ray.position + ray.direction * hit.hit_dist;  \n    hit.hp_normal = -sign(ray.direction) * step(yzx, t1) * step(zxy, t1);\n  \n    // Calculate uv.\n    if (abs(hit.hp_normal.x) == 1.)      hit.uv = (hit.hit_point.zy + 1.)*.5;\n    else if (abs(hit.hp_normal.y) == 1.) hit.uv = (hit.hit_point.xz + 1.)*.5;\n    else                                 hit.uv = (hit.hit_point.xy + 1.)*.5;\n        \n    if (abs(ray.position.x) < size.x && // inside box?\n        abs(ray.position.y) < size.y &&\n        abs(ray.position.z) < size.z)\n    {\n        hit.is_inside = 1.;\n        hit.hit_dist = max(tN, tF);\n        hit.hit_point = ray.position + ray.direction * hit.hit_dist;\n        hit.hp_normal = abs(abs(hit.hit_point.x) - size.x) < 1e-6 ? vec3(hit.hit_point.x,0,0) : \n                        abs(abs(hit.hit_point.y) - size.y) < 1e-6 ? vec3(0,hit.hit_point.y,0) :\n                        vec3(0,0,hit.hit_point.z);\n    }\n    else hit.is_inside = 0.;\n    \n    return hit;\n}\n\n/*\n    Matricies for column vectors and row major matricies,\n    because i prefer this variant)\n    \n    Multiplication order:\n    T2 * T1 * T0 * V;\n    \n    Representation for points and directions\n    in homogeneous coordinates:\n        Points     p = vec4(p.xyz, 1),\n        Direction  d = vec4(p.xyz, 0).\n*/\nmat4 scale(vec3 s)\n{\n    mat4 M = mat4(\n        s.x,   0,   0, 0,\n          0, s.y,   0, 0,\n          0,   0, s.z, 0,\n          0,   0,   0, 1);\n    return transpose(M);\n}\nmat4 rotX(float rad)\n{\n    float s = sin(rad), c = cos(rad);\n    mat4 M = mat4(\n         1, 0,  0, 0,\n         0, c, -s, 0,\n         0, s,  c, 0,\n         0, 0,  0, 1);\n    return transpose(M);\n}\nmat4 rotY(float rad)\n{\n    float s = sin(rad), c = cos(rad);\n    mat4 M = mat4(\n         c, 0, s, 0,\n         0, 1, 0, 0,\n        -s, 0, c, 0,\n         0, 0, 0, 1);\n    return transpose(M);\n}\nmat4 rotZ(float rad)\n{\n    float s = sin(rad), c = cos(rad);\n    mat4 M = mat4(\n         c, -s, 0, 0,\n         s,  c, 0, 0,\n         0,  0, 1, 0,\n         0,  0, 0, 1);\n    return transpose(M);\n}\nmat4 translate(vec3 t)\n{\n    mat4 M = mat4(\n        1, 0, 0, t.x,\n        0, 1, 0, t.y,\n        0, 0, 1, t.z,\n        0, 0, 0,   1);\n    return transpose(M);\n}\nmat4 fwd_srt_transform(vec3 s, vec3 r, vec3 t) // scale, rotate, translate\n{\n    return translate(t) * rotX(r.x) * rotY(r.y) * rotZ(r.z) * scale(s);\n}\nmat4 bwd_srt_transform(vec3 s, vec3 r, vec3 t) // scale, rotate, translate\n{\n    return inverse(translate(t) * rotX(r.x) * rotY(r.y) * rotZ(r.z) * scale(s));\n}\nRAY apply_transform_to_ray(RAY ray, mat4 T)\n{\n    vec4 P = vec4(ray.position + ray.direction, 1);   \n         P = T * P;\n         \n    RAY res;\n    res.position = (T * vec4(ray.position, 1.)).xyz;\n    res.direction = normalize(P.xyz - res.position);\n    return res;\n}\nvec3 apply_transformation_to_normal(vec3 normal, mat4 T)\n{\n    mat3 SR = mat3(T[0].xyz, T[1].xyz, T[2].xyz);\n    // https://paroj.github.io/gltut/Illumination/Tut09%20Normal%20Transformation.html\n    normal = normal * transpose(inverse(SR));\n    \n    return normalize(normal);\n}\nvec3 apply_transformation_to_point(vec3 p, mat4 T)\n{\n    vec4 P = vec4(p, 1.); \n    return (T * P).xyz;\n}","name":"Common","description":"","type":"common"}]}
{"ver":"0.1","info":{"id":"7ttyDf","date":"1665026163","viewed":137,"name":"epilepsy for free","username":"spadge","description":":( please be careful","likes":3,"published":1,"flags":32,"usePreview":0,"tags":["practice"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"Xdf3Rn","filepath":"/media/a/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","previewfilepath":"/media/ap/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","type":"video","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    float messedUpStr = 0.0005;\n    float offset = 0.5;\n    float r,g,b;\n    float time = mod(iTime,1.0);\n    float ctime = cos(iTime);\n    float stime = sin(iTime);\n    float ttime = tan(iTime);\n    float halfRes = iResolution.xy.x * 0.5;\n    \n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord *  1.0 / iResolution.xy ;\n    vec2 uv2 = fragCoord *  1.0 / iResolution.xy ;\n    vec3 iChan2 = (texture(iChannel2, uv).xyz);\n    \n    vec3 iChan0 = (texture(iChannel0, uv).xyz);\n    iChan0 *= (texture(iChannel0, vec2(uv.x ,uv.y )).xyz)\n            *(texture(iChannel0, vec2(uv.x ,uv.y )).xyz)\n            *(texture(iChannel0, vec2(uv.x ,uv.y )).xyz)\n            *(texture(iChannel0, vec2(uv.x ,uv.y )).xyz) * 0.25;\n \n    vec3 iChan1 = (texture(iChannel1, uv).xyz);\n\n    uv = fragCoord / 3.0 * mod( fragCoord, cos(stime * 10.1 * ttime) )/ iResolution.xy ;\n    vec3 iChan0Mod = vec3( mod(iChan0.x, uv.y * 0.10),\n                           mod(iChan0.y, uv.x * 0.3),\n                           mod(iChan0.z, uv.x * uv.y)* 0.50); \n    iChan0Mod /= vec3(texture(iChannel0, uv * iResolution.xy).xyz * 5.0);\n                           \n    r = 0.5 - (((ctime * 0.15) * uv.x ) + (( -stime      ) * uv.y) * 0.5);\n    g = 0.5 - (((-ctime      ) * uv.x ) + (( stime * 0.15) * uv.y) * 0.5);\n  \n    b  = offset - (((stime     ) * (uv.x * (ctime * 10.0))) + (( ctime -offset      ) * (uv.y* (stime * 10.0))))*0.5;\n    r += offset - (((ttime     ) * (uv.y * (stime / 10.0))) + (( ctime +offset      ) * (uv.x* (ctime / 10.0))))*0.5;\n    g += offset - (((ctime     ) * (uv.x * (stime * 10.0))) + (( stime +offset      ) * (uv.y* (ttime * 10.0))))*0.5;\n    \n    \n    b *= stime * ctime;\n    g *= ctime * stime;\n    r *= stime * ctime;\n   \n    r *=  mod(ctime, stime);\n    g *=  mod(stime, ctime);\n    b /=  mod(ctime, stime);\n    \n    // build colour\n    vec3 col = fetchData(iChannel0, SCREEN_COLOR_ADDR).rgb;\n    col += vec3(r * ((ctime - stime)*0.5), g * ctime, b * stime);\n    col -= iChan0 / (iChan0 *0.25)/( iChan0Mod * (col * mod(ctime,stime) *( r + g) /b));\n\n \n    col *= sin(iChan0.x) *2.5;\n    iChan0 -=  (texture(iChannel1, uv * iResolution.xy).xyz) * 2.25;\n    \n        col /= vec3(1.0 - mod(col.x, stime * uv.y * r),\n                    1.0 - mod(col.y, ctime * uv.x * g),\n                    1.0 - mod(col.z, ttime * uv.x * uv.y *b))*0.5; \n                    \n    col += iChan0 * col * 2.0;\n   // col += mod( iChan1, col); // get rid of the background, only apply the effect to whatever is left after greenscreen cutout\n    \n    vec3 outCol = ((col * messedUpStr ) + (iChan0 * (1.0 - messedUpStr))) + 0.05;\n    float fkd2 =  uv.x;\n    outCol = ( (outCol * fkd2) + (iChan0 * (1.0 - fkd2)) );\n    \n    outCol += iChan2;\n    \n    // makes the orig input video more visible\n    vec3 iChan0Clean = (texture(iChannel0, (fragCoord *  1.0 / iResolution.xy)).xyz);\n    \n    if ((outCol.r + outCol.g + outCol.b <= 0.01))\n    {\n        vec3 mixedOutCol = vec3(iChan0Clean.r, (iChan0Clean.g * outCol.g), iChan0Clean.b) * 0.5;\n        outCol *= (mixedOutCol);\n        outCol += (mixedOutCol);\n    }\n    \n\tvec3 fg = texture( iChannel0, uv2 ).xyz;   \n    float maxrb = max( fg.r, fg.b );\n    float k = clamp( (fg.g-maxrb)*5.0, 0.0, 1.0 );    \n\tfloat ll = length( fg );\n    fg.g = min( fg.g, maxrb*0.8 );\n    fg = ll*normalize(fg);\n    \n    \n    //fg += outCol * 20.0;\n    fg =  mix(fg, outCol, k);\n    \n    outCol += fg;\n    //outCol += (fg * fg) / outCol;\n    \n    \n    // Output to screen\n    fragColor = vec4(outCol,1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"// Addresses:\n// These should be ivec2s containing the pixel coordinates of where certain data\n// should go. The coordinates are not normalize but can range from (0, 0) to\n// (iResolution.x, iResolution.y).\nconst ivec2 SCREEN_COLOR_ADDR = ivec2(0, 0);\n\n// Unfortunately, the only way to define functions that sample iChannels in Common\n// is with #define :(\n\n// buf - iChannel to read from\n// addr - the data address in the form of an ivec2 (vector containing two integers)\n#define fetchData(buf, addr) texelFetch(buf, addr, 0)\n\n// buf_pos - fragment position (fragCoord)\n// addr - the data address in the form of an ivec2\n// storeData() just evaluates if the data address matches the fragment position\n// in which case the data should be stored in fragColor.\n#define storeData(buf_pos, addr) ivec2(buf_pos) == addr","name":"Common","description":"","type":"common"},{"inputs":[{"id":"Xdf3Rn","filepath":"/media/a/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","previewfilepath":"/media/ap/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","type":"video","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    float messedUpStr = 0.000000000001;\n    float offset = 0.5;\n    float r,g,b;\n    float time = mod(iTime,1.0);\n    float ctime = cos(iTime);\n    float stime = sin(iTime);\n    float ttime = tan(iTime);\n    float halfRes = iResolution.xy.x * 0.5;\n    \n    // Normalized pixel coordinates (from 0 to 1)\\ \n    vec2 uv = fragCoord *  1.0 / iResolution.xy ;\n    vec2 uv3 = fragCoord *  1.0 / iResolution.xy ;\n    uv /= mod(-uv.x, ctime * ttime);\n    uv *= (uv.x, stime * ttime);\n    uv -= mod(-uv.x, stime * ttime);\n    uv *= mod(uv.x, ctime * ttime);\n    uv += (vec2( uv.x + -.5, uv.y - .5) * (mod(iTime *666.6 *ttime /ctime, .5) * 2.5)) +vec2(.5,.5);\n    uv += fragCoord *  stime / iResolution.xy;\n    uv -= fragCoord / mod( ttime, ctime) / iResolution.xy;\n    \n    vec3 iChan0 = (texture(iChannel0, uv3).xyz);\n    iChan0 *= (texture(iChannel0, vec2(uv.x ,uv.y )).xyz)\n             *(texture(iChannel0, vec2(uv.x ,uv.y )).xyz)\n             *(texture(iChannel0, vec2(uv.x ,uv.y )).xyz)\n             *(texture(iChannel0, vec2(uv.x ,uv.y )).xyz) * 0.25;\n \n    vec3 iChan1 = (texture(iChannel1, uv3).xyz);\n    uv = fragCoord / 3.0 * mod( fragCoord, cos(stime * 10.1 * ttime) )/ iResolution.xy ;\n    vec3 iChan0Mod = vec3( mod(iChan0.x, uv.y * 0.10),\n                           mod(iChan0.y, uv.x * 0.3),\n                           mod(iChan0.z, uv.x * uv.y)* 0.50); \n    iChan0Mod /= vec3(texture(iChannel0, uv * iResolution.xy).xyz * 5.0);\n                           \n    r = 0.5 - (((ctime * 0.3) * uv.x ) + (( -stime      ) * uv.y) * 0.5);\n    g = 0.5 - (((-ctime      ) * uv.x ) + (( stime * 0.3) * uv.y) * 0.5);\n  \n    b  = offset - (((stime     ) * (uv.x * (ctime * 10.0))) + (( ctime -offset      ) * (uv3.y* (stime * 10.0))))*0.5;\n    r += offset - (((ttime     ) * (uv.y * (stime / 10.0))) + (( ctime +offset      ) * (uv.x* (ctime / 10.0))))*0.5;\n    g += offset - (((ctime     ) * (uv.x * (stime * 10.0))) + (( stime +offset      ) * (uv3.y* (ttime * 10.0))))*0.5;\n    \n    \n    b *= stime * ctime;\n    g *= ctime * stime;\n    r *= stime * ctime;\n   \n    r *=  mod(ctime, stime);\n    g *=  mod(stime, ctime);\n    b /=  mod(ctime, stime);\n    \n    // build colour\n    vec3 col = fetchData(iChannel0, SCREEN_COLOR_ADDR).rgb;\n    col += vec3(r * ((ctime - stime)*0.5), g * ctime, b * stime);\n    col *= iChan0 / (iChan0 *0.25)/( iChan0Mod * (col * mod(ctime,stime) *( r + g) /b));\n\n \n    col /= sin(iChan0.x) *2.5;\n    iChan0 *=  (texture(iChannel1, uv * iResolution.xy).xyz) * 2.25;\n    \n        col += vec3(1.0 - mod(col.x, stime * uv.y * r),\n                    1.0 - mod(col.y, ctime * uv.x * g),\n                    1.0 - mod(col.z, ttime * uv.x * uv.y *b))*0.5;                   \n    \n    vec3 outCol = ((col * messedUpStr ) + (iChan0 * (1.0 - messedUpStr))) + 0.05;\n    float fkd2 = cos(uv3.x * 200.0);\n    outCol -= ( (outCol - fkd2) + (iChan0 * (1.0 - fkd2)) ) * ((stime * ttime) * messedUpStr);\n\n    // Output to screen\n    fragColor = vec4(outCol,1.0);\n}","name":"Buffer B","description":"","type":"buffer"}]}
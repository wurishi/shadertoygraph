{"ver":"0.1","info":{"id":"WdBcDG","date":"1587234154","viewed":223,"name":"Biquadratic Heightfield","username":"spalmer","description":"using biquadratic filtering to smooth a heightfield.  Based on paniq's biquadratic filter [url]https://shadertoy.com/view/wtXXDl[/url] and [url]https://shadertoy.com/view/Wslcz7[/url]","likes":3,"published":1,"flags":48,"usePreview":0,"tags":["raymarch","heightfield","filtering","biquadratic"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsBSR3","filepath":"/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","previewfilepath":"/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Based on paniq's biquadratic filter https://shadertoy.com/view/wtXXDl\n// and stripped down Bullet Train https://shadertoy.com/view/Wslcz7\n    \n// see also 1D Quadratic Filter at https://shadertoy.com/view/wdjcz1\n// where I stripped the filter down even further.\n\n\n#define Noise   iChannel1\n// blue noise\n#define BufferC iChannel2\n// camera state\n\n// most configurable options here\n// btw do not leave the Common tab selected while viewing the toy\n// as it seems to cause major fps stutters!\n\n// no shadows since I took out the regula falsi\n\nconst float\n  displ = 64. // terrain vertical displacement\n, ch1res = 1024. // FIXME iChannelResolution[1].y is uniform though, not constant; hard-coded blue noise texture resolution\n, tscale = 2. / ch1res / displ // terrain scale\n;\n\nconst vec3 sunDir = normalize(vec3(.2,.5,.7));\nconst float ambient = .06;\n\nconst float specularity = 16.; // power\nconst vec3 specularColor = vec3(.5);\n\nconst vec3 diffuseColor = vec3(.4,.5,.3); //vec3(.8);\nconst float hatmo = 85000.; // air extinct distance\nconst float depthscale = 12.; // fog exaggeration\nconst float depthlimit = 7e3;\nconst float fogdensity = 1e-4;\n\n#define IZERO min(0, iFrame)\n\n\n// this entire thing started off as https://shadertoy.com/view/tlGXDK\n// then that turned into https://shadertoy.com/view/Wslcz7\n// well now I turned it back into a simple heightfield renderer\n// so I can try using biquadratic filter on a terrain\n// biquadratic filter idea taken from paniq https://shadertoy.com/view/wtXXDl\n\nvec4 tfetch(sampler2D ch, ivec2 t, ivec2 r)\n{\n    ivec2 c = t % r; //ivec2(uvec2(t) % uvec2(r)); //\n    if (c.x < 0) c.x += int(r.x); // % handles negative values differently on some platforms\n    if (c.y < 0) c.y += int(r.y);\n    return texelFetch(ch, c, 0); // software uv wrap on fetch\n}\n\nvec4 quadratic(vec4 a, vec4 b, vec4 c, float f)\n{\n    float g = (f + 1.) * .5, h = f * .5;\n    return mix(mix(a, b, g), mix(b, c, h), f);\n}\n\n// software biquadratic filter of texture, 9 taps\nvec4 biquadratic(sampler2D ch, vec2 q, vec2 r)\n{\n    vec2 s = q * r - .0; ivec2 t = ivec2(floor(s)), u = ivec2(r); s -= vec2(t);\n    vec4 a = tfetch(ch, t + ivec2(-1,-1), u)\n       , b = tfetch(ch, t + ivec2( 0,-1), u)\n       , c = tfetch(ch, t + ivec2( 1,-1), u)\n       , d = tfetch(ch, t + ivec2(-1, 0), u)\n       , e = tfetch(ch, t + ivec2( 0, 0), u)\n       , f = tfetch(ch, t + ivec2( 1, 0), u)\n       , g = tfetch(ch, t + ivec2(-1, 1), u)\n       , h = tfetch(ch, t + ivec2( 0, 1), u)\n       , i = tfetch(ch, t + ivec2( 1, 1), u)\n       ;\n   \tvec4 q0 = quadratic(a, b, c, s.x)\n       , q1 = quadratic(d, e, f, s.x)\n       , q2 = quadratic(g, h, i, s.x);\n    return quadratic(q0, q1, q2, s.y);\n}\n// it seems that, unfortunately, the biquadratic filter\n// is only C1 continuous, and the eye picks up on the \n// C2 discontinuity at the joins between grid cells!\n// They exhibit as mach banding, visible to the eye.\n// I suspect would require bicubic sampling to overcome it properly.\n// But could also simply blur the normal sampling enough to hide it.\n\n// software bilinear filter of texture, 4 taps\nvec4 bilinear(sampler2D ch, vec2 q, vec2 r)\n{\n    vec2 s = q * r - .5; ivec2 t = ivec2(floor(s)), u = ivec2(r); s -= vec2(t);\n    vec4 a = tfetch(ch, t + ivec2( 0, 0), u)\n       , b = tfetch(ch, t + ivec2( 1, 0), u)\n       , c = tfetch(ch, t + ivec2( 0, 1), u)\n       , d = tfetch(ch, t + ivec2( 1, 1), u)\n       ;\n    s = (3. - 2.*s)*s*s; // HACK iq suggestion:  smoothstep curve\n//    s = ((6.*s - 15.)*s + 10.)*s*s*s; // HACK even smoother\n    return mix(mix(a, b, s.x)\n             , mix(c, d, s.x), s.y);\n}\n\nfloat hillheight(vec2 q)\n{\n   q = q * tscale; // texture scaling hack\n #define CH iChannel1\n #define CR iChannelResolution[1].xy\n #define CC w\n    //x //\n  #if 0\n    // biquadratic fbm heightmap\n    vec2 cs = .51 * cossin(radians(30.)); //1./3.*pi);\n    mat2 L = mat2(cs * vec2(1,-1), cs.yx); q *= 2.;\n    float h = 1.4*dot(vec3(\n        biquadratic(CH, L*L*q, CR).CC\n      , biquadratic(CH,   L*q, CR).CC\n      , biquadratic(CH,     q, CR).CC\n      ), vec3(.5, .33, .17));\n  #elif 1\n    // biquadratic software filter heightmap\n    float h = biquadratic(CH, q, CR).CC;\n  #elif 1\n    // bilinear software filter heightmap\n    float h = bilinear(CH, q, CR).CC;\n  #else\n    // bilinear hardware filter heightmap - has severe subpixel precision issues\n    float h = texture(CH, q).CC;\n  #endif\n #undef CC\n #undef CR\n #undef CH\n    return clamp(h, 0., 1.); // just in case\n}\n\nfloat sceneDistance(vec3 q)\n{\n    float hd = q.y + (1. - hillheight(q.xz)) * displ\n        , ld = q.y + 0.*displ; // clip plane?\n    return hd; //max(ld, hd); //min(ld, hd); //\n}\n\nconst float boundh = 0.; // bounding plane toward +Y above heightfield\n\n// iq's looped simplex gradient, excellent!\n// https://iquilezles.org/articles/normalsSDF\nvec3 sceneNormal(vec3 q, float h)\n{\n    vec3 n = vec3(0);\n    for (int i = IZERO + 4; i-- > 0; ) {\n        vec3 e = vec3((ivec3(i+3, i, i+i)&2) - 1);\n        n += sceneDistance(q + e * h) * e;\n    }\n    return normalize(n);\n}\n\nvoid sceneSurface(int uniformzero\n      , vec3 phit, inout float t\n      , out vec3 albedo, out vec3 n, out float datmo)\n{\n    bool is_hit = (t >= 0.);\n    float dsky = hatmo / depthscale;\n    datmo = t;\n    bool sky = !is_hit || t > dsky;\n    albedo = vec3(1);\n    if (sky) {\n        datmo = hatmo;\n        albedo = vec3(0);\n        n *= -0.;\n        t = dsky; \n    } else { // hit sdf\n\t\tconst float normal_precisionb = .01,\n            normal_precisions = .0001;\n    \tfloat h = normal_precisionb + normal_precisions * t;\n    \tn = sceneNormal(phit, h);\n      \talbedo = diffuseColor; // HACK material is only albedo atm\n    \tdatmo *= depthscale;\n    }\n}\n\nvec3 sceneAtmosphere(vec3 c, vec3 ro, vec3 rd, float t, float lv, float datmo)\n{\n    return mix(rd * .5 + .5, c, exp2(-fogdensity*min(datmo, hatmo)));\n}\n\nRay3 queryRay; // globals suck eh; having second thoughts about this solution but too lazy to fix rn\n\nvec3 queryAt(float t) \n{\n    vec3 q = queryRay.o + queryRay.d * t;\n    return q;\n}\n\n// the parametric function of the ray;\n// given global queryRay and given index along it,\n// compute position along ray p and return sdf(p)\nfloat sdfQueryRay(float t)\n{\n    return sceneDistance(queryAt(t));\n}\n\n// t is ray index into queryRay\n// d should be sdfQueryAt(t)\n// ot is t at prior step\n// od is d at prior step aka sdfQueryAt(ot)\n// r is a scale factor relating progress along t to the d value; usually somewhere around .9 works well for sdfs.\n// a is a minimum step size and determines the fine structure scale where details won't be skipped.\nvoid sdfQueryRayStep(inout float t, inout float d, float i, float r, float a)\n{\n    float s = 1e-4 + d * r;\n    t += d * r; //t += max(s, a);\n    d = sdfQueryRay(t);\n}\n\nfloat sdfqrRayMarch(vec3 ro, vec3 rd, float rate, float thresh, int iter)\n{\n    queryRay.o = ro, queryRay.d = rd;\n    float rit = 1. / float(iter);\n    float ret = -1.;\n    float t = .0, d = sdfQueryRay(t);\n    do {\n        if (abs(d) <= thresh*t) {\n            t = max(t, 0.);\n            ret = t;\n            break;\n        }\n        sdfQueryRayStep(t, d, float(iter)*rit, rate, 1e-3); \n        // important optimization:\n        // heading toward sky past bound plane? give up!\n        if (rd.y >= 0. && queryAt(t).y > boundh) break;\n    } while (iter-- > 0);\n    if (rd.y < 0. && ret < thresh) ret = min(depthlimit, mix(t, ro.y / -rd.y, .1)); // rescue rays that should definitely have hit the ground\n    return ret;\n}\n\n\n// TODO need tmax arg, limit max trace distance; really, lo, hi range would be nice\nfloat raymarch(vec3 ro, vec3 rd, int nsteps)\n{\n    // TODO tune threshold - .008 (*t) fixes most of the undermarching on silhouette edges,\n    // but it breaks the precision enough that it becomes visible in the lighting!!!\n    // so I'm rolling with .002 for now\n    return sdfqrRayMarch(ro, rd, .71, .002, nsteps);\n}\n\nvec4 LightingBlinnPhong(vec3 n, vec3 v, vec3 L, vec3 albedo, float d, float satten)\n{\n    float amb = clamp(.5 + .5 * n.y, 0., 1.); // hemispherical ambient\n    float lv = clamp(dot(L, n) * satten, 0., 1.); // n dot l\n    vec3 h = normalize(v + L);\n\n\tfloat dl = mix(lv, amb, ambient);\n\tvec3 c = dl * albedo;\n    \n    float spec = pow(clamp(dot(h, n), 0., 1.), specularity);\n    spec *= lv * specularity * .038; // divide by 8*pi\n\tc += spec * specularColor;\n    return vec4(c, 1);\n}\n\n// p is fragment world pos, v is view dir (toward eye), n is surf normal, t is distance from p to camera plane\n// lv is dot(-L,v), albedo is diffuse/ambient color, datmo is (fake scaled) frag depth\nvec3 sceneLight(vec3 p, vec3 v, vec3 n, float t, float lv, vec3 albedo, float datmo)\n{\n\treturn LightingBlinnPhong(n, v, sunDir, albedo, t, 1.).rgb;\n}\n\n// raymarch to find termination depth when ray hits solid object\nfloat sceneDepth(vec3 ro, vec3 rd)\n{\n    int nsteps = 256; //192; //128; //96; //64; //32; // + int(quality * 64.); //48; ////160; //32; //\n    nsteps = int(float(nsteps)*exp2(min(0.,iResolution.y/-2560.))) + 1; // perf scaling by window size\n    //nsteps /= max(1, int(8. / (2.+log2(iResolution.y))); // perf scaling by window size\n    //if (iResolution.y > 800.) nsteps -= 16; // help large window perf\n    //if (iResolution.y > 1200.) nsteps -= 16; // help fullscreen perf\n    nsteps = max(nsteps, 128); // looks really bad without enough iterations\n    //nsteps += IZERO; // HACK prevent unwise compiler loop unrolling; can't do in Common because uniforms aren't directly accessible there\n    // don't need IZERO if using iResolution though!\n    return raymarch(ro, rd, nsteps);\n}\n\nvec3 RenderScene(vec3 ro, vec3 rd, float time, out float d)\n{\n    vec3 c = vec3(0);\n    d = sceneDepth(ro, rd);\n    float datmo;\n    vec3 albedo, normal;\n    vec3 hitp = ro + rd * d;\n    sceneSurface(IZERO, hitp, d, albedo, normal, datmo);\n    float lv = dot(sunDir, rd); // factor of all fog and eye glare lighting\n    c = sceneLight(hitp, -rd, normal, d, lv, albedo, datmo);\n    c = sceneAtmosphere(c, ro, rd, d, lv, datmo);\n    return c;\n}\n\nvec3 Render(vec2 fragCoord, float nz, vec2 r, Ray3 camera)\n{\n    mat3 iview = cameraMatrix(camera.d);\n    vec3 ro, rd, vd;\n    vd = viewRayDir((2.*fragCoord - r) / r.y, pi/4.);\n\tro = camera.o, rd = normalize(iview * vd);\n    ro += .15 * nz * rd;\n\tfloat d;\n    return RenderScene(ro, rd, iTime, d);\n}\n\nvoid mainImage(out vec4 o, vec2 p)\n{\n    float j = rand(p);\n\to = vec4(Render(p, j, iResolution.xy, cameraRay(BufferC)), 1);\n    vec3 c = o.rgb;\n    c = pow(c, vec3(1.0/2.2)); // to sRGB\n    c += vec3(.75/256. * j); // dither quantization bands\n    o = vec4(c, 1);\n}\n\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"const float pi = acos(-1.); //3.141592;\n\n// buffer mapping logic, could wrap to subsequent rows\nint slotid(ivec2 loc) { return loc.x; }\nivec2 slotloc(int id) { return ivec2(id, 0); }\n\nvec4 loadValue(sampler2D buf, int slot_id)\n{\n    return texelFetch(buf, slotloc(slot_id), 0);\n}\n\n\n// channel allocations can't be done in Common,\n// as the defines for the iChannel# samplers have not yet been set.\n// but we can allocate the slots within BufferC at least.\n\nconst int\n  slotCameraPosition = 0\n, slotCameraForward  = 1\n, slotDesiredForward = 2\n, slotMouseOld       = 3 // iMouse from prior frame\n, slotCount          = 4\n;\n// e^(i*r) = vec2(cos(r), sin(r)) = Euler's identity\nvec2 cossin(float r)\n{\n    return sin(vec2(r + .5*pi, r));\n}\n\n// cheap rotation transform on p by s=(cos(a),sin(a))\nvoid rot(inout vec2 p, vec2 s) \n{\n\tp = p * s.x + vec2(p.y, -p.x) * s.y;\n} // then can rot(q.xz, cossin(a))\n\n// build a 3x3 camera orientation matrix given forward direction vector, assuming up is +Y\nmat3 cameraMatrix(vec3 camFwd)\n{\n    vec3 w = normalize(camFwd)\n       , u = normalize(cross(vec3(0, 1, 0), w))\n       , v = normalize(cross(w, u));\n    return mat3(u, v, w);\n} // inverse view matrix\n// then transform by pw = iview * pv;\n\n// implements inverse proj matrix transform (postclip to view dir)\n// with hfovy in radians\nvec3 viewRayDir(vec2 q, float hfovy)\n{\n\treturn normalize(vec3(q, 1./sin(hfovy)));\n}\n\nstruct Ray3\n{\n    vec3 o, d; // origin and direction vectors\n};\n\n// refactored to Common; complicated by BufferC isn't available directly!\nvec3 cameraPosition(sampler2D BufC) \n{\n    return loadValue(BufC, slotCameraPosition).xyz;\n}\n\nvec3 cameraDirection(sampler2D BufC) \n{\n    return loadValue(BufC, slotCameraForward).xyz;\n}\n\nRay3 cameraRay(sampler2D BufC)\n{\n    return Ray3(cameraPosition(BufC), cameraDirection(BufC));\n}\n\nfloat rand(float x)\n{\n    // see https://stackoverflow.com/questions/12964279/whats-the-origin-of-this-glsl-rand-one-liner\n    x = sin(x*7.);\n    x *= 43708.8672;\n    x = fract(x);\n    return x;\n}\n// hash\nfloat rand(vec2 x) \n{ \n    return rand(dot(x, vec2(11.07,10.71)));\n}\n\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// Debug Camera from https://shadertoy.com/view/WlVGDh\n\n// BufferC controls the state, mostly the camera location+direction\n// but wound up needing old mouse state and, for smoothing,\n// the desired facing direction.\n\n#define BufferC   iChannel2\n#define Keyboard  iChannel3\n\nconst float moverate = 8.0;\nconst float turnratemouse = .02;\nconst float turnratekbd = 2.6;\n\n\nvec3 desiredDirection() \n{\n    return loadValue(BufferC, slotDesiredForward).xyz;\n}\n\nvec4 oldMouse() \n{\n    return loadValue(BufferC, slotMouseOld);\n}\n\nbool asleep(vec2 mouse) // in shadertoy.com shader browser thumbnail? \n{\n    return dot(mouse, mouse) <= 2.;\n}\n\n// read keyboard key, return 1.0 if down\n// ultimately want to do differencing of negatives from positives\nfloat key(int vk) // key down state value as a float fraction\n{\n    float s = loadValue(Keyboard, vk).x; // read keyboard key state from texture\n    return step(.5, s); // test if down\n}\n\nconst int\n  KEY_SPACE = 32\n, KEY_CTRL  = 17 // DO NOT use control generally as when held, bad things can happen to our window or tab\n, KEY_SHIFT = 16\n, KEY_C     = 67\n// https://wikipedia.org/wiki/Arrow_keys#WASD_keys\n, KEY_W     = 87\n, KEY_A     = 65\n, KEY_S     = 83\n, KEY_D     = 68\n// in DVORAK it's ,AOE, in AZERTY it's ZQSD\n, KEY_Z     = 90 // but Image tab is using it for showing depth FIXME\n, KEY_Q     = 81\n, KEY_O     = 79\n, KEY_E     = 69\n, KEY_COMMA = 188 //188 JS, 44 ASCII\n, KEY_X     = 88 // used by Image tab; should keys move to Common tab?\n#if 0 \n    // AZERTY ZQSD\n, KEY_FW    = KEY_Z\n, KEY_LF    = KEY_Q\n, KEY_BW    = KEY_S\n, KEY_RT    = KEY_D\n#elif 0 \n    // DVORAK ,AOE\n, KEY_FW    = KEY_COMMA\n, KEY_LF    = KEY_A\n, KEY_BW    = KEY_O\n, KEY_RT    = KEY_E\n#else\n    // QWERTY\n, KEY_FW    = KEY_W\n, KEY_LF    = KEY_A\n, KEY_BW    = KEY_S\n, KEY_RT    = KEY_D\n#endif\n, KEY_UW    = KEY_SPACE\n, KEY_DW    = KEY_C  // anything but control!\n, KEY_LEFT  = 37 // arrow keys for lookaround\n, KEY_RIGHT = 39\n, KEY_UP    = 38\n, KEY_DOWN  = 40\n;\n\nvec3 cameraMovement(bool shift)\n{\n    vec3 campos = cameraPosition(BufferC);\n    float\n      fw = key(KEY_FW)\n    , bw = key(KEY_BW)\n    , lf = key(KEY_LF)\n    , rt = key(KEY_RT)\n    , up = key(KEY_UW)\n    , dn = key(KEY_DW);\n    vec3 camfwd = cameraDirection(BufferC);\n    if (asleep(iMouse.xy)) fw = .5; // automate forward\n    //if (asleep(iMouse.xy)) campos = -4. * camfwd + objectpos; // orbit // * objectscale\n    mat3 camori = cameraMatrix(camfwd);\n    vec3 cammove = vec3(rt-lf, up-dn, fw-bw) * iTimeDelta * moverate;\n    if (shift) cammove *= 4.0; // shift key for speed boost\n    campos += camori * cammove;\n    const float camradius = .04;\n    //vec3 normal = sceneNormal(campos, 1e-7, IZERO);\n    //float cdist = sceneDistance(campos);\n    //campos += normal * -min(cdist - camradius, .0); // TODO reenable collision with sdf\n//    campos.y = max(campos.y, -displ);\n    return campos;\n}\n\nvec3 cameraSteering(bool shift)\n{\n    vec3 desiredRot = desiredDirection();\n    vec4 oMouse = oldMouse();\n    bool lmb = iMouse.z >= 0.;\n    bool olmb = oMouse.z >= 0.;\n    float shiftmod = shift ? .5 : 1.; // shift actually slows rotation down\n    vec2 orbit = vec2(0);\n    if (asleep(iMouse.xy)) {\n    \torbit = vec2(.15*iTimeDelta, 0);   // slow spin\n\t} else {\n    \tif (lmb && olmb) {\n\t        vec2 m = iMouse.xy - oMouse.xy;\n    \t    orbit += m * turnratemouse * shiftmod;\n    \t} \n    \t{\n    \t\tfloat aL = key(KEY_LEFT), aR = key(KEY_RIGHT), aU = key(KEY_UP), aD = key(KEY_DOWN);\n\t        vec2 m = vec2(aR - aL, aU - aD);\n    \t    orbit += m * iTimeDelta * turnratekbd * shiftmod;\n        }\n    }\n    if (dot(orbit,orbit) != 0.) {\n        rot(desiredRot.xz, vec2(cossin(orbit.x)));\n        vec2 vr = vec2(1.,desiredRot.y);\n        rot(vr, cossin(-orbit.y));\n        desiredRot.xz *= max(1e-1f, vr.x); // do not flip signs here!\n        desiredRot.y = vr.y;\n  \t\tdesiredRot = normalize(desiredRot);\n    }\n    return desiredRot;\n}\n\n// smoothing filter\nvec3 cameraSmoothing()\n{\n    vec3 camfwd = cameraDirection(BufferC);\n    vec3 desiredFwd = desiredDirection();\n    camfwd = normalize(mix(desiredFwd, camfwd, exp2(-64.*iTimeDelta)));\n    return camfwd;\n}\n\n// a debugging fly camera using keyboard WASD + mouse + C/space\n// stores camera position,aim,etc. into c as a \n// color coded vector suitable for output to buffer\nvoid debugFlyCamera(out vec4 c, vec2 p)\n{    \n    ivec2 ip = ivec2(p);\n    c = loadValue(BufferC, ip.x); // passthru by default\n    bool shift = key(KEY_SHIFT) > .5;\n    bool init = iFrame < 3; //iFrame == 0; // thumbnail issues\n    switch (slotid(ip)) {\n      case slotCameraPosition: {\n \t    c.xyz = init ? vec3(-2.0,6.1,-33.5) : cameraMovement(shift);            \n        break;\n      }\n      case slotCameraForward: {\n        c.xyz = init ? vec3(0.,0.,1.) : cameraSmoothing();\n        break;\n      }\n      case slotDesiredForward: {\n        c.xyz = init ? vec3(0.,0.,1.) : cameraSteering(shift);\n        break;\n      }\n      case slotMouseOld: {\n        c = iMouse;\n        break;\n      }\n      default:\n        break;\n    }\n}\n\n// output to Buffer C\nvoid mainImage(out vec4 c, vec2 p)\n{    \n    if (p.y >= 1. && int(p.x) >= slotCount) discard;\n    //if (p.y >= 1. || p.x >= float(slotCount)) return; // ignore most pixels - otherwise using an entire buffer is really bad\n    debugFlyCamera(c, p);\n}\n\n","name":"Buffer C","description":"","type":"buffer"}]}
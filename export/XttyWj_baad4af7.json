{"ver":"0.1","info":{"id":"XttyWj","date":"1534099486","viewed":198,"name":"Font with feedback","username":"pickledchickenfoot","description":"Connor Bell's feedback demo + mattz & mds2's font\n\nhttps://www.shadertoy.com/view/ldsczf\nhttps://www.shadertoy.com/view/4sVyWh","likes":5,"published":1,"flags":48,"usePreview":0,"tags":["sdf","text","font","feedbackloop"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n   \tvec2 uv = fragCoord.xy / iResolution.xy;\n    vec4 tex = texture(iChannel0, uv);\n    fragColor = 1.-min(vec4(.795), pow(tex, vec4(2.75)));\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGzr","filepath":"/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","previewfilepath":"/media/ap/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"/* \"SDF texture filtering, take 2\" by mattz\n   License Creative Commons Attribution 3.0 (CC BY 3.0) Unported License.\n\n   LEGEND: \n\n     TOP LEFT (red):       raw, low-res SDF texture \n     BOTTOM LEFT: (green): Gaussian blurred SDF texture\n     TOP RIGHT (blue):     new nonlinear filtering scheme\n     BOTTOM RIGHT (gold):  average of blue and green \n\n   More details at https://twitter.com/matt_zucker/status/977269288359915520\n\n   This is combining thoughts from my previous two textures:\n\n     - \"distance texture smoothing\"\n       https://www.shadertoy.com/view/4sycW1\n\n     - \"sketchy font distance\"\n       https://www.shadertoy.com/view/MdycWh\n\n   The first one started with an inspiration about nonlinear \n   filtering of distance textures, but I got the math wrong and ended\n   up with an overcomplicated implementation of Gaussian smoothing.\n\n   The second one was an attempt to visualize the local linear \n   approximations to boundary implied by the distance and gradient\n   at each point in the SDF texture.\n\n   This time I think I finally got the math right on my nonlinear\n   filtering, and I'm really pleased with the results! It does a much\n   better job preserving corners than the Gaussian-blurred distance\n   texture.\n\n   The only downside is that it uses 16 texture fetches per distance\n   query. If you comment out the HIGH_QUALITY define below, you \n   can see what the 9-tap version looks like (does worse on letters\n   like A,M,N,W with steep inward-facing corners).\n\n   See https://www.shadertoy.com/view/llcXRl for documentation about\n   the font texture.\n\n */\n\n#define HIGH_QUALITY\n\n// texture is 1024x1024\nconst float TEX_RES = 1024.;\n\n// texture is 16x16 glyphs\nconst float GLYPHS_PER_UV = 16.;\n\n// since the texture is uint8 it has a bias to represent 0\nconst float TEX_BIAS = 127./255.;\n\n// get font UV coords from screen coords\nvec2 font_from_screen(vec2 tpos, float font_size, vec2 char_pos) {    \n    return (tpos/font_size + char_pos + 0.5)/GLYPHS_PER_UV;\n}\n\n//////////////////////////////////////////////////////////////////////\n// sample font texture \n\nvec3 sample_grad_dist(vec2 uv, float font_size) {\n    \n    vec3 grad_dist = (textureLod(iChannel0, uv, 0.).yzw - TEX_BIAS) * font_size;\n\n    grad_dist.y = -grad_dist.y;\n    grad_dist.xy = normalize(grad_dist.xy + 1e-5);\n    \n    return grad_dist;\n    \n}\n\n//////////////////////////////////////////////////////////////////////\n// Gaussian blur of distance channel - does not use gradient info\n\nfloat sample_dist_gaussian(vec2 uv, float font_size) {\n\n    float dsum = 0.;\n    float wsum = 0.;\n    \n    const int nstep = 3;\n    \n    const float w[3] = float[3](1., 2., 1.);\n    \n    for (int i=0; i<nstep; ++i) {\n        for (int j=0; j<nstep; ++j) {\n            \n            vec2 delta = vec2(float(i-1), float(j-1))/TEX_RES;\n            \n            float dist = sample_grad_dist(uv-delta, font_size).z;\n            float wij = w[i]*w[j];\n            \n            dsum += wij * dist;\n            wsum += wij;\n\n        }\n    }\n    \n    return dsum / wsum;\n}\n\n//////////////////////////////////////////////////////////////////////\n// Nonlinear filtering of SDF texture using gradient info.\n// \n// Here's the story, slightly changed from yesterday's version:\n//\n// Given a signed distance and a gradient, every pixel in an SDF\n// texture provides a local linear approximation to the distance\n// function.\n//\n// We assume the SDF texture stores for every pixel location A both\n// the signed distance d(A) to the surface, as well as the gradient\n// g(A) of the SDF. For d to be a true signed distance function,\n// it must be true that g(A) is a unit vector; however, in practice\n// we need to normalize g due to filtering and precision issues.\n//\n// Now if we linearize the distance function in the vicinity of A,\n// we find for any small displacement 𝛿:\n//\n//   d(A + 𝛿) ≈ d(A) + dot(𝛿, g(A))\n//\n// Ok, now let's imagine that we want an improved estimate of the\n// distance at some pixel location B. We will take a weighted average\n// over the local linearizations of the distance function provided\n// in a small window around B, with roughly Gaussian weights:\n//\n//   +---+---+---+  \n//   |A00|A01|A02|  d(Aij + 𝛿ij) ≈ d(Aij) + dot(𝛿ij, g(Aij))\n//   +---+---+---+  \n//   |A10| B |A12|  now let B = Aij + 𝛿ij, so 𝛿ij = B - Aij \n//   +---+---+---+  \n//   |A20|A21|A22|  and so d(B) ≈ d(Aij) + dot(B - Aij, g(Aij))\n//   +---+---+---+\n//\n// In fact, we don't even need to restrict ourselves to the texel\n// grid; we can use GPU's texture resampling to compute these local\n// linearizations anywhere, not just at texel centers. In practice, \n// I find a 4x4 neighborhood looks nicer than 3x3.\n//\n// Along the way we can compute a Gaussian blur of the distance \n// function (as the function above does) for very little extra\n// effort.\n//\n// Since the new filtering method tends to make convex corners\n// bulge and concave corners pucker and the Gaussian blur tends \n// to have the *opposite* effect, simply averaging the two looks\n// better than either one alone, I think.\n\n\nvec2 sample_dist_smart(vec2 uv, float font_size) {\n        \n#ifdef HIGH_QUALITY\n    const int nstep = 4;\n    const float w[4] = float[4](1., 2., 2., 1.);\n#else\n    const int nstep = 3;\n    const float w[3] = float[3](1., 2., 1.);\n#endif\n    \n    vec2  dsum = vec2(0.);\n    float wsum = 0.;\n    \n    for (int i=0; i<nstep; ++i) {\n        \n        float ui = float(i)/float(nstep-1);\n                \n        for (int j=0; j<nstep; ++j) {\n            \n            float uj = float(j)/float(nstep-1);\n            \n            vec2 delta = (-1.  + 2.*vec2(ui,uj))/TEX_RES;\n            \n            vec3 grad_dist = sample_grad_dist(uv-delta, font_size);\n            vec2 pdelta = delta * GLYPHS_PER_UV * font_size;\n            \n            float dline = grad_dist.z + dot(grad_dist.xy, pdelta);\n               \n            float wij = w[i]*w[j];\n            \n            dsum += wij * vec2(dline, grad_dist.z);\n            wsum += wij;\n\n        }\n    }\n    \n    return dsum / wsum;\n    \n}\n\n//////////////////////////////////////////////////////////////////////\n// main function\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n\n    // which character to render now\n    int char = int(mod(iTime + 64., 256.));\n    \n    int char2 = int(mod(iTime + 65., 256.));\n    float blend = mod(iTime, 1.0);\n    if (char == 64) { char = 29; } else if (char == 29) { char = 64; }\n    \n    for (int i=32; i<127; ++i) {\n        if (texelFetch(iChannel1, ivec2(i,0), 0).x != 0.) {\n            char = i;\n        }\n    }\n        \n    const bool screenshot_mode = false; \n    bool use_mouse = max(iMouse.x, iMouse.y) > 20.;\n    \n    vec2 p, m;\n    float font_size = 1.1 * iResolution.y;\n\n    if (use_mouse) {\n        \n        p = (fragCoord - 0.5*iResolution.xy);\n        m = fragCoord - iMouse.xy;\n        \n    } else {\n        \n        font_size = 0.6 * iResolution.y;\n        \n        p = (fragCoord - iResolution.xy * vec2(0.25, 0.25));\n        m = fragCoord - iResolution.xy * 0.5;\n\n        vec2 repeat = iResolution.xy * vec2(0.5, 0.5);\n        p -= floor(p/repeat + 0.5) * repeat;\n    \n    }  \n    \n    // character offset  within font texture\n    vec2 char_pos = vec2(ivec2(char%16, 15-char/16));\n    vec2 char_pos2 = vec2(ivec2(char2 % 16, 15 - char2/16));\n        \n    // get uv in font texture\n    vec2 uv = font_from_screen(p, font_size, char_pos);\n    vec2 uv2 = font_from_screen(p, font_size, char_pos2);\n \n    vec3 bgcolor;\n    float dfont;\n    float dfont2;\n    \n    if (m.x < 0.) {\n        if (m.y > 0.) {\n            bgcolor = vec3(1, 0.9, 0.9);\n            dfont = sample_grad_dist(uv, font_size).z;\n            dfont2 = sample_grad_dist(uv2, font_size).z;\n        } else {\n            bgcolor = vec3(0.9, 1, 0.9);\n            dfont = sample_dist_gaussian(uv, font_size);\n            dfont2 = sample_dist_gaussian(uv2, font_size);\n        }\n    } else {\n        if (m.y > 0.) {\n            bgcolor = vec3(0.9, 0.95, 1);\n            dfont = sample_dist_smart(uv, font_size).x;\n            dfont2 = sample_dist_smart(uv2, font_size).x;\n        } else {\n            \n            bgcolor = vec3(1, 0.95, 0.9);\n            vec2 sg = sample_dist_smart(uv, font_size);\n            dfont = mix(sg.y, sg.x, 0.5);\n            vec2 sg2 = sample_dist_smart(uv2, font_size);\n            dfont2 = mix(sg2.y, sg2.x, 0.5);\n            \n        }\n    }\n    \n    vec2 box = abs(p) - 0.5*font_size;\n    dfont = max(dfont, max(box.x, box.y));\n    dfont2 = max(dfont2, max(box.x, box.y));\n    \n    float dborder = min(abs(m.x), abs(m.y));\n\n    vec3 color = bgcolor*smoothstep(0., 1., mix(dfont, dfont2, blend));\n    color = mix(color, vec3(0.7), smoothstep(1., 0., dborder-.5));\n\n    fragColor = vec4(color, 1);\n\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// This buffer is the feedback loop\n\n// iq noise\n\nfloat hash( float n )\n{\n    return fract(sin(n)*43758.5453123);\n}\n\nfloat noise( in vec2 x )\n{\n    vec2 p = floor(x);\n    vec2 f = fract(x);\n\n    f = f*f*(3.0-2.0*f);\n\n    float n = p.x + p.y*157.0;\n\n    return mix(mix( hash(n+  0.0), hash(n+  1.0),f.x),\n               mix( hash(n+157.0), hash(n+158.0),f.x),f.y);\n}\n\n// hue by netgrind(?)\n\nvec3 hue(vec3 color, float shift) {\n\n    const vec3  kRGBToYPrime = vec3 (0.299, 0.587, 0.114);\n    const vec3  kRGBToI     = vec3 (0.596, -0.275, -0.321);\n    const vec3  kRGBToQ     = vec3 (0.212, -0.523, 0.311);\n\n    const vec3  kYIQToR   = vec3 (1.0, 0.956, 0.621);\n    const vec3  kYIQToG   = vec3 (1.0, -0.272, -0.647);\n    const vec3  kYIQToB   = vec3 (0.2, -1.107, 2.0);\n\n    // Convert to YIQ\n    float   YPrime  = dot (color, kRGBToYPrime);\n    float   I      = dot (color, kRGBToI);\n    float   Q      = dot (color, kRGBToQ);\n\n    // Calculate the hue and chroma\n    float   hue     = atan (Q, I);\n    float   chroma  = sqrt (I * I + Q * Q);\n\n    // Make the user's adjustments\n    hue += shift;\n\n    // Convert back to YIQ\n    Q = chroma * sin (hue);\n    I = chroma * cos (hue);\n\n    // Convert back to RGB\n    vec3    yIQ   = vec3 (YPrime, I, Q);\n    color.r = dot (yIQ, kYIQToR);\n    color.g = dot (yIQ, kYIQToG);\n    color.b = dot (yIQ, kYIQToB);\n\n    return color;\n}\n\nfloat fractalNoise(vec2 pos) {\n\tfloat n = 0.;\n\tfloat scale = 1. / 1.5;\n\tfor (int i = 0; i < 5; i += 1) {\n\t\tn += noise(pos) * scale;\n\t\tscale *= 0.5;\n\t\tpos *= 2.;\n\t}\n\treturn n;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n   \tvec2 uv = fragCoord.xy / iResolution.xy;\n    \n    // Convert the uv's to polar coordinates to scale up  \n    vec2 polarUv = (uv * 2.0 - 1.0);\n    float angle = atan(polarUv.y, polarUv.x);\n    \n    // Scale up the length of the vector by a noise function feeded by the angle and length of the vector\n    float ll = length(polarUv)*0.5 - fractalNoise(vec2(sin(angle*4. + iTime*2.) + length(uv)*10., length(uv)*20. + sin(angle*4.)))*0.005 ;\n    \n    vec3 base = texture(iChannel0, uv).rgb;\n    \n    // Convert the scaled coordinates back to cartesian\n    vec2 offs = vec2(cos(angle)*ll + 0.5, sin(angle)*ll + 0.5);\n    \n    // sample the last texture with uv's slightly scaled up\n    vec3 overlay = texture(iChannel1, offs.xy).rgb;\n    \n    // Since the colors of the iChannel0 are monochrome, set a color channel to zero to do a hue shift\n    base.b = 0.;\n    \n    // Apply a hue shift to the overlaid image so it cascades in the feedback loop\n    overlay = hue(overlay, .3);\n    \n    // Additively blend the colors together\n    vec4 col = vec4(clamp(vec3(0.),vec3(1.),base + overlay*0.86), 1.0);\n    \n    fragColor = col;\n}","name":"Buffer B","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"WdXBR8","date":"1587764134","viewed":540,"name":"Rhombic Dodecahedron Voxels","username":"spalmer","description":"a different kind of voxel shape.  Not the most efficient space-filling sphere packing arrangement, but relatively simple.  May be useful for something.  Enjoy!\nApparently this is known as face-centered cubic lattice (FCC)","likes":14,"published":1,"flags":48,"usePreview":0,"tags":["raycast","voxel","tiling","fcc"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4sfGRr","filepath":"/media/a/27012b4eadd0c3ce12498b867058e4f717ce79e10a99568cca461682d84a4b04.bin","previewfilepath":"/media/ap/27012b4eadd0c3ce12498b867058e4f717ce79e10a99568cca461682d84a4b04.bin","type":"volume","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Voxels shaped like rhombic dodecahedrons\n// using a 3D checkerboard sphere packing lattice\n\n// see Common tab for more info.\n// debug fly camera controlled by keyboard+mouse; see Buffer C.\n\n#define BufferC   iChannel2\n\n// signed distance\n\nfloat dbox(float p)\n{\n    return abs(p) - 1.;\n}\n\nfloat dslab(vec3 q, vec3 n, float h)\n{\n    return abs(dot(q, n)) - h;\n}\n\nfloat dball(vec3 p)\n{\n    return length(p)\n        - 1.; //1.4 * sqrt(.5); //1.25; //sqrt(2.); //.75; //- sqrt(.5); // - .05; //.866; //.7071; //1.; //\n}\n\n// iq's, mostly\nfloat dseg(vec3 q, vec3 a, vec3 b)\n{\n    q -= a; b -= a;\n    return length(q - b * clamp(dot(q, b) / dot(b, b), 0., 1.));\n}\n\n// a rhombic dodecahedron, larger than a unit sphere\nfloat drhombdod(vec3 p)\n{\n    p = abs(p); // then sort so x is largest\n    if (p.x < p.y) p = p.yxz;\n    if (p.x < p.z) p = p.zxy;\n\t// order of smaller two doesn't matter much\n    const float r = sqrt(.5);\n    float\n      d0 = dslab(p, vec3(r,r,0), r * 1.5)\n    , d1 = dslab(p, vec3(r,0,r), r * 1.5)\n    , d2 = dslab(p, vec3(0,r,r), r * 1.5)\n    , maxslab = max(max(d0,d1), d2);\n    if (maxslab > 0.) { // not inside\n        vec3 q = p - vec3(1.5,0,0); // relative to corner, easier to check planes with\n        if (q.x + 2.*q.z - q.y > 0. && q.x + 2.*q.y - q.z > 0.)\n        \treturn dseg(p, vec3(1.5,0,0), vec3(.75));\n    }\n    return maxslab;\n}\n\n// main model selector\nfloat dshape(vec3 q)\n{\n    float scale = sqrt(.45); //1.; \n    q /= scale; \n    return scale * (\n       fract(iTime * .125) < .75 //true //\n       ? \n        drhombdod\n        (q)\n       :\n        dball\n        (q)\n        );\n}\n\nivec3 vid(vec3 q)\n{\n    ivec3 i = ivec3(floor(q));\n    if (((i.x^i.y^i.z)&1) != 0) {\n        vec3 f = q - vec3(i) - .5;\n        ivec3 g = ivec3(sign(f));\n        f = abs(f);\n        if (f.x > f.y && f.x > f.z)\n            i.x += g.x;\n        else if (f.y > f.z)\n            i.y += g.y;\n        else\n            i.z += g.z;      \n    }\n    return i;\n}\n\n// IDEA:\n// for voxel storage with this tiling arrangement,\n// can halve the required storage:\n// can store even and odd planes in one plane!\n// even planes are:\n// XOXOXO\n// OXOXOX\n// XOXOXO\n// OXOXOX\n// and odd planes are:\n// OXOXOX\n// XOXOXO\n// OXOXOX\n// XOXOXO\n// so just interleave the storage!  \n// What's used by one plane is unused\n// by next plane, and vice versa.\nivec3 voxStorageCoord(ivec3 vid)\n{\n    vid.z >>= 1;\n    return vid;\n}\n\n// centralized voxel scale\nfloat vscale()\n{\n    return 1.; //sin(iTime*.1)*.2 + 1.; //.5; //\n}\n\nbool isvoxel(ivec3 q)\n{\n    vec3 p = vec3(q) * vscale();\n//    return q.y <= 0;\n    //ivec3 r = ivec3(iChannelResolution[0]);\n    //ivec3 qwrap = q % r;\n    //qwrap += ((qwrap >> 31) + 1) * r;\n    //float t = texelFetch(iChannel0, qwrap, 0).x;\n    //float t = texture(iChannel0, vec3(qwrap) / iChannelResolution[0]).x;\n    //float t = texture(iChannel0, vec3(q) / vec3(iChannelResolution[0].x)).x;\n    //float t = texture(iChannel0, vec3(q) / vec3(32)).x;\n    float t = sin(.13*float(p.x)) * sin(.12*float(p.z)) * .5 + .5;\n    return .5 > \n        (t - .5) * 8.\n         + float(p.y);\n}\n// see Sparse Sphere Field for a better scheme:  https://shadertoy.com/view/wdSfWR\nfloat dvoxel(vec3 p)\n{\n    // probably must iterate over the neighbors to get even a nearby estimate of distance\n    // for now I'm limiting scan to about 1 distance unit accuracy, and clamping.\n    // which severely limits the speed the ray marcher can proceed.\n    // For now that's ok since at least it prevents overmarching and missing features.\n    float vs = vscale();\n    ivec3 h = vid(p / vs);\n    float d = 3.4e38;\n    if (isvoxel(h))\n        d = dshape(p/vs - vec3(h) - .5);\n    for (int k = IZERO - 1; k < 2; k += 2) {\n     for (int j = IZERO - 1; j < 2; j += 2) {\n         ivec3 q;\n         q = h + ivec3(0,j,k);\n         if (isvoxel(q)) {\n             float x = dshape(p/vs - vec3(q) - .5);\n        \t d = min(d, x);\n         }\n         q = h + ivec3(j,k,0);\n         if (isvoxel(q)) {\n             float x = dshape(p/vs - vec3(q) - .5);\n        \t d = min(d, x);\n         }\n         q = h + ivec3(j,0,k);\n         if (isvoxel(q)) {\n             float x = dshape(p/vs - vec3(q) - .5);\n        \t d = min(d, x);\n         }\n     }\n    }\n    return clamp(d, -.7, .7); //clamp(d, -1., 1.); //clamp(d, -.5, .5); //d; //\n}\n\n\n// for a simpler scene where I simply wanted to fill space\n// with balls tiled in this fashion, I actually came up with\n// a simpler scheme; idk if it would still work if they\n// were tightly packed or otherwise overlapping, and \n// I'm still not sure how to handle that some cells may be \n// completely empty; but this was working out quite a lot better\n// because it only ever checked one shape instance per step:\n/* // from example scene from Fly Camera, which isn't yet public \n// but is at https://shadertoy.com/view/tdsfR4\n\tvec3 p ...; float tile = 2.; ivec3 i = ivec3(floor(p/tile));\n    if (((i.x^i.y^i.z)&1) != 0) {\n        vec3 d = p - .5*tile;\n        vec3 a = abs(d);\n        d = sign(d);\n        if (a.x > a.y && a.x > a.z) d.yz = vec2(0.); // x max\n        else if (a.y > a.z) d.xz = vec2(0.); // y max\n        else d.xy = vec2(0.); // z largest component\n    \tp -= d * tile; // snap to closest neighbor cell\n    }\n// pretty sure it's not yet optimal anyway but better than current scheme\n*/\n\n\nfloat sceneDistance(vec3 q)\n{\n    return dvoxel(q);    \n}\n\n\nconst float normal_precision = 0.01; //0.08; //\n\n// iq's looped simplex gradient, excellent!\n// https://iquilezles.org/articles/normalsSDF\n// I really did a number on the bitshifting though!\nvec3 sceneNormal(vec3 q, float blur)\n{\n    float h = normal_precision\n        * sqrt(1./3.) // .5773\n        * (1. + 128.*blur) // antialiasing, band limit TODO tuning!! maybe need iResolution?\n        ;\n    vec3 n = vec3(0);\n    int i = IZERO;\n    for (; i < 4; ++i) {\n        vec3 e = vec3((ivec3(i+3, i, i+i)&2) - 1);\n        n += sceneDistance(q + e * h) * e;\n    }\n    return normalize(n);\n}\n\nvec3 sceneMaterial(vec3 q, float blur)\n{\n    ivec3 i = vid(q/vscale());\n    // simple grey plastic is fine for the object\n    vec3 albedo = diffuseColor;\n    vec3 vc = sin(vec3(i & 7)*6.28/8.) * .5 + .5;\n   \treturn albedo * vc;\n}\n\nvoid sceneSurface(vec3 phit, inout float t\n      , out vec3 albedo, out vec3 n, out float datmo)\n{\n    float blur = .01; //AntialiasPosition(phit);\n    bool is_hit = (t >= 0.);\n    float dsky = hatmo / depthscale;\n    datmo = t;\n    bool sky = !is_hit || t > dsky;\n    albedo = vec3(1);\n    if (sky) {\n        datmo = hatmo; //dsky; //\n        albedo = vec3(0);\n        n *= -0.;\n        t = dsky;\n    } else { // hit sdf, so render it over bg, lit\n\t\tn = sceneNormal(phit, blur);\n      \talbedo = sceneMaterial(phit - n * .02, blur); \n    \tdatmo *= depthscale;\n    }\n}\n\nvec3 sceneAtmosphere(vec3 c, vec3 ro, vec3 rd, float t, float lv, float datmo)\n{\n    datmo = min(datmo, hatmo);\n    c = mix(csky, c, exp2(-fogdensity * datmo));\n    c += pow(max(0., dot(rd, lightDir)), 128.);\n    return c;\n}\n\nstruct Ray3 \n{\n    vec3 o, d; // origin and direction vectors\n};\n\nRay3 queryRay;\n\nvec3 queryAt(float t) \n{\n    return queryRay.o + queryRay.d * t;\n}\n\n// the parametric function of the ray;\n// given global queryRay and given index along it,\n// compute position along ray p and return sdf(p)\nfloat sdfQueryRay(float t)\n{\n    return sceneDistance(queryAt(t));\n}\n\n// a single iteration of a linear bracketed root finder algorithm aka regula falsi;\n// Linearly interpolate the position of a root between two known values on either side\n// returns mix factor to use between original two points\n// v0 = sdf(x0) and v1 = sdf(x1), then xRoot ~= mix(x0, x1, FalsePositionEstimate(v0, v1))\n// x0 and x1 *must* bracket the root, so v0 and v1 must have opposite signs or be zero.\n// takes two samples from field and returns interpolation factor between them where zero is likely to be found\nfloat FalsePositionEstimate(float v0, float v1)\n{\n\tfloat l = v0 - v1; \n\treturn abs(l) < 1e-24 ? .5 : v0 / l;\n}\n\nvec2 sdfqrFalsePositionStep(inout float x0, inout float x1, inout float v0, inout float v1)\n{\n    float u = FalsePositionEstimate(v0, v1);\n    float x = mix(x0, x1, u); // new guess\n    float d = sdfQueryRay(x); // NOTE function is hardcoded.\n\tif (d < 0. == v0 < 0.)\n        v0 = d, x0 = x;\n\telse\n        v1 = d, x1 = x;\n    return vec2(x, d);\n}\n// result.x should then be between input x0 and x1, and closer than either.\n// result.y is the function's value at the new point result.x\n// on exit, either x0 or x1 will now contain the return value.x, and the extent should have shrunk.\n// post-result bracketing situation *should* be an improvement.\n// at some point you can stop calling it, and just use the midpoint of the remaining bracket.\n\n// now all that remains is to call it, perhaps repeatedly, until satisfied\n\n// usually even a few iterations does wonders.\nfloat sdfqrFalsePosition(inout float p0, inout float p1, inout float v0, inout float v1, int niter, float tol)\n{\n\tfloat x;\n    for (int i = niter; i-- > 0; ) {\n        vec2 r = sdfqrFalsePositionStep(p0, p1, v0, v1);\n        x = r.x;\n        if (abs(r.y) < tol) break;\n    }\n    return x;\n}\n\n// t is ray index into queryRay\n// d should be sdfQueryAt(t)\n// ot is t at prior step\n// od is d at prior step aka sdfQueryAt(ot)\n// r is a scale factor relating progress along t to the d value; usually somewhere around .9 works well for sdfs.\n// a is a minimum step size and determines the fine structure scale where details won't be skipped.\nvoid sdfQueryRayStep(inout float t, inout float d, inout float ot, inout float od, float i, float r, float a)\n{\n    float t0 = t, d0 = d; // copy input values for later\n    float p = .5 * d / od;\n    float s = 1e-4 + d * r;\n    t += max(s, a);\n    d = sdfQueryRay(t);\n    ot = t0, od = d0;\n}\n\nfloat sdfqrRayMarch(vec3 ro, vec3 rd, float rate, int iter)\n{\n    queryRay.o = ro, queryRay.d = rd;\n    float rit = 1. / float(iter);\n    float ret = -1.;\n    float t = .0, t1 = -1e-9, d = sdfQueryRay(t);\n    float d1 = d + 1e-9;\n    do {\n        if (d <= .0) {\n        \tt = sdfqrFalsePosition(t, t1, d, d1, 4, 5e-4);\n            ret = t;\n            break;\n        }\n        sdfQueryRayStep(t, d, t1, d1, float(iter)*rit, rate, 9e-4);\n    } while (iter-- > 0);\n    if (iter < 0 && d <= .1) ret = t+d;\n    return ret;\n}\n\nfloat raymarch(vec3 ro, vec3 rd, int nsteps)\n{\n    float t = sdfqrRayMarch(ro, rd, .72, nsteps);\n\treturn t;\n}\n\nfloat rayshadow(vec3 ro, vec3 rd, int nsteps)\n{\n    if (rd.y <= 0. || ro.y <= 0.) return 1.;\n    float t = sdfqrRayMarch(ro, rd, 1.25, nsteps);\n\treturn t >= 0. ? 0. : 1.; // hard shadows atten\n}\n\n// basic plasticky BRDF - not going for photoreal here\nvec4 LightingBlinnPhong(vec3 n, vec3 v, vec3 albedo, float d, float satten)\n{\n    float amb = clamp(.5 + .5 * n.y, 0., 1.); // hemispherical ambient\n    float lv = clamp(dot(lightDir, n) * satten, 0., 1.); // n dot l\n    vec3 h = normalize(v + lightDir);\n\n\tfloat dl = mix(lv, amb, ambient); // diffuse+ambient lighting\n\tvec3 c = dl * albedo;\n    \n    float spec = pow(clamp(dot(h, n), 0., 1.), specularity);\n    spec *= lv * specularity * .038; // should mul by n*l and power, divide by 8*pi\n\tc += spec * specularColor;\n    return vec4(c, 1);\n}\n\n// p is fragment world pos, v is view dir (toward eye), n is surf normal, t is distance from p to camera plane\n// lv is dot(-L,v), albedo is diffuse/ambient color, datmo is (fake scaled) frag depth\n// returns premultiplied alpha color c of lit fragment\nvec3 sceneLight(vec3 p, vec3 v, vec3 n, float t, float lv, vec3 albedo, float datmo) //vec3 ro, vec3 rd, float t,\n{\n    float satten = 1.;\n   #if 0 // shadows - look bad due to inaccuracy and self-shadow acne\n    float nl = dot(n,lightDir);\n    if (nl > 0.) {\n    \tint nshadowsteps = IZERO + 32; //16; //\n    \tp += .01 * n + .006 * lightDir * nl; //max(nl,0.); // self-shadow bias hacks        \n    \tsatten = rayshadow(p, lightDir, nshadowsteps);\n    }\n   #endif\n\treturn LightingBlinnPhong(n, v, albedo, t, satten).rgb;\n}\n\n// raymarch to find termination depth when ray hits solid object\nfloat sceneDepth(vec3 ro, vec3 rd)\n{\n    int nsteps = 64; //96; //48; //\n    nsteps += IZERO; // HACK prevent compiler loop unrolling\n\tfloat d = sdfqrRayMarch(ro, rd, .99, nsteps);\n    if (true && !(d >= 0.)) { // rescue failed marches, undermarches\n        d = ro.y / -rd.y;\n        if (!(d >= 0.))\n            d = -1.; //hatmo / depthscale; // TODO 'dome'\n    }\n    return d;\n}\n\nvec3 RenderScene(vec3 ro, vec3 rd, out float d)\n{\n    float lv = dot(lightDir, rd); // factor of all fog and eye glare lighting\n    vec3 c = vec3(0);\n    d = sceneDepth(ro, rd);\n    float datmo;\n    vec3 albedo, normal;\n    vec3 hitp = ro + rd * d;\n    sceneSurface(hitp, d, albedo, normal, datmo);\n    c = sceneLight(hitp, -rd, normal, d, lv, albedo, datmo);\n    c = sceneAtmosphere(c, ro, rd, d, lv, datmo);\n    return c;\n}\n\nvoid ViewRay(vec2 p, out vec3 ro, out vec3 rd, out vec3 vd)\n{\n    vec2 R = iResolution.xy;\n    vec2 q = (p + p - R) / R.y;\n    vec3 camera_pos = cameraPosition(BufferC);\n    vec3 camera_dir = cameraDirection(BufferC);\n    mat3 M = cameraMatrix(camera_dir);\n    const float hfovy = pi/6.;\n    vd = normalize(vec3(q, 1./sin(hfovy)));\n    ro = camera_pos, rd = normalize(M * vd);\n}\n\nvoid mainImage(out vec4 c, vec2 p)\n{\n    vec3 ro, rd, vd;\n    ViewRay(p, ro, rd, vd);\n    float d;\n    c.rgb = RenderScene(ro, rd, d);\n    c.rgb = pow(c.rgb, vec3(1./2.2)); // to srgb-ish gamma\n    c.a = 1.;\n}\n\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"const float pi = 3.141592;\nconst vec3 lightDir = normalize(vec3(0,.5,.866));\nconst float ambient = .3;\nconst float fogdensity = .001;\nconst float specularity = 32.;\nconst vec3 specularColor = vec3(.3);\nconst vec3 diffuseColor = vec3(.7,.9,.5);\nconst float hatmo = 85000.; // air extinct distance\nconst float depthscale = 96.; // fog exaggeration for horizon look mostly, affects sun also though\nconst vec3 csky = vec3(.2,.4,.6);\n\nconst int slotCameraPosition = 0;\nconst int slotCameraForward  = 1;\nconst int slotDesiredForward = 2;\nconst int slotMouseOld       = 3; // iMouse from prior frame\nconst int slotCount          = 4;\n\nint slotid(ivec2 loc) { return loc.x; }\nivec2 slotloc(int id) { return ivec2(id, 0); }\n\nvec4 loadValue(sampler2D buf, int slot_id)\n{\n    return texelFetch(buf, slotloc(slot_id), 0);\n}\n\nvec2 cossin(float r)\n{\n    return sin(r + vec2(.5*pi, 0));\n}\n\n// cheap rotation transform on p by s=(cos(a),sin(a))\nmat2 mrot(vec2 s)\n{\n    return mat2(s.x, -s.y, s.y, s.x);\n} // then can q.xz = mrot(cossin(a)) * q.xz;\n\n// build a 3x3 camera orientation matrix given forward direction vector, assuming up is +Y\nmat3 cameraMatrix(vec3 camFwd)\n{\n    const vec3 camUp = vec3(0, 1, 0); // hard-coded :( HACK\n    vec3 w = normalize(camFwd)\n       , u = normalize(cross(camUp, w))\n       , v = normalize(cross(w, u));\n    return mat3(u, v, w);\n}\n// then I just transform by pw = MC * pv;\n// I think I should transpose it, as view matrix instead!\n// then it'd be pw = pv * MV;\n\n// BufferC isn't available directly!\nvec3 cameraPosition(sampler2D BufC) \n{\n    return loadValue(BufC, slotCameraPosition).xyz;\n}\n\nvec3 cameraDirection(sampler2D BufC) \n{\n    return loadValue(BufC, slotCameraForward).xyz;\n}\n\n\nbool asleep(vec2 mouse) // in shadertoy.com shader browser thumbnail? \n{\n    return dot(mouse, mouse) <= 2.;\n}\n\n#define IZERO min(iFrame, 0) // for preventing loop unrolling\n\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// BufferC controls the state, mostly the camera location+direction\n// but wound up needing old mouse state and, for smoothing,\n// the desired facing direction.\n\n#define BufferC   iChannel2  // also the shader fragColor output\n#define Keyboard  iChannel3\n\nconst float moverate = 1.;\nconst float turnratemouse = .02; // since mouse can't go outside window, must be pretty fast\nconst float turnratekbd = 2.6;\n\n\nvec3 desiredDirection() \n{\n    return loadValue(BufferC, slotDesiredForward).xyz;\n}\n\nvec4 oldMouse() \n{\n    return loadValue(BufferC, slotMouseOld);\n}\n\n\n// read keyboard key, return 1.0 if down\n// ultimately want to do differencing of negatives from positives\nfloat key(int vk) // key down state value as a float fraction\n{\n    float s = loadValue(Keyboard, vk).x; // read keyboard key state from texture\n    return step(.5, s); // test if down\n}\n\nconst int\n  KEY_SPACE = 32\n//, KEY_CTRL  = 17 // DO NOT use control generally as when held, bad things can happen to our window or tab\n, KEY_SHIFT = 16\n, KEY_C     = 67\n// https://en.wikipedia.org/wiki/Arrow_keys#WASD_keys\n, KEY_W     = 87\n, KEY_A     = 65\n, KEY_S     = 83\n, KEY_D     = 68\n// in DVORAK it's ,AOE, in AZERTY it's ZQSD\n, KEY_Z     = 90 // but Image tab is using it for showing depth FIXME\n, KEY_Q     = 81\n, KEY_O     = 79\n, KEY_E     = 69\n, KEY_COMMA = 188 //188 JS, 44 ASCII\n, KEY_X     = 88 // used by Image tab; should keys move to Common tab?\n, KEY_LEFT  = 37 // arrow keys for lookaround\n, KEY_RIGHT = 39\n, KEY_UP    = 38\n, KEY_DOWN  = 40 // I suppose you could bind them instead of WASD if you really prefer, but then must use mouse to look\n#if 0 // AZERTY ZQSD\n, KEY_FW    = KEY_Z\n, KEY_LF    = KEY_Q\n, KEY_BW    = KEY_S\n, KEY_RT    = KEY_D\n#elif 0 // DVORAK ,AOE\n, KEY_FW    = KEY_COMMA\n, KEY_LF    = KEY_A\n, KEY_BW    = KEY_O\n, KEY_RT    = KEY_E\n#else // QWERTY\n, KEY_FW    = KEY_W\n, KEY_LF    = KEY_A\n, KEY_BW    = KEY_S\n, KEY_RT    = KEY_D\n#endif\n, KEY_UW    = KEY_SPACE\n, KEY_DW    = KEY_C  // anything but control!\n;\n\nvec3 cameraMovement(bool shift)\n{\n    vec3 campos = cameraPosition(BufferC);\n    float\n      fw = key(KEY_FW)\n    , bw = key(KEY_BW)\n    , lf = key(KEY_LF)\n    , rt = key(KEY_RT)\n    , up = key(KEY_UW)\n    , dn = key(KEY_DW);\n    if (asleep(iMouse.xy)) fw = .5; // automate forward in thumbnails\n    vec3 camfwd = cameraDirection(BufferC);\n    mat3 camori = cameraMatrix(camfwd);\n    vec3 cammove = vec3(rt-lf, up-dn, fw-bw) * iTimeDelta * moverate;\n    if (shift) cammove *= 4.0; // shift key for speed boost\n    campos += camori * cammove;\n    const float camradius = .04;\n//    campos += sdfnormal(campos) * -min(sdf(campos) - camradius, .0); // TODO redo collision with sdf, need to move stuff to Common\n    return campos;\n}\n\nvec3 cameraSteering(bool shift)\n{\n    vec3 desiredRot = desiredDirection();\n    vec4 oMouse = oldMouse();\n    bool lmb = iMouse.z >= 0.;\n    bool olmb = oMouse.z >= 0.;\n    float shiftmod = shift ? .5 : 1.; // shift actually slows rotation down\n    vec2 orbit = vec2(0);\n    if (asleep(iMouse.xy)) {\n    \torbit = vec2(.05*iTimeDelta, 0);   // attract mode slow spin\n\t} else {\n    \tif (lmb && olmb) {\n\t        vec2 m = iMouse.xy - oMouse.xy;\n    \t    orbit += m * turnratemouse * shiftmod;\n    \t} \n    \t{\n    \t\tfloat aL = key(KEY_LEFT), aR = key(KEY_RIGHT), aU = key(KEY_UP), aD = key(KEY_DOWN);\n\t        vec2 m = vec2(aR - aL, aU - aD);\n    \t    orbit += m * iTimeDelta * turnratekbd * shiftmod;\n        }\n    }\n    if (dot(orbit,orbit) != 0.) {\n        desiredRot.xz = mrot(cossin(orbit.x)) * desiredRot.xz;\n        vec2 vr = vec2(1.,desiredRot.y);\n        vr = mrot(cossin(-orbit.y)) * vr;\n        desiredRot.xz *= max(1e-1f, vr.x); // do not flip signs here!\n        desiredRot.y = vr.y;\n  \t\tdesiredRot = normalize(desiredRot);\n    }\n    return desiredRot;\n}\n\n// smoothing filter\nvec3 cameraSmoothing()\n{\n    vec3 camfwd = cameraDirection(BufferC);\n    vec3 desiredFwd = desiredDirection();\n    camfwd = normalize(mix(desiredFwd, camfwd, exp2(-64.*iTimeDelta)));\n    return camfwd;\n}\n\n// implements a debugging fly camera using keyboard WASD + mouse + C/space\n// stores camera position,aim,etc. into c as a \n// color coded vector suitable for output to buffer\nvoid debugFlyCamera(out vec4 c, vec2 p)\n{    \n    ivec2 ip = ivec2(p);\n\t// ignore most pixels - otherwise using an entire buffer is really bad\n    if (!(ip.y == 0 && ip.x < slotCount)) discard;\n    c = loadValue(BufferC, ip.x); // passthru by default\n    bool shift = key(KEY_SHIFT) > .5;\n    bool init = iFrame == 0;\n    switch (slotid(ip)) {\n      case slotCameraPosition: {\n \t    c.xyz = init ? vec3(.0,8.5,-3.5) : cameraMovement(shift);            \n        break;\n      }\n      case slotCameraForward: {\n        c.xyz = init ? vec3(0.,0.,1.) : cameraSmoothing();\n        break;\n      }\n      case slotDesiredForward: {\n        c.xyz = init ? vec3(0.,0.,1.) : cameraSteering(shift);\n        break;\n      }\n      case slotMouseOld: {\n        c = iMouse;\n        break;\n      }\n      default:\n        break;\n    }\n}\n    // 4 inefficient pixels shouldn't be a huge deal\n\n// output to Buffer C\nvoid mainImage(out vec4 c, vec2 p)\n{\n    debugFlyCamera(c, p);\n}\n\n","name":"Buffer C","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"XslBRM","date":"1495362538","viewed":869,"name":"POM Experiment","username":"Hamneggs","description":"Okay guys, doing parallax occlusion mapping in a DF raymarcher is a lil' different from real life. The trick was using a volume rather than a surface.","likes":4,"published":1,"flags":0,"usePreview":0,"tags":["experiment","parallax","bump","bumpmapping","occlusion","mapping","pom"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XsfGzn","filepath":"/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","previewfilepath":"/media/ap/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","type":"cubemap","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4sf3Rr","filepath":"/media/a/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","previewfilepath":"/media/ap/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"#define EPSILON .01\t\t\t/* Marching arrival threshold */\n#define VOLHHEIGHT .0625      /* Volume half-height. */\n#define VOLHEIGHT .125        /* Volume half-height. */\n#define ITERSINV 0.0078125  /* 1 / (POM Iterations) */\n#define ITERS 256\t\t\t/* POM iterations. */\n\nconst vec2 POMSCALE = vec2(.4);\t// POM scale.\nconst vec3 VOLSIZE = vec3(3, VOLHHEIGHT, 3); // Size of the POM volume. \nconst vec3 VOLPOS = vec3(0,0,0); // Position of the POM volume.\nconst vec3 VOLNORM = vec3(0,1,0); // Normal of the POM volume floor.\nconst vec3 LIGHTDIR = vec3(0.315244, -0.945732, 0.078811); // Light dir.\n\n// TEKF's wonderful polar camera. (https://www.shadertoy.com/view/XdsGDB)\nvoid camPolar( out vec3 p, out vec3 d, in vec3 o, in vec2 r, \n               in float dist, in float zoom, in vec2 fragCoord )\n{\n\tvec2 c = cos(r);\n\tvec4 s;\n\ts.xy = sin(r);\n\ts.zw = -s.xy;\n\td.xy = fragCoord.xy - iResolution.xy*.5;\n\td.z = iResolution.y*zoom;\n\td = normalize(d);\n\td.yz = d.yz*c.x + d.zy*s.zx;\n\td.xz = d.xz*c.y + d.zx*s.yw;\n\tp = o - dist*vec3(c.x*s.y,s.z,c.x*c.y);\n}\n\n// IQ's signed box DF.\nfloat pomVol( vec3 p )\n{\n      p-= VOLPOS;\n      vec3 d = abs(p) - VOLSIZE;\n      return min(max(d.x,max(d.y,d.z)),0.0) + length(max(d,0.0));\n}\n// Multi-tap surface normal.\nvec3 norm( in vec3 p)\n{\n\treturn normalize(vec3(pomVol(vec3(p.x+EPSILON,p.y,p.z)),\n\t\t\t\t\t\t  pomVol(vec3(p.x,p.y+EPSILON,p.z)),\n\t\t\t\t\t\t  pomVol(vec3(p.x,p.y,p.z+EPSILON)))-pomVol(p));\n}\n\nfloat pomSample( in sampler2D t, in vec2 uv )\n{\n    float r = texture(t, uv*POMSCALE).r;\n    return r*r*VOLHEIGHT;\n}\n\n// Texture based normal.\nvec3 pomnorm( in sampler2D t, in vec2 uv )\n{\n    // The ol' cross product of two surface gradients technique.\n    vec2 d = vec2(EPSILON*.5, 0);\n    vec3 dx = vec3(EPSILON,\n                   pomSample(t,uv+d.xy)-pomSample(t,uv-d.xy),\n                   0);\n    vec3 dy = vec3(0,\n                   pomSample(t,uv+d.yx)-pomSample(t,uv-d.yx),\n                   EPSILON);\n    return normalize(cross(normalize(dy),normalize(dx)));\n}\n\n// Parallax occlusion mapping. -->RGB(hit)\nvec4 pom( in vec3 ro, in vec3 rd, out vec3 p, out vec3 n )\n{\n\t// Let's first transform ro to volume space. This way\n    // ro.y will be the height above the POM floor.\n    vec3 vro = ro-(VOLPOS+VOLHHEIGHT)*rd;\n    vec3 pro = ro, pvro = vro;\n    \n    // The distance along the view vector we need to travel in order to\n    // have moved VOLHEIGHT/ITERS vertically.\n    float t = (VOLHEIGHT*ITERSINV)/dot(rd,-VOLNORM);\n    t = min(t, VOLSIZE.x/512.*POMSCALE.x);\n    \n    // Now we can march the ray through the volume.\n    float s = 0.0;\n    for(int i = 0; i < ITERS; ++i)\n    {\n        // Make sure we're still in the current volume. Note\n        // that this check is in worldspace.\n        if(pomVol(ro)>EPSILON*2.0)\n        {\n            p = ro-rd*pomVol(ro);\n            n = vec3(0);\n            return vec4(0);\n        }\n        \n        // Get the current sample.\n        s = pomSample(iChannel1,vro.xz);\n        \n        // Check it.\n        if(vro.y < s) break;\n        \n        // Update the sample positions.\n        t = t;\n        vro += rd*t;\n        ro += rd*t;\n    }\n    \n    // If we reach the bottom, we return.\n    p = ro;\n    n = pomnorm(iChannel1, vro.xz);\n    return vec4(vec3(s,s,s)*vro.y,1);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Create the ol' vectors.\n    vec3 ro = vec3(0), rd = vec3(0);\n    \n    // Establish camera.\n    vec2 m;\n    if(length(iMouse.xy)<=.001) m = vec2(.5,.1);\n    else m = iMouse.yx/iResolution.yx;\n    m *= vec2(1.5,6.28); // Movement scaling.\n    camPolar(ro, rd, vec3(0.0, 0.0, 0.0), m, 6.0, 1.0, fragCoord);\n    \n    // March.\n    float t = 0.0; int hit = 0;\n    for(int i = 0; i < 64; ++i)\n    {\n        float d = pomVol(ro+rd*t);\n        if(d < .01) { hit = 1; break; }\n        t += d;\n    }\n    \n    // Check to see if we hit anything, because if we didn't we can\n    // shortcut to sky.\n    if(hit == 0) {fragColor = texture(iChannel0, rd); return;}\n    \n    // Calculate POM.\n    vec3 p, n;\n    vec4 col = pom(ro+rd*t,rd, p, n);\n    \n    // We might be able to shortcut out again.\n    if(col.a < .5) {fragColor = texture(iChannel0, rd); return;}\n    \n    // Tweak that output color. This value is essentially depth,\n    // and it gives a nice 'lil AO effect.\n    col += .125;\n    \n    // Do basic lighting outside of POM to demonstrate that normal we get.\n    col *= clamp(dot(-LIGHTDIR, n), 0.2, 1.0);\n    \n    // Gamma.\n    col = pow(col, vec4(1.0/2.2));\n\n    // Mix with sky where we don't have \n    fragColor = clamp(col, 0.0, 1.0);\n}","name":"Image","description":"","type":"image"}]}
{"ver":"0.1","info":{"id":"stSyWc","date":"1650314680","viewed":159,"name":"Raytracing 4 - MIS and LDS","username":"KylBlz","description":"\"Raytracing 3 - Surface Sampling\" took 5 PCG samples and smoothed over 16 frames, this one takes 2 R2 samples and smooths over just 8 frames. Now we are somewhat independent of scene complexity and we can pile on more estimators...","likes":6,"published":1,"flags":32,"usePreview":0,"tags":["ray","sampling","tracing","surface","lambertian","multiple","importance"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\n// Thanks Paniq\nvec3 linear_srgb(vec3 x) {\n    return mix(1.055*pow(x, vec3(1./2.4)) - 0.055, 12.92*x, step(x, vec3(0.0031308)));\n}\n\nvec3 srgb_linear(vec3 x) {\n    return mix(pow((x + 0.055)/1.055,vec3(2.4)), x / 12.92, step(x, vec3(0.04045)));\n}\n\n// Paniq's ACES fitted from https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl\nvec3 ACESFitted(vec3 color) {\n\t// ODT_SAT => XYZ => D60_2_D65 => sRGB\n    color = color * mat3(\n        0.59719, 0.35458, 0.04823,\n        0.07600, 0.90834, 0.01566,\n        0.02840, 0.13383, 0.83777\n    );\n    // Apply RRT and ODT\n    vec3 a = color * (color + 0.0245786) - 0.000090537;\n    vec3 b = color * (0.983729 * color + 0.4329510) + 0.238081;\n    color = a / b;\n\t// Back to color space\n    color = color * mat3(\n         1.60475, -0.53108, -0.07367,\n        -0.10208,  1.10813, -0.00605,\n        -0.00327, -0.07276,  1.07602\n    );\n    // Clamp to [0, 1]\n    return clamp(color, 0.0, 1.0);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    // get all variables from G and D buffers\n    int ho;\n    float asp, vv;\n    vec2 ro = INIT_ROT.xy, lo = INIT_ROT.xy;\n    vec3 rl = INIT_POS.xyz, rd, ll = INIT_POS.xyz, ld, hn, hl;\n    decodeAll(fragCoord, iResolution.xy, iFrame, iChannel0, iChannel1, asp, rl, ro, rd, ll, lo, ld, vv, hn, ho, hl);\n    mat3 surf = getSurface(ho, hl);\n    // sample D buffer\n    vec4 dBuffer = texelFetch(iChannel1, ivec2(fragCoord.xy), 0);\n    // apply first surface properties\n    dBuffer.rgb *= surf[0];\n    // tonemap\n    fragColor.rgb = linear_srgb(ACESFitted(10.0 * dBuffer.rgb / floor(dBuffer.a)));\n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"//////////////////////////////// Rendering Configuration ////////////////////////////////\n\n// always use biased sampling (fallback to unbiased ground truth)\n#define BIASED\n// raymarching steps\n#define STEPS 128\n// number of frames to reproject and smooth over time\n#define TEMPORALSMOOTHING 8\n\n// direct lit lambert surface\n#define SMP_DIRECT_LAMBERT 1\n// lambert surface lit lambert surface\n#define SMP_LAMBERT_SURFACE_LAMBERT 1\n\n// unbiased light samples\n#define SMP_UNBIAS 1\n// bias sample weight to reduce initial unbiased variance\n#define BIAS_WEIGHT 1\n\nconst float\teps = 0.001,     ieps = 0.999,   zfar = 50.0,       FOV = 2.0,\n            HPI = 1.5707963, PI = 3.1415926, TWOPI = 6.2831853, SQRT2 = 1.4142136, SC45 = 0.7071068;\nconst vec4 INIT_POS = vec4(4.8, 0.50, -9.5, 0.0),\n    \t   INIT_ROT = vec4(0.2, 0.85,  0.0, 0.0);\n\n//////////////////////////////// Random tools ////////////////////////////////\n\n// generate a unique value for each pixel/frame\nint genSeed(in int iFrame, in ivec2 fragCoord, in ivec2 iResolution) {\n    return (fragCoord.x + fragCoord.y*2 + iFrame*17) + (fragCoord.x*1811 ^ fragCoord.y*1019);\n}\n\nvec3 weyl3(in int v) {\n    return fract(vec3(v*ivec3(13743434, 11258243, 9222443)) / exp2(24.0));\n}\n\n// fudged a bit to cut it off close to the (0,1) interval\nvec3 logit3(in vec3 v) {\n    vec3 t = 0.988 * (v + 0.006);\n    return log(t / (1.0 - t)) * 0.221 + 0.5;\n}\n\nvoid basis(in vec3 n, out vec3 f, out vec3 r) {\n    float s = (n.z >= 0.0)? 1.0: -1.0;\n    float a = 1.0 / (s + n.z);\n    float b = -n.x*n.y*a;\n    f = vec3(1.0 - n.x*n.x*a*s, b*s, -n.x*s);\n    r = vec3(b, s - n.y*n.y*a, -n.y);\n}\n\nvec3 rotateXY(in vec3 p, in vec2 angle) {\n\tvec2 c = cos(angle), s = sin(angle);\n    vec3 o = p;\n\to.yz *= mat2(c.x, s.x, -s.x, c.x); \n    o.xz *= mat2(c.y, s.y, -s.y, c.y);\n\treturn o;\n}\n\n//////////////////////////////// Sampling tools ////////////////////////////////\n\n// linear angle of sphere at distance D with radius R\nfloat linearAngle(float d, float r) {\n    return asin(clamp(r/d, eps, ieps));\n}\n\n// solid angle of sphere given distance squared and radius squared\nfloat solidAngle(float d2, float r2) {\n    return (1.0 - sqrt(1.0 - clamp(r2/d2, 0.0, 1.0))) * TWOPI;\n}\n\nfloat Lambertian(in vec3 hn, in vec3 nlv) {\n    return max(eps, dot(nlv, hn));\n}\n\n// using gaussian distribution\nvec3 uniformSphere(in int seed) {\n    vec3 rnd = logit3(weyl3(seed));\n    return rnd * 2.0 - 1.0;\n}\n\n// using normalized gaussian distribution\nvec3 uniformDir(in int seed) {\n    return normalize(uniformSphere(seed));\n}\n\n// only one hemisphere\nvec3 uniformHemiDir(in vec3 hn, in int seed) {\n    vec3 rnd = uniformDir(seed);\n    return rnd * sign(dot(hn, rnd));\n}\n\n// cosine distribution (unbiased sampling)\nvec3 cosHemiDir(vec3 hn, int seed) {\n    vec3 rnd = uniformDir(seed);\n    return normalize(hn + rnd * ieps);\n}\n\n// uniform sample cone (biased sampling)\nvec3 uniformConeDir(vec3 lv, float lr, in int seed) {\n    vec3 rnd = weyl3(seed);\n    float sa = linearAngle(length(lv), lr);\n    float rad = sqrt(rnd.x) * tan(sa);\n    float tha = rnd.y * TWOPI;\n    vec3 r, u, nlv = normalize(lv);\n    basis(nlv, r, u);\n    return normalize(nlv + rad * (r * cos(tha) + u * sin(tha)));\n}\n\n//////////////////////////////// Scene Modeling ////////////////////////////////\n\nvec2 sdMin(in vec2 a, in vec2 b) {\n    if (a.x < b.x)\n        return a;\n    return b;\n}\n\nfloat sdBox(in vec3 p, in mat3 o, in vec3 s) {\n    vec3 d = abs(p * o) - s;\n    return min(max(d.x, max(d.y, d.z)), 0.0) + length(max(d, 0.0));\n}\n\nconst int\n    LIGHT = 1,\n    FLOOR = 2,\n    WALL1 = 3,\n    BOX = 4,\n    WALL2 = 6,\n    CEIL = 7;\n    \n// light parameters\nvec4 light = vec4(5.5, 5.0, -4.0, 1.0);\nvec3 lightColor = vec3(10.0, 9.0, 8.0);\n\n// scene geometry, returns distance X and object Y\nvec2 sdf(in vec3 l, in int o) {\n    vec2 d = vec2(zfar, 0.);\n    if (o != FLOOR) d = sdMin(d, vec2(l.y + 0.0, FLOOR));\n    if (o != CEIL)  d = sdMin(d, vec2(-l.y + 10.0, CEIL));\n    if (o != WALL1) d = sdMin(d, vec2(-l.x + 10.0, WALL1));\n    if (o != WALL2) d = sdMin(d, vec2(l.z + 10.0, WALL2));\n    if (o != LIGHT) d = sdMin(d, vec2(length(l - light.xyz) - light.w, LIGHT));\n    if (o != BOX)   d = sdMin(d, vec2(sdBox(l - vec3(7.5, 0.93, -7.5), mat3(1.0), vec3(0.8)) - 0.1, BOX));\n    return d;\n}\n\n// scene color, returns reflection [0], emission [1], and transmission [2] colors RGB\nmat3 getSurface(in int ho, in vec3 hl) {\n    mat3 ret;\n    if (ho == LIGHT) {\n        ret[0] = vec3(1.0); // reflection color\n        ret[1] = lightColor; // emission color\n        ret[2] = vec3(1.0); // diffuse (x) specular (y)\n    } else if (ho == BOX) {\n        ret[0] = vec3(0.025 + 0.1 * float(int(floor(hl.x * 4.0) + floor(hl.y * 4.0) + floor(hl.z * 4.0)) & 1)); // reflection color\n        ret[1] = vec3(0.0); // emission color\n        ret[2] = vec3(1.0); // diffuse (x) specular (y)\n    } else if (ho < 1) {\n        \n    } else {\n        float refl = float(int(ho == FLOOR || ho == CEIL)) * (0.5 + float(int(floor(hl.x) + floor(hl.y) + floor(hl.z)) & 1)) * 0.25 + 0.75;\n        float matCol = float(ho);\n        float cm = cos(matCol) * 0.025;\n        float sm = sin(matCol) * 0.025;\n        ret[0] = vec3(0.05 + cm, 0.05 + sm, 0.05 - (cm + sm) * 0.25) * refl;\n        ret[1] = vec3(0.0); // emission color\n        ret[2] = vec3(refl, refl * 0.5, 0.0); // diffuse (x) specular (y)\n    }\n    // loose the average energy for the material, 0.07 based on measurements from unbiased rendering\n    // Crank it up 10x ;)\n    ret[2] *= 0.7;\n    return ret;\n}\n\nvec3 norm(in vec3 p, in float ep) {\n    vec3 n = vec3(0.0);\n    for (int i = 0; i < 4; ++i) {\n        vec3 e = 0.5773*(2.0*vec3((((i+3)>>1)&1), ((i>>1)&1), (i&1))-1.0);\n        n += e * sdf(p + e*ep, -1).x;\n    }\n    return normalize(n);\n}\n\nvec2 march(in vec3 l, in vec3 rd, in int o) {\n    float t = 0.0;\n    vec2 sdSmp;\n    for (int i = 0; i < STEPS; ++i) {\n        sdSmp = sdf(l + rd * t, o);\n        t += sdSmp.x;\n        if (sdSmp.x < eps)\n            break;\n        if (t > zfar)\n            return vec2(zfar, 0.0);\n    }\n    return vec2(min(t, zfar), sdSmp.y);\n}\n\n//////////////////////////////// Buffers ////////////////////////////////\n\n// diffuse light buffer\nfloat encodeDbuffer(in int o) {\n    return float(o) * 0.1;\n}\n\nint decodeDbuffer(in float a) {\n    return int(fract(a) * 10.1);\n}\n\n// geometry buffer\nvoid encodeGbuffer(out vec4 val, in vec3 n, in int o, in float t) {\n    val = vec4(n * float(o), t);\n}\n\nvoid decodeGbuffer(in vec4 val, out vec3 n, out int o, out float t) {\n    t = val.w;\n    o = int(length(val.xyz)+eps);\n    n = val.xyz / float(o);\n}\n\n// last loc, last orient, hit loc, hit object, 1/aspect, channel, resolution\nvec4 reprojectDbuffer(in vec3 ll, in vec2 lo, in vec3 hl, in int ho, in float asp, sampler2D iChannel, in vec2 iChanRes) {\n    // last camera basis\n    vec3 lf = rotateXY(vec3(0.0, 0.0, 1.0), lo);\n    vec3 r = normalize(cross(lf, vec3(0.0, 1.0, 0.0)));\n    vec3 u = normalize(cross(lf, r));\n    // dir to point\n    vec3 nhl = normalize(ll - hl);\n    // project into last cam basis\n    vec2 luv = vec2(dot(nhl, r), dot(nhl, u));\n    // project onto imaging plane NDC coords\n    luv = (luv * FOV) / (dot(nhl, lf) * vec2(asp, 1.0));\n    // ndc to image pixel coords (minus half pixel, glsl uses 'pixel centers')\n    vec2 fuv = (luv * -0.5 + 0.5) * iChanRes - 0.5;\n    ivec2 iuv = ivec2(fuv);\n    // bounds check\n    if (any(greaterThan(iuv, ivec2(iChanRes)-1)) || any(lessThan(iuv, ivec2(0))))\n        return vec4(0.0);\n    vec2 a = clamp(fuv - vec2(iuv), vec2(0.0), vec2(1.0));\n    // samples with matching materials are considered\n    vec4 col   = texelFetch(iChannel, iuv, 0);\n    vec4 colx  = texelFetch(iChannel, iuv + ivec2(1, 0), 0);\n    vec4 coly  = texelFetch(iChannel, iuv + ivec2(0, 1), 0);\n    vec4 colxy = texelFetch(iChannel, iuv + ivec2(1, 1), 0);\n    float c1 = float(int(decodeDbuffer(col.a) == ho));\n    float c2 = float(int(decodeDbuffer(colx.a) == ho));\n    float c3 = float(int(decodeDbuffer(coly.a) == ho));\n    float c4 = float(int(decodeDbuffer(colxy.a) == ho));\n    // get number of samples that matched\n    float n = c1 + c2 + c3 + c4;\n    // fanciest mixing\n    if (n > 3.0)\n        return mix(mix(col/col.a, colx/colx.a, a.x), mix(coly/coly.a, colxy/colxy.a, a.x), a.y) * min(col.a, min(colx.a, min(coly.a, colxy.a)));\n    if (n < 1.0)\n        return vec4(0.0);\n    // fallback mixing\n    return (c1*col + c2*colx + c3*coly + c4*colxy);\n}\n\n// just a big 'ol helper function that gets all the values\nvoid decodeAll(in vec2 fragCoord, in vec2 iResolution, in int iFrame, in sampler2D gBuffer, in sampler2D lastFrame, out float asp, out vec3 rl, out vec2 ro, out vec3 rd, out vec3 ll, out vec2 lo, out vec3 ld, out float vv, out vec3 hn, out int ho, out vec3 hl) {\n    asp = iResolution.x / iResolution.y;\n    vec2 ndca = (2.0 * fragCoord.xy / iResolution.xy - 1.0) * vec2(asp, 1.0);\n    // get current cam\n    if (iFrame > 1) {\n        rl = texelFetch(gBuffer, ivec2(0, int(iResolution.y) - 1), 0).xyz;\n        ro = texelFetch(gBuffer, ivec2(1, int(iResolution.y) - 1), 0).xy;\n        ll = texelFetch(lastFrame, ivec2(0, int(iResolution.y) - 1), 0).xyz;\n        lo = texelFetch(lastFrame, ivec2(1, int(iResolution.y) - 1), 0).xy;\n    }\n    rd = rotateXY(normalize(vec3(ndca, FOV)), ro);\n    ld = rotateXY(normalize(vec3(ndca, FOV)), lo);\n\tvv = length(rl - ll);\n    // get last trace\n    float ht;\n    decodeGbuffer(texelFetch(gBuffer, ivec2(fragCoord.xy), 0), hn, ho, ht);\n    hl = rl + rd * ht;\n}\n","name":"Common","description":"","type":"common"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//////////////////////////////// Rendering Configuration ////////////////////////////////\n\nmat3 cameraPoses(in float t) {\n    float time = mod(t, 6.0);\n    if (time < 2.)\n        return mat3(vec3(4.8, 0.5, -9.5), vec3(0.2, 0.85, 0.), vec3(0.0));\n    else if (time < 4.)\n        return mat3(vec3(4.8, 0.5, -4.8), vec3(0.15, 2.33, 0.), vec3(0.0));\n    else if (time < 6.)\n        return mat3(vec3(-3.5, 2.5, -4.0), vec3(0.1, 1.8, 0.), vec3(0.0));\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n\n\tvec3 l = INIT_POS.xyz,\n         o = INIT_ROT.xyz;\n    // move the camera\n    if (iFrame > 1) {\n        // just smoothstep between some nice angles\n        float t = iTime * 0.5;\n        mat3 cLast = cameraPoses(t);\n        mat3 cNext = cameraPoses(t + 1.0);\n        float ft = fract(t);\n        ft = ft*ft*(3.0-2.0*ft);\n        l = mix(cLast[0], cNext[0], ft);\n        o = mix(cLast[1], cNext[1], ft);\n    }\n\n    float asp = iResolution.x / iResolution.y;\n    vec2 ndca = (2.0 * fragCoord.xy / iResolution.xy - 1.0) * vec2(asp, 1.0);\n    vec3 d = rotateXY(normalize(vec3(ndca, FOV)), o.xy);\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(l, 0.0);\n            return;\n        } else if (x == 1) {\n            fragColor = vec4(o, 0.0);\n            return;\n        }\n    }\n    \n    // initial scene march\n    vec2 h = march(l, d, -1);\n    // encode normal, object ID, and depth\n    fragColor = vec4(0.0);\n    // normal, object, distance\n    encodeGbuffer(fragColor, norm(l + d * h.x, eps), int(h.y), h.x);\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"\n//////////////////////////////// PDF only ////////////////////////////////\n\n// lambertian surface illuminated by a sphere light, returns sample direction XYZ, pdf W\nvec4 SphereLightPDF(in vec3 hl, in vec3 hn, in vec4 li, in int seed) {\n    vec3 lv = li.xyz - hl;\n    vec3 lambDir = uniformConeDir(lv, li.w, seed);\n    float lpdf = solidAngle(dot(lv, lv), li.w*li.w);\n    return vec4(lambDir, lpdf);\n}\n\n// lambertian surface illuminated by a lambertian surface, returns sample direction XYZ, pdf W\nvec4 LambertianPlanePDF(in vec3 hl, in vec3 hn, in vec4 li, in vec3 pl, in vec3 pn, in int seed) {\n    // dot project light onto plane\n    vec3 d = li.xyz - pn * dot(li.xyz - pl, pn);\n    // surface to diffuse point d\n    vec3 dv = d - hl;\n    // diffuse point to light\n    vec3 ld = li.xyz - d;\n    // cosine sample disc on ground below\n    float frad = min(length(dv), length(ld)) * 0.9;\n    vec3 lambDir = uniformConeDir(dv, frad, seed);\n    // PDF book keeping\n    float lpdf = solidAngle(dot(dv,dv), frad*frad) / PI;\n    float g2pdf = Lambertian(pn, -lambDir);\n    return vec4(lambDir, lpdf * g2pdf);\n}\n\n//////////////////////////////// sampling only ////////////////////////////////\n\n// marches the light, returns contribution RGB\nvec3 LightContribution(in vec3 hl, in int ho, in vec4 lvpdf) {\n    vec2 lm = march(hl, lvpdf.xyz, ho);\n    if (int(lm.y) == LIGHT)\n        return lightColor * lvpdf.w;\n    return vec3(0.0);\n}\n\n// marches the surface and light, returns contribution RGB\nvec3 LambertianPlaneContribution(in vec4 lvpdf, in vec3 hl, in int ho, in vec3 pl, in vec3 pn, in int po, in vec4 li, in int seed) {\n    // diffuse plane sample\n    vec2 dres = march(hl, lvpdf.xyz, ho);\n    if (int(dres.y) != po)\n        return vec3(0.0);\n    // move off the surface a little bit\n    vec3 _hl = hl + lvpdf.xyz * dres.x; // + pn * eps;\n    vec3 _lv = li.xyz - _hl;\n    float _lv2 = dot(_lv, _lv);\n    // light sampling\n    vec3 sampleDir = uniformConeDir(_lv, li.w, seed);\n    vec3 lc = LightContribution(_hl, po, vec4(sampleDir, lvpdf.w));\n    mat3 surf = getSurface(int(dres.y), _hl);\n    // surface emission, energy, color, light energy\n    return surf[1] + surf[2].x * surf[0] * lc;\n}\n\n//////////////////////////////// Sampling Strategy ////////////////////////////////\n\n// diffuse MIS\nvec3 DMIS(in vec3 hl, in vec3 hn, in int ho, in int seed) {\n    vec3 ret = vec3(0.0);\n\n#if SMP_DIRECT_LAMBERT\n    // take direct light sample(s), but there is only 1 light so all the MIS is commented out ;)\n    vec3 smpDirect = vec3(0.0);\n\n    for (int i = 0; i < SMP_DIRECT_LAMBERT; ++i) {\n        int si = seed + i;\n        // get all PDFs\n        vec4 dlpdf = SphereLightPDF(hl, hn, light, si);\n        // apply lambert pdf so we can use this estimator later for Phong as well\n        dlpdf.w *= Lambertian(hn, dlpdf.xyz);\n        // compute CDF\n        //float lightCDF = dlpdf.w;\n        // roulette sampling\n        //vec3 rnd = weyl3(si.z) * lightCDF;\n        //if (rnd.z <= lightCDF) {\n            smpDirect += LightContribution(hl, ho, dlpdf); // * (lightCDF / max(eps, dlpdf.w));\n        //}\n    }\n    ret += smpDirect / float(SMP_DIRECT_LAMBERT);\n#endif\n\n#if SMP_LAMBERT_SURFACE_LAMBERT\n    // take indirect diffuse samples\n    vec3 smpIDD = vec3(0.0);\n    for (int i = 0; i < SMP_LAMBERT_SURFACE_LAMBERT; ++i) {\n        int si = seed + i;\n        // get all PDFs\n        vec4 fdpdf = LambertianPlanePDF(hl, hn, light, vec3(0.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0), si);\n        vec4 cdpdf = LambertianPlanePDF(hl, hn, light, vec3(0.0, 10.0, 0.0), vec3(0.0, -1.0, 0.0), si);\n        vec4 w1dpdf = LambertianPlanePDF(hl, hn, light, vec3(10.0, 0.0, 0.0), vec3(-1.0, 0.0, 0.0), si);\n        vec4 w2dpdf = LambertianPlanePDF(hl, hn, light, vec3(0.0, 0.0, -10.0), vec3(0.0, 0.0, 1.0), si);\n        // apply lambert pdf\n        fdpdf.w *= Lambertian(hn, fdpdf.xyz);\n        cdpdf.w *= Lambertian(hn, cdpdf.xyz);\n        w1dpdf.w *= Lambertian(hn, w1dpdf.xyz);\n        w2dpdf.w *= Lambertian(hn, w2dpdf.xyz);\n        // compute CDF\n        float floorDiffCDF = fdpdf.w;\n        float ceilDiffCDF = floorDiffCDF + cdpdf.w;\n        float w1DiffCDF = ceilDiffCDF + w1dpdf.w;\n        float w2DiffCDF = w1DiffCDF + w2dpdf.w;\n        // roulette sampling\n        vec3 rnd = weyl3(si) * w2DiffCDF;\n        if (rnd.z <= floorDiffCDF)\n            smpIDD += LambertianPlaneContribution(fdpdf, hl, ho, vec3(0.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0), FLOOR, light, si) * (w2DiffCDF / max(eps, fdpdf.w));\n        else if (rnd.z <= ceilDiffCDF)\n            smpIDD += LambertianPlaneContribution(cdpdf, hl, ho, vec3(0.0, 10.0, 0.0), vec3(0.0, -1.0, 0.0), CEIL, light, si) * (w2DiffCDF / max(eps, cdpdf.w));\n        else if (rnd.z <= w1DiffCDF)\n            smpIDD += LambertianPlaneContribution(w1dpdf, hl, ho, vec3(10.0, 0.0, 0.0), vec3(-1.0, 0.0, 0.0), WALL1, light, si) * (w2DiffCDF / max(eps, w1dpdf.w));\n        else\n            smpIDD += LambertianPlaneContribution(w2dpdf, hl, ho, vec3(0.0, 0.0, -10.0), vec3(0.0, 0.0, 1.0), WALL2, light, si) * (w2DiffCDF / max(eps, w2dpdf.w));\n    }\n    ret += smpIDD / float(SMP_LAMBERT_SURFACE_LAMBERT);\n#endif\n\n    return ret;\n}\n\n// do unbiased sampling (diffuse BRDF)\nvec3 Unbiased(in vec3 hl, in vec3 hn, in int ho, in int seed) {\n    // unbiased sampling (GT)\n    vec3 smpUnbias = vec3(0.0);\n    for (int i = 0; i < SMP_UNBIAS; ++i) {\n        int si = seed + i;\n        // sample light\n        smpUnbias += LightContribution(hl, ho, vec4(cosHemiDir(hn, si), PI));\n    }\n    return smpUnbias /= float(SMP_UNBIAS);\n}\n\n//////////////////////////////// Main Image ////////////////////////////////\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n\n    bool biased = false;\n    int ho;\n    float asp, vv;\n    vec2 ro = INIT_ROT.xy, lo = INIT_ROT.xy;\n    vec3 rl = INIT_POS.xyz, rd, ll = INIT_POS.xyz, ld, hn, hl;\n    decodeAll(fragCoord.xy, iResolution.xy, iFrame, iChannel0, iChannel1, asp, rl, ro, rd, ll, lo, ld, vv, hn, ho, hl);\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(rl, 0.0);\n            return;\n        } else if (x == 1) {\n            fragColor = vec4(ro, 0.0, 0.0);\n            return;\n        }\n    }\n    \n    // reproject last frame onto this one\n    fragColor = reprojectDbuffer(ll, lo, hl, ho, asp, iChannel1, iResolution.xy);\n    fragColor.a = floor(fragColor.a);\n    if (fragColor.a < eps) {\n        // if sample failed, start with biased sampling to minimize variance\n        biased = true;\n    }\n\n#ifdef BIASED\n    // force biased rendering\n    biased = true;\n#endif\n    \n    // accumulate a maximum of TEMPORALSMOOTHING frames\n    if (fragColor.a > float(TEMPORALSMOOTHING)) {\n        fragColor *= float(TEMPORALSMOOTHING) / fragColor.a;\n    }\n\n    mat3 surf = getSurface(ho, hl);\n    // surface color\n    vec3 rc = vec3(1.0); // do later\n    // surface emissive\n    fragColor.rgb += rc * surf[1];\n\n    // ignore light\n    if (ho != LIGHT) {\n        int seed = genSeed(iFrame, ivec2(fragCoord.xy), ivec2(iResolution.xy));\n        if (biased) {\n            // direct sample lights\n            fragColor.rgb += rc * DMIS(hl, hn, ho, seed);\n        } else {\n            // unbiased sampling (GT)\n            fragColor.rgb += rc * Unbiased(hl, hn, ho, seed);\n        }\n    }\n    fragColor.a += 1.0 + encodeDbuffer(ho);\n}\n","name":"Buffer B","description":"","type":"buffer"}]}
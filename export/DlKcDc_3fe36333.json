{"ver":"0.1","info":{"id":"DlKcDc","date":"1700746526","viewed":75,"name":"Anisotropic Kuwahara filter v2","username":"Althar","description":"My 2nd attempt at implementing the anisotropic kuwahara filter based on the original paper which can be found here : https://www.kyprianidis.com/p/pg2009/jkyprian-pg2009.pdf\n","likes":2,"published":1,"flags":32,"usePreview":0,"tags":["filter","kuwahara"],"hasliked":0,"parentid":"DtKczW","parentname":"Anisotropic Kuwahara filter"},"renderpass":[{"inputs":[{"id":"4dfGRn","filepath":"/media/a/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","previewfilepath":"/media/ap/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Applies the Anisotropic Kuwahara filter to the source image\n// This implementation is based on my own interpretation of the formulas described in : https://www.kyprianidis.com/p/pg2009/jkyprian-pg2009.pdf\n\nvec4 compute_kuwahara_filter(sampler2D sampler, sampler2D lut, sampler2D eigen_vector, vec2 uv, vec2 rcpSize)\n{\n    // Scale for sampling the LUT\n    vec2 lutScaler = float(FILTER_LUT_SIZE) / iResolution.xy;\n    \n    // Sample the eigen vector. local rotation and anisotropy\n    vec4 t = texture(eigen_vector, uv);\n    \n    // Compute ellipse transform\n    mat2 S  = mat2(FILTER_ALPHA / (FILTER_ALPHA + t.w), 0.0, 0.0, (FILTER_ALPHA + t.w) / FILTER_ALPHA);\n    mat2 R  = mat2(cos(t.z), -sin(t.z), sin(t.z), cos(t.z));\n    mat2 SR = S * R;\n\t\n\t// Local average (m) and standard deviation (s)\n\tvec4 m[FILTER_NOOF_SECTORS];\n\tvec3 s[FILTER_NOOF_SECTORS];\n\t\n\t// Initialise local average and standard deviation\n\tfor (int i = 0 ; i < FILTER_NOOF_SECTORS ; ++i)\n\t{\n\t\tm[i] = vec4(0.0);\n\t\ts[i] = vec3(0.0);\n\t}\t\n\t\n\t// Compute average and standard deviation\n\tfor (int x = -FILTER_KERNEL_RADIUS ; x <= FILTER_KERNEL_RADIUS ; ++x)\n\t{\n\t\tfor (int y = -FILTER_KERNEL_RADIUS ; y <= FILTER_KERNEL_RADIUS ; ++y)\n\t\t{\n            // Compute local offset\n            vec2 offset = vec2(float(x), float(y));\n            \n            // Transform into ellipse space\n            vec2 sr_offset = SR * (offset / float(FILTER_KERNEL_RADIUS));\n            \n            // Only sample points inside the ellipse (radius of '0.5' in uv space)\n            if (dot(offset / float(FILTER_KERNEL_RADIUS), offset / float(FILTER_KERNEL_RADIUS)) <= 0.25)\n            {\n                // Sample colours\n                vec3 colour0 = texture(sampler, uv + offset * rcpSize).xyz;\n                vec3 colour1 = texture(sampler, uv - offset * rcpSize).xyz;\n                \n                // Square for the standard deviation\n                vec3 colour0_sqr = colour0 * colour0;\n                vec3 colour1_sqr = colour1 * colour1;\n\n                // Integrate average and standard deviation\n                vec4 w0123 = texture(lut, fract((vec2(0.5) + sr_offset) * lutScaler));\n                vec4 w4567 = texture(lut, fract((vec2(0.5) - sr_offset) * lutScaler));\n                for (int k = 0; k < 4; ++k) \n                {\n                    m[k]   += vec4(colour0 * w0123[k], w0123[k]);\n                    s[k]   += colour0_sqr * w0123[k];\n                    \n                    m[k]   += vec4(colour1 * w4567[k], w4567[k]);\n                    s[k]   += colour1_sqr * w4567[k];\n                    \n                    m[k+4] += vec4(colour1 * w0123[k-4], w0123[k-4]);\n                    s[k+4] += colour1_sqr * w0123[k-4];\n                    \n                    m[k+4] += vec4(colour0 * w4567[k-4], w4567[k-4]);\n                    s[k+4] += colour0_sqr * w4567[k-4];\n                }\n            }\n\t\t}\n\t}\n\t\n\t// Compute filter output\n\tvec4 result = vec4(0.0);\n\tfor (int i = 0 ; i < FILTER_NOOF_SECTORS ; ++i)\n\t{\n        m[i].xyz         /= m[i].w;\n        s[i]              = abs(s[i] / m[i].w - m[i].xyz * m[i].xyz);\n        \n        float si_sqr      = sqrt(dot(s[i], s[i]));\n\t\tfloat alphaI      = 1.0 / (1.0 + pow(255.0 * si_sqr, FILTER_SHARPNESS));\n\t\t\n\t\tresult.xyz       += alphaI * m[i].xyz;\n\t\tresult.w         += alphaI;\n\t}\n    \n    return vec4(result.xyz / result.w, 1.0);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{ \n    // Inverse size - here we scale based on the input resolution for consistent results when full-screening\n    ivec2 size   = textureSize(iChannel0, 0);\n    vec2 rcpSize = 1.0 / vec2(size);\n    \n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord / iResolution.xy;\n    \n    // Either display the contents of the weighing function LUT or the filtered image (default)\n    if (SHOW_LUT)\n    {\n        fragColor = texture(iChannel1, uv).xyzw;\n    }\n\n    else if (SHOW_TENSOR || SHOW_EIGEN)\n    {\n        fragColor = texture(iChannel2, uv).xyzw;\n    }\n    else \n    {\n        float cursor_x          = iMouse.z > 0.0 ? (iMouse.x / iResolution.x) : (cos(iTime * 0.5) * 0.5 + 0.5);\n        float blend_factor      = step(uv.x, cursor_x);\n        float line_blend_factor = step(1.0 / iResolution.x, abs(cursor_x - uv.x));\n        \n        vec3 unfiltered         = texture(iChannel0, uv).xyz;\n        vec3 filtered           = compute_kuwahara_filter(iChannel0, iChannel1, iChannel2, uv, rcpSize).xyz;\n        \n        vec3 blended            = mix(unfiltered, filtered, blend_factor);\n        vec3 final              = mix(vec3(0.0), blended, line_blend_factor);\n        \n        fragColor               = vec4(final, 1.0);\n    }\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Computes the weighing function - intended to be precomputed ONCE and subsequently sampled\n\nfloat compute_chi(vec2 sr, int i, int N)\n{\n    float minChi = ((2.0 * float(i) - 1.0) * PI) / float(N);\n    float maxChi = ((2.0 * float(i) + 1.0) * PI) / float(N);\n    float chi    = (sr.x > minChi && sr.x <= maxChi && sr.y <= 1.0) ? 1.0 : 0.0;\n    \n    return chi;\n}\n\n// Compute gaussian weighinhg function as a function of the polar coordinates, quadrant index and count\nfloat compute_gaussian_weighing_function(vec2 uv, int i, int N, vec2 rcpSize)\n{\n    // #TODO : Figure out where sigma r 'comes from'. The paper mentions them but never how they are derived\n    float sigma_r = 0.25 * float(FILTER_LUT_SIZE - 1);\n    float sigma_s = sigma_r * 0.5;\n    \n    // Radial decay\n    vec2 sr          = compute_polar_coordinates(uv * 2.0 - 1.0);  \n    float gaussian_r = gaussian(sigma_r, sr.y * float(FILTER_LUT_KERNEL_RADIUS));\n    \n    // Chi gaussian \n    vec3 gaussian_s = vec3(0.0);\n\tfor (int x = -FILTER_LUT_KERNEL_RADIUS ; x <= FILTER_LUT_KERNEL_RADIUS ; ++x)\n\t{\n\t\tfor (int y = -FILTER_LUT_KERNEL_RADIUS ; y <= FILTER_LUT_KERNEL_RADIUS ; ++y)\n\t\t{\n            vec2 offset    = vec2(float(x), float(y));\n            \n            float gaussian = gaussian(sigma_s, offset.x) * gaussian(sigma_s, offset.y);\n            \n            vec2 pos       = (uv + offset * rcpSize) * 2.0 - 1.0;\n            vec2 sr_offset = compute_polar_coordinates(pos);  \n            \n            float chi      = compute_chi(sr_offset, i, N);\n            \n            gaussian_s.x  += gaussian * chi;\n            gaussian_s.y  += gaussian;\n            gaussian_s.z   = max(gaussian_s.z, gaussian * chi);\n\t\t}\n\t}\n    \n    // Normalisation factor, typically based off the maximum value in the LUT - just approximate it here\n    float normalisation_factor = 1.0 / (1.0 * pow(gaussian(sigma_s, float(FILTER_LUT_KERNEL_RADIUS) * 0.25), 2.0));\n\n    // Combine & normalise : Ki = (Xi * GSs) . GSr\n\treturn (gaussian_s.x / gaussian_s.y) * gaussian_r * normalisation_factor;\n}\n\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord / vec2(FILTER_LUT_SIZE);\n    \n    // Kernel nornalisation\n    vec2 rcpSize = 1.0 / vec2(FILTER_LUT_SIZE);\n    \n    // Only want to compute the LUT in a small section (defined by FILTER_LUT_KERNEL_RADIUS)\n    if (abs(uv.x) <= 1.0 && abs(uv.y) <= 1.0)\n    {\n        // Compute weighing functions\n        float K0 = compute_gaussian_weighing_function(uv, 0, FILTER_NOOF_SECTORS, rcpSize);\n        float K1 = compute_gaussian_weighing_function(uv, 1, FILTER_NOOF_SECTORS, rcpSize);\n        float K2 = compute_gaussian_weighing_function(uv, 2, FILTER_NOOF_SECTORS, rcpSize);\n        float K3 = compute_gaussian_weighing_function(uv, 3, FILTER_NOOF_SECTORS, rcpSize);\n        \n\n        // Only need to write out 4 sectors as there is radial symmetry\n        fragColor = vec4(K0, K1, K2, K3);\n    }\n    else\n    {\n        fragColor = vec4(0.0, 0.0, 0.0, 0.0);\n    }\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"// General constants\nconst float PI                      = 3.141592653589793238462643383279502884197;\nconst float EPSILON                 = 0.0000001;\n\n// Kuwahara constants\nconst int FILTER_NOOF_SECTORS      \t= 8;     // Number of sectors, typically '8'\nconst float FILTER_ALPHA \t\t\t= 1.0;   // Alpha of '1.0' resulting in a maximum possible exentricity of '4.0'\nconst float FILTER_STD_DEVIATION   \t= 2.0;   // Standard deviation for the Gaussian filter of '2.0'\nconst int FILTER_KERNEL_RADIUS      = 8;     // Radius of the kernel chosen to fit the chosen standard deviation with suitable quality\nconst float FILTER_SHARPNESS \t\t= 8.0;   // Sharpness of the filter\n\n// LUT generation\nconst int FILTER_LUT_KERNEL_RADIUS  = 16;    // Radius of the kernel for the LUT (typically half the size of the LUT)\nconst int FILTER_LUT_SIZE           = 32;    // Size of the LUT\n\n// Debug constants\nconst bool SHOW_LUT                 = false;\nconst bool SHOW_TENSOR              = false;\nconst bool SHOW_EIGEN               = false;\n\n// Gaussian function\nfloat gaussian(float sigma, float x)\n{\n    return exp(-(x * x) / (2.0 * sigma * sigma));\n}\n\n// Computes polar coordinates (angle, radius) from a position centered around the origin\nvec2 compute_polar_coordinates(vec2 pos)\n{\n    float s = atan(pos.y, pos.x);\n    float r = sqrt(max(dot(pos, pos), EPSILON));\n    \n    return vec2(s, r);\n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dfGRn","filepath":"/media/a/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","previewfilepath":"/media/ap/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// Computes the structure tensor & the first (horizontal) gaussian blur\n\n// Computes a structure tensor \nvec3 compute_structure_tensor(sampler2D sampler, vec2 uv, vec2 rcpSize)\n{\n\t// Use the Sobel operators\n    vec3 fx = (\n           -1.0 * texture(sampler, uv + vec2(-rcpSize.x, \t-rcpSize.y)).xyz +\n           -2.0 * texture(sampler, uv + vec2(-rcpSize.x,  \t 0.0)).xyz + \n           -1.0 * texture(sampler, uv + vec2(-rcpSize.x,  \t rcpSize.y)).xyz +\n           +1.0 * texture(sampler, uv + vec2( rcpSize.x, \t-rcpSize.y)).xyz +\n           +2.0 * texture(sampler, uv + vec2( rcpSize.x,  \t 0.0)).xyz + \n           +1.0 * texture(sampler, uv + vec2( rcpSize.x,  \t rcpSize.y)).xyz\n           ) / 4.0;\n\n    vec3 fy = (\n           -1.0 * texture(sampler, uv + vec2(-rcpSize.x,\t-rcpSize.y)).xyz + \n           -2.0 * texture(sampler, uv + vec2( 0.0, \t\t\t-rcpSize.y)).xyz + \n           -1.0 * texture(sampler, uv + vec2( rcpSize.x, \t-rcpSize.y)).xyz +\n           +1.0 * texture(sampler, uv + vec2(-rcpSize.x,  \t rcpSize.y)).xyz +\n           +2.0 * texture(sampler, uv + vec2( 0.0,  \t\t rcpSize.y)).xyz + \n           +1.0 * texture(sampler, uv + vec2( rcpSize.x, \t rcpSize.y)).xyz\n           ) / 4.0;\n   \n\t// Return structure tensor in the form (E, F, G)\n\treturn vec3(dot(fx, fx), dot(fx, fy), dot(fy, fy));\n} \n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Inverse size - here we scale based on the input resolution for consistent results when full-screening\n    ivec2 size   = textureSize(iChannel0, 0);\n    vec2 rcpSize = 1.0 / vec2(size);\n    \n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord / iResolution.xy;\n    \n    vec4 total_sample = vec4(0.0);\n\tfor (int x = -FILTER_KERNEL_RADIUS ; x <= FILTER_KERNEL_RADIUS ; ++x)\n\t{\n        // #TODO : Results are noticeably smoother when halving the radius\n        vec2 offset        = 0.5 * vec2(float(x), 0.0);\n\n        float gaussian     = gaussian(FILTER_STD_DEVIATION, offset.x);\n\n        total_sample.xyz  += gaussian * compute_structure_tensor(iChannel0, uv + offset * rcpSize, rcpSize);\n        total_sample.w    += gaussian;\n\t}\n\t\n    // Write out horizontally blurred structure tensor\n\tfragColor = vec4(total_sample.xyz / total_sample.w, 1.0);\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// Computes the second (vertical) gaussian blur of the structure tensor\n\nvec4 compute_eigen_vector(in vec3 g)\n{\n\t// Compute eigen values\n\tfloat lambda1 = 0.5 * (g.x + g.z + sqrt(max(pow(g.x - g.z, 2.0) + 4.0 * pow(g.y, 2.0), EPSILON)));\n\tfloat lambda2 = 0.5 * (g.x + g.z - sqrt(max(pow(g.x - g.z, 2.0) + 4.0 * pow(g.y, 2.0), EPSILON)));\n    \n\t// Compute eigenvector\n\tvec2 t = vec2(lambda1 - g.x, -g.y);\n    \n    // Normalisation - entirely optional but useful for visualisation purposes\n    t = length(t) > 0.0 ? normalize(t) : vec2(0.0f, 1.0f); \n    \n\t// Compute location orientation\n\tfloat phi = atan(t.y, t.x);\n\t\n\t// Compute anisotropy\n    float A = clamp((lambda1 - lambda2) / max(lambda1 + lambda2, EPSILON), 0.0, 1.0);\n    \n\t// Return eigenvector, local orientation anc anisotropy\n\treturn vec4(t, phi, A);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Inverse size - here we scale based on the input resolution for consistent results when full-screening\n    ivec2 size   = textureSize(iChannel0, 0);\n    vec2 rcpSize = 1.0 / vec2(size);\n    \n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord / iResolution.xy;\n    \n    vec4 total_sample = vec4(0.0);\n    for (int y = -FILTER_KERNEL_RADIUS ; y <= FILTER_KERNEL_RADIUS ; ++y)\n    {\n        // #TODO : Results are noticeably smoother when halving the radius\n        vec2 offset        = 0.5 * vec2(0.0, float(y));\n\n        float gaussian     = gaussian(FILTER_STD_DEVIATION, offset.y);\n\n        total_sample.xyz  += gaussian * texture(iChannel0, uv + offset * rcpSize).xyz;\n        total_sample.w    += gaussian;\n    }\n\t\n\t\n    // Final structure tensor in the form (E, F, G)\n\tvec3 g = total_sample.xyz / total_sample.w;\n    \n    // Compute eigen values (or return the tensor for debugging purposes)\n    if (SHOW_TENSOR)\n    {\n        fragColor = vec4(g, 1.0);\n    }\n    else\n    {\n        fragColor = compute_eigen_vector(g);\n    }\n}","name":"Buffer C","description":"","type":"buffer"}]}
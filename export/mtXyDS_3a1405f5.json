{"ver":"0.1","info":{"id":"mtXyDS","date":"1691097932","viewed":64,"name":"1. Raytracer (transformations)","username":"Envy24","description":"Shows how to apply transformations to rays, normals and points.","likes":2,"published":1,"flags":0,"usePreview":0,"tags":["raytracing","ray","sphere","intersection","approximation","normal","base"],"hasliked":0,"parentid":"ctXcDB","parentname":"0. Raytracer (base)"},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/* https://www.shadertoy.com/view/DdsGDj */\n#define MOUSE_OFFSET ( iMouse.z > 0. ? iMouse.xy - iResolution.xy * 0.5 : vec2(0) )\nvec2 map_to_centered_ndc(in vec2 SC, in float scale, in vec2 origin, in bool mouse_drag)\n{\n    vec2 M = MOUSE_OFFSET * (mouse_drag == true ? 1. : 0.);\n    return ((2. * (SC - M) - iResolution.xy) / iResolution.y) * scale + origin;\n}\n\nvec3 get_background() { return vec3(.1, .4, .6); }\n\n#define NUM_OF_OBJECTS ( 2 )\nmat4 FWDs[NUM_OF_OBJECTS]; // per object forward transformations.\nmat4 BWDs[NUM_OF_OBJECTS]; // per object backward transformations.\n\nvoid init_transformations()\n{    \n    float s = (1.+sin(iTime)) * 0.5, T = iTime*0.1;\n    //float s = 1., T = 0.;\n    FWDs[0] = fwd_srt_transform(vec3(1,s+0.1,1), vec3(T,0,0), vec3(-1,0,0));\n    BWDs[0] = inverse(FWDs[0]);\n    FWDs[1] = fwd_srt_transform(vec3(1,1,s+0.1), vec3(0,T,0), vec3(1,0,0));\n    BWDs[1] = inverse(FWDs[1]);\n}\n\nHIT find_closest_intersection(RAY ray)\n{\n    HIT c_hit; c_hit.hit_dist = 9e5;\n    int hit_something = 0; // Set only once, when firts hit occurs.\n    int hitted_idx = 0;\n    float min_sq_d = 9e5;\n    \n    for (int i = 0; i < NUM_OF_OBJECTS; ++i)\n    {\n        HIT hit;\n                        \n        // Apply inverse transform.\n        RAY r = apply_transform_to_ray(ray, BWDs[i]);\n        \n        // Intersect with simplified primitives.\n        switch (i)\n        {\n        case 0: hit = ray_unit_sphere_int(r); break;\n        case 1: hit = ray_unit_sphere_int(r); break;\n        //case 2: hit = ray_unit_sphere_int(r); break;\n        }\n        \n        if (hit.hit_something == 1) // Hit i-th object?\n        {\n            // Recover hit point in world coordinates.\n            hit.hit_point = apply_transformation_to_point(hit.hit_point, FWDs[i]);\n            \n            // Calculate squared distance in world coordinates.\n            vec3 CAMtoHP = hit.hit_point - ray.position;\n            float sq_d = dot(CAMtoHP, CAMtoHP);\n            \n            if (min_sq_d > sq_d) // Find closer hit-point?\n            {\n                // Update distance.\n                min_sq_d = sq_d;\n                \n                // Save hit data.\n                c_hit = hit;\n                c_hit.hitted_idx = i;\n            }\n        }\n        \n        // If we find any hit, then this value will be set to 1 before the function exits.\n        hit_something = max(hit.hit_something, hit_something);\n    }\n\n    // Save global hit flag.\n    c_hit.hit_something = hit_something;\n\n    // Recover normal (cheap, so i don't use branch here).\n    c_hit.hp_normal = apply_transformation_to_normal(c_hit.hp_normal, BWDs[c_hit.hitted_idx]);\n\n    return c_hit;\n}\n\nvec3 lambert(RAY ray, HIT hit) // lambert reflectance model\n{\n    vec3 light_pos = vec3(2,3,0),\n         hp_to_l = normalize(light_pos - hit.hit_point),\n         obj_col = 1.-get_background();\n         \n    float diffuse = max(dot(hp_to_l, hit.hp_normal), 0.);\n    \n    return hit.hit_something == 1 ?\n        obj_col * diffuse :\n        get_background();\n}\n\nvec3 scene(vec2 SC)\n{\n    init_transformations();\n\n    // Generate primary ray.\n    vec2 MP = iMouse.xy == vec2(0) ?\n        vec2(0) :\n        map_to_centered_ndc(iMouse.xy, 1., vec2(0), false);\n    RAY ray = perspective_camera(SC, vec3(0,0,6), vec3(MP, 0), iResolution.xy);\n\n    // Trace scene.\n    HIT hit = find_closest_intersection(ray);\n    \n    // Process lights.\n    return lambert(ray, hit);\n}\n\n// Basic anti-aliasing (supersample).\nvec3 OSSAA(in vec2 SC)\n{\n    vec3 col = vec3(0);\n    float order = 1., inv = 1./(2.*order + 1.), blur = 1.;\n\n    for (float y = -order; y <= order; y += 1.0)\n        for (float x = -order; x <= order; x += 1.0)\n        {\n            vec2 offset = (blur*vec2(x, y)) * inv;\n            col += scene(SC + offset);\n        }\n        \n    order = 2.*order + 1.;\n    return col / (order*order);  \n}\n\nvoid mainImage( out vec4 O, in vec2 SC )\n{\n    //O = vec4(scene(SC),1.0);\n    O = vec4(OSSAA(SC), 1.0);\n    \n    // Camera look_at.\n    O = mix(O, vec4(0,1,0,1), smoothstep(3., 0., length(SC - 0.5*iResolution.xy) - 2.));\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"// Structures.\nstruct RAY\n{\n    vec3 position;\n    vec3 direction;\n};\nstruct HIT\n{\n    int hit_something;\n    float hit_dist;\n    vec3 hit_point;\n    vec3 hp_normal;\n    vec2 uv;\n    int hitted_idx;\n};\n// Cameras.\nRAY perspective_camera(vec2 SC, vec3 position, vec3 look_at, vec2 resolution)\n{\n    float zFocalLength = 50.0; // mm.\n    vec3 camera = position;\n\n    vec3 f = normalize(look_at - camera);               // forward\n    vec3 r = normalize(cross(vec3(0.0, -1.0, 0.0), f)); // right\n    vec3 u = normalize(cross(r, f));                    // up\n        \n    float size = 36.0;        // Sensor Fit: Mode = Auto.    \n    float aspectRatio = resolution.x / resolution.y;\n    float vpWidth = size;\n    float vpHeight = vpWidth / aspectRatio;\n           \n    // Before uv=[0;1][0;1]\n    vec2 uv = SC / resolution.xy;\n    uv.x = (uv.x * vpWidth) - vpWidth * 0.5;\n    uv.y = (uv.y * vpHeight) - vpHeight * 0.5;\n    // After uv=[-vpWidth*0.5; vpWidth*0.5][-vpHeight*0.5; vpHeight*0.5]\n\n    return RAY(\n        camera,\n        normalize(uv.x * r + uv.y * u + f * zFocalLength));\n}\n\n// Ray-Object intersection routines.\nHIT ray_unit_sphere_int(RAY ray) // sphere_pos always equals vec3(0), and sphere_r equals to 1.\n{\n    float half_b = dot(ray.position, ray.direction),\n          c = dot(ray.position, ray.position) - 1.,\n          discriminant = (half_b * half_b - c),\n          sqrtDiscriminant = sqrt(discriminant),\n          root = min(-half_b - sqrtDiscriminant, -half_b + sqrtDiscriminant);\n    \n    HIT hit;\n    \n    if (discriminant < 0. || // no real roots?\n        root < 0.)           // behind camera?\n    { \n        hit.hit_something = 0;\n        hit.hit_dist = 9e5;\n        return hit; \n    }\n    \n    hit.hit_something = 1;\n    hit.hit_dist = root;\n    hit.hit_point = ray.position + ray.direction * root;\n    hit.hp_normal = normalize(hit.hit_point);\n    \n    const float inv_pi = 0.31830988618;\n    const float inv_tau = 0.1591549430918953;\n    float x = hit.hit_point.x, y = hit.hit_point.y, z = hit.hit_point.z;\n    hit.uv = vec2(0.5) + vec2(atan(x, z) * inv_tau, -asin(-y) * inv_pi);\n    \n    return hit;\n}\n\n/*\n    Matricies for column vectors and row major matricies,\n    because i prefer this variant)\n    \n    Multiplication order:\n    T2 * T1 * T0 * V;\n    \n    Representation for points and directions\n    in homogeneous coordinates:\n        Points     p = vec4(p.xyz, 1),\n        Direction  d = vec4(p.xyz, 0).\n*/\nmat4 scale(vec3 s)\n{\n    mat4 M = mat4(\n        s.x,   0,   0, 0,\n          0, s.y,   0, 0,\n          0,   0, s.z, 0,\n          0,   0,   0, 1);\n    return transpose(M);\n}\nmat4 rotX(float rad)\n{\n    float s = sin(rad), c = cos(rad);\n    mat4 M = mat4(\n         1, 0,  0, 0,\n         0, c, -s, 0,\n         0, s,  c, 0,\n         0, 0,  0, 1);\n    return transpose(M);\n}\nmat4 rotY(float rad)\n{\n    float s = sin(rad), c = cos(rad);\n    mat4 M = mat4(\n         c, 0, s, 0,\n         0, 1, 0, 0,\n        -s, 0, c, 0,\n         0, 0, 0, 1);\n    return transpose(M);\n}\nmat4 rotZ(float rad)\n{\n    float s = sin(rad), c = cos(rad);\n    mat4 M = mat4(\n         c, -s, 0, 0,\n         s,  c, 0, 0,\n         0,  0, 1, 0,\n         0,  0, 0, 1);\n    return transpose(M);\n}\nmat4 translate(vec3 t)\n{\n    mat4 M = mat4(\n        1, 0, 0, t.x,\n        0, 1, 0, t.y,\n        0, 0, 1, t.z,\n        0, 0, 0,   1);\n    return transpose(M);\n}\nmat4 fwd_srt_transform(vec3 s, vec3 r, vec3 t) // scale, rotate, translate\n{\n    return translate(t) * rotX(r.x) * rotY(r.y) * rotZ(r.z) * scale(s);\n}\nmat4 bwd_srt_transform(vec3 s, vec3 r, vec3 t) // scale, rotate, translate\n{\n    return inverse(translate(t) * rotX(r.x) * rotY(r.y) * rotZ(r.z) * scale(s));\n}\nRAY apply_transform_to_ray(RAY ray, mat4 T)\n{\n    vec4 P = vec4(ray.position + ray.direction, 1);   \n         P = T * P;\n         \n    RAY res;\n    res.position = (T * vec4(ray.position, 1.)).xyz;\n    res.direction = normalize(P.xyz - res.position);\n    return res;\n}\nvec3 apply_transformation_to_normal(vec3 normal, mat4 T)\n{\n    mat3 SR = mat3(T[0].xyz, T[1].xyz, T[2].xyz);\n    // https://paroj.github.io/gltut/Illumination/Tut09%20Normal%20Transformation.html\n    normal = normal * transpose(inverse(SR));\n    \n    return normalize(normal);\n}\nvec3 apply_transformation_to_point(vec3 p, mat4 T)\n{\n    vec4 P = vec4(p, 1.); \n    return (T * P).xyz;\n}","name":"Common","description":"","type":"common"}]}
{"ver":"0.1","info":{"id":"7dBBDt","date":"1647355390","viewed":97,"name":"Adaptive mean","username":"guitio2002","description":"Adaptive mean:\nhttps://github.com/Apress/ray-tracing-gems/blob/master/Ch_25_Hybrid_Rendering_for_Real-Time_Ray_Tracing/MultiscaleMeanEstimator.hlsl\n\nCode is in \"Buffer C\".","likes":3,"published":1,"flags":32,"usePreview":0,"tags":["adaptive","mean"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\n#define ZOOM 4.0\n\nvec3 fetchSamples(in uint sample_index)\n{\n    uvec2 sample_coords = uvec2(sample_index % uint(iResolution.x),\n                                sample_index / uint(iResolution.x));\n    vec2  sample_uv     = (vec2(sample_coords) + 0.5) / iResolution.xy;\n\n    float sample_value = texture(iChannel0, sample_uv).x;\n    vec2  sample_mean1 = texture(iChannel1, sample_uv).xy;\n    float sample_mean2 = texture(iChannel2, sample_uv).x;\n\n    return vec3(sample_value, sample_mean1.x / sample_mean1.y, sample_mean2);\n}\n\nfloat distanceToCurve(in vec2 uv, in vec2 x, in vec2 y)\n{\n    return abs((x.y - x.x) * (y.x - uv.y) - (x.x - uv.x) * (y.y - y.x)) / sqrt(pow(x.y - x.x, 2.0) + pow(y.y - y.x, 2.0));\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    // Fetch the frame index\n    vec2 uv    = fragCoord / iResolution.xy;\n    uint frame = uint(texture(iChannel0, uv).y - 1.0);\n\n    // Find our interpolation position\n    float sample_interp = (iResolution.x - fragCoord.x) / ZOOM;\n    if (sample_interp > float(frame)) { fragColor = vec4(0.0); return; }\n    sample_interp = float(frame) - sample_interp; // relative to frame\n\n    // And fetch the corresponding samples\n    uint sample_index = uint(sample_interp);\n    vec3 sample_left  = fetchSamples(sample_index + 0u);\n    vec3 sample_right = fetchSamples(sample_index + 1u);\n\n    // Calculate the curves coefficients\n    vec2 sample_pos    = vec2((iResolution.x - ZOOM * float(frame - sample_index - 0u)) / iResolution.x,\n                              (iResolution.x - ZOOM * float(frame - sample_index - 1u)) / iResolution.x);\n    vec3 sample_curves = vec3(distanceToCurve(uv, sample_pos, vec2(sample_left.x, sample_right.x)),\n                              distanceToCurve(uv, sample_pos, vec2(sample_left.y, sample_right.y)),\n                              distanceToCurve(uv, sample_pos, vec2(sample_left.z, sample_right.z)));\n    sample_curves      = (1.0 - smoothstep(0.0, 3e-3, sample_curves));\n\n    // Now, we can display :)\n    vec3 col1 = vec3(1.0, 0.6, 0.0) * sample_curves.x;\n    vec3 col2 = vec3(0.0, 0.6, 1.0) * sample_curves.y;\n    vec3 col3 = vec3(0.6, 1.0, 0.0) * sample_curves.z;\n\n    fragColor = vec4(max(col1, max(col2, col3)), 1.0);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[{"id":"Xsf3zn","filepath":"/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"/media/ap/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"\n#define MEAN (0.75 * (0.5 * sin(iTime) + 0.5))\n\n#define DEV  (0.25 * (0.5 * cos(iTime) + 0.5) + 0.125)\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    // Fetch our sampling data\n    vec2 uv   = fragCoord / iResolution.xy;\n    vec2 prev = texture(iChannel0, uv).xy;\n\n    // Decode the sample value and count\n    float sample_value = prev.x;\n    uint  sample_count = uint(prev.y);\n    uint  sample_index = uint(fragCoord.x) + uint(fragCoord.y) * uint(iResolution.x);\n\n    // Generate a new sample\n    if (sample_index == (sample_count % uint(iResolution.x * iResolution.y)))\n    {\n        sample_value = MEAN + DEV * (2.0 * texture(iChannel1, uv).x - 1.0);\n    }\n\n    // Advance the sample counter\n    fragColor = vec4(sample_value, float(++sample_count), 0.0, 0.0);\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"\n#define MAX_SAMPLE_COUNT 28.0\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    // Fetch our sampling data\n    vec2 uv   = fragCoord / iResolution.xy;\n    vec2 curr = texture(iChannel0, uv).xy;\n\n    // Decode the sample value and count\n    float sample_value = curr.x;\n    uint  sample_count = uint(curr.y - 1.0);\n    uint  sample_index = uint(fragCoord.x) + uint(fragCoord.y) * uint(iResolution.x);\n\n    // We only process the newly added sample\n    if (sample_index != (sample_count % uint(iResolution.x * iResolution.y)))\n    {\n        fragColor = texture(iChannel1, uv);\n        return;\n    }\n\n    // Fetch the history if we have some...\n    vec2 prev = vec2(0.0);\n\n    if (sample_count > 0u)\n    {\n        uint prev_index = ((sample_count - 1u) % uint(iResolution.x * iResolution.y));\n\n        uvec2 sample_coords = uvec2(prev_index % uint(iResolution.x),\n                                    prev_index / uint(iResolution.x));\n        vec2  sample_uv     = (vec2(sample_coords) + 0.5) / iResolution.xy;\n\n        prev = texture(iChannel1, sample_uv).xy;\n    }\n\n    // ... and integrate the new sample\n    prev.xy += vec2(sample_value, 1.0);\n\n    if (prev.y >= MAX_SAMPLE_COUNT)\n    {\n        prev.xy *= MAX_SAMPLE_COUNT / prev.y;\n    }\n\n    fragColor = vec4(prev.xy, 0.0, 0.0);\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"\n// https://github.com/Apress/ray-tracing-gems/blob/master/Ch_25_Hybrid_Rendering_for_Real-Time_Ray_Tracing/MultiscaleMeanEstimator.hlsl\nstruct MultiscaleMeanEstimatorData\n{\n    float mean;\n    float shortMean;\n    float vbbr;\n    float variance;\n    float inconsistency;\n};\n\nvec4 packMME(in MultiscaleMeanEstimatorData mme)\n{\n    return vec4(mme.mean, mme.shortMean, mme.variance,\n       uintBitsToFloat(packHalf2x16(vec2(mme.vbbr, mme.inconsistency))));\n}\n\nMultiscaleMeanEstimatorData unpackMME(in vec4 data)\n{\n    MultiscaleMeanEstimatorData mme;\n    mme.mean          = data.x;\n    mme.shortMean     = data.y;\n    mme.variance      = data.z;\n    mme.vbbr          = unpackHalf2x16(floatBitsToUint(data.w)).x;\n    mme.inconsistency = unpackHalf2x16(floatBitsToUint(data.w)).y;\n    return mme;\n}\n\nvoid MultiscaleMeanEstimator(in float y, inout MultiscaleMeanEstimatorData data, in float shortWindowBlend)\n{\n    float mean          = data.mean;\n    float shortMean     = data.shortMean;\n    float vbbr          = data.vbbr;\n    float variance      = data.variance;\n    float inconsistency = data.inconsistency;\n\n    // Suppress fireflies\n    {\n        float dev           = sqrt(max(1e-5, variance));\n        float highThreshold = 0.1 + shortMean + dev * 8.0;\n        float overflow      = max(0.0, y - highThreshold);\n                        y  -= overflow;\n    }\n\n    float delta  = y - shortMean;\n    shortMean    = mix(shortMean, y, shortWindowBlend);\n    float delta2 = y - shortMean;\n\n    // This should be a longer window than shortWindowBlend to avoid bias\n    // from the variance getting smaller when the short-term mean does.\n    float varianceBlend = shortWindowBlend * 0.5;\n    variance            = mix(variance, delta * delta2, varianceBlend);\n    float dev           = sqrt(max(1e-5, variance));\n\n    float shortDiff    = mean - shortMean;\n    float relativeDiff = abs(shortDiff) / max(1e-5, dev);\n    inconsistency      = mix(inconsistency, relativeDiff, 0.08);\n\n    float varianceBasedBlendReduction = clamp(0.5 * shortMean / max(1e-5, dev), 1.0 / 32.0, 1.0);\n    float catchUpBlend                = clamp(smoothstep(0.0, 1.0, relativeDiff * max(0.02, inconsistency - 0.2)), 1.0 / 256.0, 1.0);\n    catchUpBlend                     *= vbbr;\n\n    vbbr = mix(vbbr, varianceBasedBlendReduction, 0.1);\n    mean = mix(mean, y, clamp(catchUpBlend, 0.0, 1.0));\n\n    data.mean          = mean;\n    data.shortMean     = shortMean;\n    data.vbbr          = vbbr;\n    data.variance      = variance;\n    data.inconsistency = inconsistency;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    // Fetch our sampling data\n    vec2 uv   = fragCoord / iResolution.xy;\n    vec2 curr = texture(iChannel0, uv).xy;\n\n    // Decode the sample value and count\n    float sample_value = curr.x;\n    uint  sample_count = uint(curr.y - 1.0);\n    uint  sample_index = uint(fragCoord.x) + uint(fragCoord.y) * uint(iResolution.x);\n\n    // We only process the newly added sample\n    if (sample_index != (sample_count % uint(iResolution.x * iResolution.y)))\n    {\n        fragColor = texture(iChannel1, uv);\n        return;\n    }\n\n    // Fetch the history if we have some...\n    vec4 prev = vec4(0.0);\n\n    if (sample_count > 0u)\n    {\n        uint prev_index = ((sample_count - 1u) % uint(iResolution.x * iResolution.y));\n\n        uvec2 sample_coords = uvec2(prev_index % uint(iResolution.x),\n                                    prev_index / uint(iResolution.x));\n        vec2  sample_uv     = (vec2(sample_coords) + 0.5) / iResolution.xy;\n\n        prev = texture(iChannel1, sample_uv);\n    }\n    \n    // Perform the multi-scale mean estimation\n    MultiscaleMeanEstimatorData mme = unpackMME(prev);\n\n    MultiscaleMeanEstimator(sample_value, mme, 0.08);\n\n    fragColor = packMME(mme);\n}\n","name":"Buffer C","description":"","type":"buffer"}]}
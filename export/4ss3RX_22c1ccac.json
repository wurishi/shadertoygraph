{"ver":"0.1","renderpass":[{"outputs":[],"inputs":[{"channel":0,"type":"texture","id":"4sf3Rn","filepath":"/media/a/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","sampler":{"filter":"mipmap","wrap":"repeat","vflip":"false","srgb":"false","internal":"byte"}},{"channel":1,"type":"video","id":"Xdf3Rn","filepath":"/media/a/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","sampler":{"filter":"linear","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"}}],"code":"// How \"high\" a scanline is in normalised screen coordinates.\n// 480p is the NTSC standard, I chose 400, looks better.\n// Here's a great technical resource on scanlines: http://scanlines.hazard-city.de/\nconst float SCANLINE_HEIGHT = 1.0 / 400.0;\n// Flips channel 1 along Y, set to 0.0 or 1.0.\nconst float FLIP_Y = 1.0;\n// How many texels apart to sample for blur.\nconst float BLUR_SIZE = 1.5;\n\nconst float GHOSTING_SCALE = 0.2;\n\nconst float GAMMA = 0.98;\n\nfloat scanline(vec2 uv)\n{\n\tfloat on = step(mod(uv.y, SCANLINE_HEIGHT * 2.0), SCANLINE_HEIGHT);\n\t// This softens the scanline a bit by creating a gradient from \n\t// black to white to black again, for each scanline.\n\tfloat bias = clamp(sin(fract(uv.y / SCANLINE_HEIGHT) * 3.1417) * 1.15, 0.0, 1.0);\n\treturn mix(0.35, 1.0, on * bias);\n}\n\nfloat rand(vec2 uv)\n{\n\tfloat samplenoise = (texture(iChannel1, vec2(0.5)).r + texture(iChannel1, vec2(0.25)).r) / 2.0;\n\tfloat noise = texture(iChannel0, vec2(0, uv.y * 0.009)).r  * samplenoise;\n\treturn noise;\n}\n\nvec4 tape_noise(vec2 uv)\n{\t\n\tfloat noise = rand(uv);\n\t\t\n\tuv.y += cos(uv.x * ((6.28 * noise) * 8.0)) * 0.001;\n\t\n\treturn texture(iChannel1, vec2(fract(noise), uv.y));\n}\n\nvec4 video_sample(vec2 uv)\n{\n\tvec2 texel_size = vec2(1.0) / iChannelResolution[1].xy;\n\t\n\tfloat noise = rand(uv);\n\tvec2 warp = vec2(sin(uv.y * ((6.28 * noise) * 24.0)) * 0.001,\n\t\t\t\t\t cos(uv.x * ((6.28 * noise) * 12.0)) * -0.001);\n\tvec4 tape_noise_val = tape_noise(uv);\n\tuv += tape_noise_val.g * 0.025;\n\t\n\t// Fringe-location.\n\tvec4 fringe = texture(iChannel1, uv + (texel_size * 0.02));\n\t\t\n\ttexel_size *= BLUR_SIZE;\n\t\n\t// Blur.\n\t// 4 sampling points is not much, but actually fits the desired look pretty well.\n\tvec4 video00 = texture(iChannel1, uv) * 0.25;\n\tvec4 video10 = texture(iChannel1, uv + (vec2(texel_size.x, 0.0))) * 0.25;\n\tvec4 video01 = texture(iChannel1, uv + (vec2(0.0, texel_size.y))) * 0.25;\n\tvec4 video11 = texture(iChannel1, uv + (texel_size)) * 0.25;\n\t\n\tvec4 final = (video00 + video10 + video01 + video11);\n\tfinal.b = fringe.b;\n\t\n\t// Some cheap ghosting.\n\tmat2 scale = \n\t\tmat2(0.5, 0.0,\n\t\t\t 0.0, 0.5);\n\tvec4 ghost = texture(iChannel1,  scale * (vec2(0.5, 0.5) +uv));\n\t// Gamma up for fast contrast.\n\tghost = pow(ghost, vec4(7.0)) * GHOSTING_SCALE;\n\tghost.rgb = ghost.rrr;\t\n\t\n\tfinal = pow(final + ghost, vec4(GAMMA));\n\tfinal.r *= 0.9 + fract(noise);\n\t\n\treturn final * 1.2 + (clamp(final / (tape_noise_val*2.0), -.5, 2.0) * 0.2); \n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n\t\n\tvec4 video = video_sample(vec2(uv.x, mix(1.0 - uv.y, uv.y, FLIP_Y)));\n\t\n\tfragColor = vec4(0.0) + (scanline(uv) * video);\n}","name":"Image","description":"","type":"image"}],"flags":{"mFlagVR":false,"mFlagWebcam":false,"mFlagSoundInput":false,"mFlagSoundOutput":false,"mFlagKeyboard":false,"mFlagMultipass":false,"mFlagMusicStream":false},"info":{"id":"4ss3RX","date":"1375863547","viewed":749,"name":"Bad video","username":"skurmedel","description":"Tries to mimic some kind of crappy video feed.","likes":9,"published":1,"flags":0,"usePreview":0,"tags":["procedural","2d","noise","video"],"hasliked":0,"parentid":"","parentname":""}}
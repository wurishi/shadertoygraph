{"ver":"0.1","info":{"id":"WtffRB","date":"1596984724","viewed":337,"name":"IK Chain Solver","username":"spalmer","description":"just a fork of arkan's toy, attempting to make it stateful, hopefully more robust and efficient.","likes":13,"published":1,"flags":32,"usePreview":0,"tags":["ik","inverse","kinematics"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// fork of toy by arkan's Inverse Kynematic (CCD)\n// at https://shadertoy.com/view/tt2cWV\n// Inspired by: https://zalo.github.io/blog/inverse-kinematics/#hinges\n\n// TODO the long names are killing me ;)\n// I took a pass at cleanup already but could use a bit more\n\n// make AA 1 if your machine is slow, 2 or more for quality\n#define AA 1\n\n// light direction\nconst vec3 light = normalize(vec3(-.4, .7, -.6));\n\nfloat sdPlane(vec3 p)\n{\n    return p.y;\n}\n\nfloat sdSphere(vec3 p, float s)\n{\n    return length(p) - s;\n}\n        \nfloat sdBox(vec3 p, vec3 b)\n{    \n    // center the box on its base:\n    p.y = p.y - b.y;\n    // without the above it's centered about the mid section\n    vec3 d = abs(p) - b;\n    return min(max(d.x, max(d.y, d.z)), 0.) + length(max(d, 0.));\n}\n\nfloat joint_field(Joint j, vec3 pos)\n{\n    mat4 m;\n    m[0] = vec4(cross(j.dir, j.ortho), 0); // x\n\tm[1] = vec4(j.dir,   0); // y\n\tm[2] = vec4(j.ortho, 0); // z\n    m[3] = vec4(j.org,   1);        \n\treturn sdBox(vec3(inverse(m) * vec4(pos, 1)),\n                 vec3(j.radius, j.len*.5, j.radius));\n}    \n// vec2 used for scene tracing:\n// x: signed distance from field\n// y: material (for simplicity we only use a\n// single float which we'll translate to a color later.)\n// union, combine objects\nvec2 opU(vec2 d1, vec2 d2)\n{\n    return d1.x < d2.x ? d1 : d2;\n}\n// Compute final distance field of all joints\nvec2 eval_joints(Joint joints[njoints], vec2 field, vec3 pos, vec3 goal)\n{\n    vec2 res = field;\n    float mat = 20.;\n    for (int i = IZERO; i < njoints; ++i) {\n        float joint_val = joint_field(joints[i], pos);\n        mat += 20.;\n        res = opU(res, vec2(joint_val, mat));\n    }\n    // effector:\n    vec3 effector = get_effector(joints);\n    mat += 20.;\n    float f = sdSphere(pos - effector, rad*1.5);\n    res = opU(res, vec2(f, mat));\n    // goal:    \n    mat += 20.;\n    f = sdSphere(pos - goal, rad*1.5);\n    res = opU(res, vec2(f, mat));\n    return res;\n}\n\nvec2 eval_field(vec3 pos, Joint joints[njoints])\n{\n    vec2 res = vec2(1e10, -1e7);    \n    float t = mod(iTime, 10.) / 10.;    \n    res = eval_joints(joints, res, pos, \n           get_goal(iMouse.xyz, iResolution.xy, iTime));    \n    res = opU(res, vec2(sdPlane(pos), 1));    \n    return res;\n}\n\nvec2 cast_ray(vec3 ro, vec3 rd, Joint joints[njoints])\n{\n    float tmin = .1, tmax = 100.;\n  #if 1\n    // bounding volume optimization\n    float tp1 = (0.-ro.y) / rd.y;\n    if (tp1 > 0.)\n        tmax = min(tmax, tp1);\n    float tp2 = (1.6-ro.y) / rd.y;\n    if (tp2 > 0.) {\n        if (ro.y > 1.6)\n            tmin = max(tmin, tp2);\n        else\n            tmax = min(tmax, tp2);\n    }\n  #endif\n\n    float t = tmin\n    , m = -1.;\n    for (int i = IZERO; i < 100; ++i) {\n        float precis = 5e-6 * t;\n        vec2 res = eval_field(ro + rd * t, joints);\n        if (res.x < precis || t > tmax)\n            break;\n        t += res.x;\n        m = res.y;\n    }\n\n    if (t > tmax)\n        m = -1.;\n    return vec2(t, m);\n}\n\n// used for both actual shadow and reflection\nfloat SoftShadow(vec3 ro, vec3 rd, \n                 float tmin, float tmax,\n                 Joint joints[njoints])\n{\n    float res = 1.;\n    float t = tmin;\n    for (int i = IZERO; i < 16; ++i) {\n        float h = eval_field(ro + rd*t, joints).x;\n        res = min(res, max(t/tmax, 4. * h/t)); //sqrt(max(t/tmax, 4. * h/t))); //mix(3. * h/t, 1., t/tmax)); //3. * h/t);\n        t += max(h, tmin); //clamp(h, .02, .10);\n        if (h < 0.001 || t > tmax)\n            break;\n    }\n    res = clamp(res, 0., 1.);\n    res = pow(res, .25); //1. - pow(max(0., 1.-res), 4.); //1.-(1.-res)*(1.-res); //sqrt(res); //\n    return res;\n}\n\nfloat AmbientOcclusion(vec3 pos, vec3 normal, Joint joints[njoints])\n{\n    float occ = 0.;\n    float sca = 1.;\n    int ni = 5;\n    for (int i = IZERO; i < ni; ++i) {\n        float hr = .01 + .12*float(i)/float(ni);\n        vec3 aopos =  normal * hr + pos;\n        float dd = eval_field(aopos, joints).x;\n        occ += -(dd-hr) * sca;\n        sca *= .95;\n    }\n    return clamp(1. - 3.*occ, 0., 1.);\n}\n\n/*\nvec3 compute_normal(vec3 pos, Joint joints[njoints])\n{\n    vec2 e = vec2(1,-1) * .5773 * .0005;\n    // FIXME loop with IZERO please - iq tetrahedral gradient is cool though\n    return normalize(e.xyy * eval_field(pos + e.xyy, joints).x +\n                     e.yyx * eval_field(pos + e.yyx, joints).x +\n                     e.yxy * eval_field(pos + e.yxy, joints).x +\n                     e.xxx * eval_field(pos + e.xxx, joints).x);\n}\n*/\n// iq's looped simplex gradient, excellent! loop idea by Thomas Hooper\n// https://iquilezles.org/articles/normalsSDF \"An Important Implementation Detail\"\n// I really did a number on the bitshifting though!\n// stolen from https://shadertoy.com/view/tlGXDK\nvec3 compute_normal(vec3 pos, Joint joints[njoints])\n{\n    float h = .0005\n        * sqrt(1./3.) // .5773\n        //* (1. + 128.*blur) // antialiasing, band limit TODO tuning!! maybe need iResolution?\n        ;\n    vec3 n = vec3(0);\n    int i = 0;\n    i = IZERO;\n    for (; i < 4; ++i) {\n        vec3 e = vec3((ivec3(i+3, i, i+i)&2) - 1);\n        n += eval_field(pos + e * h, joints).x * e;\n    }\n    return normalize(n);\n}\n\nvec3 render(Joint joints[njoints], vec3 ro, vec3 rd)\n{\n    vec3 c = vec3(.8, 1, 1); //+ rd.y * 0.8; // bg gradient modulated by ray dir?\n    vec2 res = cast_ray(ro, rd, joints);\n    // TODO refactor all this lighting and material stuff\n    float t = res.x; // Ray parameter: origin + direction * t\n    float material = res.y; // material associated to the intersected surface\n    if (material > -.5) {\n        vec3 pos = ro + t*rd;\n        vec3 n = compute_normal(pos, joints);\n        vec3 reflection = reflect(rd, n);\n        // material albedo\n        c = .45 + .35 * sin(vec3(.05, .08, .10) * (material - 1.));\n         // lighting\n        float occlusion = AmbientOcclusion(pos, n, joints);\n        vec3  hal       = normalize(light-rd);\n        float ambient   = clamp(.5+.5*n.y, 0., 1.);\n        float diffusion = clamp(dot(n, light), 0., 1.);\n        float bac       = clamp(dot(n, normalize(vec3(-light.x,0,-light.z))), 0., 1.) * clamp(1.-pos.y, 0., 1.);\n        float dom       = smoothstep(-0.1, 0.1, reflection.y);\n        float fre       = pow(clamp(1.0+dot(n,rd), 0., 1.), 2.);\n\n        diffusion *= SoftShadow(pos, light     , .01, 1.5, joints);\n        dom       *= SoftShadow(pos, reflection, .01, 1. , joints);\n\n        float spe = pow(clamp(dot(n, hal), 0., 1. ), 16.) *\n                    diffusion * (.04 + .96*pow(clamp(1.+dot(hal,rd), 0., 1.), 5.));\n\n        vec3 lin = vec3(0);\n        lin += 1.30 * diffusion * vec3(1.00, 0.80, 0.55);\n        lin += 0.40 * ambient   * vec3(0.40, 0.60, 1.00) * occlusion;\n        lin += 0.50 * dom       * vec3(0.40, 0.60, 1.00) * occlusion;\n        lin += 0.50 * bac       * vec3(0.25, 0.25, 0.25) * occlusion;\n        lin += 0.25 * fre       * vec3(1.00, 1.00, 1.00) * occlusion;\n\n        c = c*lin;\n        c += 10. * spe * vec3(1.00, 0.90, 0.70);\n    }\n    c = mix(vec3(.95, .97, 1.), c, exp(-.00005 * t * t * t) ); // iso fog\n    return c; //clamp(color, 0., 1.);\n}\n\nstruct Camera\n{\n    vec3 right;\n    vec3 up;\n    vec3 fwd; // forward\n    vec3 pos; // position\n    float fov; // field of view halfangle in radians\n};\n// TODO just use a matrix, idk why so complicated tbh\n/*Camera camera_init()\n{\n    Camera c;\n    c.pos = vec3(0);\n    c.fwd = vec3(0, 0, 1);\n    c.right = vec3(1, 0, 0);\n    c.up = vec3(0, 1, 0);\n    c.fov = radians(30.);\n    return c;\n}*/\n//    float t = mod(iTime, 10.) / 10.;\n//    cam.pos = vec3(mat4x4_rotate(vec3(0.0, 1.0, 0.0), t*3.14) * vec4(-3.4, 1.2, 0.5, 1.0));\n // = camera_init();\n\n// dir and up must already be orthogonal\n/*void set_fwd_and_up(inout Camera cam, vec3 dir, vec3 up)\n{\n    c.fwd = normalize(dir);\n    c.right = normalize(cross(up, dir));\n    c.up = normalize(up);\n}*/\n\nvoid set_fwd(inout Camera c, vec3 dir)\n{\n    c.fwd = normalize(dir);\n    float dot_prod = dot(c.fwd, vec3(0, 1, 0));\n    vec3 ax = abs(dot_prod) > .999 ? vec3(1, 0, 0) : vec3(0, 1, 0);\n    c.right = cross(ax, c.fwd);\n    c.right = normalize(c.right);\n    c.up = cross(c.fwd, c.right);\n}\n\nvoid look_at(inout Camera c, vec3 aimed)\n{\n    set_fwd(c, aimed - c.pos);\n}\n\nvoid primary_ray(vec2 uv,\n                 out vec3 rd, out vec3 ro)\n{\n    Camera cam;\n    cam.fov = radians(30.);\n    cam.pos = vec3(-1.1, .3, 0);\n    look_at(cam, vec3(0, .15, 0));\n    rd = normalize(cam.fwd * (1. / tan(cam.fov)) + (\n          cam.right * (uv.x - .5) * iResolution.x / iResolution.y\n        + cam.up    * (uv.y - .5)));\n    ro = cam.pos;\n}\n\nvoid mainImage(out vec4 o, vec2 p)\n{\n    Joint[njoints] joints;\n    loadState(joints, ivec2(p), BufA, ivec2(ResA), IZERO);\n    vec3 col = vec3(0);\n  #if AA > 1\n    for (int m = IZERO; m < AA; ++m) {\n        for (int n = IZERO; n < AA; ++n) {\n            vec2 q = (vec2(float(m),float(n)) / float(AA)) - .5;\n            vec2 pixel = p + q;\n  #else\n            vec2 pixel = p;\n  #endif\n            vec3 ro, rd;\n            primary_ray(pixel / iResolution.xy, rd, ro);\n            vec3 c = render(joints, ro, rd);\n            col += c;\n  #if AA > 1\n        }\n    }\n    col /= float(AA*AA);\n  #endif\n\n    col = pow(col, vec3(.4545)); // gamma\n    o = vec4(col, 1);\n}\n\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"// make this 1 to enable hinge constraints\n#define HINGE 0\n\n#define BufA iChannel0\n#define ResA iChannelResolution[0].xy\n\nconst int njoints = 4 // Number of joints in the chain\n, datapixelsperjoint = 4 // should be power of 2, enough to hold packed Joint struct\n, ndatapixels = njoints * datapixelsperjoint\n;\n\n// joint display radius:\nconst float rad = .01;\n\n#define IZERO min(0, iFrame)\n/* // quaternion stuff wasn't actually used\n// quat[0], quat[1], quat[2], quat[3] respectively\n// w, i, j, k coefficients or W, X, Y, Z\n// vec part: quat[1], quat[2], quat[3] or quat.yzw\n// scalar part: quat[0] or quat.x\n#define quaternion vec4\n// FIXME it'd be way better to put the scalar in w and the axis in xyz\n// because getting the axis out with .yzw swizzle looks awkward.\n// and nobody wants to use the array indexing with quaternions.\n// I could make an actual struct!  But would lose operators, \n// not that most of them work the way we need anyway.\n// rotate vector 'v' by quaternion\nvec3 rotate(quaternion q, vec3 v)\n{\n    vec3 qv = q.xyz; //q.yzw;\n\treturn v + cross(2. * qv, cross(qv, v) + v * q[0]);\n}\n\nquaternion qrotation_from_vecs(vec3 u, vec3 v) \n{\n    float norm_u_norm_v = sqrt(dot(u, u) * dot(v, v))\n    , real_part = norm_u_norm_v + dot(u, v);\n    vec3 w;\n    if (real_part < 1.e-6 * norm_u_norm_v) {\n        // If u and v are exactly opposite, rotate 180 degrees\n        // around an arbitrary orthogonal axis. Axis normalisation\n        // can happen later, when we normalise the quaternion. \n        real_part = 0.;\n        w = abs(u.x) > abs(u.z) ? vec3(-u.y, u.x, 0.0)\n                                : vec3(0.0, -u.z, u.y);\n    } else {\n        // Otherwise, build quaternion the standard way.\n        w = cross(u, v);\n    }\n    return normalize(quaternion(w.x, w.y, w.z, real_part));\n}\n*/\nmat3 mat3_rotate(vec3 axis, float radian_angle)\n{\n\tvec3 n = normalize(axis);\n\tfloat cp = cos(radian_angle), sp = sin(radian_angle), acp = 1. - cp\n    , nxz = n.x * n.z, nxy = n.x * n.y, nyz = n.y * n.z;\n\treturn mat3(\n        cp + acp * n.x * n.x,  acp * nxy + sp * n.z,  acp * nxz - sp * n.y,\n        acp * nxy - sp * n.z,  cp + acp * n.y * n.y,  acp * nyz + sp * n.x,\n        acp * nxz + sp * n.y,  acp * nyz - sp * n.x,  cp + acp * n.z * n.z);\n}\n\n/*mat4x4 mat4x4_build(mat3x3 m3)   \n{\n\tmat4x4 m4;\n\tm4[0] = vec4(m3[0], 0);\n\tm4[1] = vec4(m3[1], 0);\n\tm4[2] = vec4(m3[2], 0);\n\tm4[3] = vec4(0, 0, 0, 1);\n\treturn m4;    \n}\n\nmat3 to_mat3(mat4 m4)   \n{\n\tmat3 m3;\n\tm3[0] = vec3(m4[0]);\n\tm3[1] = vec3(m4[1]);\n\tm3[2] = vec3(m4[2]);    \n\treturn m3;    \n}*/ // just use cast!\n\nvec3 transform_as_point(mat4 m, vec3 point)\n{\n\treturn vec3(m * vec4(point, 1));\n}\n\nmat4 mat4_rotate(vec3 axis, float radian_angle)\n{\n\treturn mat4(mat3_rotate(axis, radian_angle));    \n}\n\nmat4 mat4_translate(vec3 t)\n{\n\treturn mat4(1.0, 0.0, 0.0, 0,\n\t            0.0, 1.0, 0.0, 0,\n\t            0.0, 0.0, 1.0, 0,\n\t            t.x, t.y, t.z, 1);\n}\n\n/*mat4 mat4_translate(float x, float y, float z) // overload wrapper for loose scalars\n{\n\treturn mat4_translate(vec3(x, y, z));    \n}*/\n\nmat4 mat4_scale(vec3 s)\n{\n\treturn mat4(s.x, 0.0, 0.0, 0,\n\t            0.0, s.y, 0.0, 0,\n\t            0.0, 0.0, s.z, 0,\n\t            0.0, 0.0, 0.0, 1);\n}\n\nmat4 mat4_rotate(vec3 center, vec3 axis, float radian_angle) \n{\n\tmat4 r = mat4_rotate(axis, radian_angle);\n    return mat4_translate(center) * r * mat4_translate(-center);\n}\n\nmat4 rotation_from_vecs(vec3 center, vec3 dir_to_effector, vec3 dir_to_goal)\n{\n    dir_to_goal = normalize(dir_to_goal);\n    dir_to_effector = normalize(dir_to_effector);\n    vec3 axis = cross(dir_to_effector, dir_to_goal);\n    float dot_val = dot(dir_to_effector, dir_to_goal);\n    return dot_val > 1. - 1e-5 ? mat4(1) :\n    \tmat4_rotate(center, axis, acos(max(-1., dot_val)));\n}\n\n\nstruct Joint \n{\n\tvec3  org;   // origin of the joint    \n\tvec3  dir;   // direction the joint points to\n\tvec3  ortho; // cross direction\n\tvec3  axis;  // axis of rotation (if enabled)    \n\tfloat len;\n\tfloat radius;    \n};\n// ensure that will fit in datapixelsperjoint vec4 at possibly half precision!\nJoint pixelToJoint(vec4 pix[datapixelsperjoint])\n{\n\tJoint j;\n\tj.org   = pix[0].xyz; j.len    = pix[0].w;\n\tj.dir   = pix[1].xyz; j.radius = pix[1].w;\n\tj.ortho = pix[2].xyz;\n\tj.axis  = pix[3].xyz;\n    j.dir = normalize(j.dir);\n    j.axis = normalize(j.axis);\n    j.ortho = normalize(j.ortho);\n\treturn j;\n}\n    \nvec4 jointToPixel(Joint j, int i)\n{\n\tvec4 v;\n\t       if (i == 0) {\n\t\tv = vec4(j.org, j.len);\n\t} else if (i == 1) {\n\t\tv = vec4(j.dir, j.radius);\n\t} else if (i == 2) {\n\t\tv = vec4(j.ortho, 0);\n\t} else if (i == 3) {\n\t\tv = vec4(j.axis, 0);\n\t}\n\treturn v;\n}\n\nvoid transform(out Joint joints[njoints], int i, mat4 transfo)\n{\n    mat3 t3 = mat3(transfo);\n\tfor (int j = 0; j <= i; ++j) {\n        Joint joint = joints[j];\n        joint.org   = transform_as_point(transfo, joint.org);\n        joint.dir   = t3 * joint.dir;\n        joint.axis  = t3 * joint.axis;\n        joint.ortho = t3 * joint.ortho;\n        joints[j] = joint;\n\t}    \n}\n\t\t//joint_list[j].frame  = transfo * joints[j].frame;\n    // Apply rotation to the joint and upper joints in the chain.\t\n    // We know the joints are ordered from tip to base:\n/*\nvoid transform(out Joint joints[njoints], int i, vec3 center, quaternion rot)\n{\n\tfor (int j = 0; j <= i; ++j) {\n        joints[j].org   = rotate(rot, joints[j].org - center) + center;\n        joints[j].dir   = rotate(rot, joints[j].dir);\n        joints[j].ortho = rotate(rot, joints[j].ortho);\n        joints[j].axis  = rotate(rot, joints[j].axis);\n\t}    \n}\n*/\nvec3 get_effector(Joint joints[njoints])\n{\n\tJoint tip = joints[0];    \n    return tip.org + tip.dir * tip.len;\n}\n    //return get_position(tip.frame) + /*normalize*/(y_axis(tip.frame)) * tip.len;\n\nvec3 get_goal(vec3 mouse, vec2 res, float time)\n{\n\tvec2 d = mouse.z >= 0. && dot(mouse.xy, mouse.xy) > 2.\n        ? mouse.xy / res\n        : vec2(cos(time), sin(.33*time)) * .5 + .5;\n    return vec3(.1, .7*d.y, .7-1.4*d.x);\n}\n\nvoid loadState(out Joint joints[njoints], ivec2 p, sampler2D ch, ivec2 res, int zero)\n{\n    for (int i = zero; i < njoints; ++i) {\n\t    vec4[datapixelsperjoint] data;\n    \tfor (int j = 0; j < datapixelsperjoint; ++j)\n        \tdata[j] = texelFetch(ch, ivec2(j + i * datapixelsperjoint,0), 0);\t\n\t\tjoints[i] = pixelToJoint(data);\n\t}\n}\n    // texelFetch should be ok since shadertoy.com provides a fallback layer for GLES 1\n\nvec4 saveState(Joint joints[njoints], ivec2 p)\n{\n    return p.y > 0 || p.x > ndatapixels ? vec4(0) :\n\t    jointToPixel(joints[p.x / datapixelsperjoint], p.x & (datapixelsperjoint-1));\n}\n    //p.x % datapixelsperjoint);\n    // HACK assumed datapixelsperjoint is a power of 2 so I can get working on WebGL 1\n    // could use p.x - (p.x / datapixelsperjoint) * datapixelsperjoint or whatever, route through mod() as float\n\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// FIXME idk why the base gets rotated strangely after a while.\n// In fact I'm not sure why it doesn't turn most of the time.\n// I still don't really understand how this works!\n\nvoid solve_IK(inout Joint joints[njoints])\n{\n    vec3 goal = get_goal(iMouse.xyz, iResolution.xy, iTime);\n    for (int iter = IZERO; iter < 2; ++iter) {\n    \tfor (int i = IZERO; i < njoints; ++i) {\n    \t\tJoint current = joints[i];    \n    \t\t// effector (global pos)\n            // First element of the list is always at the top of the joint chain    \t\t\n    \t\tvec3 effector = get_effector(joints)\n    \t\t// joint origin (global pos)    \t\t\n    \t\t, origin = current.org    \n    \t\t, dir_to_goal = goal - origin            \n    \t\t, dir_to_effector = effector - origin\n    \t\t, pre_axis = current.axis;\n            // rotation (global)            \n            mat4 rot = rotation_from_vecs(origin, dir_to_effector, dir_to_goal);\n            transform(joints, i + IZERO, rot);            \n          #if HINGE\n            rot = rotation_from_vecs(origin, joints[i].axis, pre_axis);\n            transform(joints, i + IZERO, rot);\n          #endif\n    \t}\n    }    \n}\n\n// now that we get state from Buffer A, we\n// don't need nearly so many iterations of the solver\n// and the entire toy runs much more efficiently\n// because each (sub!) pixel of Image does not need \n// to compute the IK solution every frame.\n// But a whole bunch of fragments do get run for BufferA.\n\nvec4 nextState(ivec2 p)\n{\n    Joint[njoints] joints;\n    loadState(joints, p, BufA, ivec2(ResA), IZERO);\n    solve_IK(joints);\n    return saveState(joints, p);\n}\n\n// set initial pose only on iFrame==0\nvec4 initialState(ivec2 p)\n{\n    const float height = .1;\n    const mat3 I = mat3(1); // identity matrix\n    const vec3 // I[axis]\n      X = I[0] //vec3(1, 0, 0) //\n    , Y = I[1] //vec3(0, 1, 0) //\n    , Z = I[2] //vec3(0, 0, 1) //\n    , dir  = Y \n    , next = dir * height\n\t, t = vec3(0) // origin\n    , j3 = t // bottom box on plane\n    , j2 = j3 + next // stack\n    , j1 = j2 + next\n    , j0 = j1 + next\n\t;\t\n    Joint[njoints] j;\n\tj[0] = Joint(j0, dir, X, X, height, rad);\n    j[1] = Joint(j1, dir, X, Z, height, rad);\n\tj[2] = Joint(j2, dir, X, X, height, rad);\n    j[3] = Joint(j3, dir, X, Y, height, rad);\n    return saveState(j, p);\n}\n\nvec4 writeState(ivec2 p)\n{\n    if (p.y > 0 || p.x > ndatapixels)\n        discard;\n    return iFrame < 3 //iFrame == 0 // thumbnail issues\n        ? initialState(p)\n    \t: nextState(p);\n}\n\nvoid mainImage(out vec4 o, vec2 p)\n{    \n    o = writeState(ivec2(p));\n}\n\n","name":"Buffer A","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"3tlBW7","date":"1614619190","viewed":4608,"name":"PBR + IBL","username":"alro","description":"Use mouse to move camera. Change cubemap in BufferB to change lighting. \n","likes":74,"published":1,"flags":32,"usePreview":1,"tags":["lighting","triplanar","specular","convolution","normal","metal","brdf","diffuse","material","ibl","pbr","dielectric","energy","roughness"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4sf3Rr","filepath":"/media/a/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","previewfilepath":"/media/ap/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","type":"texture","channel":3,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n\n    Physically based rendering with direct and image based lighting.\n\n    Changing the cubemap in BufferB will propagate the new data to other tabs and trigger\n    a re-render. Changing the resolution will use the existing data textures scaled to the\n    new viewport. Because we use a texture atlas in BufferC, seam artifacts can appear.\n\n    Edit 1: Added anisotropic BRDF and trick for IBL\n\n    Edit 2: Added environment map filtering option ENV_FILTERING. Disabled by default.\n\n    Edit 3: Fix missing /PI scaling for diffuse irradiance\n\n    Edit 4: Some notes on spherical harmonics and changes to environment filtering\n    \n    Edit 5: Added a source discussing the details of spherical harmonics calculation\n    \n    Edit 6: Cleaned up specular sampling, corrected IBL calculation, added multiple scattering\n\n    Based on:\n    https://learnopengl.com/PBR/Theory\n    https://google.github.io/filament/Filament.html\n    https://cseweb.ucsd.edu/~ravir/papers/envmap/envmap.pdf\n\n    https://www.shadertoy.com/view/ld3SRr\n    https://www.shadertoy.com/view/ls3Szr\n    https://www.shadertoy.com/view/lscBW4\n\n    BufferA: Input and resolution change\n    BufferB: Diffuse IBL with spherical harmonics\n    BufferC: Specular IBL with prefiltered and BRDF integration maps\n\n    BufferB also stores an equirectangular projection of the cubemap it loads. This is used\n    as input for BufferC and also as the environment map for Image. This allows us to rerender\n    the scene by changing just one iChannel input in BufferB.\n\n    BufferC creates 5 prefiltered environment maps of decreasing resolution for various \n    roughness values. These are interpolated between to get the correct specular reflection\n    on the spheres. BufferC also creates a two channel BRDF integration map needed for the \n    split-sum IBL.\n\n*/\n\n//  ----------------------- Uncomment to view buffer outputs -----------------------\n\n\n// Use the matrices from BufferB to replace the environment map\n//#define DISPLAY_DIFFUSE_SH\n\n\n// The equirectangular projection of the cubemap from BufferB\n//#define DISPLAY_ENVIRONMENT_MAP\n\n\n// Prefiltered maps and BRDF integration map from BufferC\n//#define DISPLAY_SPECULAR_MAPS\n\n\n//  --------------------------------------------------------------------------------\n\n\n// ----- Toggle two point lights\n#define LIGHTS\n\n// ----- Move lights\n//#define ANIMATE_LIGHTS\n\n// ----- Tone map spheres\n#define TONEMAPPING\n\n// Multiplied by strength later\nconst vec3 lightColour = vec3(1.0);\n\n// Normal mapping using triplanar texture mapping of iChannel3\nconst vec3 DETAIL_SCALE = vec3(0.05);\nconst vec3 BLENDING_SHARPNESS = vec3(2.0);\nconst float DETAIL_HEIGHT = 0.05;\n\n// ----- TODO: Physically based camera and light sources\n// Shadertoy cubemaps are not HDR and diffuse irradiance can seem quite dull.\n// We can artificially increase the strength of the image radiance in BufferB\nconst float AMBIENT_STRENGTH = 1.0;\nconst float EXPOSURE = 1.0;\n\nconst float SHADOW_SHARPNESS = 8.0;\n\n// Raymaching of scene geometry\nconst float EPSILON = 1e-3;\nconst float MIN_DIST = 0.01;\nconst int MAX_STEPS = 128;\nconst float MAX_DIST = 100.0;\n\n// Sphere size\nfloat radius = 3.0;\n\n// Sphere positioning in capped domain repetition\nconst float CELL = 10.0;\nconst float HALF_CELL = 0.5 * CELL;\n\n//-------------------------- Camera ---------------------------\n\nvec3 rayDirection(float fieldOfView, vec2 fragCoord) {\n    vec2 xy = fragCoord - iResolution.xy / 2.0;\n    float z = (0.5 * iResolution.y) / tan(radians(fieldOfView) / 2.0);\n    return normalize(vec3(xy, -z));\n}\n\n// https://www.geertarien.com/blog/2017/07/30/breakdown-of-the-lookAt-function-in-OpenGL/\nmat3 lookAt(vec3 camera, vec3 at, vec3 up){\n  vec3 zaxis = normalize(at-camera);    \n  vec3 xaxis = normalize(cross(zaxis, up));\n  vec3 yaxis = cross(xaxis, zaxis);\n\n  return mat3(xaxis, yaxis, -zaxis);\n}\n\n\n//-------------------------- Geometry -------------------------\n\nfloat sphereSDF(vec3 p, float radius) {\n    return length(p) - radius;\n}\n\nvec3 getLightPosition(int i){\n\n    #ifdef ANIMATE_LIGHTS\n        float offset = 2.8+0.45*iTime;\n    #else\n        float offset = 2.8;\n    #endif\n\n    if(i == 0){\n        return vec3(30.0*cos(offset), 4.0, 30.0*sin(offset)); \n    }\n    return vec3(-2.0*cos(2.0*offset), 12.0,  -2.0*sin(2.0*offset));\n}\n\nfloat getLightSDF(vec3 p){\n    float d = MAX_DIST;\n    d = min(MAX_DIST, sphereSDF(p-getLightPosition(0), 0.2));\n    d = min(d, sphereSDF(p-getLightPosition(1), 0.2));\n    return d;\n}\n\nfloat getSDF(vec3 p){\n\n    vec3 l = vec3(1,0,1);\n    return sphereSDF(p-CELL*clamp(round(p/CELL),-l,l), radius);\n}\n\nfloat distanceToScene(vec3 cameraPos, vec3 rayDir, float start, float end, bool scene) {\n\t\n    float depth = start;\n    \n    float dist;\n    \n    for (int i = 0; i < MAX_STEPS; i++){\n    \n        if(scene){\n            dist = getSDF(cameraPos + depth * rayDir);\n        }else{\n            dist = getLightSDF(cameraPos + depth * rayDir);\n        }\n        \n        if (dist < EPSILON){ return depth; }\n        \n        depth += dist;\n        \n        if (depth >= end){ return end; }\n    }\n    \n    return depth;\n}\n\n// Tetrahedral normal technique with a loop to avoid inlining getSDF()\n// This should improve compilation times\n// https://iquilezles.org/articles/normalsSDF\nvec3 getNormal(vec3 p){\n    vec3 n = vec3(0.0);\n    int id;\n    for(int i = ZERO; i < 4; i++){\n        vec3 e = 0.5773*(2.0*vec3((((i+3)>>1)&1),((i>>1)&1),(i&1))-1.0);\n        n += e*getSDF(p+e*EPSILON);\n    }\n    return normalize(n);\n}\n\nvec3 getTriplanar(vec3 position, vec3 normal){\n    vec3 xaxis = texture(iChannel3, DETAIL_SCALE.x*(position.zy)).rgb;\n    vec3 yaxis = texture(iChannel3, DETAIL_SCALE.y*(position.zx)).rgb;\n    vec3 zaxis = texture(iChannel3, DETAIL_SCALE.z*(position.xy)).rgb;\n\n    vec3 blending = abs(normal);\n\tblending = normalize(max(blending, 0.00001));\n    blending = pow(blending, BLENDING_SHARPNESS);\n\tfloat b = (blending.x + blending.y + blending.z);\n\tblending /= b;\n\n    return\txaxis * blending.x + \n       \t\tyaxis * blending.y + \n        \tzaxis * blending.z;\n}\n\n\n// Return the position of p extruded in the normal direction by normal map\nvec3 getDetailExtrusion(vec3 p, vec3 normal, vec3 idx){\n    float m = 0.0;\n    if(idx.x == 0.0){\n        m = 1.0;\n    }\n    if(idx.x == 1.0){\n        m = 0.2;\n    }\n    float detail = m * DETAIL_HEIGHT*length(getTriplanar(12.0*p, normal));\n    return p + detail * normal;\n}\n\n// Return the normal direction after applying a normal map\nvec3 getDetailNormal(vec3 p, vec3 normal, vec3 idx){\n    vec3 tangent;\n    vec3 bitangent;\n    // Construct orthogonal directions tangent and bitangent to sample detail gradient in\n    pixarONB(normal, tangent, bitangent);\n    \n    tangent = normalize(tangent);\n    bitangent = normalize(bitangent);\n    \n    float EPS = 1e-3;\n    vec3 delTangent = \tgetDetailExtrusion(p + tangent * EPS, normal, idx) - \n        \t\t\t\tgetDetailExtrusion(p - tangent * EPS, normal, idx);\n    \n    vec3 delBitangent = getDetailExtrusion(p + bitangent * EPS, normal, idx) - \n        \t\t\t\tgetDetailExtrusion(p - bitangent * EPS, normal, idx);\n    \n    return normalize(cross(delTangent, delBitangent));\n}\n\n//---------------------------- Material ----------------------------\n\n// The domain is repeated and clamped. Store the cell a point is in to vary sphere materials\nvec3 getIndex(vec3 p){\n    return 1.0 + floor((p+HALF_CELL) / CELL);\n}\n\n// Base colour for dielectrics. This is overwritten for metals.\nvec3 getAlbedo(vec3 p, vec3 normal, vec3 idx){\n\n    // Have a smooth white dielectric sphere to demonstrate diffuse IBL\n    if(idx.x == 2.0 && idx.z == 2.0){\n        return vec3(1);\n    }\n    \n    // Green corner sphere\n    if(idx.x == 0.0 && idx.z == 0.0){\n        return vec3(0.0625, 0.375, 0.0625);\n    }\n    \n    // Diffuse colour for mixed sphere\n    if(idx.x == 0.0 && idx.z == 1.0){\n        return vec3(0.0125, 0.2625, 0.3125);\n    }\n    \n    // Sky blue\n    if(idx.x == 0.0 && idx.z == 2.0){\n        return vec3(0.1125, 0.4125, 1.0);\n    }\n    \n    // Striped\n    if(idx.x == 2.0 && idx.z == 1.0){\n        return mix(vec3(0.0625), vec3(1.0, 0.8125, 0.125), \n            smoothstep(0.0, 0.2, sin(5.8*p.y + 5.8*p.z)));\n    }\n    \n    // Orange.\n    return vec3(0.875, 0.125, 0.0);\n}\n\n// Metalness is binary\nfloat getMetalness(vec3 p, vec3 normal, vec3 idx){\n    if(idx.x == 0.0 && idx.z == 1.0){\n        // Have one sphere mixing metal and dielectric based on texture\n        return length(getTriplanar(12.0*p, normal)) > 0.4 ? 1.0 : 0.0;\n    }else{\n        // Middle row is metal\n        return mod(idx.x, 2.0);\n    }\n}\n\nfloat getRoughness(vec3 p, vec3 normal, float metalness, vec3 idx){\n    float roughness = 0.0;\n    if(idx.x == 0.0 && idx.z == 1.0){\n        // Mixed sphere roughness depends on material\n        roughness = metalness == 1.0 ?\n            0.25*saturate(length(getTriplanar(1.0*p, normal)))\n          : 0.5*length(getTriplanar(12.0*p, normal));\n    }else if(idx.x == 1.0 && idx.z == 2.0){\n        // Copper sphere roughness\n        roughness = 0.3;\n    }else{\n        // Rougness gradient in z direction\n        roughness = idx.z / 3.0;\n    }\n\n    // Stop roughness being 0 or 1\n    return clamp(roughness, 0.05, 0.999);\n}\n\n\n//---------------------------- PBR ----------------------------\n\n// Trowbridge-Reitz AKA GGX\nfloat distribution(vec3 n, vec3 h, float roughness){\n    float a_2 = roughness * roughness;\n\treturn a_2/(PI * pow(pow(dot_c(n, h), 2.0) * (a_2 - 1.0) + 1.0, 2.0));\n}\n\n// Schlick-Beckmann\nfloat geometry(float cosTheta, float k){\n\treturn (cosTheta) / (cosTheta * (1.0 - k) + k);\n}\n\nfloat smiths(float NdotV, float NdotL, float roughness){\n    float k = pow(roughness + 1.0, 2.0) / 8.0; \n\treturn geometry(NdotV, k) * geometry(NdotL, k);\n}\n\n// Anisotropic distribution and visibility functions from Filament\n// GGX\nfloat distributionAnisotropic(float NoH, vec3 h, vec3 t, vec3 b, float at, float ab) {\n    float ToH = dot(t, h);\n    float BoH = dot(b, h);\n    float a2 = at * ab;\n    vec3 v = vec3(ab * ToH, at * BoH, a2 * NoH);\n    float v2 = dot(v, v);\n    float w2 = a2 / v2;\n    return a2 * w2 * w2 * (1.0 / PI);\n}\n\n// Smiths GGX correlated anisotropic\nfloat smithsAnisotropic(float at, float ab, float ToV, float BoV,\n                                       float ToL, float BoL, float NoV, float NoL) {\n    float lambdaV = NoL * length(vec3(at * ToV, ab * BoV, NoV));\n    float lambdaL = NoV * length(vec3(at * ToL, ab * BoL, NoL));\n    float v = 0.5 / (lambdaV + lambdaL);\n    return saturate(v);\n}\n\n// Fresnel-Schlick\nvec3 fresnel(float cosTheta, vec3 F0){\n    return F0 + (1.0 - F0) * pow(1.0 - cosTheta, 5.0);\n} \n\nvec3 fresnelSchlickRoughness(float cosTheta, vec3 F0, float roughness){\n    return F0 + (max(vec3(1.0-roughness), F0) - F0) * pow(1.0 - cosTheta, 5.0);\n}\n\n// Cook-Torrance BRDF\nvec3 BRDF(vec3 p, vec3 n, vec3 viewDir, vec3 lightDir, vec3 albedo, float metalness, \n            float roughness, vec3 F0,\n            vec3 tangent, vec3 bitangent, float anisotropy,\n            vec3 energyCompensation){\n            \n    vec3 h = normalize(viewDir + lightDir);\n    float cosTheta = dot_c(h, viewDir);\n    \n    // Lambertian diffuse reflectance\n    vec3 diffuse = albedo / PI;\n    \n    // Normal distribution\n    // What fraction of microfacets are aligned in the correct direction\n    float D;\n\n    // Fresnel term\n    // How reflective are the microfacets viewed from the current angle\n    vec3 F = fresnelSchlickRoughness(cosTheta, F0, roughness);\n\n    // Geometry term\n    // What fraction of the microfacets are lit and visible\n    float G;\n    \n    // Visibility term. \n    // In Filament it combines the geometry term and the denominator\n    float V;\n    \n    float NdotL = dot_c(lightDir, n);\n    float NdotV = dot_c(viewDir, n);\n    \n    if(anisotropy == 0.0){\n    \n        D = distribution(n, h, roughness);\n        G = smiths(NdotV, NdotL, roughness);\n        V = G / max(0.0001, (4.0 * NdotV * NdotL));\n        \n    }else{\n    \n        float at = max(roughness * (1.0 + anisotropy), 0.001);\n        float ab = max(roughness * (1.0 - anisotropy), 0.001);\n        \n        D = distributionAnisotropic(dot_c(n, h), h, tangent, bitangent, at, ab);\n        \n        V = smithsAnisotropic(at, ab, dot_c(tangent, viewDir), \n                                                     dot_c(bitangent, viewDir),\n                                                     dot_c(tangent, lightDir), \n                                                     dot_c(bitangent, lightDir),\n                                                     dot_c(n, viewDir), \n                                                     dot_c(n, lightDir));\n    \n    }\n    \n    // Specular reflectance\n    vec3 specular = D * F * V;\n    \n    specular *= energyCompensation;\n    \n    // Combine diffuse and specular\n    vec3 kD = (1.0 - F) * (1.0 - metalness);\n    return kD * diffuse + specular;\n}\n\n\n//---------------------------- Shadows ----------------------------\n\n// https://iquilezles.org/articles/rmshadows\nfloat softShadow(vec3 pos, vec3 rayDir, float start, float end, float k ){\n    float res = 1.0;\n    float depth = start;\n    for(int counter = ZERO; counter < MAX_STEPS; counter++){\n        float dist = getSDF(pos + rayDir * depth);\n        if( abs(dist) < EPSILON){ return 0.0; }       \n        if( depth > end){ break; }\n        res = min(res, k*dist/depth);\n        depth += dist;\n    }\n    return res;\n}\n\n\n//------------------------------ IBL ------------------------------\n\n// BufferB writes matrices of the spherical harmonics coefficients for red, green and blue.\n// These can be used to get the channel value in a given direction\nvec3 getSHIrradiance(vec3 normal){\n\n    vec4 n = vec4(normal, 1.0);\n    \n    mat4 redMatrix = mat4(\n        texelFetch(iChannel1, ivec2(0,0), 0),\n        texelFetch(iChannel1, ivec2(0,1), 0),\n        texelFetch(iChannel1, ivec2(0,2), 0),\n        texelFetch(iChannel1, ivec2(0,3), 0));\n    \n    \n    mat4 grnMatrix = mat4(\n        texelFetch(iChannel1, ivec2(1,0), 0),\n        texelFetch(iChannel1, ivec2(1,1), 0),\n        texelFetch(iChannel1, ivec2(1,2), 0),\n        texelFetch(iChannel1, ivec2(1,3), 0));\n    \n    \n    mat4 bluMatrix = mat4(\n        texelFetch(iChannel1, ivec2(2,0), 0),\n        texelFetch(iChannel1, ivec2(2,1), 0),\n        texelFetch(iChannel1, ivec2(2,2), 0),\n        texelFetch(iChannel1, ivec2(2,3), 0));\n    \n    float r = dot(n, redMatrix * n);\n    float g = dot(n, grnMatrix * n);\n    float b = dot(n, bluMatrix * n);\n    \n    return vec3(r, g, b);\n}\n\n// Get the environment colour from the equirectangular projection of the cubemap from bufferB\n// Clamp texture coordinates to reduce the seam artifact\nvec3 getEnvironment(vec3 rayDir, vec2 scaleSize){\n    vec2 texCoord = vec2((atan(rayDir.z, rayDir.x) / TWO_PI) + 0.5, acos(rayDir.y) / PI);\n    texCoord.x = clamp(texCoord.x, 1.e-3, 0.999);\n    texCoord *= scaleSize;\n    return texture(iChannel1, texCoord).rgb;\n}\n\n// https://google.github.io/filament/Filament.md.html#lighting/imagebasedlights/anisotropy\nvec3 getReflectedVector(vec3 v, vec3 n, vec3 t, vec3 b, float roughness, float anisotropy) {\n    vec3  anisotropyDirection = anisotropy >= 0.0 ? b : t;\n    vec3  anisotropicTangent  = cross(anisotropyDirection, -v);\n    vec3  anisotropicNormal   = cross(anisotropicTangent, anisotropyDirection);\n    vec3  bentNormal          = normalize(mix(n, anisotropicNormal, abs(anisotropy)));\n\n    return reflect(v, bentNormal);\n}\n\n// Get two prefiltered roughness environment maps and linearly interpolate\n// between them to get the roughness data needed.\nvec3 getEnvironment(vec3 rayDir, float roughness, vec2 scaleSize){\n\n    // There are 5 levels of roughness (0.0, 0.25, 0.5, 0.75, 1.0)\n    float level1 = floor(1.0+(roughness) * 5.0);\n    \n    // Level 0 would give us the entire atlas\n    level1 = max(1.0, level1);\n    \n    float level2 = level1 + 1.0;\n    level2 = min(level2, 5.0);\n    \n    // The dimensions of the projection tile as a fraction of the viewport.\n    float size1 = 1.0/pow(2.0, level1);\n    float size2 = 1.0/pow(2.0, level2);\n    \n    // The offset in the x direction. y offset is always 0\n    float offset1 = 0.0;\n    float i;\n    // The offset of the tile in the atlas is the sum of tiles before it (1/2 + 1/4 + ...)\n    for(i = 1.0; i < level1; i++){\n    \toffset1 += 1.0/pow(2.0, i);\n    }\n    \n    float offset2 = offset1 + 1.0/pow(2.0, i);\n    \n    vec2 texCoord1 = vec2((atan(rayDir.z, rayDir.x) / TWO_PI) + 0.5, acos(rayDir.y) / PI);\n                    \n    vec2 texCoord2 = vec2((atan(rayDir.z, rayDir.x) / TWO_PI) + 0.5, acos(rayDir.y) / PI);\n\n    float f = fract(roughness * 5.0);\n    \n    \n    // Clamp texture coordinates to reduce the seam artifact. Depends on level.\n    texCoord1.x = clamp(texCoord1.x, 0.0 + level1 * 0.005, 1.0 - level1 * 0.005);\n    texCoord2.x = clamp(texCoord2.x, 0.0 + level2 * 0.005, 1.0 - level2 * 0.005);\n    \n    \n    // Scale and offset to correct atlas tile\n    texCoord1 = vec2(offset1, 0.0) + size1 * texCoord1;\n    texCoord2 = vec2(offset2, 0.0) + size2 * texCoord2;\n    \n    // When changing to fullscreen, the atlas is not rerendered. \n    // Find the scaled relative coordinates\n    texCoord1 *= scaleSize;\n    texCoord2 *= scaleSize;\n    \n    return mix(texture(iChannel2, texCoord1).rgb, texture(iChannel2, texCoord2).rgb, f);\n}\n\nvec2 getBRDFIntegrationMap(vec2 coord, vec2 scaleSize){\n    // Avoid reading outside the tile in the atlas\n    coord = clamp(coord, 1e-5, 0.99);\n    vec2 texCoord = vec2(coord.x/2.0, coord.y / 2.0 + 0.5);\n    texCoord *= scaleSize;\n    return texture(iChannel2, texCoord).rg;\n}\n\n\n//---------------------------- Lighting ----------------------------\n\nvec3 getIrradiance(vec3 p, vec3 rayDir, vec3 geoNormal, vec3 idx, vec2 scaleSize){\n    vec3 I = vec3(0);\n    vec3 radiance = vec3(0);\n    vec3 lightDir = vec3(0);\n    vec3 vectorToLight = vec3(0);\n    \n    vec3 n = getDetailNormal(p, geoNormal, idx);\n    vec3 albedo = getAlbedo(p, n, idx);\n    float metalness = getMetalness(p, n, idx);\n    float roughness = getRoughness(p, n, metalness, idx);\n    \n    // Index of refraction for common dielectrics. Corresponds to f0 4%\n    float IOR = 1.5;\n\n    // Reflectance of the surface when looking straight at it along the negative normal\n    vec3 F0 = vec3(pow(IOR - 1.0, 2.0) / pow(IOR + 1.0, 2.0));\n    \n    float anisotropy = 0.0;\n    \n    // Metals tint specular reflections.\n    // https://docs.unrealengine.com/en-US/RenderingAndGraphics/Materials/PhysicallyBased/index.html\n    vec3 tintColour;\n    if(idx.x == 1.0 && idx.z == 1.0){\n        // Silver\n        tintColour = vec3(0.972, 0.960, 0.915);\n    }else if(idx.x == 1.0 && idx.z == 2.0){\n        // Copper\n        // Add darker circles\n        float weight = length(getTriplanar(8.0*(p.xxx+p.yyy+p.zzz), geoNormal));\n        tintColour = saturate(0.6 + max(0.2, weight)) * vec3(0.955, 0.637, 0.538);\n        anisotropy = -0.5;\n        // Remove normal mapping\n        n = geoNormal;\n    }else{\n        // Gold\n        // https://www.youtube.com/watch?v=j-A0mwsJRmk&ab_channel=ACMSIGGRAPH\n        tintColour = vec3(1.022, 0.782, 0.344);\n    }\n\n    F0 = mix(F0, tintColour, metalness);\n    \n    vec2 envBRDF = getBRDFIntegrationMap(vec2(dot_c(n, -rayDir), roughness), scaleSize);\n    // https://google.github.io/filament/Filament.html#materialsystem/improvingthebrdfs/energylossinspecularreflectance\n    vec3 energyCompensation = 1.0 + F0 * (1.0 / envBRDF.y - 1.0);\n    \n    // Anisotropy directions\n    vec3 tangent;\n    vec3 bitangent;\n    \n    if(anisotropy != 0.0){\n    \n        //Normalise position\n        vec3 pos = p - idx * vec3(CELL); \n\n        //Tangent and bitangent on a sphere have a nice solution given an orientation direction\n        //https://computergraphics.stackexchange.com/questions/5498/compute-sphere-tangent-for-normal-mapping\n        tangent = normalize(cross(vec3(1), pos));\n        bitangent = normalize(cross(geoNormal, tangent));\n    }\n    \n    // Find direct lighting for all sources\n    \n    #ifdef LIGHTS\n    for(int i = ZERO; i < 2; i++){\n        \n        vec3 position = getLightPosition(i);\n        vectorToLight = position-p;\n        lightDir = normalize(vectorToLight);\n        radiance = i == 0 ? 1.5 * lightColour : 1.0 * lightColour;\n        \n        float shadow = softShadow(p + n * EPSILON * 2.0, lightDir, MIN_DIST, length(vectorToLight), SHADOW_SHARPNESS);\n                                  \n        I +=  shadow \n            * BRDF(p, n, -rayDir, lightDir, albedo, metalness, roughness, F0, tangent, bitangent, anisotropy, energyCompensation) \n            * radiance \n            * dot_c(n, lightDir);\n    }\n\n    #endif\n    \n    // Find ambient diffuse IBL component\n    \n    vec3 F = fresnelSchlickRoughness(dot_c(n, -rayDir), F0, roughness);\n\tvec3 kD = (1.0 - F) * (1.0 - metalness);\n\tvec3 irradiance = AMBIENT_STRENGTH * getSHIrradiance(n);\n\tvec3 diffuse    = irradiance * albedo / PI;\n    \n    // Find ambient specular IBL component\n    \n    vec3 R;\n    \n    if(anisotropy == 0.0){\n        R = reflect(rayDir, n);\n    }else{      \n        R = getReflectedVector(rayDir, n, tangent, bitangent, roughness, anisotropy);\n    }\n    \n    vec3 prefilteredColor = getEnvironment(R, roughness, scaleSize);   \n    vec3 specular = prefilteredColor * mix(envBRDF.xxx, envBRDF.yyy, F0);\n    \n    specular *= energyCompensation;\n    \n\tvec3 ambient = kD * diffuse + specular;\n    \n    // Combine direct and IBL lighting\n    return ambient + I;\n}\n\n// https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/\nvec3 ACESFilm(vec3 x){\n    return clamp((x * (2.51 * x + 0.03)) / (x * (2.43 * x + 0.59) + 0.14), 0.0, 1.0);\n}\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n\n    // Read the size of the texture atlas and environment map\n    vec2 atlasSize = texelFetch(iChannel2, ivec2(5.5), 0).rg;\n    vec2 scaleSize = 1.0/(iResolution.xy/atlasSize);\n    \n    vec3 rayDir = rayDirection(60.0, fragCoord);\n\n    //----------------- Define a camera -----------------\n\n    vec3 cameraPos = texelFetch(iChannel0, ivec2(0.5, 1.5), 0).xyz;\n    vec3 targetDir = -cameraPos;\n    vec3 up = vec3(0.0, 1.0, 0.0);\n\n    // Get the view matrix from the camera orientation\n    mat3 viewMatrix = lookAt(cameraPos, targetDir, up);\n\n    // Transform the ray to point in the correct direction\n    rayDir = normalize(viewMatrix * rayDir);\n    \n    //---------------------------------------------------\n\n    vec3 p;\n    vec3 col;\n    \n    float distToLight = MAX_DIST;\n    \n    #ifdef LIGHTS\n        distToLight = distanceToScene(cameraPos, rayDir, MIN_DIST, MAX_DIST, false);\n    #endif\n    float t = distanceToScene(cameraPos, rayDir, MIN_DIST, distToLight, true);\n    \n    if(t < MAX_DIST){\n        p = cameraPos + rayDir * t;\n        vec3 normal = getNormal(p);\n        vec3 idx = getIndex(p);\n        if(t == distToLight){\n            col = lightColour;\n        }else{\n            col = EXPOSURE * getIrradiance(p, rayDir, normal, idx, scaleSize);\n            #ifdef TONEMAPPING\n                col = ACESFilm(col);\n            #endif\n        }\n    } else {\n        col = getEnvironment(rayDir, scaleSize);\n        #ifdef DISPLAY_DIFFUSE_SH\n            col = getSHIrradiance(rayDir);\n        #endif\n    }\n      \n    vec2 uv = fragCoord.xy/iResolution.xy;\n\n    #ifdef DISPLAY_ENVIRONMENT_MAP\n        col = texture(iChannel1, uv*scaleSize).rgb;\n    #endif\n    \n    #ifdef DISPLAY_SPECULAR_MAPS\n        col = texture(iChannel2, uv*scaleSize).rgb;\n    #endif\n    \n    col = gamma(col);\n    \n    fragColor = vec4(col,1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Track mouse movement and resolution change between frames and set camera position.\n\n#define CAMERA_DIST 20.0\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    \n    // Work with just the first four pixels.\n    if((fragCoord.x == 0.5) && (fragCoord.y < 4.0)){\n        \n        vec4 oldData = texelFetch(iChannel0, ivec2(0.5), 0).xyzw;\n\n        vec2 oldPolarAngles = oldData.xy;\n        vec2 oldMouse = oldData.zw;\n\n        vec2 polarAngles = vec2(0);\n        vec2 mouse = iMouse.xy / iResolution.xy; \n        \n        // Stop camera going directly above and below\n        float angleEps = 0.01;\n\n        float mouseDownLastFrame = texelFetch(iChannel0, ivec2(0.5, 3.5), 0).x;\n        \n        // If mouse button is down and was down last frame.\n        if(iMouse.z > 0.0 && mouseDownLastFrame > 0.0){\n            \n            // Difference between mouse position last frame and now.\n            vec2 mouseMove = mouse - oldMouse;\n            polarAngles = oldPolarAngles + vec2(5.0, 3.0) * mouseMove;\n            \n        }else{\n            polarAngles = oldPolarAngles;\n        }\n        \n        polarAngles.x = modulo(polarAngles.x, 2.0 * PI - angleEps);\n        polarAngles.y = min(PI - angleEps, max(angleEps, polarAngles.y));\n\n        // Store mouse data in the first pixel of Buffer A.\n        if(fragCoord == vec2(0.5, 0.5)){\n            // Set value at first frames.\n            if(iFrame < 10){\n                polarAngles = vec2(PI / 4.0, 1.33);\n                mouse = vec2(0);\n            }\n            fragColor = vec4(polarAngles, mouse);\n        }\n\n        // Store camera position in the second pixel of Buffer A.\n        if(fragCoord == vec2(0.5, 1.5)){\n            // Cartesian direction from polar coordinates.\n            vec3 cameraPos = normalize(vec3(-cos(polarAngles.x) * sin(polarAngles.y), \n                                             cos(polarAngles.y), \n                                            -sin(polarAngles.x) * sin(polarAngles.y)));\n\n            fragColor = vec4(CAMERA_DIST * cameraPos, 1.0);\n        }\n        \n        // Store resolution change data in the third pixel of Buffer A.\n        if(fragCoord == vec2(0.5, 2.5)){\n            float resolutionChangeFlag = 0.0;\n            // The resolution last frame.\n            vec2 oldResolution = texelFetch(iChannel0, ivec2(0.5, 2.5), 0).yz;\n            \n            if(iResolution.xy != oldResolution){\n            \tresolutionChangeFlag = 1.0;\n            }\n            \n        \tfragColor = vec4(resolutionChangeFlag, iResolution.xy, 1.0);\n        }\n           \n        // Store whether the mouse button is down in the fourth pixel of Buffer A\n        if(fragCoord == vec2(0.5, 3.5)){\n            if(iMouse.z > 0.0){\n            \tfragColor = vec4(vec3(1.0), 1.0);\n            }else{\n            \tfragColor = vec4(vec3(0.0), 1.0);\n            }\n        }\n        \n    }\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"XsfGzn","filepath":"/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","previewfilepath":"/media/ap/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","type":"cubemap","channel":2,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"/*\n\n    Diffuse IBL using spherical harmonics\n\n    Read the environment map and calculate 9 spherical harmonics coefficients for each channel.\n    The coefficients will describe the low frequency data of the environment. We can use them\n    to construct a matrix which, when multiplied with a view vector, will give the data in \n    that direction. The low frequency data is similar to a convoluted irradiance map and is \n    used for diffuse image based lighting, which gives us the ambient colour for shading. \n\n    Based on:\n    [1] https://cseweb.ucsd.edu/~ravir/papers/envmap/envmap.pdf\n    [2] http://orlandoaguilar.github.io/sh/spherical/harmonics/irradiance/map/2017/02/12/SphericalHarmonics.html\n    [3] https://metashapes.com/blog/realtime-image-based-lighting-using-spherical-harmonics/\n    [4]\thttps://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere/26127012#26127012\n    [5] https://bduvenhage.me/geometry/2019/07/31/generating-equidistant-vectors.html\n    [6] https://andrew-pham.blog/2019/08/26/spherical-harmonics/\n    [7] http://www.cse.chalmers.se/~uffe/xjobb/Readings/GlobalIllumination/Spherical%20Harmonic%20Lighting%20-%20the%20gritty%20details.pdf\n\n    This tab writes the matrix from equation 12 of [1] used in lighting calculations later.\n    We also store an equirectangular projection of the environment map and track cubemap change.\n\n    Notes:\n    - Most implementations use coefficients instead of matrices. We are assuming that matrix \n      vector multiplication is more efficient on GPUs (also compacts the code)\n    - Matrices need 16 * 3 floats for RGB whereas coefficients need 9 * 3\n    - There is a proposed GLTF extension which would include SH coefficients\n    - The matrices are symmetric, so column/row majority does not change the result\n\n    - SH works well in environments where the light strength has a uniform distribution. In \n      scenes with a very strong light source (like the Sun in an HDR file) SH will produce \n      ringing. These artefacts are caused by the Gibbs phenomenon where the coefficents turn \n      negative. Visually this leads to dark rings and a bright spot opposite the strong light\n      source. One fix is to use a windowing function but this increases the total brightness.\n      Reading SH values from a lower MIP level (or convolved map) can blur the result and \n      reduce ringing (while also increasing total brightness). A pre-convolved \n      diffuse environment map can be used instead of SH.\n\n      Alternatively spherical gaussians can be used instead of SH:\n      https://therealmjp.github.io/posts/sg-series-part-5-approximating-radiance-and-irradiance-with-sgs/\n\n*/\n\n// Constants cn from equation 12 in [1]\nconst float c1 = 0.429043;\nconst float c2 = 0.511664;\nconst float c3 = 0.743125;\nconst float c4 = 0.886227;\nconst float c5 = 0.247708;\n\n// First 9 spherical harmonics coefficients from equation 3 in [1]\nconst float Y00 = 0.282095;\nconst float Y1n = 0.488603; // 3 direction dependent values\nconst float Y2n = 1.092548; // 3 direction dependent values\nconst float Y20 = 0.315392;\nconst float Y22 = 0.546274;\n\nvec3 getRadiance(vec3 dir){\n    // Shadertoy textures are gamma corrected. Undo for lighting calculations.\n    vec3 col = inv_gamma(texture(iChannel2, dir).rgb);\n    // Add some bloom to the environment\n    col += 0.5 * pow(col, vec3(2));\n    return col;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n    vec3 currentColour = texture(iChannel2, vec3(1,1,1)).rgb;\n\n    bool cubemapChangedFlag = texelFetch(iChannel1, ivec2(4.5, 4.5), 0).rgb != currentColour;\n    //bool resolutionChanged = texelFetch(iChannel0, ivec2(0.5, 2.5), 0).r > 0.0;\n    \n    bool run = iFrame == 0 || cubemapChangedFlag;\n    \n    if(run){\n    \n        vec4 col = vec4(0);\n        \n        // Store an equirectangular projection of the environment map. Subsequent code will\n        // overwrite specific pixels to store the SH matrices and state flags but this \n        // should not be visible in the final render.\n        vec2 texCoord = fragCoord.xy / iResolution.xy;\n        vec2 thetaphi = ((texCoord * 2.0) - vec2(1.0)) * vec2(PI, HALF_PI); \n        vec3 rayDir = vec3( cos(thetaphi.y) * cos(thetaphi.x), \n                           -sin(thetaphi.y), \n                            cos(thetaphi.y) * sin(thetaphi.x));\n\n        col = vec4(getRadiance(rayDir), 1.0);\n        // Ensure radiance is not 0\n        col.x = max(col.x, 1e-5);\n        col.y = max(col.y, 1e-5);\n        col.z = max(col.z, 1e-5);\n\n\n    //------------------------------------------------------------------------------------\n    //----------------------------------- BUG? -------------------------------------------\n    //------- It should be fragCoord.x < 3.0 because we write and read 3 matrices --------\n    //------- But that will give the wrong result and I can't figure out why -------------\n    //------------------------------------------------------------------------------------\n    //------------------------------------------------------------------------------------\n\n        if(fragCoord.x < 4.0 && fragCoord.y < 4.0){\n\n            // Coefficient values to accumulate\n            vec3 L00 = vec3(0);\n            vec3 L1_1 = vec3(0);\n            vec3 L10 = vec3(0);\n            vec3 L11 = vec3(0);\n\n            vec3 L2_2 = vec3(0);\n            vec3 L2_1 = vec3(0);\n            vec3 L20 = vec3(0);\n            vec3 L21 = vec3(0);\n            vec3 L22 = vec3(0);\n\n            // To make the sampling rate scalable and independent of the cubemap dimensions, \n            // we can sample a set number of equidistant directions on a sphere. While this is \n            // not doable for all number of directions, a good approximation is the Fibonacci \n            // spiral on a sphere.\n\n            // From [4]\n            // Golden angle in radians\n            float phi = PI * (3.0 - sqrt(5.0));\n            \n            // The loop should not run every frame but Windows FPS drops anyway. \n            // This seems to have fixed it\n            float sampleCount;\n            if(run){\n                sampleCount = iResolution.x < 2000.0 ? SH_SAMPLE_COUNT : SH_LOW_SAMPLE_COUNT;\n            }else{\n                sampleCount = 1.0;\n            }\n\n            for(float i = float(ZERO); i < sampleCount; i++){\n\n                float y = 1.0 - (i / sampleCount) * 2.0;\n                // Radius at y\n                float radius = sqrt(1.0 - y * y);  \n\n                // Golden angle increment\n                float theta = phi * i;\n\n                float x = cos(theta) * radius;\n                float z = sin(theta) * radius;\n\n                // Sample direction\n                vec3 dir = normalize(vec3(x, y, z));\n\n                // Envronment map value in the direction (interpolated)\n                vec3 radiance = getRadiance(dir);\n\n                // Accumulate value weighted by spherical harmonic coefficient in the direction\n                L00 += radiance * Y00;\n                L1_1 += radiance * Y1n * dir.y;\n                L10 += radiance * Y1n * dir.z;\n                L11 += radiance * Y1n * dir.x;\n                L2_2 += radiance * Y2n * dir.x * dir.y;\n                L2_1 += radiance * Y2n * dir.y * dir.z;\n                L20 += radiance * Y20 * (3.0 * pow(dir.z, 2.0) - 1.0);\n                L21 += radiance * Y2n * dir.x * dir.z;\n                L22 += radiance * Y22 * (pow(dir.x, 2.0) - pow(dir.y, 2.0));\n            }\n\n            // Scale the sum of coefficents on a sphere\n            float factor = 4.0*PI / sampleCount;\n\n            L00 *= factor;\n            L1_1 *= factor;\n            L10 *= factor;\n            L11 *= factor;\n            L2_2 *= factor;\n            L2_1 *= factor;\n            L20 *= factor;\n            L21 *= factor;\n            L22 *= factor;\n\n            // Write three 4x4 matrices to bufferB\n            // GLSL matrices are column major\n            int idxM = int(fragCoord.y-0.5);\n\n            if(fragCoord.x == 0.5){\n                mat4 redMatrix;\n                redMatrix[0] = vec4(c1*L22.r, c1*L2_2.r, c1*L21.r, c2*L11.r);\n                redMatrix[1] = vec4(c1*L2_2.r, -c1*L22.r, c1*L2_1.r, c2*L1_1.r);\n                redMatrix[2] = vec4(c1*L21.r, c1*L2_1.r, c3*L20.r, c2*L10.r);\n                redMatrix[3] = vec4(c2*L11.r, c2*L1_1.r, c2*L10.r, c4*L00.r-c5*L20.r);\n                col = redMatrix[idxM];\n            }\n\n            if(fragCoord.x == 1.5){\n                mat4 grnMatrix;\n                grnMatrix[0] = vec4(c1*L22.g, c1*L2_2.g, c1*L21.g, c2*L11.g);\n                grnMatrix[1] = vec4(c1*L2_2.g, -c1*L22.g, c1*L2_1.g, c2*L1_1.g);\n                grnMatrix[2] = vec4(c1*L21.g, c1*L2_1.g, c3*L20.g, c2*L10.g);\n                grnMatrix[3] = vec4(c2*L11.g, c2*L1_1.g, c2*L10.g, c4*L00.g-c5*L20.g);\n                col = grnMatrix[idxM];\n            }\n\n            if(fragCoord.x == 2.5){\n                mat4 bluMatrix;\n                bluMatrix[0] = vec4(c1*L22.b, c1*L2_2.b, c1*L21.b, c2*L11.b);\n                bluMatrix[1] = vec4(c1*L2_2.b, -c1*L22.b, c1*L2_1.b, c2*L1_1.b);\n                bluMatrix[2] = vec4(c1*L21.b, c1*L2_1.b, c3*L20.b, c2*L10.b);\n                bluMatrix[3] = vec4(c2*L11.b, c2*L1_1.b, c2*L10.b, c4*L00.b-c5*L20.b);\n                col = bluMatrix[idxM];\n            }\n        }\n        \n        // Store a sample colour of the cubemap to detect load and change\n        if(fragCoord.x == 4.5 && fragCoord.y == 4.5){\n              col = vec4(texture(iChannel2, vec3(1,1,1)).rgb, 1.0);\n        }\n        \n        // Store the size of the render\n        if(fragCoord.x == 5.5 && fragCoord.y == 5.5){\n             col = vec4(iResolution.xy, 0.0, 1.0);\n        }\n        \n        fragColor = col;\n    }else{\n        // Reuse data\n        fragColor = texelFetch(iChannel1, ivec2(fragCoord.xy), 0);\n    }\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"/*\n    Copyright (c) 2021 al-ro\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in all\n    copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    SOFTWARE.\n*/\n\n#define PI 3.14159\n#define TWO_PI (2.0 * PI)\n#define HALF_PI (0.5 * PI)\n\n#define GAMMA 2.2\n#define INV_GAMMA (1.0/GAMMA)\n\n// When 1, we sample the environment map mip levels, getting more blurred results. \n// See changes in BufferC. \n// This can be used with HDR environment maps to get rid of fireflies in specular reflections.\n#define ENV_FILTERING 0\n\n#define SH_SAMPLE_COUNT 1024.0\n#define SH_LOW_SAMPLE_COUNT 128.0\n\n#define BRDF_SAMPLE_COUNT 1024\n#define BRDF_LOW_SAMPLE_COUNT 128\n\n#if ENV_FILTERING == 1\n    #define SAMPLE_COUNT 1024\n    #define LOW_SAMPLE_COUNT 128\n#else\n    #define SAMPLE_COUNT 1024\n    #define LOW_SAMPLE_COUNT 128\n#endif\n\n//  Variable iterator initializer to stop loop unrolling\n#define ZERO (min(iFrame,0))\n\n// Normal mapping will lead to an impossible surface where the view ray and normal dot product\n// is negative. Using PBR, this leads to negative radiance and black artefacts at detail \n// fringes. See \"Microfacet-based Normal Mapping for Robust Monte Carlo Path Tracing\" by \n// SchÃ¼ssler et al. for a discussion of a physically correct solution. \n// We just clamp the dot product with a normal to some small value.\nconst float minDot = 1e-5;\n\n// Clamped dot product\nfloat dot_c(vec3 a, vec3 b){\n\treturn max(dot(a, b), minDot);\n}\n\n// Get orthonormal basis from surface normal\n// https://graphics.pixar.com/library/OrthonormalB/paper.pdf\nvoid pixarONB(vec3 n, out vec3 b1, out vec3 b2){\n\tfloat sign_ = n.z >= 0.0 ? 1.0 : -1.0;\n\tfloat a = -1.0 / (sign_ + n.z);\n\tfloat b = n.x * n.y * a;\n\tb1 = vec3(1.0 + sign_ * n.x * n.x * a, sign_ * b, -sign_ * n.x);\n\tb2 = vec3(b, sign_ + n.y * n.y * a, -n.y);\n}\n\nvec3 gamma(vec3 col){\n\treturn pow(col, vec3(INV_GAMMA));\n}\n\nvec3 inv_gamma(vec3 col){\n\treturn pow(col, vec3(GAMMA));\n}\n\nfloat saturate(float x){\n    return max(0.0, min(x, 1.0));\n}\n\nfloat modulo(float m, float n){\n  return mod(mod(m, n) + n, n);\n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"/*\n\n    Specular IBL based on:\n\n    https://learnopengl.com/PBR/IBL/Specular-IBL\n    http://holger.dammertz.org/stuff/notes_HammersleyOnHemisphere.html\n    http://www.pbr-book.org/3ed-2018/Sampling_and_Reconstruction/The_Halton_Sampler.html\n    https://google.github.io/filament/Filament.html#annex/choosingimportantdirectionsforsamplingthebrdf\n    https://google.github.io/filament/Filament.html#lighting/imagebasedlights/distantlightprobes\n    https://google.github.io/filament/Filament.html#toc9.5\n\n    Precompute the specular irradiance maps for varying roughness values and lay them out as \n    equirectangular projections in a texture atlas.\n\n    For each roughness level we sample BufferB map in the specular lobe direction using a low \n    discrepancy sequence. The rougher the surface, the larger the specular lobe and the \n    blurrier the final image. \n\n    While the result should depend on both the view direction and the normal, we set these to \n    be equal. This results in wrong reflections especially as the view and normal angle \n    increases but it's an acceptable tradeoff for this approximating approach.\n\n    We also generate a BRDF integration map. This 2 channel image will store the BRDF value \n    based on the roughness of the surface and the angle between the normal and the view ray. \n    This does not depend on the environment map and can be calculated independently of any \n    scene.\n\n*/\n\nvec3 getEnvironment(vec3 rayDir, float level){\n    vec2 texCoord = vec2((atan(rayDir.z, rayDir.x) / TWO_PI) + 0.5, acos(rayDir.y) / PI);\n    return texture(iChannel1, texCoord, level).rgb;\n}\n\n// ------------- Hammersley sequence generation using radical inverse -------------\n\n//  http://holger.dammertz.org/stuff/notes_HammersleyOnHemisphere.html\n//  http://www.pbr-book.org/3ed-2018/Sampling_and_Reconstruction/The_Halton_Sampler.html\n\n//  While it looks like an arcane faerie incantation, it actually makes sense if you follow \n//  the references. Bring some tea.\n\nfloat radicalInverse(uint bits) {\n    bits = (bits << 16u) | (bits >> 16u);\n    bits = ((bits & 0x55555555u) << 1u) | ((bits & 0xAAAAAAAAu) >> 1u);\n    bits = ((bits & 0x33333333u) << 2u) | ((bits & 0xCCCCCCCCu) >> 2u);\n    bits = ((bits & 0x0F0F0F0Fu) << 4u) | ((bits & 0xF0F0F0F0u) >> 4u);\n    bits = ((bits & 0x00FF00FFu) << 8u) | ((bits & 0xFF00FF00u) >> 8u);\n    return float(bits) * 2.3283064365386963e-10; // / 0x100000000\n}\n\nvec2 hammersley(int i, int N){\n    return vec2(float(i)/float(N), radicalInverse(uint(i)));\n}\n\n// -------------------------------------------------------------------------------\n\n//  Return a world space sample vector based on a random hemisphere point, the surface normal\n//  and the roughness of the surface.\n//  https://google.github.io/filament/Filament.html#annex/choosingimportantdirectionsforsamplingthebrdf\n\n// From tangent-space vector to world-space sample vector\nvec3 rotateToNormal(vec3 L, vec3 N){\n    vec3 tangent;\n    vec3 bitangent;\n\n    pixarONB(N, tangent, bitangent);\n\n    tangent = normalize(tangent);\n    bitangent = normalize(bitangent);\n\n    return normalize(tangent * L.x + bitangent * L.y + N * L.z);\n}\n\n// Return a world-space halfway vector H around N which corresponds to the GGX normal\n// distribution. Reflecting the view ray on H will give a light sample direction\nvec3 importanceSampleGGX(vec2 Xi, vec3 N, float roughness){\n    float a = roughness*roughness;\n\n    // GGX importance sampling\n    float cosTheta = sqrt((1.0 - Xi.x) / (1.0 + (a * a - 1.0) * Xi.x));\n    float sinTheta = sqrt(1.0 - cosTheta * cosTheta);\n    float phi = Xi.y * 2.0 * PI;\n\n    vec3 L = normalize(vec3(cos(phi) * sinTheta, sin(phi) * sinTheta, cosTheta));\n\n    return rotateToNormal(L, N);\n}\n\n// Trowbridge-Reitz AKA GGX\nfloat distribution(float NdotH, float roughness){\n    float a2 = roughness * roughness;\n\treturn a2 /(PI * pow(NdotH * NdotH * (a2 - 1.0) + 1.0, 2.0));\n}\n\nvec3 getPreFilteredColour(vec3 N, float roughness, int sampleCount){\n    vec3 R = N;\n    vec3 V = R;\n    \n    float totalWeight = 0.0;\n    vec3 prefilteredColor = vec3(0.0);    \n    \n    // Generate sampleCount number of a low discrepancy random directions in the \n    // specular lobe and add the environment map data into a weighted sum.\n    for(int i = ZERO; i < sampleCount; i++){\n    \n        // Low discrepancy random point in uniform square\n        vec2 Xi = hammersley(i, sampleCount);\n        // Halfway vector\n        vec3 H = importanceSampleGGX(Xi, N, roughness);\n        // Light vector\n        vec3 L = normalize(reflect(-V, H));\n\n        float NdotL = dot_c(N, L);\n        \n        if(NdotL > 0.0){\n        \n            float level = 0.0;\n            \n        #if ENV_FILTERING == 1\n            // Sample the mip levels of the environment map\n            // https://placeholderart.wordpress.com/2015/07/28/implementation-notes-runtime-environment-map-filtering-for-image-based-lighting/\n            // Vectors to evaluate pdf\n            float NdotH = dot_c(N, H);\n            float VdotH = dot_c(V, H);\n\n            float pdf = distribution(NdotH, roughness*roughness) * NdotH / (4.0 * VdotH);\n\n            // Solid angle represented by this sample\n            float omegaS = 1.0 / (float(sampleCount) * pdf);\n\n            // This should be the size of a level 0 cubemap face. In practice, twice the \n            // resolution works better to get rid of fireflies in specular reflections. \n            // In the current shadertoy code we need another way to find the ratio of pixels\n            // at different levels. Not yet implemented.\n            float envMapSize = 512.0;\n            // Solid angle covered by 1 pixel\n            float omegaP = 4.0 * PI / (6.0 * envMapSize * envMapSize);\n            // Original paper suggests biasing the mip to improve the results\n            float mipBias = 1.0;\n            level = max(0.5 * log2(omegaS / omegaP) + mipBias, 0.0);\n        #endif\n        \n            prefilteredColor += getEnvironment(L, level) * NdotL;\n            totalWeight      += NdotL;\n        }\n    }\n    prefilteredColor = prefilteredColor / totalWeight;\n\n    return prefilteredColor;\n}\n\n// Schlick-Beckmann\nfloat geometry(float cosTheta, float k){\n\treturn (cosTheta) / (cosTheta * (1.0 - k) + k);\n}\n\nfloat smithShadowing(float NdotV, float NdotL, float roughness){\n    // IBL uses a different k than direct lighting\n    float k = (roughness * roughness) / 2.0; \n\treturn geometry(NdotV, k) * geometry(NdotL, k);\n}\n\n// https://google.github.io/filament/Filament.html#toc9.5\nvec2 integrateBRDF(float NdotV, float roughness, int sampleCount){\n    \n    // Surface normal\n    vec3 N = vec3(0.0, 0.0, 1.0);\n\n    // Generate view direction for fragment such that dot(N, V) is uv.x\n    vec3 V = normalize(vec3(sqrt(1.0 - NdotV * NdotV), 0.0, NdotV));\n\n    // To accumulate\n    vec2 result = vec2(0);\n    \n    for(int i = ZERO; i < sampleCount; i++){\n    \n        // Low discrepancy random point in uniform square\n        vec2 Xi = hammersley(i, sampleCount);\n        // Halfway vector\n        vec3 H = importanceSampleGGX(Xi, N, roughness);\n        // Light vector\n        vec3 L = normalize(reflect(-V, H));\n\n        float NdotL = dot_c(N, L);\n        float NdotH = dot_c(N, H);\n        float VdotH = dot_c(V, H);\n\n        if(NdotL > 0.0){\n            float G = smithShadowing(NdotV, NdotL, roughness);\n            float S = (G * VdotH) / (NdotH * NdotV);\n            \n            // Fresnel-Schlick\n            float F = pow(1.0 - VdotH, 5.0);\n\n            // Multiple scattering approach from Filament\n            result.x += F * S;\n            result.y += S;\n        }\n    }\n\n    return result / float(sampleCount);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n    vec3 currentColour = texelFetch(iChannel1, ivec2(4.5, 4.5), 0).rgb;\n\n    // If environment map has changed, we need to rerun the convolution\n    bool cubemapChangedFlag = texelFetch(iChannel2, ivec2(4.5, 4.5), 0).rgb != currentColour;\n    \n    // bool resolutionChanged = texelFetch(iChannel0, ivec2(0.5, 2.5), 0).r > 0.0;\n    \n    bool run = iFrame == 0 || iFrame == 10 || cubemapChangedFlag;\n    \n    if(run){\n    \n        // The loop should not run every frame but Windows FPS drops anyway. \n        // This seems to have fixed it (the shader, not Windows)\n        int sampleCount;\n        if(run){\n            sampleCount = iResolution.x < 2000.0 ? SAMPLE_COUNT : LOW_SAMPLE_COUNT;\n        }else{\n            sampleCount = 1;\n        }\n    \n        vec3 col = vec3(0);\n        float factor = 1.0/2.0;\n        float roughness = 0.0;\n        \n        if(fragCoord.y < 0.5*iResolution.y){\n            if(fragCoord.x > 0.5*iResolution.x){\n                factor = 1.0/4.0;\n                roughness = 0.25;\n            }    \n            if(fragCoord.x > 0.75*iResolution.x){\n                factor = 1.0/8.0;\n                roughness = 0.5;\n            }\n            if(fragCoord.x > 0.875*iResolution.x){\n                factor = 1.0/16.0;\n                roughness = 0.75;\n            }  \n            if(fragCoord.x > 0.9375*iResolution.x){\n                factor = 1.0/32.0;\n                roughness = 1.0;\n            }\n\n            vec2 texCoord = fragCoord.xy / (iResolution.xy * factor);\n            vec2 thetaphi = ((texCoord * 2.0) - vec2(1.0)) * vec2(PI, HALF_PI); \n            vec3 rayDir = vec3( cos(thetaphi.y) * cos(thetaphi.x), \n                               -sin(thetaphi.y), \n                                cos(thetaphi.y) * sin(thetaphi.x));\n            \n            // Don't do costly prefiltering for roughness 0 and perfect reflection\n            if(fragCoord.x < 0.5 * iResolution.x){\n                col = getEnvironment(rayDir, 0.0);\n            }else{\n                col = getPreFilteredColour(rayDir, roughness, sampleCount);\n            }    \n        }else{\n            if(fragCoord.x < 0.5*iResolution.x){\n                // Only render the BRDF in the first frames\n                if(iFrame == 0 || iFrame == 10){\n                    vec2 texCoord = vec2(2.0*fragCoord.x/iResolution.x, \n                                         2.0*(fragCoord.y/iResolution.y - 0.5));\n                    vec2 c = integrateBRDF(texCoord.x, texCoord.y, \n                    iResolution.x < 2000.0 ? BRDF_SAMPLE_COUNT : BRDF_LOW_SAMPLE_COUNT);\n                    col = vec3(c.x, c.y, 0.0);\n                }else{\n                    col = texture(iChannel2, fragCoord.xy/iResolution.xy).rgb;\n                }\n            }\n        }\n        // Store current colour of the environment map from BufferB to detect change\n        if(fragCoord.x == 4.5 && fragCoord.y == 4.5){\n             col = texelFetch(iChannel1, ivec2(4.5, 4.5), 0).rgb;\n        }\n        \n        // Store the size of the render\n        if(fragCoord.x == 5.5 && fragCoord.y == 5.5){\n             col = vec3(iResolution.xy, 0.0);\n        }\n        \n        fragColor = vec4(col, 1.0);\n        \n    }else{\n        fragColor = texture(iChannel2, fragCoord.xy/iResolution.xy);\n    } \n}","name":"Buffer C","description":"","type":"buffer"}]}
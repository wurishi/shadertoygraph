{"ver":"0.1","info":{"id":"lcjXzW","date":"1706114800","viewed":242,"name":"Temporal AO denoised","username":"kuranes","description":"Stabilize Denoise Temporal  AO WIP\n- 16 AO samples per pixel \n- temporal accumulate result ( sum / count )\n- denoise (bilateral blur) and merge with previous frames\n","likes":17,"published":1,"flags":48,"usePreview":0,"tags":["blur","denoise","reprojection"],"hasliked":0,"parentid":"ldtGWl","parentname":"Temporal reprojection"},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// goal is \"self stabilized blur\" for AO\n//\n// https://developer.download.nvidia.com/video/gputechconf/gtc/2020/presentations/s22699-fast-denoising-with-self-stabilizing-recurrent-blurs.pdf\n// https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9985-exploring-ray-traced-future-in-metro-exodus.pdf\n//\n// UI\n// - Mouse Move for camera anim\n// - hit SPACE for cam anim\n// - X for objects anim\n// - C for disocclusion debug\n// - V for \"tangent plane\" reproj on/off\n//\n// Ref: https://www.shadertoy.com/view/ldtGWl (reproj scene)\n// Ref: https://www.shadertoy.com/view/mtlGDM (bilateral upsample)\n// Denoise Collection: https://www.shadertoy.com/playlist/7cffzS\n// \n//\n//-------------------------------------------------------------------------------------------------------\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n    \n    \n    vec4 a = texture(iChannel0,uv);\n    vec4 b = texture(iChannel1,uv);\n    vec4 c = texture(iChannel2,uv);\n    vec4 d = texture(iChannel3,uv);\n    \n   \n    vec3 color = vec3(0.0);\n    float flip = 0.0;\n    \n    if(a.x > -0.5)\n    {\n        flip =   (a.z > 1.0 ? 0.0 : 1.0);\n        // lerp(denoisedSignal, inputSignal, 0.5 * accumSpeed)\n        //color = vec3(pow(d.y / d.z, 1.0));\n        color = vec3(mix(a.y/ a.z, d.y / d.z, 0.5));\n        // TODO \n        // - keys for on/off  the diff\n        // - need to disable also in buffer A or reset\n        //     to no accumulate the \"blur\" for real diff\n        // diff\n        //if (uv.x < 0.5){\n        //    color = vec3(pow(a.y / a.z, 1.2));\n        //}\n        //else{\n        //    color = vec3(pow(d.y / d.z, 1.2));\n        //}\n    }\n    else\n    {\n        color = vec3(a.yzw);\n    }\n    \n        \n    vec4 buttons = texelFetch( iChannel0, ivec2(1,0), 0 );\n    if (buttons.z == 1.0)\n   \t\tcolor = mix(color, vec3(1.0) - color, flip);\n    \n    fragColor = vec4(color,1.0);\n\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dX3zn","filepath":"/media/a/550a8cce1bf403869fde66dddf6028dd171f1852f4a704a465e1b80d23955663.png","previewfilepath":"/media/ap/550a8cce1bf403869fde66dddf6028dd171f1852f4a704a465e1b80d23955663.png","type":"cubemap","channel":2,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"\n// computes ambient occlusion ammount on the scene;\n// (nudged a lot toward \"up\" of the scene, no \"grazing ray\")\n\n// RETURNS:\n// - R: depth map\n// - G: AO \n// - B: sample count\n\n\n// TODO: \n// - motion vectors (plus tricks around it)\n// - reset on camera anim on/off  (buffer A)\n// - key switch between depth or bilateral upsample (buffer D)\n// - key +/- depth sigma (buffer C)\n// - VS spatio-termporal reservoir ?\n// - Solve the Buffer Count problem (need to AO in half res really... drop DAU? )\n// - Add classic Taa on top (scene TAA, variance clipping etc)\n\n// UI: store data in bottom left pixel\n// - previous camera\n// - keys pressed and latency key buffering \n// - key +/- depth sigma (buffer C)\n\n//-------------------------------------------------------------------------------------------------------\nfloat \tcompute_ao(intersection_info i,vec2 uv, int frame)\n{\n    float ao = 0.0;\n    const float count = SAMPLE_COUNT;\n\n    ray r;\n    r.point = i.pos_ws - i.normal_ws * 0.02;\n\n    for(float x = 0.0; x < count; x += 1.0)\n    {\n        r.dir = random_hemisphere_direction(i.normal_ws,vec2_n1rand(uv,x, iTime));\n        // nudge toward top\n        r.dir =  normalize(r.dir + vec3(0.0, 0.0, 0.45));\n        intersection_info j = scene(r, i.dist_id.y, 0.5, frame);\n        if(abs(j.dist_id.y - i.dist_id.y) > 0.5)\n        {\n            ao += 1.0;\n        }\n    }\n\n    ao /= count;\n\n    return (1.0 - ao);\n}\n\n//-------------------------------------------------------------------------------------------------------\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\n    vec4 buttons = get(vec2(1.0,0.0),  iChannel0);\n\n   \n    float rot = 0.0;\n    float height = 0.5;\n\n    if (iMouse.x > 0.0 && iMouse.y > 0.0){\n        rot = iMouse.x * 20.0 / iChannelResolution[0].x;\n        height = iMouse.y * 5.0 / iChannelResolution[0].y - 1.0;\n    }\n\n    if(iMouse.z < 0.5)\n    {\n        if (buttons.x == 1.0){\n            rot = -(iTime - 7.0) * 0.2;\n            height = 0.5;\n        }\n    \n    }\n\n\n\n    vec3 camera_position = vec3(cos(rot),sin(rot),height) * 20.0;\n    \n    \n    if(fragCoord.y < 1.0 && fragCoord.x < 4.0)\n    {\n        \n        //---------------------------------------------------------\n        // UI stuff\n        if(iFrame == 0)\n        {\n            fragColor = vec4(0.0);\n        }\n        else\n        {\n            vec2 pixel_size = vec2(1.0) / iChannelResolution[0].xy;\n\n            // prevent too fast state   \n            vec4 toggleFrame = get(vec2(2.0,0.0), iChannel0);\n\n            if (int(toggleFrame.x) + 20 < iFrame ){\n            \n                // TODO: store rot + height for real pause on \"space\"\n                if (keyPress(32, iChannel1)){ // SPACE for camera rotation\n                    buttons.x = buttons.x == 1.0 ? 0.0 : 1.0;\n                    toggleFrame.x = float(iFrame);\n                }\n                if (keyPress(88, iChannel1)){ // X for object anumation\n                    buttons.y = buttons.y == 1.0 ? 0.0 : 1.0;\n                    toggleFrame.x = float(iFrame);\n                }\n                if (keyPress(67, iChannel1)){ // C for disocclusion debug\n                    buttons.z = buttons.z == 1.0 ? 0.0 : 1.0;\n                    toggleFrame.x = float(iFrame);\n                }\n                if (keyPress(86, iChannel1)){ // V for tangent plane trick\n                    buttons.w = buttons.w == 1.0 ? 0.0 : 1.0; \n                    toggleFrame.x = float(iFrame);\n                }\n            }\n\n        \n            //store new position\n            write(vec4(camera_position,0.0),vec2(0.0,0.0),fragColor,fragCoord);\n            write(buttons,vec2(1.0,0.0),fragColor,fragCoord);\n            write(toggleFrame,vec2(2.0,0.0),fragColor,fragCoord);\n        }\n        \n        return;\n        \n    }else{\n        //---------------------------------------------------------\n        // AO\n    \n        vec2 uv = fragCoord.xy / iResolution.xy;\n\n\n        float aspect = iResolution.x / iResolution.y;\n\n        uv = uv * 2.0 - 1.0;\n\n        uv.x *= aspect;\n\n        //uv.x -> [-1;1] * aspect ratio;\n        //uv.y -> [-1;1]\n\n        //read from bufferA\n\n        vec3 old_camera_position = get(vec2(0.0,0.0), iChannel0).xyz;\n\n        //compute current ray:\n        ray r = screen_space_to_world_space(camera_position,vec3(0.0),uv);\n\n        vec4 frame = vec4(0.0);\n        //intersect scene and compute AO:\n        intersection_info i;\n        intersection_info iOld;\n        int frameNum = 0;\n        if (buttons.g == 1.0)   { \n            frameNum = iFrame;\n            //intersect scene and compute AO:\n            i = scene(r, -1.0, 1.5, frameNum);\n            // old frame position of animated objects\n            iOld = scene(r, -1.0, 1.5, frameNum - 1);\n        }\n        else{\n            //intersect scene and compute AO:\n            i = scene(r, -1.0, 1.5, frameNum);\n            // old frame position\n            iOld = i;\n        }\n    \n        if(i.dist_id.y > -0.5)\n        {\n            frame.x = i.dist_id.x;\n            // frameNum to move the object here too\n            frame.y = compute_ao(i,uv, frameNum);\n            frame.z = 1.0; // history reset\n\n            //---------------------------------------------------------\n            // reprojection and temporal merge\n            // - try to accumulate samples by reprojection:\n            // - get previous UV at old position\n            vec3 reproj_uv = world_space_to_screen_space(old_camera_position,vec3(0.0),iOld.pos_ws);\n            vec2 reproj_uv01 = reproj_uv.xy;\n            reproj_uv01.x /= aspect;\n            reproj_uv01 = reproj_uv01 * 0.5 + 0.5;\n\n            if(\treproj_uv01.x > 0.0 && reproj_uv01.x < 1.0 && \n                reproj_uv01.y > 0.0 && reproj_uv01.y < 1.0 &&\n                reproj_uv.z > -0.5\n              )\n            {\n                //we are using old viewport v\n                vec4 old_pixel = texture(iChannel0,reproj_uv01);\n                if(old_pixel.x > 0.0)\n                {\n                    // compute old pos at previous xy\n                    ray oldray = screen_space_to_world_space(old_camera_position,vec3(0.0),reproj_uv.xy);\n                    vec3 old_pos_ws = oldray.point + oldray.dir * old_pixel.x;\n\n                     // tangent trick plane per default\n                    float ofs;\n                    vec4 buttons = get(vec2(2.0,2.0),   iChannel0);\n                    \n                    if (buttons.w == 0.0){ \n                        // slide 44 \n                        // https://developer.download.nvidia.com/video/gputechconf/gtc/2020/presentations/s22699-fast-denoising-with-self-stabilizing-recurrent-blurs.pdf\n                        float distToPlane = dot(iOld.normal_ws, old_pos_ws - i.pos_ws);\n                        ofs = abs( distToPlane );\n\n                    }\n                    else { \n                        ofs = length(old_pos_ws - i.pos_ws);\n                    }\n                    if( ofs < REPROJ_DELTA)\n                    {\n                        frame.y += old_pixel.y; //accumulate ao\n                        frame.z += old_pixel.z; //add previous sample count\n                        \n                        // \n                        // https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9985-exploring-ray-traced-future-in-metro-exodus.pdf\n                        // slide 58\n                        frame.w = 1.0;\n                        //frame.w = step(ofs, REPROJ_DELTA);\n                        //frame.w = REPROJ_DELTA - ofs;\n                    }\n                    else{\n                        frame.w = 0.0;\n                    }\n\n\n                }\n            }\n\n        }\n        else\n        {\n            frame.x = -1.0;\n            frame.yzw = texture(iChannel2,r.dir).rgb;\n        }\n\n\n\n        fragColor = frame;\n    }\n    \n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"// goal is \"self stabilized blur\" for AO\n//\n// https://developer.download.nvidia.com/video/gputechconf/gtc/2020/presentations/s22699-fast-denoising-with-self-stabilizing-recurrent-blurs.pdf\n// https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9985-exploring-ray-traced-future-in-metro-exodus.pdf\n//\n// UI\n// - Mouse Move for camera anim\n// - hit SPACE for cam anim\n// - X for objects anim\n// - C for disocclusion debug\n// - V for \"tangent plane\" reproj on/off\n//\n// Ref: https://www.shadertoy.com/view/ldtGWl (reproj scene)\n// Ref: https://www.shadertoy.com/view/mtlGDM (bilateral upsample)\n// Denoise Collection: https://www.shadertoy.com/playlist/7cffzS\n// \n//\n#define NEAR 2.0\n#define INF 1000.0\n#define MPI 3.1415926\n\n// depth delta for reproj acceptance\n#define REPROJ_DELTA 0.01\n// Ao sample per pixel (spp)\n#define SAMPLE_COUNT 1.0\n\n//-------------------------------------------------------------------------------------------------------\n// blur\nfloat Gaussian(float sigma, float x)\n{\n    return exp(-(x*x) / (2.0 * sigma*sigma));\n}\n\n//-------------------------------------------------------------------------------------------------------\n// UI\nbool keyPress(int ascii, sampler2D keyboard) { return (texture(keyboard,vec2((.5+float(ascii))/256.,0.25)).x > 0.); }\nfloat isTexel( vec2 coord, vec2 pos ) { vec2 d = abs(coord - pos - 0.5); return 0.5 - max(d.x,d.y); }\nvec4 get( in vec2 position, sampler2D tex )\n{\n    return texelFetch( tex, ivec2(position), 0 );\n}\nvoid write( in vec4 value, in vec2 position, inout vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = ( isTexel(fragCoord,position ) > 0.0 ) ? value : fragColor;\n}\n\n\n//-------------------------------------------------------------------------------------------------------\n//  Data for Buffer A \n//-------------------------------------------------------------------------------------------------------\nstruct ray\n{\n    vec3 point;\n    vec3 dir;\n};\n\nstruct intersection_info\n{\n    vec3 \tpos_ws;\n    vec3 \tnormal_ws;\n    vec2 \tdist_id;//if dist_id.y < 0.0 -> intersection is invalid; or if dist_id.x > FAR\n};\n    \n//-------------------------------------------------------------------------------------------------------\n// (re)projections  \n//-------------------------------------------------------------------------------------------------------\nray screen_space_to_world_space(vec3 camera_position,vec3 camera_target,vec2 uv)\n{\n    vec3 camera_dir = normalize(camera_target - camera_position);\n\tvec3 view_right = normalize(cross(vec3(0.0,0.0,1.0),camera_dir));\n    vec3 view_up = cross(camera_dir,view_right);\n    \n    ray r;\n    r.point = camera_position;\n    r.dir = normalize(camera_dir * NEAR + view_right * uv.x + view_up * uv.y);\n    \n    return r;\n}\n\n//returns xy->uv > [-1..1] (with aspect), z < 0 if invalid\nvec3 world_space_to_screen_space(vec3 camera_position,vec3 camera_target,vec3 position_ws)\n{\n    vec3 to_point = position_ws - camera_position;\n    vec3 to_point_nrm = normalize(to_point);\n    \n    vec3 camera_dir = normalize(camera_target - camera_position);\n\tvec3 view_right = normalize(cross(vec3(0.0,0.0,1.0),camera_dir));\n    vec3 view_up = (cross(camera_dir,view_right));\n    \n    vec3 fwd = camera_dir * NEAR;\n    \n    float d = dot(camera_dir,to_point_nrm);\n    if(d < 0.01)\n        return vec3(0.0,0.0,-1.0);\n    \n    d = NEAR / d;\n    \n    to_point = to_point_nrm * d - fwd;\n    \n    float x = dot(to_point,view_right);\n    float y = dot(to_point,view_up);\n    return vec3(x,y,1.0);\n}\n\n//-------------------------------------------------------------------------------------------------------\n// intersections  \n//-------------------------------------------------------------------------------------------------------\nvec2 intersect_sphere(vec3 ro, vec3 rd, float radius)\n{\n    float sq_radius = radius * radius;\n    float\t\trtl = dot(ro,ro);\n    if ( rtl <= sq_radius )\n        return vec2(INF,-INF); //inside sphere\n    float\t\tca = - dot(ro,rd);\n    if ( ca < 0.0 )\n        return vec2(INF,-INF); //ray is directed away from the sphere\n    float\t\thc = sq_radius - rtl + ( ca * ca );\n    if ( hc < 0.0 )\n        return vec2(INF,-INF);\n    hc = sqrt(hc);\n    return vec2(ca - hc,ca + hc);\n}\nvec2 intersect_box(vec3 ro, vec3 rd,vec3 _min,vec3 _max)\n{\n    vec3 start = (_min - ro) / rd;\n    vec3 end = (_max - ro) / rd;\n    \n    vec3 a = min(start,end);\n    vec3 b = max(start,end);\n    \n    return vec2(\n        \tmax(a.x,max(a.y,a.z)),\n    \t\tmin(b.x,min(b.y,b.z))\n        );\n}\nvec3 box_normal_from_point(vec3 point,vec3 box_extents)\n{\n\tvec3 normal = vec3(0.0);\n\tfloat m = INF;\n\tfloat d;\n\n\td = abs(box_extents.x - abs(point.x));\n\tif (d < m)\n\t{\n\t\tm = d;\n\t\tnormal = vec3(1.0,0.0,0.0) * sign(point.x);    // Cardinal axis for X\n\t}\n\n\td = abs(box_extents.y - abs(point.y));\n\tif (d < m)\n\t{\n\t\tm = d;\n\t\tnormal = vec3(0.0,1.0,0.0) * sign(point.y);    // Cardinal axis for Y\n\t}\n\n\td = abs(box_extents.z - abs(point.z));\n\tif (d < m)\n\t{\n\t\tm = d;\n\t\tnormal = vec3(0.0,0.0,1.0) * sign(point.z);    // Cardinal axis for Z\n\t}\n\n\treturn normal;\n}\n\nfloat intersect_sphere(inout intersection_info inf,float id, vec3 ro, vec3 rd,vec3 pos, float radius)\n{\n    vec2 d = intersect_sphere(ro - pos,rd,radius);\n    //intersection is closer and avoid self intersection:\n    if(d.x < d.y && d.x < inf.dist_id.x && abs(inf.dist_id.y - id) > 0.5)\n    {\n        inf.pos_ws = ro + rd * d.x;\n        inf.normal_ws = normalize(inf.pos_ws - pos);\n    \tinf.dist_id = vec2(d.x,id);\n        return 1.0;\n    }\n    return 0.0;\n}\nfloat intersect_box(inout intersection_info inf,float id, vec3 ro, vec3 rd,vec3 _min, vec3 _max)\n{\n    vec2 d = intersect_box(ro,rd,_min,_max);\n    if(d.x > d.y || d.x < 0.0)\n        return 0.0;\n    if(d.x < inf.dist_id.x && abs(inf.dist_id.y - id) > 0.5)\n    {\n        vec3 center = (_max + _min) / 2.0;\n        inf.pos_ws = ro + rd * d.x;\n        inf.normal_ws = box_normal_from_point(inf.pos_ws - center,_max - center);\n    \tinf.dist_id = vec2(d.x,id);\n        return 1.0;\n    }\n    return 0.0;\n}\n\n\n//-------------------------------------------------------------------------------------------------------\n// Scene  \n//-------------------------------------------------------------------------------------------------------\nintersection_info \tscene(ray r,float ignore_obj, float exit_value, int frameNum)\n{\n    intersection_info inf;\n    inf.dist_id = vec2(INF,ignore_obj);\n    \n    //spheres\n    if(intersect_sphere(inf,1.0,r.point,r.dir,\n        vec3(sin(float(frameNum) / 10.0) - 8.0,5.5,1.0),3.0) > exit_value) return inf;\n        \n    if(intersect_sphere(inf,2.0,r.point,r.dir,vec3(-4.0,12.0, 0.0),2.0) > exit_value) return inf;\n    \n    //boxes\n    if(intersect_box(inf,3.0,r.point,r.dir,vec3(-70.0),vec3(70.0,70.0,-2.0)) > exit_value) return inf;\n    if(intersect_box(inf,4.0,r.point,r.dir,vec3(-3.0,-4.0,-2.0),vec3(2.0,2.0,5.0)) > exit_value) return inf;\n    if(intersect_box(inf,5.0,r.point,r.dir,vec3(-4.2,-3.5,1.0),vec3(-3.0,-2.5,4.0)) > exit_value) return inf;\n    if(intersect_box(inf,6.0,r.point,r.dir,vec3(-3.0,2.0,-4.0),vec3(-2.0,3.5,0.0)) > exit_value) return inf;\n    \n    // Todo: handle disocclusion\n    if(intersect_box(inf,7.0,r.point,r.dir, \n        vec3(7.0,4.0,sin(float(frameNum) / 10.0) + 5.0),\n        vec3(9.0,9.0,sin(float(frameNum) / 10.0) + 1.0)) > exit_value) return inf;\n        \n        \n    if(intersect_box(inf,8.0,r.point,r.dir,vec3(7.0,-4.0,-1.5),vec3(12.0,0.0,2.0)) > exit_value) return inf;\n    \n    if(intersect_box(inf,9.0,r.point,r.dir,vec3(12.0,12.0,-4.0),vec3(13.0,13.0,10.0)) > exit_value) return inf;\n    \n    if(intersect_box(inf,10.0,r.point,r.dir,vec3(-30.0,-30.0,-4.0),vec3(30.0,-13.0,5.0)) > exit_value) return inf;\n    \n    \n    \n    return inf;\n}\n\n//-------------------------------------------------------------------------------------------------------\n// some random stuff\n//-------------------------------------------------------------------------------------------------------\nfloat nrand( vec2 n )\n{\n\treturn fract(sin(dot(n.xy, vec2(12.9898, 78.233)))* 43758.5453);\n}\nfloat n1rand( vec2 n, float iTime )\n{\n\tfloat t = fract( iTime );\n\tfloat nrnd0 = nrand( n + 0.07*t );\n\treturn nrnd0;\n}\nvec2 vec2_n1rand( vec2 n , float offset, float iTime )\n{\n\tfloat t = fract( iTime ) + offset;\n\tfloat nrnd0 = nrand( n + 0.07 * t );\n    float nrnd1 = nrand( n + 0.075 * (t + 1.0) );\n\treturn vec2(nrnd0,nrnd1);\n}\nvec3 random_sphere_direction(vec2 random_value)\n{\n\tfloat s = random_value.x * MPI * 2.0;\n\tfloat t = random_value.y * 2.0 - 1.0;\n\treturn vec3(sin(s), cos(s), t) / sqrt(1.0 + t * t);\n}\nvec3 random_hemisphere_direction(vec3 dir,vec2 random_value)\n{\n\tvec3 v = random_sphere_direction(random_value);\n\treturn v * sign(dot(v, dir));\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// Copyright © 2019 Michal 'spolsh' Klos\n// License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\n// RETURNS:\n// - R: depth map\n// - G: AO \n// - B: sample count\n\n// TODO:\n// - average or keep most signifiant ?\n\n\n\n// Downsample to half resolution to mimic postprocesses workflow\n//-------------------------------------------------------------------------------------------------------\nconst vec2 c_offset[4] = vec2[](\n    vec2(0., 0.),\n    vec2(0., 1.),\n    vec2(1., 0.),\n    vec2(1., 1.)\n);\n\n//-------------------------------------------------------------------------------------------------------\nvec4 MaxDepthDownsample(vec2 P)\n{\n    vec2 scaledP = 2.0*P;\n    vec2 c_textureSize = iChannelResolution[0].xy;\n\tvec2 c_texelSize = 1.0 / c_textureSize;\n    vec2 pixel = (floor( scaledP * c_textureSize + 0.5 ) / c_textureSize) - vec2(0.5*c_texelSize);\n    \n    vec4 depthMax = vec4(0.0, 0.0, 0.0, 0.0);\n    vec4 depthAverage = vec4(-100.0, 0.0, 0.0, 0.0);\n    \n    for (int i = min(iFrame,0); i < 4; i++) {\n        vec4 texSample = textureLod(iChannel0, pixel + c_texelSize * c_offset[i], 0.0);\n        depthAverage += texSample;\n        // keeps only the biggest Depth\n        if (texSample.r > depthMax.r) {\n            depthMax = texSample;\n        }\n    }\n    return depthAverage / 4.0;\n    //return depthMax;\n}\n\n//-------------------------------------------------------------------------------------------------------\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{    \n    fragColor = vec4(0.0);\n    vec2 uv = gl_FragCoord.xy/iResolution.xy;\n    if (uv.x > 0.5 || uv.y > 0.5) return;\n    \n    fragColor = MaxDepthDownsample(uv);\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"\n//   Bilateral Joined Gaussian Blur in half resolution.\n//\n//   This should be done in two passes (horizontal and vertical) \n// to do less texture samples but I already used all passes.\n//\n//   Gaussian filter is separable so filtering horizontally and then vertically \n// is equivalent of sampling in both directions like below.\n//   Bilateral filter is not separable but separable approximation\n// is often used in practice despite some minor artifacts.\n\nfloat g_sigmaX = 3.;\nfloat g_sigmaY = 3.;\nfloat g_sigmaV = 1.;\n\n// RETURNS:\n// - R: depth map\n// - G: AO \n// - B: sample count\n\n// TODO:\n// - key +/- depth sigma\n\n//-------------------------------------------------------------------------------------------------------\nvec4 JoinedBilateralGaussianBlur(vec2 uv, vec2 pixelSize)\n{   \n    const float c_halfSamplesX = 4.;\n\tconst float c_halfSamplesY = 4.;\n\n    float total = 0.0;\n    vec4 ret = vec4(0.0);\n\n    vec4 pivot = texture(iChannel0, uv);\n    \n    for (float iy = -c_halfSamplesY; iy <= c_halfSamplesY; iy++)\n    {\n        float fy = Gaussian( g_sigmaY, iy );\n        float offsety = iy * pixelSize.y;\n\n        for (float ix = -c_halfSamplesX; ix <= c_halfSamplesX; ix++)\n        {\n            float fx = Gaussian( g_sigmaX, ix ); \n            float offsetx = ix * pixelSize.x;\n            \n            vec4 value = texture(iChannel0, uv + vec2(offsetx, offsety));\n            \n            float w;\n            // w = abs(value.r  - pivot.r);\n            // float fv = Gaussian( g_sigmaV, w );\n            // w = fx*fy*fv;\n           \n            w = value.w;\n            total += w;\n            ret += w * value.rgba;\n        }\n    }\n    \n    return ret / total;\n    //return vec4(pivot.a, ret.g / total, pivot.b, pivot.a);\n    //return pivot;\n}\n  \n//-------------------------------------------------------------------------------------------------------\nvoid mainImage(out vec4 fragColor, vec2 fragCoord)\n{  \n    vec2 uv = gl_FragCoord.xy/iResolution.xy;\n    if (uv.x > 0.5 || uv.y > 0.5) {fragColor.xyz = vec3(0.0);return;}\n    \n    \n    g_sigmaV      = 0.0; // filter depth weight ( +/- to change power)\n    g_sigmaV     += 0.001;\n    float sigmaT  = 2.0;\n    \n    vec4 filtered = JoinedBilateralGaussianBlur(uv, 1.0 / iChannelResolution[0].xy);    \n    fragColor = filtered;\n}\n","name":"Buffer C","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XdfGR8","channel":0}],"code":"\n// . Joined Bilateral Gaussian blur. Raw SSAO samples from BufferC blurred based on depth values\n// . Joined Bilateral Upsampling (JBU) and Depth Aware Upsampling (DAU) comparison\n//\t\tBJU based on: https://johanneskopf.de/publications/jbu/paper/FinalPaper_0185.pdf\n//\t\t\t\t\t  https://bartwronski.com/2019/09/22/local-linear-models-guided-filter/\n//      DAU based on: http://developer.download.nvidia.com/assets/gamedev/files/sdk/11/OpacityMappingSDKWhitePaper.pdf\n\n\n// RETURNS:\n// - R: depth map\n// - G: AO \n// - B: sample count\n\n\n\nconst vec2 c_offset[4] = vec2[](\n    vec2(0., 0.),\n    vec2(0., 1.),\n    vec2(1., 0.),\n    vec2(1., 1.)\n);\n\n//-------------------------------------------------------------------------------------------------------\nvec4 DepthAwareUpsample(vec2 P)\n{ // based on Nearest-Depth-Filter: http://developer.download.nvidia.com/assets/gamedev/files/sdk/11/OpacityMappingSDKWhitePaper.pdf\n  //\t\t                        https://www.shadertoy.com/view/MllSzX\n\n    vec2 halfP = 0.5 * P;\n    vec2 c_textureSize = iChannelResolution[2].xy;\n\tvec2 c_texelSize = 1.0 / c_textureSize;\n    vec2 pixel = halfP * c_textureSize + 0.5;\n    vec2 f = fract(pixel);\n    pixel = (floor(pixel) / c_textureSize) - vec2(c_texelSize/2.0);\n\n    vec4 I = textureLod(iChannel0, P, 0.0);\n    \n    vec4 Z00 = textureLod(iChannel2, pixel + c_texelSize * c_offset[0], 0.0);\n    vec4 Z01 = textureLod(iChannel2, pixel + c_texelSize * c_offset[1], 0.0);\n    vec4 Z10 = textureLod(iChannel2, pixel + c_texelSize * c_offset[2], 0.0);\n    vec4 Z11 = textureLod(iChannel2, pixel + c_texelSize * c_offset[3], 0.0);\n    \n    vec4 tex00 = textureLod(iChannel2, pixel + c_texelSize * c_offset[0], 0.0);\n    vec4 tex01 = textureLod(iChannel2, pixel + c_texelSize * c_offset[1], 0.0);\n    vec4 tex10 = textureLod(iChannel2, pixel + c_texelSize * c_offset[2], 0.0);\n    vec4 tex11 = textureLod(iChannel2, pixel + c_texelSize * c_offset[3], 0.0);\n    \n    float diffZ00 = abs(I.w - Z00.w);\n    float diffZ01 = abs(I.w - Z01.w);\n\tfloat diffZ10 = abs(I.w - Z10.w);\n    float diffZ11 = abs(I.w - Z11.w);\n           \n    // depth discontinuity (edge) detections\n    float depthThreshold = 0.001;\n    if (diffZ00 < depthThreshold && \n        diffZ01 < depthThreshold && \n        diffZ10 < depthThreshold && \n        diffZ11 < depthThreshold) {\n                \n        // bilinear interpolation\n        return vec4( mix( mix( tex00, tex10, f.x ),\n                          mix( tex01, tex11, f.x ), f.y ));\n\n    } else {\n        \n        // pick sampler based on closest depth\n        vec4 tex = tex00;\n        float depthMinDiff = diffZ00;\n\n        if (diffZ01 < depthMinDiff) {\n            tex = tex01;\n            depthMinDiff = diffZ01;\n        }\n\n        if (diffZ10 < depthMinDiff) {\n            tex = tex10;\n            depthMinDiff = diffZ10;\n        }\n\n        if (diffZ11 < depthMinDiff) {\n            tex = tex11;\n            depthMinDiff = diffZ11;\n        }\n        \n        return tex;\n    }\n}\n\n//-------------------------------------------------------------------------------------------------------\nvec4 JoinedBilateralUpsample(vec2 P)\n{ // based on: https://johanneskopf.de/publications/jbu/paper/FinalPaper_0185.pdf\n  //           https://bartwronski.com/2019/09/22/local-linear-models-guided-filter/\n  //\t\t   https://www.shadertoy.com/view/MllSzX\n    \n    vec2 halfP = 0.5 * P;\n    vec2 c_textureSize = iChannelResolution[2].xy;\n\tvec2 c_texelSize = 1.0 / c_textureSize;\n    vec2 pixel = halfP * c_textureSize + 0.5;\n    vec2 f = fract(pixel);\n    pixel = (floor(pixel) / c_textureSize) - vec2(c_texelSize/2.0);\n    \n    vec4 I = textureLod(iChannel0, P, 0.0);\n        \n    vec4 Z00 = textureLod(iChannel1, pixel + c_texelSize * c_offset[0], 0.0);\n    vec4 Z01 = textureLod(iChannel1, pixel + c_texelSize * c_offset[1], 0.0);\n    vec4 Z10 = textureLod(iChannel1, pixel + c_texelSize * c_offset[2], 0.0);\n    vec4 Z11 = textureLod(iChannel1, pixel + c_texelSize * c_offset[3], 0.0);\n    \n    vec4 tex00 = textureLod(iChannel1, pixel + c_texelSize * c_offset[0], 0.0);\n    vec4 tex01 = textureLod(iChannel1, pixel + c_texelSize * c_offset[1], 0.0);\n    vec4 tex10 = textureLod(iChannel1, pixel + c_texelSize * c_offset[2], 0.0);\n    vec4 tex11 = textureLod(iChannel1, pixel + c_texelSize * c_offset[3], 0.0);\n       \n    float sigmaV = 0.002;\n    //    wXX = bilateral gaussian weight from depth * bilinear weight\n    float w00 = Gaussian( sigmaV, abs(I.w - Z00.w) ) * (1.-f.x) * (1.-f.y);\n    float w01 = Gaussian( sigmaV, abs(I.w - Z01.w) ) * (1.-f.x) *     f.y;\n    float w10 = Gaussian( sigmaV, abs(I.w - Z10.w) ) *     f.x  * (1.-f.y);\n    float w11 = Gaussian( sigmaV, abs(I.w - Z11.w) ) *     f.x  *     f.y;\n        \n\treturn vec4( (w00*tex00 + w01*tex01 + w10*tex10 + w11*tex11) / (w00+w01+w10+w11) );\n}\n\n//-------------------------------------------------------------------------------------------------------\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = gl_FragCoord.xy/iResolution.xy;\n    float gamma = 0.4545;\n\n    // TODO add buttons toggle\n    //fragColor = DepthAwareUpsample(uv);\n        \n    fragColor = JoinedBilateralUpsample(uv);\n    \n    \n    fragColor *= smoothstep(0.0, 0.001, abs(uv.x -0.25));\n    fragColor *= smoothstep(0.0, 0.001, abs(uv.x -0.50));\n    fragColor *= smoothstep(0.0, 0.001, abs(uv.x -0.75));\n    \n    gamma = 1.0;//4.0; // switch to exaggerate AO results   \n    \n   \n    fragColor = vec4( pow( fragColor.rgb, vec3(gamma) ), 1.0 );\n}","name":"Buffer D","description":"","type":"buffer"}]}
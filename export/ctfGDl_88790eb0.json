{"ver":"0.1","info":{"id":"ctfGDl","date":"1672626863","viewed":327,"name":"ReactionDiffusion2","username":"DigitalShadow","description":"Playing around some more with reaction diffusion effects. Should be audio reactive so long as the microphone initializes properly in Buffer A","likes":5,"published":3,"flags":36,"usePreview":0,"tags":["visualizer","reactiondiffusion","microphone"],"hasliked":0,"parentid":"mdjSzd","parentname":"Reaction Diffusion Visualizer"},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n\n    fragColor = texture(iChannel0, uv);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"XdXGRr","filepath":"/presets/mic.png","previewfilepath":"/presets/mic.png","type":"mic","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"#define PI2 6.28318530718\n#define M1 1597334677U\n#define M2 3812015801U\n\n\n//determines blob shape\nconst float blurSize1 = 4.0;\nconst float blurSize2 = 20.0;\n\n//monochrome fast blur\nfloat monoBlur(sampler2D channel, vec2 uv, vec2 scale, float step){\n    float result = 0.0;\n    int i=0;\n    vec2 d;\n    for(float y=-scale.y; y < scale.y; y+=step){\n    for(float x=-scale.x; x < scale.x; x+=step){\n        d = vec2(x, y);\n        result += texture(channel, uv + (d / iChannelResolution[0].xy)).r*(1.0-smoothstep(0.0, scale.y*2.0,  length(d)));\n\n        i++;\n    }}\n    return result / float(i);\n}\n\n//Fast Hash\n    float hash( uvec2 q ){\n    q *= uvec2(M1, M2); \n    uint n = (q.x ^ q.y) * M1;\n    return float(n) * (1.0/float(0xffffffffU));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n    //coordinates\n    vec2 uv = fragCoord/iResolution.xy;\n    vec2 uvR = (fragCoord - .5 * iResolution.xy)/iResolution.y;\n    float aspect = iResolution.x / iResolution.y;\n    \n    //noise and audio data\n    vec3 noise = vec3(1.0,1.0,1.0) * hash(uvec2(fragCoord*iTime));\n    noise.r = clamp(noise.r, 0.0, 1.0);\n    float fft = texture(iChannel1,vec2(length(uvR), 0.25)).r;\n    float wave = texture(iChannel1, vec2(uv.x, 0.75)).r;\n    \n    //lookup uv\n    vec2 uv2 = (uv - 0.5);\n    uv2 *= 0.999 * (1.0+(length(uv2/2.0) /300.0));\n    uv2 *= 1.0 - (.03 * fft) * (0.5 + 0.25 * smoothstep(length(vec2(aspect,1.0)) / 2.0, 0.0, length(uvR)));\n    uv2.x += (.0001 + .002 * fft) * sin(wave + iTime + uv2.y*10.0);\n    uv2.y += (.0001 + .002 * fft) * cos(wave + iTime + uv2.x*10.0);\n    uv2 = uv2 + 0.5;\n    \n    //feedback\n    vec3 prev = texture(iChannel0, uv2).rgb;\n   \n    //dymamic blur\n    float vB = blurSize2 - (blurSize2 * (0.5 + 0.5 * sin(iTime)) - blurSize1 - 2.0); \n    \n    //get two versions of blurred image\n    vec3 blur1 = vec3(monoBlur(iChannel0, uv2, vec2(blurSize1),blurSize1/4.0));\n    vec3 blur2 = vec3(monoBlur(iChannel0, uv2, vec2(vB),(vB)/6.0));\n    \n    //reaction diffusion\n    vec3 col = prev - (blur2 - blur1*0.999);\n\n    //seed with noise\n    //col -= (0.0 + 1.0*fft)/16.0;\n    col += (noise.r-0.5)/8.0;\n    \n    //prevent value runaway\n    col = clamp(col, 0.0, 1.0);\n\n    \n    // Output to screen\n    fragColor = vec4(col, 1.0);\n}","name":"Buffer A","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"7lSyDc","date":"1650319640","viewed":293,"name":"Raytracing 5 - Specular Buffer","username":"KylBlz","description":"This step adds MIS Direct and Indirect Phong Specular with surface sampling and reprojection. Indirect contributions are still 10x.","likes":14,"published":1,"flags":32,"usePreview":0,"tags":["ray","time","specular","tracing","buffer","reprojection","real"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// [Buffer A] Geometry buffer and camera controls\n// [Buffer B] Diffuse buffer with Geometry reprojection\n// [Buffer C] Specular buffer with Specular reprojection\n\nconst float brightness = 10.0;\n\n// Thanks Paniq\nvec3 linear_srgb(vec3 x) {\n    return mix(1.055*pow(x, vec3(1./2.4)) - 0.055, 12.92*x, step(x, vec3(0.0031308)));\n}\n\nvec3 srgb_linear(vec3 x) {\n    return mix(pow((x + 0.055)/1.055,vec3(2.4)), x / 12.92, step(x, vec3(0.04045)));\n}\n\n// Paniq's ACES fitted from https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl\nvec3 ACESFitted(vec3 color) {\n\t// ODT_SAT => XYZ => D60_2_D65 => sRGB\n    color = color * mat3(\n        0.59719, 0.35458, 0.04823,\n        0.07600, 0.90834, 0.01566,\n        0.02840, 0.13383, 0.83777\n    );\n    // Apply RRT and ODT\n    vec3 a = color * (color + 0.0245786) - 0.000090537;\n    vec3 b = color * (0.983729 * color + 0.4329510) + 0.238081;\n    color = a / b;\n\t// Back to color space\n    color = color * mat3(\n         1.60475, -0.53108, -0.07367,\n        -0.10208,  1.10813, -0.00605,\n        -0.00327, -0.07276,  1.07602\n    );\n    // Clamp to [0, 1]\n    return clamp(color, 0.0, 1.0);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    // this macro declares a bunch of variables\n    decodeAll(iChannel0, iChannel1);\n    // sample Diffuse buffer\n    vec4 dBuffer = texelFetch(iChannel1, ivec2(fragCoord.xy), 0);\n    // sample Specular buffer\n    vec4 sBuffer = texelFetch(iChannel2, ivec2(fragCoord.xy), 0);\n    \n    // apply first surface properties\n    mat3 surf = getSurface(ho, hl);\n    dBuffer.rgb *= surf[0] * surf[2].x;\n    sBuffer.rgb *= sqrt(surf[0]) * surf[2].y;\n    fragColor = sBuffer / floor(sBuffer.a) + dBuffer / floor(dBuffer.a);\n    fragColor.rgb = linear_srgb(ACESFitted(fragColor.rgb * brightness));\n    \n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"//////////////////////////////// Rendering Configuration ////////////////////////////////\n\n// always use biased sampling (fallback to unbiased ground truth)\n#define BIASED\n// raymarching steps\n#define STEPS 128\n// number of frames to reproject and smooth over time\n#define TEMPORALSMOOTHING 8\n\n// direct lit lambert surface\n#define SMP_DIRECT_LAMBERT 1\n// lambert surface lit lambert surface\n#define SMP_LAMBERT_SURFACE_LAMBERT 1\n// phong surface lit lambert surface\n#define SMP_LAMBERT_SURFACE_PHONG 1\n\n// direct lit phong surface\n#define SMP_DIRECT_PHONG 1\n// lambert surface lit phong surface\n#define SMP_PHONG_SURFACE_LAMBERT 1\n// phong surface lit phong surface\n#define SMP_PHONG_SURFACE_PHONG 1\n\n// unbiased light samples\n#define SMP_UNBIAS 1\n// bias sample weight to reduce initial unbiased variance\n#define BIAS_WEIGHT 1\n\n//////////////////////////////// Math Toolkit ////////////////////////////////\n\nconst float\teps = 0.001,     ieps = 0.999,   zfar = 50.0,       FOV = 2.0,\n            HPI = 1.5707963, PI = 3.1415926, TWOPI = 6.2831853, SQRT2 = 1.4142136, SC45 = 0.7071068;\nconst vec4 INIT_POS = vec4(4.8, 0.5, -9.5, 0.),\n    \t   INIT_ROT = vec4(0.2, 0.85, 0., 0.);\n\n// generate a unique value for each pixel/frame\nint genSeed(in int f, in ivec2 c, in ivec2 r) {\n    return (c.x + c.y*2 + f*17) + (c.x*1155 ^ c.y*1728);\n}\n\n// https://www.shadertoy.com/view/7dByR1\nvec3 weyl3(in int v) {\n    return fract(vec3(v*ivec3(53685, 43977, 36025)) / float(0xffffU));\n}\n\n// fudged a bit to cut it off close to the (0,1) interval\nvec3 logit3(in vec3 v) {\n    vec3 t = 0.988 * (v + 0.006);\n    return log(t / (1.0 - t)) * 0.221 + 0.5;\n}\n\nvoid basis(in vec3 n, out vec3 f, out vec3 r) {\n    float s = (n.z >= 0.0)? 1.0: -1.0;\n    float a = 1.0 / (s + n.z);\n    float b = -n.x*n.y*a;\n    f = vec3(1.0 - n.x*n.x*a*s, b*s, -n.x*s);\n    r = vec3(b, s - n.y*n.y*a, -n.y);\n}\n\nvec3 rotateXY(in vec3 p, in vec2 angle) {\n\tvec2 c = cos(angle), s = sin(angle);\n    vec3 o = p;\n\to.yz *= mat2(c.x, s.x, -s.x, c.x); \n    o.xz *= mat2(c.y, s.y, -s.y, c.y);\n\treturn o;\n}\n\n// linear angle of sphere at distance D with radius R\nfloat linearAngle(float d, float r) {\n    return asin(clamp(r/d, eps, ieps));\n}\n\n// solid angle of sphere given distance squared and radius squared\nfloat solidAngle(float d2, float r2) {\n    return (1.0 - sqrt(1.0 - clamp(r2/d2, 0.0, 1.0))) * TWOPI;\n}\n\nfloat Lambertian(in vec3 hn, in vec3 nlv) {\n    return max(eps, dot(nlv, hn));\n}\n\nfloat SchlickPhong(in vec3 rd, in vec3 hn, in vec3 nlv, in float r1, in float r2, in float gloss) {\n    vec3 rfl = reflect(rd, hn);\n   \tfloat r0 = (r1 - r2) / (r1 + r2);\n\tfloat schlick = mix(r0*r0, 1.0, pow(1.0 - min(1.0, dot(rfl, hn)), 5.0));\n    float phong = pow(max(eps, dot(nlv, rfl)), gloss);\n    return (1.0 + schlick) * phong;\n}\n\n// using gaussian distribution\nvec3 uniformSphere(int seed) {\n    vec3 rnd = logit3(weyl3(seed));\n    return rnd * 2.0 - 1.0;\n}\n\n// using normalized gaussian distribution\nvec3 uniformDir(int seed) {\n    return normalize(uniformSphere(seed));\n}\n\n// only one hemisphere\nvec3 uniformHemiDir(vec3 hn, int seed) {\n    vec3 rnd = uniformDir(seed);\n    return rnd * sign(dot(hn, rnd));\n}\n\n// cosine distribution\nvec3 cosHemiDir(vec3 hn, int seed) {\n    vec3 rnd = uniformDir(seed);\n    return normalize(hn + rnd * ieps);\n}\n\n// uniform sample cone\nvec3 uniformConeDir(vec3 lv, float lr, in int seed) {\n    vec3 rnd = weyl3(seed);\n    float sa = linearAngle(length(lv), lr);\n    float rad = sqrt(rnd.x) * tan(sa);\n    float tha = rnd.y * TWOPI;\n    vec3 r, u, nlv = normalize(lv);\n    basis(nlv, r, u);\n    return normalize(nlv + rad * (r * cos(tha) + u * sin(tha)));\n}\n\n//////////////////////////////// Scene Modeling ////////////////////////////////\n\nvec2 sdMin(in vec2 a, in vec2 b) {\n    if (a.x < b.x)\n        return a;\n    return b;\n}\n\n// Thanks iq and Dave Smith\nfloat smin( float a, float b, float k ) {\n    float h = max( k-abs(a-b), 0.0 )/k;\n    return min( a, b ) - h*h*k*0.25;\n}\n\nfloat smax(float a, float b, float k) {\n    return -smin(-a,-b,k);\n}\n\nfloat sdBox(in vec3 p, in mat3 o, in vec3 s) {\n    vec3 d = abs(p * o) - s;\n    return min(max(d.x, max(d.y, d.z)), 0.0) + length(max(d, 0.0));\n}\n\nconst int\n    LIGHT = 1,\n    FLOOR = 2,\n    WALL1 = 3,\n    BOX = 4,\n    WALL2 = 6,\n    CEIL = 7;\n\n// light parameters\nvec4 light = vec4(6.0, 5.0, -4.0, 1.0);\nvec3 lightColor = vec3(10.0, 9.0, 8.0);\n// plane parameters\nvec4 flr = vec4( 0.0, 1.0, 0.0, 0.0);\nvec4 cil = vec4( 0.0,-1.0, 0.0, 10.0);\nvec4 wa1 = vec4(-1.0, 0.0, 0.0, 10.0);\nvec4 wa2 = vec4( 0.0, 0.0, 1.0, 10.0);\n\nmat3 getSurface(in int ho, in vec3 hl) {\n    mat3 ret;\n    if (ho == LIGHT) {\n        ret[0] = vec3(1.0); // reflection color\n        ret[1] = lightColor; // emission color\n        ret[2] = vec3(1.0, 1.0, 0.0); // diffuse (x) specular (y)\n    } else if (ho == BOX) {\n        ret[0] = vec3(0.025 + 0.1 * float(int(floor(hl.x * 4.0) + floor(hl.y * 4.0) + floor(hl.z * 4.0)) & 1)); // reflection color\n        ret[1] = vec3(0.0); // emission color\n        ret[2] = vec3(1.0, 1.0, 0.0); // diffuse (x) specular (y)\n    } else if (ho < 1) {\n        \n    } else {\n        float refl = float(int(ho == FLOOR || ho == CEIL)) * (0.5 + float(int(floor(hl.x) + floor(hl.y) + floor(hl.z)) & 1)) * 0.2 + 0.8;\n        float matCol = float(ho);\n        float cm = cos(matCol) * 0.025;\n        float sm = sin(matCol) * 0.025;\n        ret[0] = vec3(0.05 + cm, 0.05 + sm, 0.05 - (cm + sm) * 0.25) * refl;\n        ret[1] = vec3(0.0); // emission color\n        ret[2] = vec3(refl, refl * 0.5, 0.0); // diffuse (x) specular (y)\n    }\n    // loose the average energy for the material, based on measurements from unbiased rendering\n    //ret[2] *= 0.07;\n    ret[2] *= 0.7;\n    return ret;\n}\n\nvec2 sdf(in vec3 l, in int o) {\n    vec2 d = vec2(zfar, 0.);\n    d = (o == FLOOR)? d: sdMin(d, vec2(dot(l, flr.xyz) + flr.w, FLOOR));\n    d = (o == CEIL )? d: sdMin(d, vec2(dot(l, cil.xyz) + cil.w, CEIL));\n    d = (o == WALL1)? d: sdMin(d, vec2(dot(l, wa1.xyz) + wa1.w, WALL1));\n    d = (o == WALL2)? d: sdMin(d, vec2(dot(l, wa2.xyz) + wa2.w, WALL2));\n    d = (o == LIGHT)? d: sdMin(d, vec2(length(l - light.xyz) - light.w, LIGHT));\n    d = (o == BOX  )? d: sdMin(d, vec2(sdBox(l - vec3(7.5, 0.93, -7.5), mat3(1.0), vec3(0.8)) - 0.1, BOX));\n    return d;\n}\n\n// Thanks Nimitz https://www.shadertoy.com/view/Xts3WM\nvec4 norcurv(in vec3 p, in float ep, in int io) {\n    vec2 e = vec2(-1., 1.)*ep;\n    float t1 = sdf(p + e.yxx, io).x, t2 = sdf(p + e.xxy, io).x;\n    float t3 = sdf(p + e.xyx, io).x, t4 = sdf(p + e.yyy, io).x;\n    return vec4(normalize(e.yxx*t1 + e.xxy*t2 + e.xyx*t3 + e.yyy*t4), (t1+t2+t3+t4 - 4.0*sdf(p, io).x)/(ep*ep));\n}\n\nvec2 march(in vec3 l, in vec3 rd, in int o) {\n    float t = 0.0;\n    vec2 sdSmp;\n    for (int i = 0; i < STEPS; ++i) {\n        sdSmp = sdf(l + rd * t, o);\n        t += sdSmp.x;\n        if (sdSmp.x < eps)\n            break;\n        if (t > zfar)\n            return vec2(zfar, 0.0);\n    }\n    return vec2(min(t, zfar), sdSmp.y);\n}\n\n//////////////////////////////// PDF only ////////////////////////////////\n\n// surface illuminated by a sphere light, returns sample direction XYZ, pdf W\nvec4 SphereLightPDF(in vec3 hl, in vec3 hn, in vec4 li, in int seed) {\n    vec3 lv = li.xyz - hl;\n    vec3 lambDir = uniformConeDir(lv, li.w, seed);\n    float lpdf = solidAngle(dot(lv,lv), li.w*li.w);\n    return vec4(lambDir, lpdf);\n}\n\n// surface illuminated by a lambertian surface, returns sample direction XYZ, pdf W\nvec4 LambertPlanePDF(in vec3 hl, in vec3 hn, in vec4 li, in vec4 pl, in int seed) {\n    // dot project light onto plane\n    vec3 d = li.xyz - pl.xyz * (dot(li.xyz, pl.xyz) + pl.w);\n    // surface to diffuse point d\n    vec3 dv = d - hl;\n    // diffuse point to light\n    vec3 ld = li.xyz - d;\n    // cosine sample disc on ground below\n    float frad = min(length(dv), length(ld)) * 0.9;\n    vec3 lambDir = uniformConeDir(dv, frad, seed);\n    // PDF book keeping\n    float lpdf = solidAngle(dot(dv,dv), frad*frad) / PI;\n    float g2pdf = Lambertian(pl.xyz, -lambDir);\n    return vec4(lambDir, lpdf * g2pdf);\n}\n\n// surface illuminated by a lambertian surface, returns sample direction XYZ, pdf W\nvec4 PhongPlanePDF(in vec3 hl, in vec3 hn, in vec4 li, in vec4 pl, in int seed) {\n    // get distance from each point to the plane\n    float a = dot(hl, pl.xyz) + pl.w;\n    float b = dot(li.xyz, pl.xyz) + pl.w;\n    // similar triangles, just use the ratio of side lengths\n    vec3 s = mix(hl - a*pl.xyz, li.xyz - b*pl.xyz, a / (a + b));\n    // surface to specular point s\n    vec3 sv = s - hl;\n    float lsv = sqrt(dot(sv, sv)) * li.w;\n    // specular point to light\n    vec3 ls = li.xyz - s;\n    // sample the image of the specular reflection on the surface TODO: implement roughness\n    vec3 ts = sv * sqrt(dot(ls, ls));\n    vec3 phongDir = uniformConeDir(ts, lsv, seed);\n    // PDF book keeping\n    float lpdf = solidAngle(dot(ts,ts), lsv*lsv) / PI;\n    float spdf = SchlickPhong(normalize(sv), -pl.xyz, normalize(ls), 1.0, 1.5, 5.0);\n    return vec4(phongDir, lpdf * spdf);\n}\n\n//////////////////////////////// sampling only ////////////////////////////////\n\n// marches the light, returns contribution RGB\nvec3 LightContribution(in vec3 hl, in int ho, in vec4 lvpdf) {\n    vec2 lm = march(hl, lvpdf.xyz, ho);\n    if (int(lm.y) == LIGHT)\n        return lightColor * lvpdf.w;\n    return vec3(0.0);\n}\n\n// marches the surface and light, returns contribution RGB\nvec3 LambertPlaneContrib(in vec4 lvpdf, in vec3 hl, in int ho, in vec4 pl, in int po, in vec4 li, in int seed) {\n    // diffuse plane sample\n    vec2 dres = march(hl, lvpdf.xyz, ho);\n    if (int(dres.y) != po)\n        return vec3(0.0);\n    // move off the surface a little bit\n    vec3 _hl = hl + lvpdf.xyz * dres.x + pl.xyz * eps;\n    vec3 _lv = li.xyz - _hl;\n    float _lv2 = dot(_lv, _lv);\n    // light sampling\n    vec3 sampleDir = uniformConeDir(_lv, li.w, seed);\n    vec3 lc = LightContribution(_hl, po, vec4(sampleDir, lvpdf.w));\n    mat3 surf = getSurface(po, _hl);\n    // surface emission, energy, color, light energy\n    return surf[1] + surf[2].x * surf[0] * lc;\n}\n\n// marches the surface and light, returns contribution RGB\nvec3 PhongPlaneContrib(in vec4 lvpdf, in vec3 hl, in int ho, in vec4 pl, in int po, in vec4 li, in int seed) {\n    // specular plane sample\n    vec2 sres = march(hl, lvpdf.xyz, ho);\n    if (int(sres.y) != po)\n        return vec3(0.0);\n    // move off the surface a little bit\n    vec3 _hl = hl + lvpdf.xyz * sres.x + pl.xyz * eps;\n    vec3 _lv = li.xyz - _hl;\n    float _lv2 = dot(_lv, _lv);\n    // light sampling\n    vec3 sampleDir = uniformConeDir(_lv, li.w, seed);\n    vec3 lc = LightContribution(_hl, po, vec4(sampleDir, lvpdf.w));\n    mat3 surf = getSurface(po, _hl);\n    // surface emission, energy, color, light energy\n    return surf[1] + surf[2].y * surf[0] * lc;\n}\n\n//////////////////////////////// Sampling Strategy ////////////////////////////////\n\n// do unbiased sampling (diffuse BRDF)\nvec3 UnbiasedLambertian(in vec3 hl, in vec3 hn, in int ho, in int seed) {\n    // unbiased sampling (GT)\n    vec3 smpUnbias = vec3(0.0);\n    for (int i = 0; i < SMP_DIRECT_LAMBERT; ++i) {\n        int si = seed + i;\n        // sample light\n        smpUnbias += LightContribution(hl, ho, vec4(cosHemiDir(hn, si), PI));\n    }\n    return smpUnbias /= float(SMP_DIRECT_LAMBERT);\n}\n\n// do unbiased sampling (specular BRDF)\nvec3 UnbiasedPhong(in vec3 rd, in vec3 hl, in vec3 hn, in int ho, in int seed) {\n    // unbiased sampling (GT)\n    vec3 smpUnbias = vec3(0.0);\n    for (int i = 0; i < SMP_DIRECT_LAMBERT; ++i) {\n        int si = seed + i;\n        // sample light\n        smpUnbias += LightContribution(hl, ho, vec4(reflect(rd, hn), 1.0)); // not sure, replace with cone sample based on roughness\n    }\n    return smpUnbias /= float(SMP_DIRECT_LAMBERT);\n}\n\n// unbiased diffuse\nvoid brdfLambertian(inout vec3 ro, inout vec3 rd, in vec3 hl, in vec3 hn, in int seed) {\n    ro = hl + hn * eps;\n    rd = cosHemiDir(hn, seed);\n}\n// unbiased specular\nvoid brdfPhong(inout vec3 ro, inout vec3 rd, in vec3 hl, in vec3 hn, in ivec3 seed) {\n    ro = hl + hn * eps;\n    rd = reflect(rd, hn); // not sure, replace with cone sample based on roughness\n}\n\n//////////////////////////////// Buffers ////////////////////////////////\n\nvoid encodeGbuffer(out vec4 val, in vec3 n, in int o, in float t) {\n    val = vec4(n * float(o), t);\n}\n\nvoid decodeGbuffer(in vec4 val, out vec3 n, out int o, out float t) {\n    t = val.w;\n    o = int(length(val.xyz)+eps);\n    n = val.xyz / float(o);\n}\n\nfloat encodeBuffer(in int o) {\n    return float(o) * 0.01001;\n}\n\nint decodeBuffer(in float a) {\n    return int(fract(a) * 100.1);\n}\n\n// use decodeAll macro below instead\nvoid _decodeAll(in vec2 fragCoord, in vec2 iResolution, in int iFrame, in sampler2D gBuffer, in sampler2D lastFrame, out float asp, out vec3 rl, out vec2 ro, out vec3 rd, out vec3 ll, out vec2 lo, out vec3 ld, out float vv, out vec3 hn, out int ho, out vec3 hl) {\n    asp = iResolution.x / iResolution.y;\n    vec2 ndca = (2.0 * fragCoord.xy / iResolution.xy - 1.0) * vec2(asp, 1.0);\n    // get current cam\n    if (iFrame > 1) {\n        rl = texelFetch(gBuffer, ivec2(0, int(iResolution.y) - 1), 0).xyz;\n        ro = texelFetch(gBuffer, ivec2(1, int(iResolution.y) - 1), 0).xy;\n        ll = texelFetch(lastFrame, ivec2(0, int(iResolution.y) - 1), 0).xyz;\n        lo = texelFetch(lastFrame, ivec2(1, int(iResolution.y) - 1), 0).xy;\n    }\n    rd = rotateXY(normalize(vec3(ndca, FOV)), ro);\n    ld = rotateXY(normalize(vec3(ndca, FOV)), lo);\n\tvv = length(rl - ll);\n    // get last trace\n    float ht;\n    decodeGbuffer(texelFetch(gBuffer, ivec2(fragCoord.xy), 0), hn, ho, ht);\n    hl = rl + rd * ht;\n}\n\n// defines variables for current ray, last ray, current hit, velocity, etc\n#define decodeAll(gBuffer, lastFrame) int ho; float asp, vv; vec2 ro = INIT_ROT.xy, lo = INIT_ROT.xy; vec3 rl = INIT_POS.xyz, ll = INIT_POS.xyz, rd, ld, hn, hl; _decodeAll(fragCoord.xy, iResolution.xy, iFrame, gBuffer, lastFrame, asp, rl, ro, rd, ll, lo, ld, vv, hn, ho, hl)\n\n// last loc, last orient, hit loc, hit object, 1/aspect, channel, resolution\nvec4 reprojectBuffer(in vec3 ll, in vec2 lo, in vec3 hl, in int ho, in float asp, sampler2D iChannel, in vec2 iChanRes) {\n    // last camera basis\n    vec3 lf = rotateXY(vec3(0.0, 0.0, 1.0), lo);\n    vec3 r = normalize(cross(lf, vec3(0.0, 1.0, 0.0)));\n    vec3 u = normalize(cross(lf, r));\n    // dir to point\n    vec3 nhl = normalize(ll - hl);\n    // project into last cam basis\n    vec2 luv = vec2(dot(nhl, r), dot(nhl, u));\n    // project onto imaging plane NDC coords\n    luv = (luv * FOV) / (dot(nhl, lf) * vec2(asp, 1.0));\n    // ndc to image pixel coords (minus half pixel, glsl uses 'pixel centers')\n    vec2 fuv = (luv * -0.5 + 0.5) * iChanRes - 0.5;\n    ivec2 iuv = ivec2(fuv);\n    // bounds check\n    if (any(greaterThan(iuv, ivec2(iChanRes)-1)) || any(lessThan(iuv, ivec2(0))))\n        return vec4(0.0);\n    vec2 a = clamp(fuv - vec2(iuv), vec2(0.0), vec2(1.0));\n    // samples with matching materials are considered\n    vec4 col   = texelFetch(iChannel, iuv, 0);\n    vec4 colx  = texelFetch(iChannel, iuv + ivec2(1, 0), 0);\n    vec4 coly  = texelFetch(iChannel, iuv + ivec2(0, 1), 0);\n    vec4 colxy = texelFetch(iChannel, iuv + ivec2(1, 1), 0);\n    float c1 = float(int(decodeBuffer(col.a) == ho));\n    float c2 = float(int(decodeBuffer(colx.a) == ho));\n    float c3 = float(int(decodeBuffer(coly.a) == ho));\n    float c4 = float(int(decodeBuffer(colxy.a) == ho));\n    // get number of samples that matched\n    float n = c1 + c2 + c3 + c4;\n    // fanciest mixing\n    if (n > 3.0)\n        return mix(mix(col/col.a, colx/colx.a, a.x), mix(coly/coly.a, colxy/colxy.a, a.x), a.y) * min(col.a, min(colx.a, min(coly.a, colxy.a)));\n    if (n < 1.0)\n        return vec4(0.0);\n    // fallback mixing\n    return (c1*col + c2*colx + c3*coly + c4*colxy);\n}\n","name":"Common","description":"","type":"common"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//////////////////////////////// Geometry Buffer ////////////////////////////////\n\nmat3 cameraPoses(in float t) {\n    float time = mod(t, 8.0);\n    if (time < 2.)\n        return mat3(vec3(4.8, 0.5, -9.5), vec3(0.2, 0.85, 0.), vec3(0.0));\n    else if (time < 4.)\n        return mat3(vec3(4.8, 0.5, -4.5), vec3(0.15, 2.4, 0.), vec3(0.0));\n    else if (time < 6.)\n        return mat3(vec3(4.5, 4.5, -7.5), vec3(-0.85, 1.2, 0.), vec3(0.0));\n    else if (time < 8.)\n        return mat3(vec3(-3.5, 2.5, -4.0), vec3(0.1, 1.8, 0.), vec3(0.0));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    \n    float asp = iResolution.x / iResolution.y;\n    vec2 ndca = (2.0 * fragCoord.xy / iResolution.xy - 1.0) * vec2(asp, 1.0);\n\n    // get current cam\n\tvec3 l = INIT_POS.xyz,\n         o = INIT_ROT.xyz;\n    if (iFrame > 1) {\n        // just smoothstep between some nice angles\n        float t = (float(iFrame) * 0.01666) * 0.5;\n        mat3 cLast = cameraPoses(t);\n        mat3 cNext = cameraPoses(t + 1.0);\n        float ft = fract(t);\n        ft = ft*ft*(3.0-2.0*ft);\n        l = mix(cLast[0], cNext[0], ft);\n        o = mix(cLast[1], cNext[1], ft);\n    }\n    vec3 d = rotateXY(normalize(vec3(ndca, FOV)), o.xy);\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(l, 0.0);\n            return;\n        } else if (x == 1) {\n            fragColor = vec4(o, 0.0);\n            return;\n        }\n    }\n    \n    // initial scene march\n    vec2 h = march(l, d, -1);\n    // get second closest object to ignore during normal computation\n    vec3 hl = l + d * h.x;\n    int ho = int(h.y);\n    int io = int(sdf(hl, ho).y);\n    // encode normal, object ID, and depth\n    vec4 ret = vec4(0.0);\n    encodeGbuffer(ret, norcurv(hl, eps, io).xyz, ho, h.x - eps);\n    fragColor = ret;\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"//////////////////////////////// Diffuse Buffer ////////////////////////////////\n\n// diffuse MIS\nvec3 DMIS(in vec3 hl, in vec3 hn, in int ho, in int si) {\n    vec3 ret = vec3(0.0);\n\n#if SMP_DIRECT_LAMBERT\n    // take direct light samples\n    vec3 smpDirect = vec3(0.0);\n    for (int i = 0; i < SMP_DIRECT_LAMBERT; ++i) {\n        si += 14;\n        // get all PDFs\n        vec4 dlpdf = SphereLightPDF(hl, hn, light, si);\n        // apply lambert pdf\n        dlpdf.w *= Lambertian(hn, dlpdf.xyz);\n        // compute CDF\n        //float lightCDF = dlpdf.w;\n        // roulette sampling\n        //vec3 rnd = weyl3(si.z) * lightCDF;\n        //if (rnd.z <= lightCDF) {\n            smpDirect += LightContribution(hl, ho, dlpdf); // * (lightCDF / max(eps, dlpdf.w));\n        //}\n    }\n    ret += smpDirect / float(SMP_DIRECT_LAMBERT);\n#endif\n\n#if SMP_LAMBERT_SURFACE_LAMBERT\n    // take indirect diffuse samples\n    vec3 smpIDD = vec3(0.0);\n    for (int i = 0; i < SMP_LAMBERT_SURFACE_LAMBERT; ++i) {\n        si += 14;\n        // get all PDFs\n        vec4 fdpdf = LambertPlanePDF(hl, hn, light, flr, si);\n        vec4 cdpdf = LambertPlanePDF(hl, hn, light, cil, si);\n        vec4 w1dpdf = LambertPlanePDF(hl, hn, light, wa1, si);\n        vec4 w2dpdf = LambertPlanePDF(hl, hn, light, wa2, si);\n        // apply lambert pdf\n        fdpdf.w *= Lambertian(hn, fdpdf.xyz);\n        cdpdf.w *= Lambertian(hn, cdpdf.xyz);\n        w1dpdf.w *= Lambertian(hn, w1dpdf.xyz);\n        w2dpdf.w *= Lambertian(hn, w2dpdf.xyz);\n        // compute CDF\n        float floorDiffCDF = fdpdf.w;\n        float ceilDiffCDF = floorDiffCDF + cdpdf.w;\n        float w1DiffCDF = ceilDiffCDF + w1dpdf.w;\n        float w2DiffCDF = w1DiffCDF + w2dpdf.w;\n        // roulette sampling\n        vec3 rnd = weyl3(si) * w2DiffCDF;\n        if (rnd.z <= floorDiffCDF)\n            smpIDD += LambertPlaneContrib(fdpdf, hl, ho, flr, FLOOR, light, si) * (w2DiffCDF / max(eps, fdpdf.w));\n        else if (rnd.z <= ceilDiffCDF)\n            smpIDD += LambertPlaneContrib(cdpdf, hl, ho, cil, CEIL, light, si) * (w2DiffCDF / max(eps, cdpdf.w));\n        else if (rnd.z <= w1DiffCDF)\n            smpIDD += LambertPlaneContrib(w1dpdf, hl, ho, wa1, WALL1, light, si) * (w2DiffCDF / max(eps, w1dpdf.w));\n        else\n            smpIDD += LambertPlaneContrib(w2dpdf, hl, ho, wa2, WALL2, light, si) * (w2DiffCDF / max(eps, w2dpdf.w));\n    }\n    ret += smpIDD / float(SMP_LAMBERT_SURFACE_LAMBERT);\n#endif\n\n#if SMP_LAMBERT_SURFACE_PHONG\n    // take indirect specular samples\n    vec3 smpIDS = vec3(0.0);\n    for (int i = 0; i < SMP_LAMBERT_SURFACE_PHONG; ++i) {\n        si += 14;\n        // get all PDFs\n        vec4 fspdf = PhongPlanePDF(hl, hn, light, flr, si);\n        vec4 cspdf = PhongPlanePDF(hl, hn, light, cil, si);\n        vec4 w1spdf = PhongPlanePDF(hl, hn, light, wa1, si);\n        vec4 w2spdf = PhongPlanePDF(hl, hn, light, wa2, si);\n        // apply lambert pdf\n        fspdf.w *= Lambertian(hn, fspdf.xyz);\n        cspdf.w *= Lambertian(hn, cspdf.xyz);\n        w1spdf.w *= Lambertian(hn, w1spdf.xyz);\n        w2spdf.w *= Lambertian(hn, w2spdf.xyz);\n        // compute CDF\n        float floorSpecCDF = fspdf.w;\n        float ceilSpecCDF = floorSpecCDF + cspdf.w;\n        float w1SpecCDF = ceilSpecCDF + w1spdf.w;\n        float w2SpecCDF = w1SpecCDF + w2spdf.w;\n        // roulette sampling\n        vec3 rnd = weyl3(si) * w2SpecCDF;\n        if (rnd.z <= floorSpecCDF)\n            smpIDS += PhongPlaneContrib(fspdf, hl, ho, flr, FLOOR, light, si) * (w2SpecCDF / max(eps, fspdf.w));\n        else if (rnd.z <= ceilSpecCDF)\n            smpIDS += PhongPlaneContrib(cspdf, hl, ho, cil, CEIL, light, si) * (w2SpecCDF / max(eps, cspdf.w));\n        else if (rnd.z <= w1SpecCDF)\n            smpIDS += PhongPlaneContrib(w1spdf, hl, ho, wa1, WALL1, light, si) * (w2SpecCDF / max(eps, w1spdf.w));\n        else\n            smpIDS += PhongPlaneContrib(w2spdf, hl, ho, wa2, WALL2, light, si) * (w2SpecCDF / max(eps, w2spdf.w));\n    }\n    ret += smpIDS / float(SMP_LAMBERT_SURFACE_PHONG);\n#endif\n\n    return ret;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    \n    bool biased = false;\n#ifdef BIASED\n    // force biased rendering\n    biased = true;\n#endif\n    // this macro declares a bunch of variables\n    decodeAll(iChannel0, iChannel1);\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(rl, 0.0);\n            return;\n        } else if (x == 1) {\n            fragColor = vec4(ro, 0.0, 0.0);\n            return;\n        }\n    }\n    \n    // reproject last frame onto this one\n    fragColor = reprojectBuffer(ll, lo, hl, ho, asp, iChannel1, iResolution.xy);\n    fragColor.a = floor(fragColor.a);\n    \n    // temporal smoothing\n    int lvv = min(TEMPORALSMOOTHING-1, int(float(TEMPORALSMOOTHING) * sqrt(length(vv))));\n    if (fragColor.a > float(TEMPORALSMOOTHING-lvv))\n        fragColor *= float(TEMPORALSMOOTHING-lvv) / fragColor.a;\n\n    // sample from surface\n    mat3 surf = getSurface(ho, hl);\n    // emissive\n    fragColor.rgb += surf[1];\n    // not nothing\n    if (ho != LIGHT) {\n        int seed = genSeed(iFrame, ivec2(fragCoord.xy), ivec2(iResolution.xy));\n        // do biased sampling\n        if (biased) {\n            // multiple importance sample lights and surfaces\n            fragColor.rgb += DMIS(hl, hn, ho, seed);\n        } else {\n            // unbiased sampling (GT)\n            fragColor.rgb += UnbiasedLambertian(hl, hn, ho, seed);\n        }\n    }\n#ifndef BIASED\n    if (biased)\n        fragColor *= float(BIAS_WEIGHT);\n#endif\n    fragColor.a += 1.0 + encodeBuffer(ho);\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"//////////////////////////////// Specular Buffer ////////////////////////////////\n\n// specular MIS\nvec3 SMIS(in vec3 rd, in vec3 hl, in vec3 hn, in int ho, in int si) {\n    vec3 ret = vec3(0.0);\n\n#if SMP_DIRECT_PHONG\n    // take direct light samples\n    vec3 smpDirect = vec3(0.0);\n    for (int i = 0; i < SMP_DIRECT_PHONG; ++i) {\n        si += 14;\n        // get all PDFs\n        vec4 dlpdf = SphereLightPDF(hl, hn, light, si);\n        // apply phong pdf\n        dlpdf.w *= SchlickPhong(rd, hn, dlpdf.xyz, 1.0, 1.5, 5.0);\n        // compute CDF\n        //float lightCDF = dlpdf.w;\n        // roulette sampling\n        //vec3 rnd = weyl3(si) * lightCDF;\n        //if (rnd.z <= lightCDF) {\n            smpDirect += LightContribution(hl, ho, dlpdf); // * (lightCDF / max(eps, dlpdf.p));\n        //}\n    }\n    ret += smpDirect / float(SMP_DIRECT_PHONG);\n#endif\n\n#if SMP_PHONG_SURFACE_LAMBERT\n    // take indirect diffuse samples\n    vec3 smpIDD = vec3(0.0);\n    for (int i = 0; i < SMP_PHONG_SURFACE_LAMBERT; ++i) {\n        si += 14;\n        // get all PDFs\n        vec4 fdpdf = LambertPlanePDF(hl, hn, light, flr, si);\n        vec4 cdpdf = LambertPlanePDF(hl, hn, light, cil, si);\n        vec4 w1dpdf = LambertPlanePDF(hl, hn, light, wa1, si);\n        vec4 w2dpdf = LambertPlanePDF(hl, hn, light, wa2, si);\n        // apply phong pdf\n        fdpdf.w *= SchlickPhong(rd, hn, fdpdf.xyz, 1.0, 1.5, 5.0);\n        cdpdf.w *= SchlickPhong(rd, hn, cdpdf.xyz, 1.0, 1.5, 5.0);\n        w1dpdf.w *= SchlickPhong(rd, hn, w1dpdf.xyz, 1.0, 1.5, 5.0);\n        w2dpdf.w *= SchlickPhong(rd, hn, w2dpdf.xyz, 1.0, 1.5, 5.0);\n        // compute CDF\n        float floorDiffCDF = fdpdf.w;\n        float ceilDiffCDF = floorDiffCDF + cdpdf.w;\n        float w1DiffCDF = ceilDiffCDF + w1dpdf.w;\n        float w2DiffCDF = w1DiffCDF + w2dpdf.w;\n        // roulette sampling\n        vec3 rnd = weyl3(si) * w2DiffCDF;\n        if (rnd.z <= floorDiffCDF)\n            smpIDD += LambertPlaneContrib(fdpdf, hl, ho, flr, FLOOR, light, si) * (w2DiffCDF / max(eps, fdpdf.w));\n        else if (rnd.z <= ceilDiffCDF)\n            smpIDD += LambertPlaneContrib(cdpdf, hl, ho, cil, CEIL, light, si) * (w2DiffCDF / max(eps, cdpdf.w));\n        else if (rnd.z <= w1DiffCDF)\n            smpIDD += LambertPlaneContrib(w1dpdf, hl, ho, wa1, WALL1, light, si) * (w2DiffCDF / max(eps, w1dpdf.w));\n        else\n            smpIDD += LambertPlaneContrib(w2dpdf, hl, ho, wa2, WALL2, light, si) * (w2DiffCDF / max(eps, w2dpdf.w));\n    }\n    ret += smpIDD / float(SMP_PHONG_SURFACE_LAMBERT);\n#endif\n\n#if SMP_PHONG_SURFACE_PHONG\n    // take indirect specular samples\n    vec3 smpIDS = vec3(0.0);\n    for (int i = 0; i < SMP_PHONG_SURFACE_PHONG; ++i) {\n        si += 14;\n        // get all PDFs\n        vec4 fspdf = PhongPlanePDF(hl, hn, light, flr, si);\n        vec4 cspdf = PhongPlanePDF(hl, hn, light, cil, si);\n        vec4 w1spdf = PhongPlanePDF(hl, hn, light, wa1, si);\n        vec4 w2spdf = PhongPlanePDF(hl, hn, light, wa2, si);\n        // apply phong pdf\n        fspdf.w *= SchlickPhong(rd, hn, fspdf.xyz, 1.0, 1.5, 5.0);\n        cspdf.w *= SchlickPhong(rd, hn, cspdf.xyz, 1.0, 1.5, 5.0);\n        w1spdf.w *= SchlickPhong(rd, hn, w1spdf.xyz, 1.0, 1.5, 5.0);\n        w2spdf.w *= SchlickPhong(rd, hn, w2spdf.xyz, 1.0, 1.5, 5.0);\n        // compute CDF\n        float floorSpecCDF = fspdf.w;\n        float ceilSpecCDF = floorSpecCDF + cspdf.w;\n        float w1SpecCDF = ceilSpecCDF + w1spdf.w;\n        float w2SpecCDF = w1SpecCDF + w2spdf.w;\n        vec3 rnd = weyl3(si) * w2SpecCDF;\n        if (rnd.z <= floorSpecCDF)\n            smpIDS += PhongPlaneContrib(fspdf, hl, ho, flr, FLOOR, light, si) * (w2SpecCDF / max(eps, fspdf.w));\n        else if (rnd.z <= ceilSpecCDF)\n            smpIDS += PhongPlaneContrib(cspdf, hl, ho, cil, CEIL, light, si) * (w2SpecCDF / max(eps, cspdf.w));\n        else if (rnd.z <= w1SpecCDF)\n            smpIDS += PhongPlaneContrib(w1spdf, hl, ho, wa1, WALL1, light, si) * (w2SpecCDF / max(eps, w1spdf.w));\n        else\n            smpIDS += PhongPlaneContrib(w2spdf, hl, ho, wa2, WALL2, light, si) * (w2SpecCDF / max(eps, w2spdf.w));\n    }\n    ret += smpIDS / float(SMP_PHONG_SURFACE_PHONG);\n#endif\n\n    return ret;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n\n    bool biased = false;\n#ifdef BIASED\n    // force biased rendering\n    biased = true;\n#endif\n    // this macro declares a bunch of variables\n    decodeAll(iChannel0, iChannel1);\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(rl, 0.0);\n            return;\n        } else if (x == 1) {\n            fragColor = vec4(ro, 0.0, 0.0);\n            return;\n        }\n    }\n    \n    // reproject last frame onto this one\n    fragColor = reprojectBuffer(ll, lo, hl, ho, asp, iChannel1, iResolution.xy);\n    fragColor.a = floor(fragColor.a);\n    \n    // temporal smoothing\n    int lvv = min(TEMPORALSMOOTHING-1, int(float(TEMPORALSMOOTHING) * sqrt(length(vv))));\n    if (fragColor.a > float(TEMPORALSMOOTHING-lvv))\n        fragColor *= float(TEMPORALSMOOTHING-lvv) / fragColor.a;\n    \n    // not nothing\n    if (ho != LIGHT) {\n        int seed = genSeed(iFrame, ivec2(fragCoord.xy), ivec2(iResolution.xy));\n        // do biased sampling\n        if (biased) {\n            // multiple importance sample lights and surfaces\n            fragColor.rgb += SMIS(rd, hl, hn, ho, seed);\n        } else {\n            // unbiased sampling (GT)\n            fragColor.rgb += UnbiasedPhong(rd, hl, hn, ho, seed);\n        }\n    }\n#ifndef BIASED\n    if (biased)\n        fragColor *= float(BIAS_WEIGHT);\n#endif\n    fragColor.a += 1.0 + encodeBuffer(ho);\n}\n","name":"Buffer C","description":"","type":"buffer"}]}
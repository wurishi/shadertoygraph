{"ver":"0.1","info":{"id":"7ssGRf","date":"1616406055","viewed":115,"name":"Radius Based Curvature","username":"rizvanner","description":"Curvature","likes":3,"published":1,"flags":0,"usePreview":0,"tags":["curvature"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dfGRn","filepath":"/media/a/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","previewfilepath":"/media/ap/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\n#define M_PI 3.1415926535897932384626433832795\n\n#define SAMPLING_RADIUS /*1.0*//*8.0*//*0.5*/0.5\n#define NUM_SAMPLING_DIRECTIONS /*8*//*16*/16\n\n#define SAMPLING_STEP /*0.0004*/0.004\n#define NUM_SAMPLING_STEPS /*4*/4\n#define TANGENT_BIAS /*0.5*/0.2/*0.0*/\n\n////\nfloat texture_lum(sampler2D tex, vec2 uv)\n{\n    vec3 rgb = texture(tex, uv).rgb;\n\n    return 0.2126 * rgb.r + 0.7152 * rgb.g + 0.0722 * rgb.b;\n}\n\nvec3 getNormal(sampler2D tex, vec2 fragCoord)\n{\n    float r = 1.0 / vec2(textureSize(iChannel0, 0)).x;\n\n    vec2 uv = fragCoord.xy/* * r*/;\n\n    float x0 = texture_lum(tex, vec2(uv.x + r, uv.y));\n    float x1 = texture_lum(tex, vec2(uv.x - r, uv.y));\n    float y0 = texture_lum(tex, vec2(uv.x, uv.y + r));\n    float y1 = texture_lum(tex, vec2(uv.x, uv.y - r));\n\n    float s = 1.0/*0.5*/;\n\n    vec3 n = normalize(vec3(x1 - x0, y1 - y0, s));\n\n    return n;\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec2 pixelPosition = ivec2(fragCoord);\n    vec2 uv = vec2(pixelPosition) / iResolution.xy;\n\n    //float start_Z = texture(/*depthMap*/iChannel0, /*out_Tex*/uv).r; //returns value (z/w+1)/2\n    float start_Z = texture_lum(iChannel0, uv);\n\n    vec3 start_Pos = vec3(/*out_Tex*/uv, start_Z);\n\n    //vec3 ndc_Pos = (2.0 * start_Pos) - 1.0; // transform to normalized device coordinates xyz/w\n    vec3 ndc_Pos = start_Pos; // transform to normalized device coordinates xyz/w\n\n    //reconstruct view space position\n    vec4 unproject = /*invEyePj * */vec4(ndc_Pos, 1.0);\n\n    vec3 viewPos = unproject.xyz/* / unproject.w*/; // 3d view space position P\n\n    vec3 viewNorm = /*texture(normalMap, out_Tex).xyz*/getNormal(iChannel0, /*fragCoord*/vec2(pixelPosition)); // 3d view space normal N\n\n    viewNorm = vec3(viewNorm.x, viewNorm.y, viewNorm.z); //tt\n    //viewNorm = vec3(0.5, 0.5, 0.5); //tt\n\n    float total = 0.0;\n\n    float sample_direction_increment = 2.0 * M_PI / float(NUM_SAMPLING_DIRECTIONS);\n\n    for (uint i = uint(0); i < uint(NUM_SAMPLING_DIRECTIONS); i++)\n    {\n        // no jittering or randomization of sampling direction just yet\n        float sampling_angle = float(i) * sample_direction_increment; // azimuth angle theta in the paper\n\n        vec2 sampleDir = vec2(cos(sampling_angle), sin(sampling_angle));\n\n        // we will now march along sampleDir and calculate the horizon\n        // horizon starts with the tangent plane to the surface, whose angle we can get from the normal\n        float tangentAngle = acos(dot(vec3(sampleDir, 0), viewNorm)) - (0.5 * M_PI) + TANGENT_BIAS;\n\n        float horizonAngle = tangentAngle;\n\n        vec3 lastDiff = vec3(0);\n\n        for (uint j = uint(0); j < uint(NUM_SAMPLING_STEPS); j++)\n        {\n            // march along the sampling direction and see what the horizon is\n            vec2 sampleOffset = float(j + uint(1)) * SAMPLING_STEP * sampleDir;\n\n            vec2 offTex = /*out_Tex*/uv + sampleOffset;\n\n            //float off_start_Z = texture(/*depthMap*/iChannel0, offTex.st).r;\n            float off_start_Z = texture_lum(iChannel0, offTex.st);\n\n            vec3 off_start_Pos = vec3(offTex, off_start_Z);\n\n            //vec3 off_ndc_Pos = (2.0 * off_start_Pos) - 1.0;\n            vec3 off_ndc_Pos = off_start_Pos;\n\n            vec4 off_unproject = /*invEyePj * */vec4(off_ndc_Pos, 1.0);\n\n            vec3 off_viewPos = off_unproject.xyz/* / off_unproject.w*/;\n\n            // we now have the view space position of the offset point\n            vec3 diff = off_viewPos.xyz - viewPos.xyz;\n\n            if(length(diff) < SAMPLING_RADIUS)\n            {\n                // skip samples which are outside of our local sampling radius\n                lastDiff = diff;\n\n                float elevationAngle = atan(diff.z / length(diff.xy));\n\n                horizonAngle = max(horizonAngle, elevationAngle);\n            }\n        }\n\n        // the paper uses this attenuation but I like the other way better\n        //float normDiff = length(lastDiff) / SAMPLING_RADIUS;\n        //float attenuation = 1.0f - normDiff*normDiff;\n\n        float attenuation = 1.0 / (1.0 + length(lastDiff));\n\n        // now compare horizon angle to tangent angle to get ambient occlusion\n        float occlusion = clamp(/*attenuation * */(sin(horizonAngle) - sin(tangentAngle)), 0.0, 1.0);\n\n        \n\n        total += 1.0 - occlusion;\n    }\n\n    total /= float(NUM_SAMPLING_DIRECTIONS);\n\n\n    fragColor = vec4(total, total, total, 1.0);\n}\n\n","name":"Image","description":"","type":"image"}]}
{"ver":"0.1","info":{"id":"wdsBzS","date":"1589069427","viewed":326,"name":"Second Reality Plasma Cube","username":"ayquo","description":"We are Hork.\nSecond Reality by Future Crew (1993) Plasma Cube scene Tribute with a retro \"320x200\" CRT effect for nostalgic feels.\nMouse-click to ignore nostalgia.\nReference: https://www.youtube.com/watch?v=iw17c70uJes&t=5m44s","likes":14,"published":1,"flags":32,"usePreview":0,"tags":["cube","plasma","second","tribute","reality","recreation"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Haico ten Lohuis - Ayquo 2020\n/* Post-processing */\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n\tif (iMouse.z > 0.)\n    {\n        fragColor = texture( iChannel0, uv);\n    \t// Gamma correction\n    \tfragColor = pow(fragColor, vec4(1./2.2) );\n        return;\n    }\n    \n    // Pixelate, exaggerate blocky half of \"mode 13h\" 320x200 pixel\n    uv.x -= mod(uv.x,  1. / 160.);\n    uv.y -= mod(uv.y,  1. / 100.);        \n    \n    // Chromatic aberration\n\tvec3 col = \t\n    \tvec3(\n        \ttexture( iChannel0, uv-vec2(.0075, 0.) ).x,\n        \ttexture( iChannel0, uv ).y,\n        \ttexture( iChannel0, uv+vec2(.0075, 0.) ).z\n        );\n\n    // Decrease contrast\n    col = clamp(col+.05, 0., 1.);\n    \n    // RGB LED \n    bool r = mod(fragCoord.x, 3.) < 1.;\n    bool b = mod(fragCoord.x, 3.) > 2.;\n    bool g = !(r||b);\n    col *= vec3(r?1.:.125, g?1.:.125, b?1.:.125);\n        \n    // Screen glare\n    float strength = 1. - length(fragCoord.xy - iResolution.yx*.5) / length(iResolution);\n    strength = smoothstep(0., 1., strength*strength);\n    col = vec3(mix(col, vec3(1.), strength * .075));\n\n    // Vignette\n    strength = 1. - length(fragCoord.xy - iResolution.xy*.5) / length(iResolution);\n    col *= vec3(smoothstep(0., 1., strength));\n\n    // Gamma correction\n    col = pow(col, vec3(1./2.2) );\n\n    fragColor = vec4(col, 1.);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"#define t (iTime+51.4)\n\n#define handleColor vec2 worldCoord = fragCoord/iResolution.xy;\\\n        worldCoord.y += sin((worldCoord.x+t*2.)*3.) * .5;      \\\n\t    fragColor = vec4(                                      \\\n\t\t\ttoColor(1. - abs(worldCoord.y - .5) * 2.0)         \\\n\t\t\t, 1.0                                              \\\n\t\t);\n\nvec3 toColor(float f, vec3 c1, vec3 c2, vec3 c3)\n{\n    return f<.5?mix(c1, c2, f*2.)*2.:mix(c2, c3, (f-.5)*2.)*1.25;\n}","name":"Common","description":"","type":"common"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"vec3 toColor(float f)\n{\n    return toColor(\n\t\tf, \n    \tvec3(0.5, 0.0, 0.0), // Dark red\n    \tvec3(1.0, 0.0, 0.0), // Red\n    \tvec3(1.0, 1.0, 0.0)  // Yellow\n\t);            \n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\thandleColor\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[{"id":"XsXGR8","channel":0}],"code":"vec3 toColor(float f)\n{\n    return toColor(\n\t\tf, \n    \tvec3(0.0, 0.0, 0.5), // Dark blue\n    \tvec3(0.0, 0.0, 1.0), // Blue\n    \tvec3(1.0, 1.0, 1.0)  // White\n\t);        \n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\thandleColor\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[],"outputs":[{"id":"4sXGR8","channel":0}],"code":"vec3 toColor(float f)\n{\n    return toColor(\n\t\tf, \n    \tvec3(0.2, 0.025, 0.125),// Dark purple\n    \tvec3(0.4, 0.05,  0.25), // Purple\n    \tvec3(0.0, 0.6,   0.24)  // Green\n\t);    \n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\thandleColor\n}","name":"Buffer C","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XdfGR8","channel":0}],"code":"/*\n* Used the Ray tracing and Box function by Inigo Quilez as starting point\n*   source: https://www.shadertoy.com/view/ld23DV\n* Modified to bare necessities\n*/\nvec4 iBox( in vec3 ro, in vec3 rd, in mat4 txx, in mat4 txi, in vec3 rad ) \n{    \n    // convert from ray to box space\n\tvec3 rdd = (txx*vec4(rd,0.0)).xyz;\n\tvec3 roo = (txx*vec4(ro,1.0)).xyz;\n\n\t// ray-box intersection in box space\n    vec3 m = 1.0/rdd;\n    vec3 n = m*roo;\n    vec3 k = abs(m)*rad;\n\t\n    vec3 t1 = -n - k;\n    vec3 t2 = -n + k;\n\n\tfloat tN = max( max( t1.x, t1.y ), t1.z );\n\tfloat tF = min( min( t2.x, t2.y ), t2.z );\n\t\n\tif( tN > tF || tF < 0.0) return vec4(-1.0);\n\n\tvec3 nor = -sign(rdd)*step(t1.yzx,t1.xyz)*step(t1.zxy,t1.xyz);\n\n    // convert to ray space\t\n\tnor = (txi * vec4(nor,0.0)).xyz;\n\n\treturn vec4( tN, nor );\n}\n\nmat4 rotationAxisAngle( vec3 v, float angle )\n{\n    float s = sin( angle );\n    float c = cos( angle );\n    float ic = 1.0 - c;\n\n    return mat4( v.x*v.x*ic + c,     v.y*v.x*ic - s*v.z, v.z*v.x*ic + s*v.y, 0.0,\n                 v.x*v.y*ic + s*v.z, v.y*v.y*ic + c,     v.z*v.y*ic - s*v.x, 0.0,\n                 v.x*v.z*ic - s*v.y, v.y*v.z*ic + s*v.x, v.z*v.z*ic + c,     0.0,\n\t\t\t     0.0,                0.0,                0.0,                1.0 );\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{   \n\tvec2 p = (-iResolution.xy + 2.0*fragCoord.xy) / iResolution.y;   \n     // camera movement\t\n\tfloat ang = 0.4*t;\n    float dist = 1.35+cos(t*.5)*.5;\n\tvec3 ro = vec3( dist*cos(ang), 0., dist*sin(ang) );\n    // camera matrix\n    vec3 ww = normalize( -ro );\n    vec3 uu = normalize( cross(ww,vec3(0.0,1.0,0.0) ) );\n    vec3 vv = normalize( cross(uu,ww));\n\t// create view ray\n\tvec3 rd = normalize( p.x*uu + p.y*vv + 2.0*ww );\n    // rotate and translate box\t\n\tmat4 rot = rotationAxisAngle( normalize(vec3(1.0,1.0,0.0)), t );\n\tmat4 txx = inverse( rot );\n    // raytrace\n\tfloat tmin = 10000.0;\n\tvec3 nor = vec3(0.0);\n\tvec3 pos = vec3(0.0);\t\n    // raytrace box\n\tvec3 box = vec3(0.5,0.5,0.5) ;\n\tvec4 res = iBox( ro, rd, txx, rot, box);\n\tif( res.x>0.0 && res.x<tmin )\n\t{\n\t\ttmin = res.x; \n\t\tnor = res.yzw;\n\t}\t\n    pos = ro + tmin*rd;\n    // recover box space data (we want to do shading in object space)\t\t\t\n    vec3 opos = (txx*vec4(pos,1.0)).xyz;\n    vec3 onor = (txx*vec4(nor,0.0)).xyz;\n    vec3 col = abs(onor.x)*texture( iChannel0, opos.yz+.5 ).xyz + \n               abs(onor.y)*texture( iChannel1, opos.zx+.5 ).xyz + \n               abs(onor.z)*texture( iChannel2, opos.xy+.5 ).xyz;\t\t\t\n\tfragColor = vec4( col, 1.0 );    \n}","name":"Buffer D","description":"","type":"buffer"}]}
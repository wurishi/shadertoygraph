{"ver":"0.1","renderpass":[{"outputs":[],"inputs":[{"channel":0,"type":"video","id":"4sX3Rn","filepath":"/media/a/c3a071ecf273428bc72fc72b2dd972671de8da420a2d4f917b75d20e1c24b34c.ogv","sampler":{"filter":"linear","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"}}],"code":"// This is a port of the NTSC encode/decode shader pair in MAME and MESS, modified to use only\n// one pass rather than an encode pass and a decode pass. It accurately emulates the sort of\n// signal decimation one would see when viewing a composite signal, though it could benefit from a\n// pre-pass to re-size the input content to more accurately reflect the actual size that would\n// be incoming from a composite signal source.\n//\n// To encode the composite signal, I convert the RGB value to YIQ, then subsequently evaluate\n// the standard NTSC composite equation. Four composite samples per RGB pixel are generated from\n// the incoming linearly-interpolated texels.\n//\n// The decode pass implements a Fixed Impulse Response (FIR) filter designed by MAME/MESS contributor\n// \"austere\" in matlab (if memory serves correctly) to mimic the behavior of a standard television set\n// as closely as possible. The filter window is 83 composite samples wide, and there is an additional\n// notch filter pass on the luminance (Y) values in order to strip the color signal from the luminance\n// signal prior to processing.\n//\n// Yes, this code could greatly use some cleaning up.\n\n// Useful Constants\nconst vec4 Zero = vec4(0.0);\nconst vec4 Half = vec4(0.5);\nconst vec4 One = vec4(1.0);\nconst vec4 Two = vec4(2.0);\nconst vec3 Gray = vec3(0.3, 0.59, 0.11);\nconst float Pi = 3.1415926535;\nconst float Pi2 = 6.283185307;\n\n// NTSC Constants\nconst vec4 A = vec4(0.5);\nconst vec4 A2 = vec4(1.0);\nconst vec4 B = vec4(0.5);\nconst float P = 1.0;\nconst float CCFrequency = 3.59754545;\nconst float NotchUpperFrequency = 3.59754545 + 2.0;\nconst float NotchLowerFrequency = 3.59754545 - 2.0;\nconst float YFrequency = 6.0;\nconst float IFrequency = 1.2;\nconst float QFrequency = 0.6;\nconst float NotchHalfWidth = 2.0;\nconst float ScanTime = 52.6;\nconst float Pi2ScanTime = 6.283185307 * 52.6;\nconst float MaxC = 2.1183;\nconst vec4 YTransform = vec4(0.299, 0.587, 0.114, 0.0);\nconst vec4 ITransform = vec4(0.595716, -0.274453, -0.321263, 0.0);\nconst vec4 QTransform = vec4(0.211456, -0.522591, 0.311135, 0.0);\nconst vec3 YIQ2R = vec3(1.0, 0.956, 0.621);\nconst vec3 YIQ2G = vec3(1.0, -0.272, -0.647);\nconst vec3 YIQ2B = vec3(1.0, -1.106, 1.703);\nconst vec4 MinC = vec4(-1.1183);\nconst vec4 CRange = vec4(3.2366);\nconst vec4 InvCRange = vec4(1.0/3.2366);\nconst float Pi2Length = Pi2 / 63.0;\nconst vec4 NotchOffset = vec4(0.0, 1.0, 2.0, 3.0);\nconst vec4 W = vec4(Pi2 * CCFrequency * ScanTime);\n\n// Color Convolution Constants\nconst vec3 RedMatrix = vec3(1.0, 0.0, 0.0);\nconst vec3 GrnMatrix = vec3(0.0, 1.0, 0.0);\nconst vec3 BluMatrix = vec3(0.0, 0.0, 1.0);\nconst vec3 DCOffset = vec3(0.0, 0.0, 0.0);\nconst vec3 ColorScale = vec3(0.95, 0.95, 0.95);\nconst float Saturation = 1.4;\n\n// Deconverge Constants\nconst vec3 ConvergeX = vec3(-0.4,  0.0, 0.2);\nconst vec3 ConvergeY = vec3( 0.0, -0.4, 0.2);\nconst vec3 RadialConvergeX = vec3(1.0, 1.0, 1.0);\nconst vec3 RadialConvergeY = vec3(1.0, 1.0, 1.0);\n\n// Scanline/Pincushion Constants\nconst float PincushionAmount = 0.015;\nconst float CurvatureAmount = 0.015;\nconst float ScanlineAmount = 0.175;\nconst float ScanlineScale = 1.0;\nconst float ScanlineHeight = 1.0;\nconst float ScanlineBrightScale = 1.0;\nconst float ScanlineBrightOffset = 0.0;\nconst float ScanlineOffset = 0.0;\nconst vec3 Floor = vec3(0.05, 0.05, 0.05);\n\n// 60Hz Bar Constants\nconst float SixtyHertzRate = (60.0 / 59.97 - 1.0); // Difference between NTSC and line frequency\nconst float SixtyHertzScale = 0.1;\n\nvec4 CompositeSample(vec2 UV, vec2 InverseRes) {\n\tvec2 InverseP = vec2(P, 0.0) * InverseRes;\n\t\n\t// UVs for four linearly-interpolated samples spaced 0.25 texels apart\n\tvec2 C0 = UV;\n\tvec2 C1 = UV + InverseP * 0.25;\n\tvec2 C2 = UV + InverseP * 0.50;\n\tvec2 C3 = UV + InverseP * 0.75;\n\tvec4 Cx = vec4(C0.x, C1.x, C2.x, C3.x);\n\tvec4 Cy = vec4(C0.y, C1.y, C2.y, C3.y);\n\n\tvec4 Texel0 = texture(iChannel0, C0);\n\tvec4 Texel1 = texture(iChannel0, C1);\n\tvec4 Texel2 = texture(iChannel0, C2);\n\tvec4 Texel3 = texture(iChannel0, C3);\n\t\n\tfloat Frequency = CCFrequency;\n\t//Frequency = Frequency;// Uncomment for bad color sync + (sin(UV.y * 2.0 - 1.0) / CCFrequency) * 0.001;\n\n\t// Calculated the expected time of the sample.\n\tvec4 T = A2 * Cy * vec4(iChannelResolution[0].y) + B + Cx;\n\tvec4 W = vec4(Pi2ScanTime * Frequency);\n\tvec4 TW = T * W;\n\tvec4 Y = vec4(dot(Texel0, YTransform), dot(Texel1, YTransform), dot(Texel2, YTransform), dot(Texel3, YTransform));\n\tvec4 I = vec4(dot(Texel0, ITransform), dot(Texel1, ITransform), dot(Texel2, ITransform), dot(Texel3, ITransform));\n\tvec4 Q = vec4(dot(Texel0, QTransform), dot(Texel1, QTransform), dot(Texel2, QTransform), dot(Texel3, QTransform));\n\n\tvec4 Encoded = Y + I * cos(TW) + Q * sin(TW);\n\treturn (Encoded - MinC) * InvCRange;\n}\n\nvec4 NTSCCodec(vec2 UV, vec2 InverseRes)\n{\n\tvec4 YAccum = Zero;\n\tvec4 IAccum = Zero;\n\tvec4 QAccum = Zero;\n\tfloat QuadXSize = iChannelResolution[0].x * 4.0;\n\tfloat TimePerSample = ScanTime / QuadXSize;\n\t\n\t// Frequency cutoffs for the individual portions of the signal that we extract.\n\t// Y1 and Y2 are the positive and negative frequency limits of the notch filter on Y.\n\t// Y3 is the center of the frequency response of the Y filter.\n\t// I is the center of the frequency response of the I filter.\n\t// Q is the center of the frequency response of the Q filter.\n\tfloat Fc_y1 = NotchLowerFrequency * TimePerSample;\n\tfloat Fc_y2 = NotchUpperFrequency * TimePerSample;\n\tfloat Fc_y3 = YFrequency * TimePerSample;\n\tfloat Fc_i = IFrequency * TimePerSample;\n\tfloat Fc_q = QFrequency * TimePerSample;\n\tfloat Pi2Fc_y1 = Fc_y1 * Pi2;\n\tfloat Pi2Fc_y2 = Fc_y2 * Pi2;\n\tfloat Pi2Fc_y3 = Fc_y3 * Pi2;\n\tfloat Pi2Fc_i = Fc_i * Pi2;\n\tfloat Pi2Fc_q = Fc_q * Pi2;\n\tfloat Fc_y1_2 = Fc_y1 * 2.0;\n\tfloat Fc_y2_2 = Fc_y2 * 2.0;\n\tfloat Fc_y3_2 = Fc_y3 * 2.0;\n\tfloat Fc_i_2 = Fc_i * 2.0;\n\tfloat Fc_q_2 = Fc_q * 2.0;\n\tvec4 CoordY = vec4(UV.y);\n\t\n\t// 83 composite samples wide, 4 composite pixels per texel\n\tfor(float n = -31.0; n < 32.0; n += 4.0)\n\t{\n\t\tvec4 n4 = n + NotchOffset;\n\t\tvec4 CoordX = UV.x + InverseRes.x * n4 * 0.25;\n\t\tvec2 TexCoord = vec2(CoordX.x, CoordY.x);\n\t\tvec4 C = CompositeSample(TexCoord, InverseRes) * CRange + MinC;\n\t\tvec4 WT = W * (CoordX  + A2 * CoordY * iChannelResolution[0].y + B);\n\t\tvec4 Cosine = 0.54 + 0.46 * cos(Pi2Length * n4);\n\n\t\tvec4 SincYIn1 = Pi2Fc_y1 * n4;\n\t\tvec4 SincYIn2 = Pi2Fc_y2 * n4;\n\t\tvec4 SincYIn3 = Pi2Fc_y3 * n4;\n\t\tvec4 SincY1 = sin(SincYIn1) / SincYIn1;\n\t\tvec4 SincY2 = sin(SincYIn2) / SincYIn2;\n\t\tvec4 SincY3 = sin(SincYIn3) / SincYIn3;\n\t\t\n\t\t// These zero-checks could be made more efficient if WebGL supported mix(vec4, vec4, bvec4)\n\t\t// Unfortunately, the universe hates us\n\t\tif(SincYIn1.x == 0.0) SincY1.x = 1.0;\n\t\tif(SincYIn1.y == 0.0) SincY1.y = 1.0;\n\t\tif(SincYIn1.z == 0.0) SincY1.z = 1.0;\n\t\tif(SincYIn1.w == 0.0) SincY1.w = 1.0;\n\t\tif(SincYIn2.x == 0.0) SincY2.x = 1.0;\n\t\tif(SincYIn2.y == 0.0) SincY2.y = 1.0;\n\t\tif(SincYIn2.z == 0.0) SincY2.z = 1.0;\n\t\tif(SincYIn2.w == 0.0) SincY2.w = 1.0;\n\t\tif(SincYIn3.x == 0.0) SincY3.x = 1.0;\n\t\tif(SincYIn3.y == 0.0) SincY3.y = 1.0;\n\t\tif(SincYIn3.z == 0.0) SincY3.z = 1.0;\n\t\tif(SincYIn3.w == 0.0) SincY3.w = 1.0;\n\t\tvec4 IdealY = (Fc_y1_2 * SincY1 - Fc_y2_2 * SincY2) + Fc_y3_2 * SincY3;\n\t\tvec4 FilterY = Cosine * IdealY;\t\t\n\t\t\n\t\tvec4 SincIIn = Pi2Fc_i * n4;\n\t\tvec4 SincI = sin(SincIIn) / SincIIn;\n\t\tif (SincIIn.x == 0.0) SincI.x = 1.0;\n\t\tif (SincIIn.y == 0.0) SincI.y = 1.0;\n\t\tif (SincIIn.z == 0.0) SincI.z = 1.0;\n\t\tif (SincIIn.w == 0.0) SincI.w = 1.0;\n\t\tvec4 IdealI = Fc_i_2 * SincI;\n\t\tvec4 FilterI = Cosine * IdealI;\n\t\t\n\t\tvec4 SincQIn = Pi2Fc_q * n4;\n\t\tvec4 SincQ = sin(SincQIn) / SincQIn;\n\t\tif (SincQIn.x == 0.0) SincQ.x = 1.0;\n\t\tif (SincQIn.y == 0.0) SincQ.y = 1.0;\n\t\tif (SincQIn.z == 0.0) SincQ.z = 1.0;\n\t\tif (SincQIn.w == 0.0) SincQ.w = 1.0;\n\t\tvec4 IdealQ = Fc_q_2 * SincQ;\n\t\tvec4 FilterQ = Cosine * IdealQ;\n\t\t\n\t\tYAccum += C * FilterY;\n\t\tIAccum += C * cos(WT) * FilterI;\n\t\tQAccum += C * sin(WT) * FilterQ;\n\t}\n\t\n\tfloat Y = dot(YAccum, One);\n\tfloat I = dot(IAccum, One) * 2.0;\n\tfloat Q = dot(QAccum, One) * 2.0;\n\t\n\tvec3 YIQ = vec3(Y, I, Q);\n\tvec3 OutRGB = vec3(dot(YIQ, YIQ2R), dot(YIQ, YIQ2G), dot(YIQ, YIQ2B));\n\t\n\treturn vec4(OutRGB, 1.0);\n}\n\nvec4 ColorConvolution(vec2 UV, vec2 InverseRes)\n{\n\tvec3 InPixel = NTSCCodec(UV, InverseRes).rgb;\n\t\n\t// Color Matrix\n\tfloat RedValue = dot(InPixel, RedMatrix);\n\tfloat GrnValue = dot(InPixel, GrnMatrix);\n\tfloat BluValue = dot(InPixel, BluMatrix);\n\tvec3 OutColor = vec3(RedValue, GrnValue, BluValue);\n\t\n\t// DC Offset & Scale\n\tOutColor = (OutColor * ColorScale) + DCOffset;\n\t\n\t// Saturation\n\tfloat Luma = dot(OutColor, Gray);\n\tvec3 Chroma = OutColor - Luma;\n\tOutColor = (Chroma * Saturation) + Luma;\n\t\n\treturn vec4(OutColor, 1.0);\n}\n\nvec4 Deconverge(vec2 UV)\n{\n\tvec2 InverseRes = 1.0 / iResolution.xy;\n\tvec2 InverseSrcRes = 1.0 / iChannelResolution[0].xy;\n\n\tvec3 CoordX = UV.x * RadialConvergeX;\n\tvec3 CoordY = UV.y * RadialConvergeY;\n\n\tCoordX += ConvergeX * InverseRes.x - (RadialConvergeX - 1.0) * 0.5;\n\tCoordY += ConvergeY * InverseRes.y - (RadialConvergeY - 1.0) * 0.5;\n\n\tfloat RedValue = ColorConvolution(vec2(CoordX.x, CoordY.x), InverseSrcRes).r;\n\tfloat GrnValue = ColorConvolution(vec2(CoordX.y, CoordY.y), InverseSrcRes).g;\n\tfloat BluValue = ColorConvolution(vec2(CoordX.z, CoordY.z), InverseSrcRes).b;\n\n\treturn vec4(RedValue, GrnValue, BluValue, 1.0);\n}\n\nvec4 ScanlinePincushion(vec2 UV)\n{\n\tvec4 InTexel = Deconverge(UV);\n\t\n\tvec2 PinUnitCoord = UV * Two.xy - One.xy;\n\tfloat PincushionR2 = pow(length(PinUnitCoord), 2.0);\n\tvec2 PincushionCurve = PinUnitCoord * PincushionAmount * PincushionR2;\n\tvec2 BaseCoord = UV;\n\tvec2 ScanCoord = UV;\n\t\n\tBaseCoord *= One.xy - PincushionAmount * 0.2; // Warning: Magic constant\n\tBaseCoord += PincushionAmount * 0.1;\n\tBaseCoord += PincushionCurve;\n\t\n\tScanCoord *= One.xy - PincushionAmount * 0.2; // Warning: Magic constant\n\tScanCoord += PincushionAmount * 0.1;\n\tScanCoord += PincushionCurve;\n\t\n\tvec2 CurveClipUnitCoord = UV * Two.xy - One.xy;\n\tfloat CurvatureClipR2 = pow(length(CurveClipUnitCoord), 2.0);\n\tvec2 CurvatureClipCurve = CurveClipUnitCoord * CurvatureAmount * CurvatureClipR2;\n\tvec2 ScreenClipCoord = UV;\n\tScreenClipCoord -= Half.xy;\n\tScreenClipCoord *= One.xy - CurvatureAmount * 0.2; // Warning: Magic constant\n\tScreenClipCoord += Half.xy;\n\tScreenClipCoord += CurvatureClipCurve;\n\t\n\t// -- Alpha Clipping --\n\tif (BaseCoord.x < 0.0) return vec4(0.0, 0.0, 0.0, 1.0);\n\tif (BaseCoord.y < 0.0) return vec4(0.0, 0.0, 0.0, 1.0);\n\tif (BaseCoord.x > 1.0) return vec4(0.0, 0.0, 0.0, 1.0);\n\tif (BaseCoord.y > 1.0) return vec4(0.0, 0.0, 0.0, 1.0);\n\t\n\t// -- Scanline Simulation --\n\tfloat InnerSine = ScanCoord.y * iChannelResolution[0].y * ScanlineScale;\n\tfloat ScanBrightMod = sin(InnerSine * Pi + ScanlineOffset * iChannelResolution[0].y);\n\tfloat ScanBrightness = mix(1.0, (pow(ScanBrightMod * ScanBrightMod, ScanlineHeight) * ScanlineBrightScale + 1.0) * 0.5, ScanlineAmount);\n\tvec3 ScanlineTexel = InTexel.rgb * ScanBrightness;\n\t\n\t// -- Color Compression (increasing the floor of the signal without affecting the ceiling) --\n\tScanlineTexel = Floor + (One.xyz - Floor) * ScanlineTexel;\n\t\n\treturn vec4(ScanlineTexel, 1.0);\n}\n\nvec4 SixtyHertz(vec2 UV)\n{\n\tvec4 InPixel = ScanlinePincushion(UV);\n\tfloat Milliseconds = iTime * 1000.0;\n\tfloat TimeStep = fract(Milliseconds * SixtyHertzRate);\n\tfloat BarPosition = 1.0 - fract(UV.y + TimeStep) * SixtyHertzScale;\n\tvec4 OutPixel = InPixel * BarPosition;\n\treturn OutPixel;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n\tvec2 InverseRes = 1.0 / iResolution.xy;\n\tvec2 UV = fragCoord.xy * InverseRes;\n    UV.y = 1.0 - UV.y;\n\n\t// Uncomment bits below in order to drop below 60fps on Radeon HD 7970 for performance testing\n\tvec4 OutPixel = SixtyHertz(UV);// * 0.75;\n\t//vec4 OtherPixel = SixtyHertz(UV+InverseRes) * 0.25;\n\tfragColor = OutPixel; //+ OtherPixel;\n}\n","name":"Image","description":"","type":"image"}],"flags":{"mFlagVR":false,"mFlagWebcam":false,"mFlagSoundInput":false,"mFlagSoundOutput":false,"mFlagKeyboard":false,"mFlagMultipass":false,"mFlagMusicStream":false},"info":{"id":"ldf3Rf","date":"1375581747","viewed":2066,"name":"Full MAME/MESS Shader Pipe","username":"UltraMoogleMan","description":"The full version of the MAME and MESS shader pipeline, minus defocus, shoehorned into one pass rather than multiple passes. Includes some extra effects not found in MAME or MESS.","likes":26,"published":1,"flags":0,"usePreview":0,"tags":["2d","postprocessing","crt","signalprocessing","emulation"],"hasliked":0,"parentid":"","parentname":""}}
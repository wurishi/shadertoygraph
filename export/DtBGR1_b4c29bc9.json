{"ver":"0.1","info":{"id":"DtBGR1","date":"1672828544","viewed":597,"name":"60FPS Volumetric Clouds on iGPU","username":"sdfgeoff","description":"ESDF to move, arrows or mouse to rotate. Yup, cuts a lot of fancy things out. ","likes":22,"published":1,"flags":48,"usePreview":0,"tags":["game","interactive","clouds","flycam"],"hasliked":0,"parentid":"ctBGR1","parentname":"Flycam Template"},"renderpass":[{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\nI had a computer game idea that involved using the sky as terrain. Of course,\nthis involves simulating large cloud-scapes - and I want it to run on my\nlaptop. So....\n\nThis is an attempt to make volumetric clouds run at interactive framerates\non an intel GPU. Of course, this doesn't leave much horse-power\nso a lot of fancy things have to be cut out. Still with some properly\ndesigned textures (to prevent artifacting - the cloud map should be a SDF)\nit should be possible to build a stylized game.\n\nDropping the resolution to half of the framebuffer makes a big difference \nin performance - enough for me to go from a single absorbtion sample to\na set of four along with transmission. And when it's running fullscreen\nI don't notice it.\n\n\n//// Open Questions\n\n - How can I get the most bang-for-buck out of lighting samples? \n   Currently I'm only doing absorption/transmission simulation, \n   and they look a bit, well, meh. Should I be doing some other \n   lighting simulation?\n\n - Is there some method other than volumetrics/raymarching that\n   holds up at close distances? I couldn't find any papers on any\n   alternates, so does anyone here have any ideas or resources?\n\n - This would need to be integrated into a traditional 3D renderer.\n   I've attempted to combine raymarched visuals into a 3D pipeline\n   before and couldn't get the Z-buffer to work. Any resources or advice for this?\n\n - Any other advice for performance? If someone wants to dig through my \n   shader code, I'd love some code review. Any advice for profiling shaders?\n\n\n//// Raymarcher notes\nRaymarcher does big steps through empty space and small steps through clouds.\nWhen it hits a cloud it back-tracks. This means that the smallest cloud \nthickness must be bigger than the big step - which is not the case with the texture\nI'm using. This is why there are some artifacts.\nThe raymarcher early aborts on full opacity and on draw distance.\n\n//// Inspiration:\nHorizon Zero Dawn put out some good presentations on this.\n\n\n\n//// License:\nWTFPL - use as you will.\n\n//// Changelog\n2023-01-04 initial version\n2023-01-05 no longer samples detail texture when opacity exceeds 80%\n\n\n*/\n\n#define BUFFER_HUD iChannel1\n#define BUFFER_CLOUDS iChannel0\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\n    fragColor = textureLod(BUFFER_CLOUDS, fragCoord / iResolution.xy * 0.5, 1.0);\n\n\n    // HUD\n    vec4 hud = texture(BUFFER_HUD, fragCoord / iResolution.xy);\n    fragColor = mix(fragColor, hud, hud.a);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"const ivec2 ADDR_CAMERA_POSITION = ivec2(0,0);\nconst ivec2 ADDR_CAMERA_ORIENTATION = ivec2(0,1);\nconst ivec2 ADDR_CAMERA_ANG_VELOCITY = ivec2(0,2);\nconst ivec2 ADDR_CAMERA_LIN_VELOCITY = ivec2(0,3);\nconst ivec2 ADDR_MOUSE_DELTA_STATE = ivec2(0,4);\n\nconst float LENS = 0.5;\nconst float PHYSICS_RADIUS = 0.05;\n\n//#define PHYSICS\n\n\n\n\nfloat physics_sdf(vec3 position) {\n    // Return zero when colliding\n#ifdef PHYSICS\n    return map(position);\n#else\n    return 10.0;\n#endif\n}\n\nvec3 physics_normal(vec3 position) {\n    // Return direction vector pointing towards free space\n#ifdef PHYSICS\n    return calc_normal(position);\n#else\n    return vec3(1.0, 0.0, 0.0);\n#endif\n}\n\n\n\n// Fetch a single pixe from a buffer\nvec4 read_data(sampler2D buffer, ivec2 address){\n    return texelFetch(buffer, address, 0);\n}\n\n\n// Create a quaternion from axis-angle notation\nvec4 quat_from_axis_angle(vec3 axis, float angle) {\n    float factor = sin(angle) / 2.0;\n    float w = cos(angle) / 2.0;\n    return normalize(vec4(axis*factor, w));\n}\n\n// Convert a quaternion into a transformation matrix\nmat4 quat_to_transform(vec4 quat, vec3 translation) {\n    vec4 q = quat;\n    vec4 q2 = quat * quat;\n    \n \treturn mat4(\n        1.0 - 2.0*(q2.y + q2.z), 2.0*(q.x*q.y - q.z*q.w), 2.0*(q.x*q.z + q.y*q.w), 0.0,\n    \t2.0*(q.x*q.y + q.z*q.w), 1.0 - 2.0*(q2.x + q2.z), 2.0*(q.y*q.z - q.x*q.w), 0.0,\n    \t2.0*(q.x*q.z - q.y*q.w), 2.0*(q.y*q.z + q.x*q.w),1.0 - 2.0*(q2.x + q2.y), 0.0,\n        translation, 0.0\n    );\n}\n\n// Multiply two quaternions\nvec4 quat_mul(vec4 a, vec4 b) {\n \treturn vec4(\n        a.w * b.x + a.x * b.w + a.y * b.z - a.z * b.y,\n        a.w * b.y - a.x * b.z + a.y * b.w + a.z * b.x,\n        a.w * b.z + a.x * b.y - a.y * b.x + a.z * b.w,\n        a.w * b.w - a.x * b.x - a.y * b.y - a.z * b.z\n    );   \n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// STATE: manages moving the camera\n\n#define BUFFER_STATE iChannel0\n#define BUFFER_KEYBOARD iChannel1\n\nconst vec3 START_POSITION = vec3(12.041,29.324,-0.991);\nconst vec4 START_QUATERNION = vec4(0., 0.707, 0.707, 0);\n\nconst vec2 MOUSE_SENSITIVITY = vec2(-0.2, 0.2);\n\n// Flight dynamics\nconst float LIN_ACCELERATION = 50.0;\nconst float LIN_DRAG = 5.0;\nconst float ANG_ACCELERATION = 10.0;\nconst float ANG_DRAG = 10.0;\n\n\n// What keys to use for controls\nconst int KEY_LEFT = 83;\nconst int KEY_UP   = 84;\nconst int KEY_RIGHT = 70;\nconst int KEY_DOWN = 71;\nconst int KEY_FORWARD = 69;\nconst int KEY_BACKWARD = 68;\n\nconst int KEY_TILT_UP = 38;\nconst int KEY_TILT_DOWN = 40;\nconst int KEY_PAN_LEFT = 37;\nconst int KEY_PAN_RIGHT = 39;\nconst int KEY_ROLL_LEFT = 87;\nconst int KEY_ROLL_RIGHT = 82;\n\n\n// Return the state of a key\nfloat get_key(int key_code) {\n    return texelFetch(BUFFER_KEYBOARD, ivec2(key_code,0), 0).x;\n}\n\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec2 address = ivec2(fragCoord);\n    \n    if (address == ADDR_CAMERA_POSITION) {\n        // Move the camera based on keypress\n    \tvec4 camera_position = read_data(BUFFER_STATE, ADDR_CAMERA_POSITION);\n        \n        if (iTime < 0.1) {\n            camera_position = vec4(START_POSITION, 0.0);\n        }\n        \n        float distance_field = physics_sdf(camera_position.xyz);\n        float penetration_distance = -(distance_field - PHYSICS_RADIUS);\n        \n        if (penetration_distance > 0.0) {\n            vec3 normal = physics_normal(camera_position.xyz);\n            camera_position.xyz += normal * penetration_distance;\n        }\n        \n        \n        vec3 translation = read_data(BUFFER_STATE, ADDR_CAMERA_LIN_VELOCITY).xyz;\n        \n        // Convert to local coordinate system\n        mat4 orientation = quat_to_transform(\n            read_data(BUFFER_STATE, ADDR_CAMERA_ORIENTATION),\n            vec3(0.0)\n        );\n        translation = (orientation * vec4(translation, 0.0)).xyz;\n        translation *= iTimeDelta;\n        \n        camera_position.xyz += translation;\n        fragColor = camera_position;\n        return;\n    }\n    \n    \n    if (address == ADDR_CAMERA_ORIENTATION) {\n        // Rotate the camera based on keypress\n        vec4 camera_orientation = read_data(BUFFER_STATE, ADDR_CAMERA_ORIENTATION);\n        \n        if (iTime < 0.1) {\n            camera_orientation = START_QUATERNION;\n        }\n        \n        vec4 velocity = read_data(BUFFER_STATE, ADDR_CAMERA_ANG_VELOCITY);\n        velocity *= iTimeDelta;\n        \n        \n        \n        vec4 pan = quat_from_axis_angle(vec3(0.0, 1.0, 0.0), velocity.x);\n        vec4 tilt = quat_from_axis_angle(vec3(1.0, 0.0, 0.0), velocity.y);\n        vec4 roll = quat_from_axis_angle(vec3(0.0, 0.0, 1.0), velocity.z);\n        \n        \n        camera_orientation = quat_mul(pan, camera_orientation); \n        camera_orientation = quat_mul(tilt, camera_orientation); \n        camera_orientation = quat_mul(roll, camera_orientation); \n        \n        fragColor = camera_orientation;\n        return;\n    }\n    if (address == ADDR_CAMERA_ANG_VELOCITY) {\n        vec4 velocity = read_data(BUFFER_STATE, ADDR_CAMERA_ANG_VELOCITY);\n        vec4 mouse_delta_data = read_data(BUFFER_STATE, ADDR_MOUSE_DELTA_STATE);\n        vec2 mouse_delta = iMouse.xy - mouse_delta_data.xy;\n        \n        vec3 acceleration = vec3(\n            get_key(KEY_PAN_LEFT) - get_key(KEY_PAN_RIGHT),\n            get_key(KEY_TILT_UP) - get_key(KEY_TILT_DOWN),\n            get_key(KEY_ROLL_RIGHT) - get_key(KEY_ROLL_LEFT)\n        );\n        if (mouse_delta_data.z > 0.0) {\n            acceleration.xy += mouse_delta * MOUSE_SENSITIVITY;\n        }\n        acceleration *= ANG_ACCELERATION;\n        velocity.xyz += acceleration * iTimeDelta;\n        \n        vec4 drag = velocity * ANG_DRAG;\n        velocity -= drag * iTimeDelta;\n        \n        fragColor = velocity;\n        return;\n    }\n    if (address == ADDR_CAMERA_LIN_VELOCITY) {\n        vec4 velocity = read_data(BUFFER_STATE, ADDR_CAMERA_LIN_VELOCITY);\n        \n        vec3 acceleration = vec3(\n            get_key(KEY_RIGHT) - get_key(KEY_LEFT),\n            get_key(KEY_UP) - get_key(KEY_DOWN),\n            get_key(KEY_FORWARD) - get_key(KEY_BACKWARD)\n        ) * LIN_ACCELERATION;\n        velocity.xyz += acceleration * iTimeDelta;\n        \n        vec4 drag = velocity * LIN_DRAG;\n        velocity -= drag * iTimeDelta;\n        \n        fragColor = velocity;\n        return;\n    }\n    if (address == ADDR_MOUSE_DELTA_STATE) {\n        fragColor = iMouse;\n    }\n}\n\n\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGzr","filepath":"/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","previewfilepath":"/media/ap/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// HUD: Draws the heads up display\n\n#define BUFFER_STATE iChannel0\n#define BUFFER_FONT iChannel1\n\nconst vec3 HUD_COLOR = vec3(1.0, 0.6, 0.0);\nconst float HUD_LINE_SIZE = 0.005;\nconst float HUD_BORDER_OFFSET = 0.08;\n\n\nvec4 hud(vec2 uv) {\n    vec4 cam_ang_velocity = read_data(BUFFER_STATE, ADDR_CAMERA_ANG_VELOCITY);\n\n    float aspect = iResolution.x / iResolution.y;\n    float borders = step(0.0, HUD_LINE_SIZE - abs((aspect - HUD_BORDER_OFFSET) - abs(uv.x)));\n    borders += step(0.0, HUD_LINE_SIZE - abs(1.0 - HUD_BORDER_OFFSET - abs(uv.y)));\n    \n    float reticle = step(abs(0.03 - length(uv + cam_ang_velocity.xy * vec2(0.2, -0.2))), HUD_LINE_SIZE);\n    \n    float hud = borders + reticle;\n    \n    hud = clamp(hud, 0.0, 0.5);\n    \n    return vec4(HUD_COLOR,hud);\n}\n\n\n\nvec4 sampleIntChar(int number, vec2 coords) {\n    return texture(BUFFER_FONT, (coords + vec2(float(number), -4.0)) / 16.0);\n}\n\n\nfloat drawInt(int number, vec2 coords, int digits) {\n    vec2 arr = coords * vec2(digits, 1.0);\n    int digitId = digits - int(ceil(arr.x));\n    float digitBase = (pow(10.0, float(digitId)));\n    number = int(floor(float(number) / digitBase)) % 10;\n    \n    float sdf = sampleIntChar(number, fract(arr)).x;\n    float edge = smoothstep(0.1, 0.9, sdf);\n    \n    return sdf;\n}\n\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 raw_uv = fragCoord/iResolution.xy;\n    vec2 uv = raw_uv;\n    uv = (uv - 0.5) * 2.0;\n    uv.x *= iResolution.x / iResolution.y;\n    \n    \n    \n    fragColor = hud(uv);\n    \n    if (uv.y < -1.0 + HUD_BORDER_OFFSET) {\n        // There is almost certainly a more effecient way to do this\n        vec2 textuv = raw_uv * vec2(1.0/4.2, 1.0) / HUD_BORDER_OFFSET * 2.0;\n        float texBuff = 0.0;\n        vec4 camera_position = read_data(BUFFER_STATE, ADDR_CAMERA_POSITION);\n        textuv.x -= HUD_BORDER_OFFSET * 3.0;\n        texBuff += drawInt(int(abs(camera_position.x * 10.0)), clamp(textuv, 0.0, 1.0), 7); \n        textuv.x -= HUD_BORDER_OFFSET * 15.0;\n        \n        texBuff += drawInt(int(abs(camera_position.y * 10.0)), clamp(textuv, 0.0, 1.0), 7); \n        textuv.x -= HUD_BORDER_OFFSET * 15.0;\n        \n        texBuff += drawInt(int(abs(camera_position.z * 10.0)), clamp(textuv, 0.0, 1.0), 7); \n        textuv.x -= HUD_BORDER_OFFSET * 15.0;\n        \n        texBuff += drawInt(int(abs(iFrameRate * 1000.0)), clamp(textuv, 0.0, 1.0), 7); \n        textuv.x -= HUD_BORDER_OFFSET * 15.0;\n        \n        fragColor = mix(fragColor, texBuff * vec4(HUD_COLOR, 1.0), texBuff);\n    }\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4sfGRr","filepath":"/media/a/27012b4eadd0c3ce12498b867058e4f717ce79e10a99568cca461682d84a4b04.bin","previewfilepath":"/media/ap/27012b4eadd0c3ce12498b867058e4f717ce79e10a99568cca461682d84a4b04.bin","type":"volume","channel":2,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdXGzr","filepath":"/media/a/8979352a182bde7c3c651ba2b2f4e0615de819585cc37b7175bcefbca15a6683.jpg","previewfilepath":"/media/ap/8979352a182bde7c3c651ba2b2f4e0615de819585cc37b7175bcefbca15a6683.jpg","type":"texture","channel":3,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// Renders clouds at half-resolution\n\n#define BUFFER_STATE iChannel0\n#define BUFFER_HUD iChannel1\n\n#define BUFFER_VOLUME_NOISE iChannel2\n#define BUFFER_CLOUD_COVER iChannel3\n\n\nconst int MAX_STEPS = 128;\nconst float DRAW_DISTANCE = 200.0;\n\n\nconst float INSIDE_STEP_SIZE = 0.6;\nconst int STEP_OUTSIDE_RATIO = 9;\nconst float OUTSIDE_STEP_SIZE = INSIDE_STEP_SIZE * float(STEP_OUTSIDE_RATIO);\n\n\nconst vec3 LIGHT_DIRECTION = normalize(vec3(0,1.0,0.5));\n\n\nvec3 renderSky(vec3 direction) {\n    float elevation = 1.0 - dot(direction, vec3(0,0,1));\n    float centered = 1.0 - abs(1.0 - elevation);\n    float sun_direction = dot(direction, LIGHT_DIRECTION);\n\n    \n    vec3 base = mix(vec3(0.15, 0.15, 0.50), vec3(0.5,0.8,0.92), pow(clamp(elevation, 0.0, 1.0), 0.5));\n    \n    float haze = pow(centered + 0.02, 4.0) * (sun_direction + 1.0) * 0.5;\n    vec3 sky = mix(base, vec3(0.99, 0.98, 0.96), clamp(haze, 0.0, 1.0));\n    \n    float sun = pow(max((sun_direction - 19.0/20.0) * 20.0 - 0.00, 0.0), 4.0);\n    return sky + vec3(1.0, 0.8, 0.5) * sun;\n}\n\n\nfloat hash14(vec4 p4)\n{\n\tp4 = fract(p4  * vec4(.1031, .1030, .0973, .1099));\n    p4 += dot(p4, p4.wzxy+33.33);\n    return fract((p4.x + p4.y) * (p4.z + p4.w));\n}\n\nvec4 alphaOver(vec4 top, vec4 bottom) {\n    float A1 = bottom.a * (1.0 - top.a);\n    \n    float A0 = top.a + A1;\n    return vec4(\n        (top.rgb * top.a + bottom.rgb * A1) / A0,\n        A0\n    );\n}\n\n\nfloat sampleCloudMapDensity(vec3 position) {\n    // Defines where the cloud are. Ideally this function acts a bit\n    // like a distance field - the density should not have any sharp edges in it.\n    //\n    // This function gets called a lot, so try to maximize it's performance.\n    \n    vec4 cloud_map = textureLod(BUFFER_CLOUD_COVER, position.xy * 0.005, 0.0);\n    \n    float density = 0.0;\n    density = (cloud_map.r - 0.4 - abs((0.5 + position.z - cloud_map.r * 2.0) * 0.1));\n    //density += pow(abs(cloud_map.g - position.z * 0.1), 3.);\n    density = max(density, cloud_map.b - 0.1 - abs(1.0 - cloud_map.b * 0.5 + position.z * 0.1));\n    \n    density = max(density, 0.0);\n    density = pow(density * 2.0, 2.0);\n    \n    return density;\n}\n\n\nvec3 lightMarch(vec3 start_position, vec3 view_direction) {\n    // Computes the lighting in the cloud at a given point\n    float lighting = 1.0;\n    float transmission = 1.0 - dot(LIGHT_DIRECTION, view_direction);\n    transmission += 0.1;\n    lighting *= clamp(1.0 - sampleCloudMapDensity(start_position + LIGHT_DIRECTION * 1.0) * 0.2 * transmission, 0.0, 1.0); // Self\n    lighting *= clamp(1.0 - sampleCloudMapDensity(start_position + LIGHT_DIRECTION * 2.0) * 0.2 * transmission, 0.0, 1.0); // Far\n    lighting *= clamp(1.0 - sampleCloudMapDensity(start_position + LIGHT_DIRECTION * 4.0) * 0.2 * transmission, 0.0, 1.0); // Far\n    lighting *= clamp(1.0 - sampleCloudMapDensity(start_position + LIGHT_DIRECTION * 8.0) * 0.2 * transmission, 0.0, 1.0); // Far\n    return vec3(lighting);\n}\n\n\n\nvec4 renderScene(vec3 start_point, vec3 direction) {\n    vec4 accumulation = vec4(0.0, 0.0, 0.0, 0.001);\n    \n    float dist_from_camera = 0.0;\n    int steps_outside_cloud = 0;\n    \n    float noise = hash14(vec4(direction * 1000.0, iTime * 10.0));\n    \n    vec3 sky = renderSky(direction);\n        \n    \n    for (int i=0; i<MAX_STEPS; i+=1) {\n        vec3 current_position = start_point + (dist_from_camera + noise * INSIDE_STEP_SIZE) * direction;\n        float cloud_map = sampleCloudMapDensity(current_position);\n        \n        \n        if (cloud_map > 0.0) {\n            if (steps_outside_cloud != 0) {\n                // First step into the cloud;\n                steps_outside_cloud = 0;\n                dist_from_camera = dist_from_camera - OUTSIDE_STEP_SIZE + INSIDE_STEP_SIZE;\n                continue;\n            }\n            steps_outside_cloud = 0;\n            \n        } else {\n            steps_outside_cloud += 1;\n        }\n        \n        float step_size = OUTSIDE_STEP_SIZE;\n        \n        if (steps_outside_cloud <= STEP_OUTSIDE_RATIO && cloud_map > 0.0) {  \n            step_size = INSIDE_STEP_SIZE;\n            \n            float density = cloud_map * 5.0;\n\n            if (accumulation.a < 0.8) {\n                // If we are already mostly opaque, there's no point sampling extra-detail.\n                vec4 small_noise_tex = textureLod(BUFFER_VOLUME_NOISE, current_position * 0.05 + vec3(0,iTime * 0.02,0), 0.0);\n                density -= pow(small_noise_tex.r, 3.0) * 3.0;\n            } else {\n                density -= 0.5;\n            }\n            \n            density *= step_size;\n            density = clamp(density, 0.0, 1.0);\n            \n            \n            \n            float fog = pow(1.0 - (dist_from_camera / DRAW_DISTANCE), 0.5);\n                        \n            vec3 lighting = lightMarch(current_position, direction);\n            \n            vec3 cloud_color = mix(\n                sky,\n                lighting,\n                clamp(fog, 0.0, 1.0)\n            );\n            \n            accumulation = alphaOver(accumulation, vec4(cloud_color, density));\n            \n        }\n        \n\n        dist_from_camera += step_size;\n        \n        if (accumulation.a > 0.98 || dist_from_camera > DRAW_DISTANCE) {\n            break;\n        }\n    }\n    \n    return vec4(alphaOver(accumulation, vec4(sky, 1.0)).rgb, dist_from_camera);\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    \n    // Ignore my coordinate transform mess here\n    vec2 raw_uv = fragCoord/iResolution.xy;\n    vec2 uv = raw_uv;\n    uv = (uv - 0.5) * 2.0;\n    \n    if (uv.x > 0. || uv.y > 0.) {\n        fragColor = vec4(0);\n        return;\n    }\n    uv = (uv + 0.5) * 2.0;\n    \n    uv.x *= iResolution.x / iResolution.y;\n    \n\n\n    // Render our geometry\n    mat4 camera_transform = quat_to_transform(\n        read_data(BUFFER_STATE, ADDR_CAMERA_ORIENTATION),\n        read_data(BUFFER_STATE, ADDR_CAMERA_POSITION).xyz\n    );\n    vec3 start_point = camera_transform[3].xyz;\n    vec3 direction = normalize(vec3(uv * LENS, 1.0));\n    direction = (camera_transform * vec4(direction, 0.0)).xyz;\n    \n\n    fragColor = renderScene(start_point, direction);\n\n    // HUD\n    //vec4 hud = texture(BUFFER_HUD, fragCoord / iResolution.xy);\n    //fragColor = mix(fragColor, hud, hud.a);\n}","name":"Buffer C","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"Nl2SWy","date":"1628534823","viewed":104,"name":"Spatial Sound Test","username":"Koulatko","description":"Trying to get some sort of 3D audio working, still not familiar enough with the science to make it sound believable (HRTFs and whatnot)\n\nHeadphones recommended (speakers have a less direct link between audio channels and what actually goes into the ear)","likes":6,"published":1,"flags":8,"usePreview":0,"tags":["3d","sound","learning"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//Some lazily thrown together raytracer from other test shaders\n\nvec4 ray_plane(vec3 ro, vec3 rd, vec4 plane){\n    float a = dot(plane.xyz, rd);\n    float b = dot(plane.xyz, ro) - plane.w;\n    return vec4(plane.xyz, max(0.0, -b/a));\n}\nvec4 ray_sphere(vec3 ro, vec3 rd, float R){\n    float d = dot(-ro, rd);\n    vec3 p = ro+d*rd;\n    float s = R*R-dot(p, p);\n    if(s < 0.0) return vec4(-1.0);\n    float o = sqrt(s);\n    float t = d - o;\n    return vec4(normalize(ro+t*rd), t);\n}\n\n\nfloat ray_scene(vec3 ro, vec3 rd, out int object_id, out vec3 nrm){\n    vec4 h;\n    vec4 h1;\n    object_id = 0;\n    h1 = ray_plane(ro, rd, vec4(0.0, 0.0, 1.0, 0.0));\n    if(h1.w > 0.0 && (h1.w < h.w || h.w <= 0.0)){\n        h = h1;\n        object_id = 1;\n    }\n    \n    h1 = ray_plane(ro, rd, vec4(0.0, -1.0, 0.0, 0.0));\n    if(h1.w > 0.0 && (h1.w < h.w || h.w <= 0.0)){\n        h = h1;\n        object_id = 2;\n    }\n    \n    h1 = ray_sphere(ro-sphere_pos(iTime), rd, 0.1);\n    if(h1.w > 0.0 && (h1.w < h.w || h.w <= 0.0)){\n        h = h1;\n        object_id = 4;\n    }\n    \n    \n    nrm = h.xyz;\n    return h.w;\n}\n\nvec3 sky(vec3 rd){\n    return 0.5*0.5+rd;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    vec3 ro = camera_pos(iTime);\n    \n    float fov = 1.4;\n    \n    vec3 rd = normalize(vec3(iResolution.x*(uv.x*2.0-1.0)/iResolution.y, (uv.y*2.0-1.0), 1.0/tan(fov/2.0)));\n    \n    rd = camera_orr(iTime)*rd;\n    \n    vec3 col;\n    vec3 lin_a = vec3(1.0);\n    vec3 lin_b = vec3(0.0);\n    \n    bool escaped = false;\n    for(int I = 0; I < 4; I++){\n        int o_id;\n        vec3 N;\n        \n        float depth = ray_scene(ro, rd, o_id, N);\n        \n        if(depth > 0.0){\n            float F0 = 0.3;\n            float F = F0 + (1.0-F0)*pow(1.0+dot(rd, N), 5.0);\n\n            ro += depth*rd;\n            rd = reflect(rd, N);\n            ro += 0.001*rd;\n\n            vec3 illum = vec3(1.0);\n            \n            vec3 diffuse = vec3(1.0);\n            \n            if(o_id == 1) diffuse = vec3(1.0, 0.1, 0.1);\n            if(o_id == 2) diffuse = vec3(0.1, 1.0, 0.1);\n            \n            if(o_id >= 1 && o_id <= 3){\n                diffuse *= 0.5+0.5*mod(floor(ro.x)+floor(ro.y)+floor(ro.z), 2.0);\n            }\n            \n            vec3 direct = diffuse*illum;\n            \n            lin_b += lin_a*(1.0-F)*direct;\n            lin_a *= F;\n        } else {escaped = true; break;}\n    }\n    \n    \n    col = pow(lin_b, vec3(1.0/2.2));\n    \n    fragColor = vec4(col,1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"vec3 sphere_pos(float time){\n    return vec3(2.0*cos(time), 2.0*sin(time)-3.0, 1.7);\n}\nvec3 camera_pos(float time){\n    return vec3(0.0, -3.0, 1.7);\n}\nmat3 camera_orr(float time){\n    //vec3 forward = normalize(sphere_pos(time)-vec3(0.0, 1.0, 1.7));\n    vec3 forward = vec3(0.0, 1.0, 0.0);\n    vec3 up = vec3(0.0, 0.0, 1.0);\n    vec3 right = cross(forward, up);\n    up = cross(right, forward);\n    \n    return mat3(right, up, forward);\n}","name":"Common","description":"","type":"common"},{"inputs":[],"outputs":[],"code":"//Channel order is all weird, patch over it with a #define for now\n//Remove if it's the wrong way\n#define SWAP_CHANNELS\n\nconst float notes[14] = float[](0.0, 2.0, 4.0, 5.0, 7.0, 9.0, 11.0, 12.0, 11.0, 9.0, 7.0, 5.0, 4.0, 2.0);\n\nfloat ear(int lr, vec3 pos, mat3 orr, int samp, float time){\n    const float c = 350.0;\n    \n    float v = 0.0;\n    \n    vec3 s_pos = sphere_pos(time);\n\n\n    vec3 cts = s_pos-pos;\n\n    float cv = 0.0;\n    float ctime = time - length(cts)/c; //Sound propagation delay for ear time difference, introduces a little bit of Doppler too\n    \n    float note = notes[int(time*2.0)%14];\n    for(int i = 0; i < 16; i++){\n        \n        float k = 2.0*float(i)+1.0; //Fourier series\n    \n        float freq = 128.0*k*exp2(note/12.0);\n        \n        float wave = 0.2*sin(freq*2.0*3.14159265358979*ctime)/k;\n        if(mod(ctime, 0.5) > 0.25) wave = 0.0;\n    \n        vec3 ear_dir = orr[0] * (lr == 1 ? 1.0 : -1.0);\n        //Very crude sound shadow\n        float costheta = dot(ear_dir, -normalize(cts));\n        float amp = exp(-0.0015*freq); //Higher frequencies are affected more\n        amp = mix(amp, 1.0, costheta*0.35+0.65);\n        //This provides no information about front/back and up/down position, unlike the real world\n        //The effect of sound origin on frequency distribution is far more complex than this\n        \n        wave *= amp;\n\n        cv += wave;\n    }\n    cv /= dot(cts, cts); //Inverse square attenuation\n    \n    v += cv;\n    return v/1.0;\n}\n\nvec2 mainSound(int samp, float time){\n    mat3 orr = camera_orr(time);\n    vec3 c_pos = camera_pos(time);\n    vec3 right = orr[0];\n    \n    float ear_distance = 0.2;\n    \n    vec3 lpos = c_pos-right*ear_distance/2.0;\n    vec3 rpos = c_pos+right*ear_distance/2.0;\n    \n    //return 0.2*clamp(vec2(ear(0, lpos, orr, samp, time)), vec2(-1.0), vec2(1.0));\n    return 0.7*vec2(ear(0, lpos, orr, samp, time), ear(1, rpos, orr, samp, time))\n    #ifdef SWAP_CHANNELS\n    .yx\n    #endif\n    ;\n}","name":"Sound","description":"","type":"sound"}]}
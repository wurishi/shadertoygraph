{"ver":"0.1","info":{"id":"l3KGWV","date":"1718272186","viewed":59,"name":"Fork Bicubic te gleed 112","username":"gleed","description":"Bottom left - dithered with a regular dither matrix (from the comment in the original shader).\nBottom right - linear-dithered with some procedural white noise (don't know what the source is).\nTop left - linear-dithered with blue noise.\nTop right - linear.","likes":0,"published":1,"flags":0,"usePreview":0,"tags":["texture","dither","cubic"],"hasliked":0,"parentid":"lcf3DN","parentname":"Bicubic texture dithering"},"renderpass":[{"inputs":[{"id":"4dX3Rn","filepath":"/media/a/bd6464771e47eed832c5eb2cd85cdc0bfc697786b903bfd30f890f9d4fc36657.jpg","previewfilepath":"/media/ap/bd6464771e47eed832c5eb2cd85cdc0bfc697786b903bfd30f890f9d4fc36657.jpg","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsBSR3","filepath":"/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","previewfilepath":"/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Public Domain under http://unlicense.org, see link for details.\n\n// A reasonably well-known technique (sometimes called \"poor man's bilinear\")\n// mimics bilinear filtering via dithering in texture space. See e.g.:\n//     https://www.flipcode.com/archives/Texturing_As_In_Unreal.shtml\n//     https://hugi.scene.org/online/coding/hugi%2020%20-%20cobil.htm\n// This shader demonstrates a bicubic variation of the technique.\n// This approach cannot use sharp kernels (with negative lobes, e.g.\n// Catmull-Rom), since while negative weights make sense, the negative\n// probabilities do not. This specific example uses cubic B-spline\n// (i.e. BC-spline with B=1, C=0).\n// This is still a 1-tap texturing approach, but the computations are\n// somewhat heavier.\n// While the merits of this approach are debatable (blurry and\n// not that cheap), now you at least can see what it looks like.\n\nivec2 XY; // Pixel coordinates.\n\n// https://www.shadertoy.com/view/dllSW7\nuint hash(uint x)\n{\n    x ^= x >> 15;\n    x ^= (x * x) | 1u;\n    x ^= x >> 17;\n    x *= 0x9E3779B9u;\n    x ^= x >> 13;\n    return x;\n}\n\n// \"Manual\" nearest. It is possible instead to bind\n// the same texture to a different channel set to nearest,\n// but whatever.\nvec4 texture_nearest(sampler2D s,vec2 uv)\n{\n    vec2 wh=vec2(textureSize(s,0));\n    uv=uv*wh;\n    uv=mod(uv,wh);\n    return texelFetch(s,ivec2(uv),0);\n}\n\nvec4 texture_dither_linear(sampler2D s,vec2 uv)\n{\n    vec2 wh=vec2(textureSize(s,0));\n    uv=uv*wh;\n    uv-=0.5; // Half-texel offset (so that samples are at integers).\n    uint h=hash(uint(65536*XY.y+XY.x)); // Screen-space hash.\n    vec2 d=vec2(h>>16,h&65535u)/65536.0; // White noise dither. Blue might be better.\n    uv+=d;\n    uv=mod(uv,wh);\n    return texelFetch(s,ivec2(uv),0);\n}\n\nvec4 texture_dither_linear_bluenoise(sampler2D s,vec2 uv, vec2 fragCoord)\n{\n    vec2 wh=vec2(textureSize(s,0));\n    uv=uv*wh;\n    uv-=0.5; // Half-texel offset (so that samples are at integers).\n    vec2 blue = texelFetch(iChannel1, ivec2(fragCoord) % ivec2(1024,1024), 0).xy;\n    uv+=blue;\n    uv=mod(uv,wh);\n    return texelFetch(s,ivec2(uv),0);\n}\n\nvec4 texture_dither_cubic(sampler2D s,vec2 uv)\n{\n    vec2 wh=vec2(textureSize(s,0));\n    uv=uv*wh;\n    uv-=0.5; // Half-texel offset (so that samples are at integers).\n    vec2 t=uv-floor(uv);\n    uv=floor(uv);\n    uint h=hash(uint(65536*XY.y+XY.x)); // Screen-space hash.\n    vec2 d=vec2(h>>16,h&65535u)/65536.0; // White noise dither. Blue might be better.\n    // It would be *nice* to just remap d via some\n    // transform f [0;1]->[lo;hi], so that distinct results of\n    // floor(f(d)) would have the probabilities we need. Finding\n    // such transform, however, looks non-trivial, so we do\n    // a low-tech solution instead.\n    // Below are 3 thresholds, which are just cumulative weights\n    // of our B-spline (multiplied by 6).\n    vec2 w0=1.0+t*(-3.0+t*(+3.0+t*-1.0)); // weight[-1]\n    vec2 w1=5.0+t*(-3.0+t*(-3.0+t*+2.0)); // weight[-1]+weight[0]\n    vec2 w2=6.0-t*t*t; // weight[-1]+weight[0]+weight[+1]\n    d*=6.0;\n    uv+=step(w0,d)+step(w1,d)+step(w2,d)-1.0;\n    uv=mod(uv,wh);\n    return texelFetch(s,ivec2(uv),0);\n}\n\nvec4 texture_dither_regular(sampler2D s,vec2 uv, vec2 fragcoord)\n{\n    vec2 wh=vec2(textureSize(s,0));\n    uv=uv*wh;\n    uv-=0.5; // Half-texel offset (so that samples are at integers).\n    \n    int X=XY.x&3,Y=XY.y&3;\n    vec2 d=vec2(\n    ((Y>>1)&1)|((X^Y)&2)|((Y&1)<<2)|(((X^Y)&1)<<3),\n    ((X>>1)&1)|((X^Y)&2)|((X&1)<<2)|(((X^Y)&1)<<3))/16.0;\n    uv+=d;\n    uv=mod(uv,wh);\n    return texelFetch(s,ivec2(uv),0);\n}\n\nvoid mainImage(out vec4 fragColor,in vec2 fragCoord)\n{\n    float scale=64.0;\n    XY=ivec2(fragCoord);\n    vec2 xy=(2.0*fragCoord-iResolution.xy)/iResolution.y;\n    vec2 uv=(xy+0.25*iTime)/scale;\n    vec3 col=vec3(0);\n    switch((xy.x>0.0?1:0)+(xy.y>0.0?2:0))\n    {\n        case 0: col=texture_dither_regular (iChannel0,uv, fragCoord).xyz; break;\n        case 1: col=texture_dither_linear(iChannel0,uv).xyz; break;\n        case 2: col=texture_dither_linear_bluenoise (iChannel0,uv, fragCoord).xyz; break;\n        case 3: col=texture              (iChannel0,uv).xyz; break;\n    }\n    fragColor=vec4(col,1.0);\n}","name":"Image","description":"","type":"image"}]}
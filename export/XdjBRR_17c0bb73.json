{"ver":"0.1","info":{"id":"XdjBRR","date":"1499300790","viewed":2375,"name":"Convolutional Neural Net","username":"rory618","description":"Work in progress building and training a convolutional neural network with a generative architecture. The number of layers can be changed - const int L = 5;\n\nTraining seems to usually become unstable and diverges but has good results at its best.\n\n\n","likes":47,"published":1,"flags":32,"usePreview":1,"tags":["gradient","neural","network","descent"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"vec4 getLetter(vec2 uv, int l){\n    vec2 letter = vec2(l-(l/16)*16,l/16);\n    return texture(iChannel0, (letter*64.0 + uv*64.0)/1024.);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n    \n    \n    vec4 lc = getLetter(uv, iFrame/50);\n    \n\tfragColor = abs(texture(iChannel1, (floor(fragCoord.xy/4.)+.5) / iResolution.xy));//(lc.wwww+(.5-iMouse.x)/iResolution.x)*iResolution.y;\n\n\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGzr","filepath":"/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","previewfilepath":"/media/ap/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"\nconst int L = 5;\nconst float _2L = pow(2.,float(L));\n\n//locations of different parts of the system\nconst vec2 _output = vec2(0,0);\nconst vec2 _grad = vec2(_2L*2.,0);\nconst vec2 _weights = vec2(0,_2L);\nconst vec2 _target = vec2(_2L*4.,0);\nconst vec2 _error = vec2(_2L*4.,_2L);\nconst vec2 _summation = vec2(_2L*4.,_2L*2.);\nconst vec2 _plot = vec2(_2L*5.,0);\nconst vec2 _bias = vec2(_2L*4.,_2L*3.);\n\n//for counting which frame it is, what values will be updated\nfloat cycle = 0.;\n\n//learning rate and stochasticity\nfloat lr = .0001;\nfloat noise = .0005;\n\nvec4 hash44(vec4 p4){\n    p4 = fract(sin(p4)  * vec4(443.897, 441.423, 437.195, 444.129)/8.);\n    p4 += dot(p4, p4.wzxy+19.19);    return fract((p4.xxyz+p4.yzzw)*p4.zywx);\n    //return fract(vec4((p4.x + p4.y)*p4.z, (p4.x + p4.z)*p4.y, (p4.y + p4.z)*p4.w, (p4.z + p4.w)*p4.x));\n}\n\n//outputs the target for the net\nvec4 target(vec2 p){\n    int l = int(iMouse.x/5.);\n    vec2 letter = vec2(l-(l/16)*16,l/16);\n    return texture(iChannel1, (letter*64.0 + p*64.0 + 1.)/1024.);\n    //return texture(iChannel1,p*.1);\n}\n\n//activation functions\nvec4 relu(vec4 x){\n    return max(vec4(0),x);\n}\nvec4 elu(vec4 x){\n    return relu(x)-.5*(sign(x)-1.)*(exp(x)-1.);\n}\n\n//get the output value at layer l, channel set c (each pixel can store 4 channels), location p\nvec4 getO(int l, int c, vec2 p){\n    float size = pow(2.,float(l));\n    if(l>0&&(p.x<0.||p.x>=size||p.y<0.||p.y>=size)){\n        return vec4(0);\n    }\n    vec2 s = _output + vec2(size,size*float(c));\n    return textureLod(iChannel0, (s + max(vec2(0),min(p,vec2(size-1.))) + .5)/iChannelResolution[0].xy,-100.);\n}\n//get the gradient at layer l, channel set c, location p\nvec4 getG(int l, int c, vec2 p){\n    float size = pow(2.,float(l));\n    vec2 s = _grad + vec2(size,size*float(c));\n    return textureLod(iChannel0, (s + max(vec2(0),min(p,vec2(size-1.))) + .5)/iChannelResolution[0].xy,-100.);\n}\n//get the weights for input layer l, filter location p, channel input ci, channel output set co, co=0 returns output channels 0-3 in a vec4\nvec4 getW(int l, vec2 p, int ci, int co){\n    float size = pow(2., float(l)); \n    vec2 s = _weights + size*vec2(ci,co) + vec2(0,float(l)*_2L/2.);\n    return textureLod(iChannel0, (s + max(vec2(0),min(p,size-1.)) + .5)/iChannelResolution[0].xy,-100.);\n}\n//get input to net\nvec4 getInput(vec2 p){\n    return textureLod(iChannel0, (p+.5)/iChannelResolution[0].xy,-100.);\n}\n//get bias at layer l for channel c\nvec4 getBias(int l, int c){\n    float i = pow(2.,float(L-l))+float(c);\n    float x = floor(i/_2L);\n    float y = i-x*_2L;\n    vec2 s = _bias + vec2(x,y);\n    return  textureLod(iChannel0, ( s + .5 )/iChannelResolution[0].xy  ,-100.);\n}\n\n//compute the derivative of an output wrt a weight\nvec4 dOdW(int l, vec2 pw, int ci, int co, vec2 po){\n    if(mod(po.x,2.0) != mod(pw.x,2.0)){\n        return vec4(0);\n    }\n    if(mod(po.y,2.0) != mod(pw.y,2.0)){\n        return vec4(0);\n    }\n    float size = pow(2.,float(l));\n    \n    return getO(l,ci,floor( (po+pw-size/2.)/2. ) );\n        \n}\n\n//compute the layer output value\nvec4 setO(int l, int c, vec2 p){\n    if(l==0 ){//first layer is just identity\n        return getInput(vec2(0,c));\n    }\n    if(l>0){//compute layer output one frame at a time\n        if(float(l)!=cycle){\n            return getO(l,c,p);\n        }\n    }\n    float size = pow(2.,float(l))/2.;\n    float is = _2L/size;\n    float ct = 0.;                  \n    vec4 res = vec4(0);\n    \n    float xl = 0.;\n    float yl = 0.;\n    if (mod(p.x,2.)>.5){\n        xl = 1.;\n    }\n    if (mod(p.y,2.)>.5){\n        yl = 1.;\n    }\n    \n    //preform the convolution using weights and previous layer\n    for(float x = -size/2.; x <= size/2.; x += 2.){\n        for(float y = -size/2.; y <= size/2.; y += 2.){\n            \n            for (float h = 0.0; h < is; h+=1.){\n                vec4 inputData = getO(l-1,int(h),floor( (p+vec2(x,y))/2. ) );\n                mat4 filterData = mat4(getW(l-1, vec2(xl,yl)+vec2(x,y)+size/2., int(4.* h + 0.), c ),\n                                       getW(l-1, vec2(xl,yl)+vec2(x,y)+size/2., int(4.* h + 1.), c ),\n                                       getW(l-1, vec2(xl,yl)+vec2(x,y)+size/2., int(4.* h + 2.), c ),\n                                       getW(l-1, vec2(xl,yl)+vec2(x,y)+size/2., int(4.* h + 3.), c ));\n                res += filterData * inputData;\n                ct++; \n                \n            }\n        }\n    }\n    \n    //add bias and activation\n    return relu(res/ct + getBias(l,c));\n}\n\n//compute the gradient\nvec4 setG(int l, int c, vec2 p){\n    if(float(L*2+1-l)!=cycle){//only update when its time\n        return getG(l,c,p);\n    }\n    float f_c = float(c);\n    if(l==L){//gradient for the last layer is just output-target\n        return(getO(l, c, p)-target(p/_2L));\n    } else {\n        vec4 G = vec4(0);\n        float size = pow(2.,float(l));\n        int ocs = int(_2L/size/2.);\n        float ct = 0.;\n        \n        //convolution for backpropagation\n        for(float x = -size/2.; x < size/2.; x += 1.){\n            for(float y = -size/2.; y < size/2.; y += 1.){\n                for(int h = 0; h < ocs; h++){\n                    vec4 grad = getG(l+1,h,p*2. + vec2(x,y));\n                    vec4 inputData = getO(l,int(f_c),floor( (p+vec2(x,y))/2. ) );\n                    mat4 filterData = mat4(getW(l, size/2.-vec2(x,y)-1., int(4.* f_c + 0.), h ),\n                                           getW(l, size/2.-vec2(x,y)-1., int(4.* f_c + 1.), h ),\n                                           getW(l, size/2.-vec2(x,y)-1., int(4.* f_c + 2.), h ),\n                                           getW(l, size/2.-vec2(x,y)-1., int(4.* f_c + 3.), h ));\n                    G += grad*(filterData*inputData);\n                    ct++; \n                }\n            }\n        }\n        \n        //cap gradients..? doesnt help\n        return min(G/ct,vec4(5));\n        \n    }\n    \n}\n\n//copute the weight updates\nvec4 setW(int l, vec2 p, int ci, int co){\n    if (iFrame == 0){\n        return (1./(2.+length(p-pow(2.,float(l))/2. )))*2.*(hash44(hash44(iDate)+hash44(vec4(p,ci,co)*float(1+l))));\n    } else {\n        vec4 dedw = vec4(0);\n        //instead of summing every derivative just do most of them randomly, kind of like dropout and less expensive\n        for (int h = 0; h < 128; h++){\n            vec2 p0 = floor(_2L*hash44(vec4(h,iFrame,p)).xy);\n\n            dedw += getG(l+1,co,p0)*dOdW(l,p,ci,co,p0);\n        }\n        vec4 rand1 = hash44(hash44(iDate)+hash44(vec4(p,ci,co)));\n        vec4 rand2 = hash44(rand1);\n        vec4 r = getW(l, p, ci, co);\n        vec4 _u = getW(l, p+vec2(0,1), ci, co);\n        vec4 _d = getW(l, p+vec2(0,-1), ci, co);\n        vec4 _l = getW(l, p+vec2(0,-1), ci, co);\n        vec4 _r = getW(l, p+vec2(0,1), ci, co);\n        if(rand1.x<.001){//weight decay\n            r *= .99;\n        }\n        //if(rand1.y<.01){ blur filters?\n        //    r = .96*r + .01*(_u+_d+_l+_r);\n        //}\n        r -= dedw*lr;//move down the gradient\n        r += (rand2-.5)*noise;//stochastisity\n        return r;\n    }\n}\n\n//set the input and change it to lower loss\nvec4 setInput(vec2 p){\n    if (iFrame == 0){\n        return hash44(hash44(iDate)+hash44(vec4(p,75,43)));\n    }\n    return getInput(p) - lr*getG(0,int(p.y),vec2(0));\n}\n//update bias values\nvec4 setBias(int l, int c){\n    if (iFrame == 0){\n        return hash44(hash44(iDate)+hash44(vec4(l,c,31,13)));\n    }\n    vec4 dedb = vec4(0);\n    for (int h = 0; h < 128; h++){\n        vec2 p0 = floor(_2L*hash44(vec4(h,iFrame,c,l)).xy);\n\n        dedb += getG(l,c,p0);\n    }\n    return .995*getBias(l,c) - lr*dedb;\n    \n}\n\n//draw everything in the right spot\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n    cycle = mod(float(iFrame),20.);\n    vec2 z = floor(fragCoord.xy);\n    if(z.x==0. && z.y < _2L){\n        fragColor = setInput(z);\n    }\n    vec2 zp = z -_output;\n    if(zp.x > 0. && zp.x < _2L*2. && zp.y >=0. && zp.y < _2L) {\n        int l = int(log2(zp.x));\n        float size = pow(2.,float(l));\n        int c = int(zp.y/size);\n        fragColor = setO(l, c, zp - size*vec2(1,c));\n    }\n    zp = z -_grad;\n    if(zp.x >= 0. && zp.x < _2L*2. && zp.y >=0. && zp.y < _2L) {\n        int l = int(log2(zp.x));\n        float size = pow(2.,float(l));\n        int c = int(zp.y/size);\n        fragColor = setG(l, c, zp - size*vec2(1,c));\n    }\n    zp = z -_weights;\n    if(zp.x >= 0. && zp.x < _2L*4. && zp.y >=0. && zp.y < _2L*float(L)/2.) {\n        int l = int(zp.y/(_2L/2.));\n        float size = pow(2.,float(l));\n        int ci = int(zp.x/size);\n        int co = int((zp.y-float(l)*(_2L/2.))/size);\n        fragColor = setW(l, zp-size*vec2(ci,co)-vec2(0,l)*(_2L/2.), ci, co);\n    }\n    zp = z -_target;\n    if(zp.x >= 0. && zp.x < _2L && zp.y >=0. && zp.y < _2L) {\n        fragColor = target(zp/_2L);\n    }\n    zp = z -_error;\n    if(zp.x >= 0. && zp.x < _2L && zp.y >=0. && zp.y < _2L) {\n        vec4 d = target(zp/_2L)-getO(L,0,zp);\n        fragColor = d*d;\n    }\n    zp = z -_summation;//summing every difference for a total loss value\n    if(zp.x >= 0. && zp.x < _2L && zp.y >=0. && zp.y < _2L) {\n        vec4 sse = vec4(0);\n        if(zp.x == 0.){\n            for(float x = 0.; x < _2L; x++){\n                sse += textureLod(iChannel0, (_error+vec2(x,zp.y)+.5)/iChannelResolution[0].xy,-100.);\n            }\n            fragColor = vec4(dot(sse,vec4(1))/(4.*_2L) );\n        } else if(zp.x== 1.&&zp.y==0.){\n            for(float y = 0.; y < _2L; y++){\n                sse.x += textureLod(iChannel0, (_summation+vec2(0,y)+.5)/iChannelResolution[0].xy,-100.).x;\n            }\n            fragColor = vec4(sse.x/_2L);\n        } else {\n            vec2 pp = zp - vec2(0,1);\n            if(pp.y<0.){\n                pp.y += _2L;\n                pp.x -= 1.;\n            }\n            fragColor = textureLod(iChannel0, (_summation+pp+.5)/iChannelResolution[0].xy,-100.);\n        }\n        \n        \n    }\n    \n    zp = z -_plot;\n    if(zp.x >= 0. && zp.x < _2L*2. && zp.y >=0. && zp.y < _2L) {\n        float n = zp.x * _2L + _2L+2.;\n        vec2 s = vec2(floor(n/_2L),mod(n,_2L));\n        float y = .5+.1*log(2.*textureLod(iChannel0, (_summation+s+.5)/iChannelResolution[0].xy,-100.).x);\n        if(y!=0.)\n        \tfragColor = vec4(1.)/(1.+10.*abs(y-zp.y/(_2L*2.)));\n    }\n    zp = z - _bias;\n    if(zp.x >= 0. && zp.x < _2L && zp.y >=0. && zp.y < _2L) {\n        float i = zp.y+zp.x*_2L;\n        int l = L-int(log2(i));\n        int c = int(i-pow(2.,float(L-l)));\n        if(l>=0)\n            fragColor = setBias(l,c);\n    }\n    \n}\n    ","name":"Buf A","description":"","type":"buffer"}]}
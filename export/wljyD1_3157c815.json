{"ver":"0.1","info":{"id":"wljyD1","date":"1594827263","viewed":130,"name":"PML 001 - Progressive raymarch","username":"Ryp","description":"Just added stochastic progressive sampling to converge on a smoother image.","likes":3,"published":1,"flags":32,"usePreview":0,"tags":["raymarch","sdf","progressive"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n\n    vec3 col = vec3(0.0);\n    \n    if( iFrame>0 )\n    {\n        col = texture( iChannel0, uv ).xyz;\n        col /= float(iFrame + 1);\n    }\n\n    fragColor = vec4(col, 1.0 );\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"float time()\n{\n    return 0.0;\n}\n\nfloat sdOctahedron( in vec3 p, in float s)\n{\n    p = abs(p);\n    float m = p.x+p.y+p.z-s;\n    vec3 q;\n         if( 3.0*p.x < m ) q = p.xyz;\n    else if( 3.0*p.y < m ) q = p.yzx;\n    else if( 3.0*p.z < m ) q = p.zxy;\n    else return m*0.57735027;\n    \n    float k = clamp(0.5*(q.z-q.y+s),0.0,s); \n    return length(vec3(q.x,q.y-s+k,q.z-k)); \n}\n\nfloat saturate(float v)\n{\n    return clamp(v, 0.0, 1.0);\n}\n\nmat4 viewMatrix(vec3 eye, vec3 center, vec3 up) {\n\tvec3 f = normalize(center - eye);\n\tvec3 s = normalize(cross(f, up));\n\tvec3 u = cross(s, f);\n\treturn mat4(\n\t\tvec4(s, 0.0),\n\t\tvec4(u, 0.0),\n\t\tvec4(-f, 0.0),\n\t\tvec4(0.0, 0.0, 0.0, 1)\n\t);\n}\n\nfloat intersectSDF(float distA, float distB) {\n    return max(distA, distB);\n}\n\nfloat unionSDF(float distA, float distB) {\n    return min(distA, distB);\n}\n\nfloat opSmoothUnion( float d1, float d2, float k )\n{\n    float h = clamp( 0.5 + 0.5*(d2-d1)/k, 0.0, 1.0 );\n    return mix( d2, d1, h ) - k*h*(1.0-h);\n}\n\nfloat differenceSDF(float distA, float distB) {\n    return max(distA, -distB);\n}\n\nfloat sdBox(vec3 p, vec3 b)\n{\n  \tvec3 d = abs(p) - b;\n  \treturn length(max(d,0.0)) + min(max(d.x,max(d.y,d.z)),0.0); // remove this line for an only partially signed sdf \n}\n\nfloat sphereSDF(vec3 p)\n{\n    return length(p) - 1.0;\n}\n\nconst int MAX_MARCHING_STEPS = 200;\nconst float EPSILON = 0.005f;\n\nfloat onion( in float d, in float h )\n{\n    return abs(d)-h;\n}\n\nfloat opRep( in vec3 p, in vec3 c)\n{\n    vec3 q = mod(p,c)-0.5*c;\n    return onion(sdOctahedron(q, 0.5),0.05);\n}\n\nfloat sceneSDF(vec3 p)\n{\n    return opRep(p + vec3(time(),time()*0.5,0), vec3(2.0, 2.0, 2.0));\n}\n\nfloat shortestDistanceToSurface(vec3 eye, vec3 marchingDirection, float start, float end) {\n    float depth = start;\n    for (int i = 0; i < MAX_MARCHING_STEPS; i++) {\n        float dist = sceneSDF(eye + depth * marchingDirection);\n        if (dist < EPSILON) {\n\t\t\treturn depth;\n        }\n        depth += dist;\n        if (depth >= end) {\n            return end;\n        }\n    }\n    return end;\n}\n\nvec3 estimateNormal(vec3 p)\n{\n    return normalize(vec3(\n        sceneSDF(vec3(p.x + EPSILON, p.y, p.z)) - sceneSDF(vec3(p.x - EPSILON, p.y, p.z)),\n        sceneSDF(vec3(p.x, p.y + EPSILON, p.z)) - sceneSDF(vec3(p.x, p.y - EPSILON, p.z)),\n        sceneSDF(vec3(p.x, p.y, p.z  + EPSILON)) - sceneSDF(vec3(p.x, p.y, p.z - EPSILON))\n    ));\n}\n\nconst float pi = 3.14159265358;\n\nfloat deg2rad(float angleDeg)\n{\n \treturn (angleDeg * pi) / 180.f;\n}\n\nfloat hash(float seed)\n{\n    return fract(sin(seed)*43758.5453 );\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    float f = float(iFrame + 1);\n    vec2 offsetUV = vec2(hash(f + 13.271), hash(f + 63.216)) - 0.5;\n    \n    vec2 positionUV = (fragCoord + offsetUV) / iResolution.xy;\n    \n    vec2 positionNDC = 2.0 * positionUV - 1.0;\n    positionNDC.y = -positionNDC.y;\n    \n    // Camera setup\n    float cameraHFovAngle = deg2rad(55.f);\n    float cameraNear = 0.1f;\n    float cameraFar = 200.0f;\n    vec3 eyePositionWS = vec3(3.5f, 1.5f + sin(time() * 0.2), 6.5f);\n\n    // Viewport calculations\n    float aspectRatioInv = iResolution.y / iResolution.x;\n    \n    float horizontalFov = cameraNear * tan(cameraHFovAngle * 0.5f);\n \tfloat verticalFov = horizontalFov * aspectRatioInv;\n    vec2 cameraViewportExtent = vec2(horizontalFov, verticalFov);\n    \n    vec3 viewRayDirectionWS = vec3(positionNDC * cameraViewportExtent, cameraNear);\n    \n    viewRayDirectionWS = (viewMatrix(eyePositionWS, vec3(0.5, 0.5, 0.5 + cos(time() * 0.5) * 0.5), vec3(0.0, 0.0, 1.0)) * vec4(viewRayDirectionWS, 0.0)).xyz;        \n    viewRayDirectionWS = normalize(-viewRayDirectionWS);\n    \n    float rayDepth = shortestDistanceToSurface(eyePositionWS, viewRayDirectionWS, cameraNear, cameraFar);\n\n    vec3 p = eyePositionWS + rayDepth * viewRayDirectionWS;\n    \n    vec3 light1PosWS = vec3(2.0, 4.0, 6.0);\n    vec3 light1Ambient = vec3(.1, .2, .1);\n    vec3 light1Color = vec3(0.9, 0.7, 0.2);\n    vec3 normalWS = estimateNormal(p);\n    vec3 L1 = normalize(light1PosWS - p);\n    vec3 V = normalize(eyePositionWS - p);\n    vec3 R1 = normalize(reflect(-L1, normalWS));\n\n    vec3 light2PosWS = vec3(4.0, -6.0, 2.0);\n    vec3 light2Color = vec3(1.0, 0.1, 0.0) * 0.4;\n    vec3 L2 = normalize(light2PosWS - p);\n    vec3 R2 = normalize(reflect(-L2, normalWS));\n    \n    float dotL1N = saturate(dot(L1, normalWS));\n    float dotL2N = saturate(dot(L2, normalWS));\n    float dotR1V = saturate(dot(R1, V));\n    float dotR2V = saturate(dot(R2, V));\n    float dotNV = saturate(abs(dot(normalWS, V)));\n        \n    // Output some color\n    vec3 color = vec3(0.0);\n    \n    float tangentHighlightPeriod = 3.5;\n    float tangentHighlightDist = abs(mod(rayDepth + tangentHighlightPeriod * 0.5, tangentHighlightPeriod) - tangentHighlightPeriod * 0.5);\n    vec3 tangentHighlightContribution = vec3(0.0, 0.2, 1.0) * (1.0/tangentHighlightDist*0.01);\n    \n   \tfloat gloss = 0.15 / (EPSILON + dotNV);\n    \n    if (rayDepth > cameraFar - EPSILON)\n    {\n        // Didn't hit anything\n        color = vec3(0.0);\n    }\n    else\n    {\n    \tcolor = light1Color * max(EPSILON, dotL1N) + light1Ambient;\n        color *= max(EPSILON, dotR1V);\n        color += vec3(0.9, 0.7, 0.2) * gloss;\n        color += tangentHighlightContribution;\n        \n        color += light2Color * max(EPSILON, dotL2N) * max(EPSILON, dotR2V);\n    }\n    \n    // Distance fog\n    vec3 fogColor = vec3(0.9, 0.3, 0.2);\n    color = mix(fogColor, color, 1.0 / (1.0 + rayDepth * 0.1));\n    \n    // Read previous frame\n    vec3 prev_color = texture(iChannel0, fragCoord / iResolution.xy).rgb;\n    if (iFrame == 0)\n    {\n        prev_color = vec3(0.0);\n    }\n    \n    // Output color\n    fragColor = vec4(prev_color + color, 1.0);\n}","name":"Buffer A","description":"","type":"buffer"}]}
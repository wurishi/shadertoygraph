{"ver":"0.1","info":{"id":"lcsSWl","date":"1707732503","viewed":26,"name":"[inspirnathan] 09 - CamLookAt","username":"hrst4","description":"[inspirnathan] 09 - CamLookAt","likes":1,"published":1,"flags":0,"usePreview":0,"tags":["inspirnathan"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// This a french translation of the highly educational Nathan Vaughn's tutorials.\n// Un grand merci à lui !\n// his website: https://inspirnathan.com/\n// original:\n// from https://inspirnathan.com/posts/56-shadertoy-tutorial-part-10\n#define PART 3\n/*\nBonjour, chers amis ! Bienvenue dans la dixième partie de ma série de tutoriels Shadertoy.\nDans ce tutoriel, nous allons apprendre à créer un modèle de caméra plus flexible qui utilise\nun point d'observation. Il sera ainsi plus facile de changer les objets que la caméra regarde.\n\n# Configuration initiale\n\nCréons un nouveau shader et ajoutons le code de base suivant que nous utiliserons pour ce tutoriel.\nRemarquez que les constantes sont maintenant définies en haut du code.\n*/\n\n#if PART == 0\n// Constants\nconst int MAX_MARCHING_STEPS = 255;\nconst float MIN_DIST = 0.0;\nconst float MAX_DIST = 100.0;\nconst float PRECISION = 0.001;\nconst float EPSILON = 0.0005;\nconst float PI = 3.14159265359;\n\n// Rotation matrix around the X axis.\nmat3 rotateX(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(1, 0, 0),\n        vec3(0, c, -s),\n        vec3(0, s, c)\n    );\n}\n\n// Rotation matrix around the Y axis.\nmat3 rotateY(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, 0, s),\n        vec3(0, 1, 0),\n        vec3(-s, 0, c)\n    );\n}\n\n// Rotation matrix around the Z axis.\nmat3 rotateZ(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, -s, 0),\n        vec3(s, c, 0),\n        vec3(0, 0, 1)\n    );\n}\n\n// Identity matrix.\nmat3 identity() {\n    return mat3(\n        vec3(1, 0, 0),\n        vec3(0, 1, 0),\n        vec3(0, 0, 1)\n    );\n}\n\nstruct Surface {\n    float sd; // signed distance value\n    vec3 col; // color\n};\n\nSurface sdBox( vec3 p, vec3 b, vec3 offset, vec3 col, mat3 transform)\n{\n  p = (p - offset) * transform; // apply transformation matrix\n  vec3 q = abs(p) - b;\n  float d = length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n  return Surface(d, col);\n}\n\nSurface sdFloor(vec3 p, vec3 col) {\n  float d = p.y + 1.;\n  return Surface(d, col);\n}\n\nSurface minWithColor(Surface obj1, Surface obj2) {\n  if (obj2.sd < obj1.sd) return obj2;\n  return obj1;\n}\n\nSurface sdScene(vec3 p) {\n  vec3 floorColor = vec3(1. + 0.7*mod(floor(p.x) + floor(p.z), 2.0));\n  Surface co = sdFloor(p, floorColor);\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(-4, 0.5, -4), vec3(1, 0, 0), identity())); // left cube\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(0, 0.5, -4), vec3(0, 0.65, 0.2), identity())); // center cube\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(4, 0.5, -4), vec3(0, 0.55, 2), identity())); // right cube\n  return co;\n}\n\nSurface rayMarch(vec3 ro, vec3 rd, float start, float end) {\n  float depth = start;\n  Surface co; // closest object\n\n  for (int i = 0; i < MAX_MARCHING_STEPS; i++) {\n    vec3 p = ro + depth * rd;\n    co = sdScene(p);\n    depth += co.sd;\n    if (co.sd < PRECISION || depth > end) break;\n  }\n  \n  co.sd = depth;\n  \n  return co;\n}\n\nvec3 calcNormal(in vec3 p) {\n    vec2 e = vec2(1, -1) * EPSILON;\n    return normalize(\n      e.xyy * sdScene(p + e.xyy).sd +\n      e.yyx * sdScene(p + e.yyx).sd +\n      e.yxy * sdScene(p + e.yxy).sd +\n      e.xxx * sdScene(p + e.xxx).sd);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n  vec2 uv = (fragCoord-.5*iResolution.xy)/iResolution.y;\n  vec3 backgroundColor = vec3(0.835, 1, 1);\n\n  vec3 col = vec3(0);\n  vec3 ro = vec3(0, 0, 3); // ray origin that represents camera position\n  vec3 rd = normalize(vec3(uv, -1)); // ray direction\n\n  Surface co = rayMarch(ro, rd, MIN_DIST, MAX_DIST); // closest object\n\n  if (co.sd > MAX_DIST) {\n    col = backgroundColor; // ray didn't hit anything\n  } else {\n    vec3 p = ro + rd * co.sd; // point on cube or floor we discovered from ray marching\n    vec3 normal = calcNormal(p);\n    vec3 lightPosition = vec3(2, 2, 7);\n    vec3 lightDirection = normalize(lightPosition - p);\n\n    float dif = clamp(dot(normal, lightDirection), 0.3, 1.); // diffuse reflection\n\n    col = dif * co.col + backgroundColor * .2; // Add a bit of background color to the diffuse color\n  }\n\n  // Output to screen\n  fragColor = vec4(col, 1.0);\n}\n\n/*\nCe code produira une scène avec trois cubes, chacun avec des couleurs différentes : rouge, vert et bleu.\n\n# Le point LookAt\n\nActuellement, lorsque nous voulons déplacer la caméra, nous devons ajuster les valeurs de l'origine des rayons.\nPour incliner la caméra, nous devons multiplier la direction du rayon par une matrice de rotation.\n\nUne autre approche consiste à créer une fonction de caméra qui accepte la position de la caméra \n(ou l'origine du rayon) et un point d'observation. \nCette fonction renvoie alors une matrice de transformation 3x3 par laquelle nous pouvons multiplier \nla direction du rayon.\n\nmat3 camera(vec3 cameraPos, vec3 lookAtPoint) {\n\tvec3 cd = normalize(lookAtPoint - cameraPos); // camera direction\n\tvec3 cr = normalize(cross(vec3(0, 1, 0), cd)); // camera right\n\tvec3 cu = normalize(cross(cd, cr)); // camera up\n\t\n\treturn mat3(-cr, cu, -cd);\n}\n\nPour comprendre comment nous en sommes arrivés à cette matrice, regardons l'image ci-dessous. \nElle a été créée sur le site web Learn OpenGL, une ressource extraordinaire pour l'apprentissage \nde l'API graphique OpenGL.\n\nhttps://inspirnathan.com/_nuxt/img/img-2.4224110.png\n\nL'image ci-dessus en dit long sur la façon dont la matrice 3x3 a été créée.\nNous devons déterminer où la caméra regarde et comment elle est inclinée en analysant trois vecteurs\nimportants de la caméra : le vecteur \"direction de la caméra\", le vecteur \"droite de la caméra\" \net le vecteur \"haut de la caméra\".\n\nÀ l'étape 1, nous commençons par la position de la caméra, qui est égale à l'origine du rayon, ro,\ndans notre code.\n\nÀ l'étape 2, nous créons un vecteur de direction de la caméra relatif à un point \"lookat\".\nDans l'image, le point d'observation est situé à l'origine dans l'espace 3D,\nmais nous pouvons déplacer ce point où nous le souhaitons. \nRemarquez que la direction de la caméra s'éloigne de la caméra.\nCela signifie qu'elle utilise la règle de la main droite que nous avons apprise dans la partie 6.\n\nvec3 cd = normalize(lookAtPoint - cameraPos); // camera direction\n\nÀ l'étape 3, un vecteur gris pointe vers le haut à partir de la caméra.\nLe vecteur de direction (0, 1, 0) représente un vecteur unitaire pour l'axe des ordonnées.\nNous créons le vecteur \"droite de la caméra\" en effectuant le produit vectoriel entre le vecteur\nunitaire de l'axe des ordonnées et la direction de la caméra.\nCela crée le vecteur rouge pointant vers la droite de la caméra.\n\nnormalize(cross(vec3(0, 1, 0), cd)); // camera right\n\nÀ l'étape 4, nous trouvons le vecteur \"caméra vers le haut\" en effectuant le produit vectoriel\nentre le vecteur de direction de la caméra et le vecteur \"caméra vers la droite\". \nCe vecteur \"caméra vers le haut\" est représenté sur l'image par un vecteur vert sortant de la caméra.\n\nvec3 cu = normalize(cross(cd, cr)); // camera up\n\nEnfin, nous créons une matrice de transformation en combinant ces vecteurs :\n\nmat3 camera(vec3 cameraPos, vec3 lookAtPoint) {\n\tvec3 cd = normalize(lookAtPoint - cameraPos); // camera direction\n\tvec3 cr = normalize(cross(vec3(0, 1, 0), cd)); // camera right\n\tvec3 cu = normalize(cross(cd, cr)); // camera up\n\t\n\treturn mat3(-cr, cu, -cd); // negative signs can be turned positive (or vice versa) to flip coordinate space conventions\n}\n\nExaminons l'instruction de retour de la fonction caméra :\n\nreturn mat3(-cr, cu, -cd);\n\nD'où viennent les signes négatifs ? C'est à nous de définir une convention sur la façon \ndont nous voulons indiquer la direction positive ou négative pour chaque axe dans l'espace 3D.\nC'est cette convention que j'utiliserai dans ce tutoriel.\nNous verrons bientôt ce qui se passe lorsque nous inversons les signes.\n\n# Application de la matrice de la caméra\n\nMaintenant que nous avons créé une fonction caméra, \nutilisons-la dans notre fonction mainImage. \nNous allons créer un point d'observation et le passer à la fonction camera.\nNous allons ensuite multiplier la matrice qu'elle renvoie par la direction du rayon, \ncomme nous l'avons fait dans la partie 9.\n\nvec3 lp = vec3(0, 0, 0); // lookat point (aka camera target)\nvec3 ro = vec3(0, 0, 3); // ray origin that represents camera position\nvec3 rd = camera(ro, lp) * normalize(vec3(uv, -1)); // ray direction\n\nLorsque vous exécutez votre code, la scène devrait être pratiquement la même. \nCependant, la caméra vise maintenant l'origine dans l'espace 3D.\nComme les cubes se trouvent à 0,5 unité du sol, la caméra est légèrement inclinée par rapport au centre.\nNous pouvons pointer la caméra directement sur le centre du cube vert en modifiant\nle point de visée pour qu'il corresponde à la position du cube vert.\n\nvec3 lp = vec3(0, 0.5, -4);\n\nSupposons que nous voulions regarder le cube rouge maintenant. \nIl se trouve actuellement à la position (-4, 0,5, -4) dans l'espace 3D. \nModifions le point d'observation pour qu'il corresponde à cette position.\n\nvec3 lp = vec3(-4, 0.5, -4);\n\nLa caméra doit maintenant pointer vers le cube rouge, qui doit se trouver au centre du canvas.\n\nhttps://inspirnathan.com/_nuxt/img/img-3.8f8a2b9.png\n\nRegardons maintenant le cube bleu.\nIl a la position (4, 0,5, -4) dans l'espace 3D, nous allons donc changer le point d'observation\npour qu'il soit égal à cette valeur.\n\nvec3 lp = vec3(4, 0.5, -4);\n\nLa caméra doit maintenant pointer vers le cube bleu, qui doit se trouver au centre du canvas.\n\nVous trouverez le code terminé ci-dessous :\n\n*/\n\n#elif PART == 1\n\n// Constants\nconst int MAX_MARCHING_STEPS = 255;\nconst float MIN_DIST = 0.0;\nconst float MAX_DIST = 100.0;\nconst float PRECISION = 0.001;\nconst float EPSILON = 0.0005;\nconst float PI = 3.14159265359;\n\n// Rotation matrix around the X axis.\nmat3 rotateX(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(1, 0, 0),\n        vec3(0, c, -s),\n        vec3(0, s, c)\n    );\n}\n\n// Rotation matrix around the Y axis.\nmat3 rotateY(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, 0, s),\n        vec3(0, 1, 0),\n        vec3(-s, 0, c)\n    );\n}\n\n// Rotation matrix around the Z axis.\nmat3 rotateZ(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, -s, 0),\n        vec3(s, c, 0),\n        vec3(0, 0, 1)\n    );\n}\n\n// Identity matrix.\nmat3 identity() {\n    return mat3(\n        vec3(1, 0, 0),\n        vec3(0, 1, 0),\n        vec3(0, 0, 1)\n    );\n}\n\nstruct Surface {\n    float sd; // signed distance value\n    vec3 col; // color\n};\n\nSurface sdBox( vec3 p, vec3 b, vec3 offset, vec3 col, mat3 transform)\n{\n  p = (p - offset) * transform; // apply transformation matrix\n  vec3 q = abs(p) - b;\n  float d = length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n  return Surface(d, col);\n}\n\nSurface sdFloor(vec3 p, vec3 col) {\n  float d = p.y + 1.;\n  return Surface(d, col);\n}\n\nSurface minWithColor(Surface obj1, Surface obj2) {\n  if (obj2.sd < obj1.sd) return obj2;\n  return obj1;\n}\n\nSurface sdScene(vec3 p) {\n  vec3 floorColor = vec3(1. + 0.7*mod(floor(p.x) + floor(p.z), 2.0));\n  Surface co = sdFloor(p, floorColor);\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(-4, 0.5, -4), vec3(1, 0, 0), identity())); // left cube\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(0, 0.5, -4), vec3(0, 0.65, 0.2), identity())); // center cube\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(4, 0.5, -4), vec3(0, 0.55, 2), identity())); // right cube\n  return co;\n}\n\nSurface rayMarch(vec3 ro, vec3 rd, float start, float end) {\n  float depth = start;\n  Surface co; // closest object\n\n  for (int i = 0; i < MAX_MARCHING_STEPS; i++) {\n    vec3 p = ro + depth * rd;\n    co = sdScene(p);\n    depth += co.sd;\n    if (co.sd < PRECISION || depth > end) break;\n  }\n  \n  co.sd = depth;\n  \n  return co;\n}\n\nvec3 calcNormal(in vec3 p) {\n    vec2 e = vec2(1, -1) * EPSILON;\n    return normalize(\n      e.xyy * sdScene(p + e.xyy).sd +\n      e.yyx * sdScene(p + e.yyx).sd +\n      e.yxy * sdScene(p + e.yxy).sd +\n      e.xxx * sdScene(p + e.xxx).sd);\n}\n\nmat3 camera(vec3 cameraPos, vec3 lookAtPoint) {\n\tvec3 cd = normalize(lookAtPoint - cameraPos); // camera direction\n\tvec3 cr = normalize(cross(vec3(0, 1, 0), cd)); // camera right\n\tvec3 cu = normalize(cross(cd, cr)); // camera up\n\t\n\treturn mat3(-cr, cu, -cd);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n  vec2 uv = (fragCoord-.5*iResolution.xy)/iResolution.y;\n  vec3 backgroundColor = vec3(0.835, 1, 1);\n\n  vec3 col = vec3(0);\n  vec3 lp = vec3(4, 0.5, -4); // lookat point (aka camera target)\n  vec3 ro = vec3(0, 0, 3); // ray origin that represents camera position\n  vec3 rd = camera(ro, lp) * normalize(vec3(uv, -1)); // ray direction\n\n  Surface co = rayMarch(ro, rd, MIN_DIST, MAX_DIST); // closest object\n\n  if (co.sd > MAX_DIST) {\n    col = backgroundColor; // ray didn't hit anything\n  } else {\n    vec3 p = ro + rd * co.sd; // point on cube or floor we discovered from ray marching\n    vec3 normal = calcNormal(p);\n    vec3 lightPosition = vec3(2, 2, 7);\n    vec3 lightDirection = normalize(lightPosition - p);\n\n    float dif = clamp(dot(normal, lightDirection), 0.3, 1.); // diffuse reflection\n\n    col = dif * co.col + backgroundColor * .2; // Add a bit of background color to the diffuse color\n  }\n\n  // Output to screen\n  fragColor = vec4(col, 1.0);\n}\n\n/*\n# Adaptation de la convention de signes\nNous avons vu précédemment que la fonction camera renvoie \nune matrice composée des trois vecteurs de la caméra.\n\nmat3 camera(vec3 cameraPos, vec3 lookAtPoint) {\n\tvec3 cd = normalize(lookAtPoint - cameraPos); // camera direction\n\tvec3 cr = normalize(cross(vec3(0, 1, 0), cd)); // camera right\n\tvec3 cu = normalize(cross(cd, cr)); // camera up\n\t\n\treturn mat3(-cr, cu, -cd);\n}\n\nSi nous configurons le point d'observation de manière à ce que la caméra pointe vers le cube vert,\nnous obtenons le code suivant :\n\n\nvec3 lp = vec3(0, 0.5, -4); // lookat point (aka camera target)\nvec3 ro = vec3(0, 0, 3); // ray origin that represents camera position\nvec3 rd = camera(ro, lp) * normalize(vec3(uv, -1)); // ray direction\n\nCela produit la scène du début de ce tutoriel où le cube rouge est à gauche du cube vert,\net le cube bleu à droite du cube vert.\nhttps://inspirnathan.com/_nuxt/img/img-1.b7c6553.png\n\nSi nous décidons d'utiliser une valeur cr positive dans la fonction de la caméra,\nvoyons ce qui se passe.\nhttps://inspirnathan.com/_nuxt/img/img-5.edb5bb9.png\n\nLe cube rouge et le cube bleu semblent changer de place, mais faites attention aux dalles du sol.\nElles sont également interverties.\nLe vecteur \"caméra droite\" est inversé, ce qui provoque un retournement de l'ensemble de la scène, \ncomme s'il s'agissait d'une image miroir de la scène originale.\n\nL'utilisation d'un vecteur positif a un impact sur ce que voit la caméra et rend la position de\nnos cubes confuse. \nNotre axe x est conçu pour être négatif à gauche du centre de la toile et positif à droite du centre.\nL'inversion du cr signifie également l'inversion de cette convention.\n\nSi nous inversons la valeur de la direction de la caméra, cd, pour qu'elle soit positive au lieu d'être\nnégative, la caméra se retournera parce qu'elle inversera la convention de l'axe z.\n\nUne autre façon d'inverser la convention de l'axe z est d'utiliser une valeur positive pour la composante z\nde la direction du rayon.\n\nvec3 rd = normalize(vec3(uv, 1)); // positive one is being used instead of negative one\n\nLorsque vous utilisez ce modèle de caméra alternatif avec un point de visée, \nil est bon de connaître les conventions que vous avez établies pour ce qui \nest positif ou négatif sur chaque axe.\n\nVous pouvez jouer avec cr, cu et cd pour obtenir des effets intéressants.\nVeillez à ce que la direction du rayon, rd, redevienne négative.\n\nLe code suivant peut créer un effet de fronde sur l'axe z pour donner l'impression\nque la caméra effectue un zoom arrière et un zoom avant très rapidement. \nCela pourrait peut-être être utilisé pour créer un effet de \"warp drive\" ?\n\nmat3 camera(vec3 cameraPos, vec3 lookAtPoint) {\n\tvec3 cd = normalize(lookAtPoint - cameraPos); // camera direction\n\tvec3 cr = normalize(cross(vec3(0, 1, 0), cd)); // camera right\n\tvec3 cu = normalize(cross(cd, cr)); // camera up\n\n\treturn mat3(-cr, cu, abs(cos(iTime)) * -cd);\n}\n\nRetournez à la matrice normale de la caméra avant de passer à la partie suivante du didacticiel.\n\nmat3 camera(vec3 cameraPos, vec3 lookAtPoint) {\n\tvec3 cd = normalize(lookAtPoint - cameraPos); // camera direction\n\tvec3 cr = normalize(cross(vec3(0, 1, 0), cd)); // camera right\n\tvec3 cu = normalize(cross(cd, cr)); // camera up\n\n\treturn mat3(-cr, cu, -cd);\n}\n\n# Rotation de la caméra autour d'une cible\n\nSupposons que nous voulions faire tourner notre caméra sur une trajectoire circulaire autour de la \nscène tout en la gardant pointée sur le cube vert.\nNous maintiendrons la caméra à une hauteur constante (composante y) au-dessus du sol.\nComme les trois cubes ont une position dont la composante y est égale à 0,5, nous nous assurerons \nque la composante y de ro, l'origine du rayon (position de la caméra), est également égale à 0,5.\n\nSi nous voulons que la caméra suive une trajectoire circulaire autour de la taille des cubes,\nnous devons nous concentrer sur la modification des composantes x et z de l'origine du rayon, ro.\n\nSi nous regardons les cubes du haut vers le bas, nous obtiendrons une vue similaire à l'illustration suivante.\nhttps://inspirnathan.com/_nuxt/img/img-6.8341b99.png\n\nDans l'image ci-dessus, la caméra suit une trajectoire circulaire (en noir).\nD'un point de vue descendant, la scène apparaît en 2D avec seulement un axe x (rouge) et un axe z (bleu).\n\nL'idée est de modifier les valeurs des composantes x et z de ro afin qu'il suive une trajectoire circulaire.\nNous pouvons y parvenir en convertissant ro.x et ro.z en coordonnées polaires.\n\nvec3 ro = vec3(0, 0.5, 0);\nro.x = cameraRadius * cos(theta);\nro.z = cameraRadius * sin(theta);\n\nLa valeur du rayon de la caméra sera augmentée jusqu'à ce que nous puissions voir tous les cubes de notre scène.\nNous avons actuellement trois cubes aux positions suivantes dans l'espace 3D\n(définies dans la fonction sdScene) :\n\nvec3(-4, 0.5, -4) // left cube\nvec3(0, 0.5, -4) // center cube\nvec3(4, 0.5, -4) // right cube\n\nPar conséquent, il peut être prudent de choisir un rayon de 10 car la distance entre le cube gauche\net le cube droit est de 4 - (-4) = 8 unités.\n\nDans notre code, nous convertirons les composantes x et z de l'origine du rayon en coordonnées\npolaires avec un rayon de 10. \nEnsuite, nous allons également décaler notre trajectoire circulaire d'un décalage de sorte que le point \nd'observation soit le centre du cercle formé par la trajectoire circulaire.\n\nvec3 lp = vec3(0, 0.5, -4); // lookat point (aka camera target)\nvec3 ro = vec3(0, 0.5, 0); // ray origin that represents camera position\n\nfloat cameraRadius = 10.;\nro.x = cameraRadius * cos(iTime) + lp.x; // convert x-component to polar and add offset \nro.z = cameraRadius * sin(iTime) + lp.z; // convert z-component to polar and add offset\n\nvec3 rd = camera(ro, lp) * normalize(vec3(uv, -1)); // ray direction\n\n\nLorsque vous exécutez le code, vous devriez voir la caméra tourner autour de la scène parce qu'elle suit\nune trajectoire circulaire, mais elle regarde toujours le cube vert à l'aide de notre point d'observation.\nhttps://inspirnathan.com/_nuxt/img/gif-2.25f03e8.gif\n\nD'un point de vue en plongée, notre caméra se déplace dans un cercle qui est décalé par les composantes\nx et z du point de visée, de sorte que nous pouvons nous assurer que le point de visée reste au centre\nde notre cercle.\nNous pouvons donc nous assurer que le point de visée reste au centre de notre cercle. \nCela garantit que la distance par rapport au cube vert, le rayon du cercle, reste équidistante\ndu cube vert tout au long de la révolution.\n\nVous pouvez utiliser le graphique que j'ai créé sur Desmos pour expérimenter la trajectoire circulaire. \nhttps://www.desmos.com/calculator/5emxoibru1\nImaginez que le cube vert se trouve au centre du cercle.\n\nL'utilisation d'un point d'observation rend notre caméra plus flexible. \nNous pouvons élever la caméra le long de l'axe y et tourner à nouveau autour du cercle, \nmais en obtenant une vue d'ensemble des cubes.\n\nEssayons d'ajuster la hauteur de la caméra (origine du rayon) et voyons ce qui se passe.\n\nvec3 ro = vec3(0, 5, 0);\n\nLorsque nous exécutons le code, nous devrions voir la caméra tourner autour des trois cubes, \nmais à une position plus élevée. \nC'est comme si nous étions un reporter d'actualités volant dans un hélicoptère.\nhttps://inspirnathan.com/_nuxt/img/gif-4.6f769bc.gif\n\nSi vous changez le point d'observation, vous devez commencer à tourner autour de ce nouveau point !\n\nVous trouverez le code terminé ci-dessous :\n\n\n*/\n\n#elif PART == 2\n// Constants\nconst int MAX_MARCHING_STEPS = 255;\nconst float MIN_DIST = 0.0;\nconst float MAX_DIST = 100.0;\nconst float PRECISION = 0.001;\nconst float EPSILON = 0.0005;\nconst float PI = 3.14159265359;\n\n// Rotation matrix around the X axis.\nmat3 rotateX(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(1, 0, 0),\n        vec3(0, c, -s),\n        vec3(0, s, c)\n    );\n}\n\n// Rotation matrix around the Y axis.\nmat3 rotateY(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, 0, s),\n        vec3(0, 1, 0),\n        vec3(-s, 0, c)\n    );\n}\n\n// Rotation matrix around the Z axis.\nmat3 rotateZ(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, -s, 0),\n        vec3(s, c, 0),\n        vec3(0, 0, 1)\n    );\n}\n\n// Identity matrix.\nmat3 identity() {\n    return mat3(\n        vec3(1, 0, 0),\n        vec3(0, 1, 0),\n        vec3(0, 0, 1)\n    );\n}\n\nstruct Surface {\n    float sd; // signed distance value\n    vec3 col; // color\n};\n\nSurface sdBox( vec3 p, vec3 b, vec3 offset, vec3 col, mat3 transform)\n{\n  p = (p - offset) * transform; // apply transformation matrix\n  vec3 q = abs(p) - b;\n  float d = length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n  return Surface(d, col);\n}\n\nSurface sdFloor(vec3 p, vec3 col) {\n  float d = p.y + 1.;\n  return Surface(d, col);\n}\n\nSurface minWithColor(Surface obj1, Surface obj2) {\n  if (obj2.sd < obj1.sd) return obj2;\n  return obj1;\n}\n\nSurface sdScene(vec3 p) {\n  vec3 floorColor = vec3(1. + 0.7*mod(floor(p.x) + floor(p.z), 2.0));\n  Surface co = sdFloor(p, floorColor);\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(-4, 0.5, -4), vec3(1, 0, 0), identity())); // left cube\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(0, 0.5, -4), vec3(0, 0.65, 0.2), identity())); // center cube\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(4, 0.5, -4), vec3(0, 0.55, 2), identity())); // right cube\n  return co;\n}\n\nSurface rayMarch(vec3 ro, vec3 rd, float start, float end) {\n  float depth = start;\n  Surface co; // closest object\n\n  for (int i = 0; i < MAX_MARCHING_STEPS; i++) {\n    vec3 p = ro + depth * rd;\n    co = sdScene(p);\n    depth += co.sd;\n    if (co.sd < PRECISION || depth > end) break;\n  }\n  \n  co.sd = depth;\n  \n  return co;\n}\n\nvec3 calcNormal(in vec3 p) {\n    vec2 e = vec2(1, -1) * EPSILON;\n    return normalize(\n      e.xyy * sdScene(p + e.xyy).sd +\n      e.yyx * sdScene(p + e.yyx).sd +\n      e.yxy * sdScene(p + e.yxy).sd +\n      e.xxx * sdScene(p + e.xxx).sd);\n}\n\nmat3 camera(vec3 cameraPos, vec3 lookAtPoint) {\n\tvec3 cd = normalize(lookAtPoint - cameraPos); // camera direction\n\tvec3 cr = normalize(cross(vec3(0, 1, 0), cd)); // camera right\n\tvec3 cu = normalize(cross(cd, cr)); // camera up\n\t\n\treturn mat3(-cr, cu, -cd);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n  vec2 uv = (fragCoord-.5*iResolution.xy)/iResolution.y;\n  vec3 backgroundColor = vec3(0.835, 1, 1);\n\n  vec3 col = vec3(0);\n  vec3 lp = vec3(0, 0.5, -4); // lookat point (aka camera target)\n  vec3 ro = vec3(0, 5, 0); // ray origin that represents camera position\n  \n  float cameraRadius = 10.;\n  ro.x = cameraRadius * cos(iTime) + lp.x; // convert to polar \n  ro.z = cameraRadius * sin(iTime) + lp.z;\n  \n  vec3 rd = camera(ro, lp) * normalize(vec3(uv, -1)); // ray direction\n\n  Surface co = rayMarch(ro, rd, MIN_DIST, MAX_DIST); // closest object\n\n  if (co.sd > MAX_DIST) {\n    col = backgroundColor; // ray didn't hit anything\n  } else {\n    vec3 p = ro + rd * co.sd; // point on cube or floor we discovered from ray marching\n    vec3 normal = calcNormal(p);\n    vec3 lightPosition = vec3(2, 2, 7);\n    vec3 lightDirection = normalize(lightPosition - p);\n\n    float dif = clamp(dot(normal, lightDirection), 0.3, 1.); // diffuse reflection\n\n    col = dif * co.col + backgroundColor * .2; // Add a bit of background color to the diffuse color\n  }\n\n  // Output to screen\n  fragColor = vec4(col, 1.0);\n}\n\n/*\n# Rotation de la caméra avec la souris\n\nVous pouvez également utiliser la souris pour déplacer la caméra dans la scène,\nmais cela nécessite quelques réglages supplémentaires.\nComme nous l'avons appris dans la partie 9 de cette série de didacticiels,\nla variable globale iMouse fournit les données relatives à la position de la souris.\n\nNous pouvons créer des coordonnées \"mouse UV\" en utilisant la ligne suivante :\n\nvec2 mouseUV = iMouse.xy/iResolution.xy; // Range: <0, 1>\n\nNous remplacerons les trois lignes suivantes, puisque nous utilisons notre souris \npour tourner autour de la scène au lieu d'utiliser le temps.\n\nfloat cameraRadius = 10.;\nro.x = cameraRadius * cos(iTime) + lp.x; // convert to polar \nro.z = cameraRadius * sin(iTime) + lp.z;\n\nLe code suivant remplacera le code ci-dessus :\n\nfloat cameraRadius = 2.;\nro.yz = ro.yz * cameraRadius * rotate2d(mix(PI/2., 0., mouseUV.y));\nro.xz = ro.xz * rotate2d(mix(-PI, PI, mouseUV.x)) + vec2(lp.x, lp.z); // remap mouseUV.x to <-pi, pi> range\n\nNous utilisons à nouveau la fonction mix pour remapper la composante x de la position de la souris.\nCette fois, nous remettons les valeurs de la plage <0,1> à la plage <-π, π>.\nNous devons également ajouter la composante x et la composante z du point d'observation.\n\nRemarquez que nous avons une fonction rotate2d qui ne spécifie pas d'axe. \nCette fonction fournira une rotation 2D à l'aide d'une matrice 2D. \nAjoutez la fonction suivante au début de votre code.\n\nmat2 rotate2d(float theta) {\n  float s = sin(theta), c = cos(theta);\n  return mat2(c, -s, s, c);\n}\n\nComme précédemment, vous devrez peut-être jouer avec le cameraRadius jusqu'à ce qu'il soit décent.\nVotre code terminé devrait ressembler à ce qui suit :\n\n*/\n#elif PART == 3\n\n// Constants\nconst int MAX_MARCHING_STEPS = 255;\nconst float MIN_DIST = 0.0;\nconst float MAX_DIST = 100.0;\nconst float PRECISION = 0.001;\nconst float EPSILON = 0.0005;\nconst float PI = 3.14159265359;\n\n// Rotate around a circular path\nmat2 rotate2d(float theta) {\n  float s = sin(theta), c = cos(theta);\n  return mat2(c, -s, s, c);\n}\n\n// Rotation matrix around the X axis.\nmat3 rotateX(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(1, 0, 0),\n        vec3(0, c, -s),\n        vec3(0, s, c)\n    );\n}\n\n// Rotation matrix around the Y axis.\nmat3 rotateY(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, 0, s),\n        vec3(0, 1, 0),\n        vec3(-s, 0, c)\n    );\n}\n\n// Rotation matrix around the Z axis.\nmat3 rotateZ(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, -s, 0),\n        vec3(s, c, 0),\n        vec3(0, 0, 1)\n    );\n}\n\n// Identity matrix.\nmat3 identity() {\n    return mat3(\n        vec3(1, 0, 0),\n        vec3(0, 1, 0),\n        vec3(0, 0, 1)\n    );\n}\n\nstruct Surface {\n    float sd; // signed distance value\n    vec3 col; // color\n};\n\nSurface sdBox( vec3 p, vec3 b, vec3 offset, vec3 col, mat3 transform)\n{\n  p = (p - offset) * transform; // apply transformation matrix\n  vec3 q = abs(p) - b;\n  float d = length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n  return Surface(d, col);\n}\n\nSurface sdFloor(vec3 p, vec3 col) {\n  float d = p.y + 1.;\n  return Surface(d, col);\n}\n\nSurface minWithColor(Surface obj1, Surface obj2) {\n  if (obj2.sd < obj1.sd) return obj2;\n  return obj1;\n}\n\nSurface sdScene(vec3 p) {\n  vec3 floorColor = vec3(1. + 0.7*mod(floor(p.x) + floor(p.z), 2.0));\n  Surface co = sdFloor(p, floorColor);\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(-4, 0.5, -4), vec3(1, 0, 0), identity())); // left cube\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(0, 0.5, -4), vec3(0, 0.65, 0.2), identity())); // center cube\n  co = minWithColor(co, sdBox(p, vec3(1), vec3(4, 0.5, -4), vec3(0, 0.55, 2), identity())); // right cube\n  return co;\n}\n\nSurface rayMarch(vec3 ro, vec3 rd, float start, float end) {\n  float depth = start;\n  Surface co; // closest object\n\n  for (int i = 0; i < MAX_MARCHING_STEPS; i++) {\n    vec3 p = ro + depth * rd;\n    co = sdScene(p);\n    depth += co.sd;\n    if (co.sd < PRECISION || depth > end) break;\n  }\n  \n  co.sd = depth;\n  \n  return co;\n}\n\nvec3 calcNormal(in vec3 p) {\n    vec2 e = vec2(1, -1) * EPSILON;\n    return normalize(\n      e.xyy * sdScene(p + e.xyy).sd +\n      e.yyx * sdScene(p + e.yyx).sd +\n      e.yxy * sdScene(p + e.yxy).sd +\n      e.xxx * sdScene(p + e.xxx).sd);\n}\n\nmat3 camera(vec3 cameraPos, vec3 lookAtPoint) {\n\tvec3 cd = normalize(lookAtPoint - cameraPos); // camera direction\n\tvec3 cr = normalize(cross(vec3(0, 1, 0), cd)); // camera right\n\tvec3 cu = normalize(cross(cd, cr)); // camera up\n\t\n\treturn mat3(-cr, cu, -cd);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n  vec2 uv = (fragCoord-.5*iResolution.xy)/iResolution.y;\n  vec2 mouseUV = iMouse.xy/iResolution.xy; // Range: <0, 1>\n  vec3 backgroundColor = vec3(0.835, 1, 1);\n\n  vec3 col = vec3(0);\n  vec3 lp = vec3(0, 0.5, -4); // lookat point (aka camera target)\n  vec3 ro = vec3(0, 5, 0); // ray origin that represents camera position\n  \n  float cameraRadius = 2.;\n  ro.yz = ro.yz * cameraRadius * rotate2d(mix(PI/2., 0., mouseUV.y));\n  ro.xz = ro.xz * rotate2d(mix(-PI, PI, mouseUV.x)) + vec2(lp.x, lp.z);\n  \n  vec3 rd = camera(ro, lp) * normalize(vec3(uv, -1)); // ray direction\n\n  Surface co = rayMarch(ro, rd, MIN_DIST, MAX_DIST); // closest object\n\n  if (co.sd > MAX_DIST) {\n    col = backgroundColor; // ray didn't hit anything\n  } else {\n    vec3 p = ro + rd * co.sd; // point on cube or floor we discovered from ray marching\n    vec3 normal = calcNormal(p);\n    vec3 lightPosition = vec3(2, 2, 7);\n    vec3 lightDirection = normalize(lightPosition - p);\n\n    float dif = clamp(dot(normal, lightDirection), 0.3, 1.); // diffuse reflection\n\n    col = dif * co.col + backgroundColor * .2; // Add a bit of background color to the diffuse color\n  }\n\n  // Output to screen\n  fragColor = vec4(col, 1.0);\n}\n\n/*\nMaintenant, vous pouvez utiliser votre souris pour tourner autour de la scène ! \nPlus précisément, vous pouvez utiliser votre souris pour tourner autour de votre point d'observation.\n\n# Conclusion\nJ'espère que vous voyez maintenant à quel point ce modèle de caméra alternatif peut être puissant !\nLe point de visée peut faciliter le déplacement de la caméra dans la scène tout en se concentrant \nsur une cible unique.\n*/\n#endif\n","name":"Image","description":"","type":"image"}]}
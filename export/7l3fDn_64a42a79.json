{"ver":"0.1","info":{"id":"7l3fDn","date":"1662911560","viewed":172,"name":"Dithering: linear vs gamma","username":"stduhpf","description":"Dithering is often used to remove banding in images. The simplest way is to work directly with the colors in gamma space, but this can lead to some overshoot in the dark areas, and therefore a slight loss of contrast. Working with linear colors fixes it.","likes":3,"published":1,"flags":0,"usePreview":0,"tags":["banding","dithering","airy","colorscience"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dfGRn","filepath":"/media/a/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","previewfilepath":"/media/ap/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsBSR3","filepath":"/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","previewfilepath":"/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","type":"texture","channel":0,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// see https://www.shadertoy.com/view/NltBD7 for a better illustration\n\n// should work better on a hardware-calibrated display with self-emissive pixels\n\n// Decrease BIT_DEPTH to make the difference between the two dithering method more noticable by eye.\n#define BIT_DEPTH 8\n\n/*\n    Top left:     linear dithering    | Top right:    gamma dithering\n    Bottom right: native quantization | Bottom right: forced quantization to BIT_DEPTH\n*/\n\n#define enable_dithering uv.y>0.\n#define linear_dithering uv.x<0.\n\n#define force_bitdepth uv.x>0.\n\nfloat smoothedAiry(float r){ //empirical approximation of light intensity from an airy spot\n    const float k0 = .85, k1 = .36, k2 = 1.21;\n\n    float rs = r*r;\n    \n    float a0 = sin(r*k0)*sin(r*k0)/(4.*rs*k0*k0); //approximation of J1²(r)/r² for r<<4\n    \n    float ai = 2.7/(r*rs); // smooth approximation for high radius (r>3)\n    \n    float m = exp(k1*k2*r-k1*rs-k1*k2*k2);\n    \n    return mix(ai,a0,m);\n}\n\n#define GAMMA vec4(2.2,2.2,2.2,1.) // assuming screen eotf is pow(rgb(a),GAMMA)\n\nvec4 eotf(vec4 signal){\n    return pow(signal,GAMMA);\n}\n\nvec4 oetf(vec4 linear){ // or rather inverse-eotf\n    return pow(linear,1./GAMMA);\n}\n\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord-.5*iResolution.xy;\n    \n    const float prec = float((1<<BIT_DEPTH)-1); //8-bit color range: 0.->255.\n    \n    vec4 noise = texture(iChannel0,(fragCoord)/iChannelResolution[0].xy);\n    noise = noise*255./256.+noise.w/256.;\n    \n\n    uv*=.2;\n    \n    float rs = dot(uv,uv);\n    float r = sqrt(rs);\n    //float a = smoothedAiry(r); //inlined because why not\n    const float k0 = .85, k1 = .36, k2 = 1.21;\n    \n    float a0 = sin(r*k0)*sin(r*k0)/(4.*rs*k0*k0);\n    \n    float ai = 1./(r*rs);\n    \n    float m = exp(k1*k2*r-k1*rs-k1*k2*k2);\n    \n    float a = mix(ai,a0,m);\n    \n    // color in linear space\n    vec4 col = 4.*vec4(.7,.9,1.,1.)*a;\n    \n    // uncomment the following line to see an image dimming out\n    //col = eotf(texture(iChannel1,2.*fragCoord/iResolution.xy))*exp2(-iTime*.5);\n    \n    if(enable_dithering)\n    if(linear_dithering)\n    {\n        //linear dithering to avoid banding (linear means less overshoot for dark pixels, so better contrast)\n        vec4 lcol = clamp(col,0.,1.); //clamp input\n        vec4 gcol = oetf(lcol); //convert to output gamma space\n\n        vec4 gcol_f = floor(gcol*prec)/prec; //floor to get the lower bound\n\n        vec4 lcol_f = eotf(gcol_f); // convert the lower bound to linear\n        vec4 lcol_c = eotf(ceil(gcol*prec)/prec); // ceil to get the upper bound, convereted to linear\n\n        vec4 x = (lcol-lcol_f)/(lcol_c-lcol_f); // get x such as lcol_f + x*(lcol_c-lcol_f) == lcol\n\n        // compare x to the noise to chose what bounding value should be selected (in gamma space)\n        col = gcol_f+step(noise,x)/prec;\n    }else{\n        //basically the same thing but directly in output gamma space, which means x is simpler to compute\n\n        vec4 gcol = oetf(clamp(col,0.,1.)); //convert the linear color to output gamma space\n\n        gcol *=prec;\n        vec4 x = fract(gcol);\n        gcol = floor(gcol)+step(noise,x);\n\n        col = gcol/prec;\n    }\n    else{\n        col = oetf(clamp(col,0.,1.));\n        if(force_bitdepth) //enforce same quantization as the dithered image\n            col = round(col*prec)/prec;\n    }\n    fragColor = col;\n}","name":"Image","description":"","type":"image"}]}
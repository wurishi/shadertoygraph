{"ver":"0.1","info":{"id":"tltGzH","date":"1575656379","viewed":417,"name":"Delta Tracking Volumes","username":"natevm","description":"This example uses delta tracking to execute a random walk through a heterogeneous volume. \nRatio tracking can optionally be used to connect the path to the light.\n// Reference paper https://graphics.pixar.com/library/ProductionVolumeRendering/paper.pdf","likes":6,"published":1,"flags":32,"usePreview":0,"tags":["raytracing","volume","rendering","tracking","delta","inhomogeneous"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XsX3zn","filepath":"/media/a/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","previewfilepath":"/media/ap/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","type":"cubemap","channel":1,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// See common for sky stuff\n// See Buffer A for delta/ratio tracking code\nfloat lineDistance(vec2 a, vec2 b, vec2 p) {\n    vec2 pa = p-a;\n    vec2 ba = b-a;\n\tfloat t = clamp(dot(pa,ba)/dot(ba,ba), 0.0, 1.0);\n    return length(pa-ba*t);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n\n    vec3 col = texture( iChannel0, uv ).xyz;\n    \n    /* bar for camera controls */\n    const vec2 slider_pos = vec2(30.0, 30.0);\n    const float slider_size = 200.0;\n    const float slider_width = 8.0;\n    if (lineDistance(slider_pos + vec2(0.0, -slider_width), slider_pos + vec2(slider_size, -slider_width),  fragCoord.xy) < 1.0 ||\n        lineDistance(slider_pos + vec2(0.0, slider_width), slider_pos + vec2(slider_size, slider_width),  fragCoord.xy) < 1.0 ||\n        lineDistance(slider_pos + vec2(0.0, -slider_width), slider_pos + vec2(0.0, slider_width),  fragCoord.xy) < 1.0 ||\n        lineDistance(slider_pos + vec2(slider_size, -slider_width), slider_pos + vec2(slider_size, slider_width),  fragCoord.xy) < 1.0 \n             ) {\n        col = vec3(1.0, 1.0, 1.0);\n    }\n    \n    fragColor = vec4( col, 1.0 );\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"// User parameters\nconst vec3 _SkyTint = vec3(0.8, 0.8, 0.8);\nconst float _AtmosphereThickness = 1.5; \n\n// constants\n#define SUN_CONVERGENCE 100.0\n#define OUTER_RADIUS 1.025 \n#define kRAYLEIGH (mix(0.0, 0.0025, pow(_AtmosphereThickness,2.5))) \n#define kMIE 0.0010 \n#define kSUN_BRIGHTNESS 30.0 \n#define kMAX_SCATTER 50.0 \n#define MIE_G (-0.990) \n#define MIE_G2 0.9801 \nconst vec3 ScatteringWavelength = vec3(.65, .57, .475);\nconst vec3 ScatteringWavelengthRange = vec3(.15, .15, .15);    \nconst float kOuterRadius = OUTER_RADIUS; \nconst float kOuterRadius2 = OUTER_RADIUS*OUTER_RADIUS;\nconst float kInnerRadius = 1.0;\nconst float kInnerRadius2 = 1.0;\nconst float kCameraHeight = 0.0001;\nconst float kHDSundiskIntensityFactor = 15.0;\nconst float kSunScale = 400.0 * kSUN_BRIGHTNESS;\nconst float kKmESun = kMIE * kSUN_BRIGHTNESS;\nconst float kKm4PI = kMIE * 4.0 * 3.14159265;\nconst float kScale = 1.0 / (OUTER_RADIUS - 1.0);\nconst float kScaleDepth = 0.25;\nconst float kScaleOverScaleDepth = (1.0 / (OUTER_RADIUS - 1.0)) / 0.25;\nconst float kSamples = 2.0;\n\nfloat Scale(float inCos)\n{\n\tfloat x = 1.0 - inCos;\n\treturn 0.25 * exp(-0.00287 + x*(0.459 + x*(3.83 + x*(-6.80 + x*5.25))));\n}\n\nvec4 ProceduralSkybox(vec3 ro, vec3 rd)\n{\n    vec3 _WorldSpaceLightPos0 = vec3(20, 20, 20);\n    vec3 kSkyTintInGammaSpace = _SkyTint;\n    vec3 kScatteringWavelength = mix(ScatteringWavelength-ScatteringWavelengthRange,ScatteringWavelength+ScatteringWavelengthRange,vec3(1,1,1) - kSkyTintInGammaSpace);\n    vec3 kInvWavelength = 1.0 / (pow(kScatteringWavelength, vec3(4.0)));\n    float kKrESun = kRAYLEIGH * kSUN_BRIGHTNESS;\n    float kKr4PI = kRAYLEIGH * 4.0 * 3.14159265;\n    vec3 cameraPos = vec3(0,kInnerRadius + kCameraHeight,0);\n    vec3 eyeRay = rd;\n    eyeRay.y = abs(eyeRay.y);\n    float far = 0.0;\n    vec3 cIn, cOut;\n    \n    far = sqrt(kOuterRadius2 + kInnerRadius2 * eyeRay.y * eyeRay.y - kInnerRadius2) - kInnerRadius * eyeRay.y;\n    vec3 pos = cameraPos + far * eyeRay;\n    float height = kInnerRadius + kCameraHeight;\n    float depth = exp(kScaleOverScaleDepth * (-kCameraHeight));\n    float startAngle = dot(eyeRay, cameraPos) / height;\n    float startOffset = depth*Scale(startAngle);\n    float sampleLength = far / kSamples;\n    float scaledLength = sampleLength * kScale;\n    vec3 sampleRay = eyeRay * sampleLength;\n    vec3 samplePoint = cameraPos + sampleRay * 0.5;\n    vec3 frontColor = vec3(0.0, 0.0, 0.0);\n    for (int i=0; i<2; i++)\n    {\n        float height = length(samplePoint);\n        float depth = exp(kScaleOverScaleDepth * (kInnerRadius - height));\n        float lightAngle = dot(normalize(_WorldSpaceLightPos0.xyz), samplePoint) / height;\n        float cameraAngle = dot(eyeRay, samplePoint) / height;\n        float scatter = (startOffset + depth*(Scale(lightAngle) - Scale(cameraAngle)));\n        vec3 attenuate = exp(-clamp(scatter, 0.0, kMAX_SCATTER) * (kInvWavelength * kKr4PI + kKm4PI));\n        frontColor += attenuate * (depth * scaledLength);\n        samplePoint += sampleRay;\n    }\n    cIn = frontColor * (kInvWavelength * kKrESun);\n    cOut = frontColor * kKmESun;\n    \n    vec3 skyColor = (cIn * (0.75 + 0.75 * dot(normalize(_WorldSpaceLightPos0.xyz), -eyeRay) * dot(normalize(_WorldSpaceLightPos0.xyz), -eyeRay))); \n    vec3 ray = -rd;\n    vec3 color = skyColor;\n    return vec4(sqrt(color),1.0);      \n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"XdX3zn","filepath":"/media/a/488bd40303a2e2b9a71987e48c66ef41f5e937174bf316d3ed0e86410784b919.jpg","previewfilepath":"/media/ap/488bd40303a2e2b9a71987e48c66ef41f5e937174bf316d3ed0e86410784b919.jpg","type":"cubemap","channel":1,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Reference paper https://graphics.pixar.com/library/ProductionVolumeRendering/paper.pdf\n\n////////////////////////////////////////////////////////////////////////////////////\n\n#define PI 3.141592654f\n#define TAU ( PI * 2.0f )\n#define EPSILON .0001\n\n#define MAX_VOLUME_DEPTH 1000\n\n// Volume definition\nint volume_type = 0; // Can be 0, 1, or 2\nfloat linear_attenuation_unit = .03; // Should be less than the \"minimum\" feature size\nfloat majorant_extinction = 1.0f;\nfloat max_grid_value = 1.0f;\n\n// Absorption and Scattering here must sum to less than or equal to the majorant\n#define ABSORPTION 0.1f\n#define SCATTERING .9f\n\n#define EMISSION 0.f\n\nvec3 bbmin = vec3(-1.0);\nvec3 bbmax = vec3(1.0);\n\nuint seed;\t//seed initialized in main\n\nuint wang_hash()\n{\n    seed = uint(seed ^ uint(61)) ^ uint(seed >> uint(16));\n    seed *= uint(9);\n    seed = seed ^ (seed >> 4);\n    seed *= uint(0x27d4eb2d);\n    seed = seed ^ (seed >> 15);\n    return seed;\n}\n\nfloat rnd()\n{\n    return float(wang_hash()) / 4294967296.0;\n}\n\nvec3 rndvec()\n{\n    float z = rnd() * 2.0f - 1.0f;\n    float a = rnd() * 2.f * PI;\n    float r = sqrt(1.0f - z * z);\n    float x = r * cos(a);\n    float y = r * sin(a);\n    return vec3(x, y, z);\n}\n\nvec3 randomSpherePoint(vec3 rand) {\n  float ang1 = (rand.x + 1.0) * PI; // [-1..1) -> [0..2*PI)\n  float u = rand.y; // [-1..1), cos and acos(2v-1) cancel each other out, so we arrive at [-1..1)\n  float u2 = u * u;\n  float sqrt1MinusU2 = sqrt(1.0 - u2);\n  float x = sqrt1MinusU2 * cos(ang1);\n  float y = sqrt1MinusU2 * sin(ang1);\n  float z = u;\n  return vec3(x, y, z);\n}\n\n//pos in uv space where we store various data\nconst vec2 acc_start_uv = vec2(0.0); //accumulation start frame\nconst vec2 camera_pos_uv = vec2(1.0, 0.0); //camera pos\nconst vec2 camera_dir_uv = vec2(2.0, 0.0); //camera pos\n\nint getAccStart() {\n\tif( iMouse.z > 0.0 ) {\n        return iFrame;\n    } else {\n        return int(texture( iChannel0, (acc_start_uv + vec2(0.5, 0.5))/iResolution.xy ).x);\n    }\n}\n\nvec4 LoadVec4(vec2 uv) { return texture( iChannel0, (uv + vec2(0.5, 0.5))/iResolution.xy ); }\n\n\nstruct Ray {\n    vec3 origin;\n    vec3 dir;\n};\n\nstruct Camera {\n    mat3 rotate;\n    vec3 pos;\n    float fovV;\n    float lensSize;\n    float focusDist;\n    vec2 iPlaneSize;\n};\n    \n// ************ CAMERA STUFF ***************\nCamera camera;\nCamera cameraOld;\n\nvoid initCamera( \tin vec3 pos,\n                \tin vec3 target,\n                \tin float fovV,\n                \tin float radius,\n                \tin float focus_dist,\n                \tout Camera c\n               ) {\n    const vec3 upDir = vec3( 0.0, 1.0, 0.0 );\n    c.rotate[2] = normalize( pos-target ); //back\n\tc.rotate[0] = normalize( cross( upDir, c.rotate[2] ) ); //right\n\tc.rotate[1] = cross( c.rotate[2], c.rotate[0] ); //up\n    c.fovV = fovV;\n    c.pos = pos;\n    c.focusDist = focus_dist;\n    c.lensSize = radius;\n    c.iPlaneSize = 2.*tan(0.5*c.fovV)*vec2(iResolution.x/iResolution.y,1.);\n}\n\nRay genRay( in Camera c, in vec2 uv, in vec2 xi ) {\n    Ray ray;\n    \n    vec2 ixy = (uv-0.5)*c.iPlaneSize;\n\tvec3 dirLocal = normalize(vec3(ixy, -1.0));\n    vec3 posGlobal = c.pos;\n\tvec3 dirGlobal = c.rotate*dirLocal;\n\treturn Ray(posGlobal, dirGlobal);\n}\n\nmat4 LookAt(vec3 eye, vec3 at, vec3 up)\n{\n  vec3 zaxis = normalize(eye - at);    \n  vec3 xaxis = normalize(cross(zaxis, up));\n  vec3 yaxis = cross(xaxis, zaxis);\n\n  zaxis = -zaxis;\n\n  mat4 viewMatrix = mat4(\n    vec4(xaxis.x, xaxis.y, xaxis.z, -dot(xaxis, eye)),\n    vec4(yaxis.x, yaxis.y, yaxis.z, -dot(yaxis, eye)),\n    vec4(zaxis.x, zaxis.y, zaxis.z, -dot(zaxis, eye)),\n    vec4(eye, 1)\n  );\n\n  return viewMatrix;\n}\n\n\n////////////////////////////////////////////////////////////////////////////////////\nvec3 miss_color(in vec3 ray_dir) {\n    return vec3(ProceduralSkybox(vec3(0.0), ray_dir));\n    //return texture(iChannel1,ray_dir).rgb;\n    \n}\n\n////////////////////////////////////////////////////////////////////////////////////\n\nbool intersect_volume_box(in vec3 raypos, in vec3 raydir, out float tmin, out float tmax) {\n    float x0 = (-0.5f - raypos.x) / raydir.x;\n    float y0 = (-0.5f - raypos.y) / raydir.y;\n    float z0 = (-0.5f - raypos.z) / raydir.z;\n    float x1 = ( 0.5f - raypos.x) / raydir.x;\n    float y1 = ( 0.5f - raypos.y) / raydir.y;\n    float z1 = ( 0.5f - raypos.z) / raydir.z;\n    tmin = max(max(max(min(z0,z1), min(y0,y1)), min(x0,x1)), 0.0f);\n    tmax = min( min( max(z0, z1), max(y0, y1 ) ), max(x0, x1) );\n    return (tmin < tmax);\n}\n\nbool in_volume(in vec3 pos) {\n    return max(abs(pos.x),max(abs(pos.y),abs(pos.z))) < 0.5f;\n}\n\nfloat sample_volume(in vec3 p) {\n    if (volume_type == 0) {\n        vec3 pos = p + vec3(0.5f, 0.5f, 0.5f);\n        int steps = 3;\n        for (int i = 0; i < steps; ++i) {\n            pos *= 3.0f;\n            int s = (int(pos.x) & 1) + (int(pos.y) & 1) + (int(pos.z) & 1);\n            if (s >= 2)\n                return 0.0f;\n        }\n        return max_grid_value;\n    } else if (volume_type == 1) {\n        float r = 0.5f * (0.5f - abs(p.y));\n        float a = float(PI * 8.0) * p.y;\n        float dx = (cos(a) * r - p.x) * 2.0f;\n        float dy = (sin(a) * r - p.z) * 2.0f;\n        return pow(max((1.0f - dx * dx - dy * dy), 0.0f), 5.0f) * max_grid_value;\n    }\n    else {\n        return max_grid_value;\n    }\n}\n\nfloat sample_volume_absorption(in vec3 p) {\n    // a bunch of different ways to do this...\n    return sample_volume(p) * ABSORPTION;\n}\n\nfloat sample_volume_scattering(in vec3 p) {\n    // a bunch of different ways to do this...\n    return sample_volume(p) * SCATTERING;\n}\n\nfloat sample_volume_emission(in vec3 p) {\n\t// a bunch of different ways to do this...\n    return sample_volume(p) * EMISSION;\n}\n\n/// Taken and modified from Algorithm 2 in \"Pixar's Production Volume Rendering\" paper.\n/// \\param x The origin of the ray.\n/// \\param w The direction of the light (opposite of ray direction). \n/// \\param d The distance along the ray to the boundary.\n/// \\param t The returned hit distance.\n/// \\param event Will be updated to represent the event that occured during tracking.\n///              0 means the boundary was hit\n///              1 means an absorption/emission occurred\n///              2 means a scattering collision occurred\n///              3 means a null collision occurred\nvoid SampleDeltaTracking(vec3 x, vec3 w, float d, out float t, out int event) {\n    float rand1 = rnd();\n    float rand2 = rnd();\n    \n    // Set new t for the current x.\n    t = (-log(1.0f - rand1) / majorant_extinction) * linear_attenuation_unit;\n    \n    // A boundary has been hit\n    if (t >= d) {\n    \tevent = 0;\n        t = d;\n        return;\n    }\n    \n    // Update current position\n    x = x - t * w;\n        \n   \tfloat absorption = sample_volume_absorption(x);\n    float scattering = sample_volume_scattering(x);\n    float extinction = absorption + scattering;\n    //float null_collision = 1.f - extinction;\n    float null_collision = majorant_extinction - extinction;\n    \n    //extinction = extinction / majorant_extinction;\n    absorption = absorption / majorant_extinction;\n    scattering = scattering / majorant_extinction;\n    null_collision = null_collision / majorant_extinction;\n    \n        \n    // An absorption/emission collision occured\n    if (rand2 < absorption) \n    {\n    \tevent = 1;\n        return;\n    }\n    \n    // A scattering collision occurred\n    else if (rand2 < (absorption + scattering)) {\n    //else if (rand2 < (1.f - null_collision)) {\n        event = 2;\n        return;\n    }\n    \n    // A null collision occurred\n    else {\n        event = 3;\n        return;    \t\n    }\n}\n\n/// Taken and modified from Algorithm 2 in \"Pixar's Production Volume Rendering\" paper.\n/// Implements the top level delta tracking algorithm, returning radiance.\n/// \\param seed The seed to use by the random number generator.\n/// \\param x The origin of the ray.\n/// \\param w The direction of the light (opposite of ray direction). \n/// \\param d The distance along the ray to the boundary.\nvec3 DeltaTracking(uint seed, vec3 x, vec3 w) {\n    float t0, t1;\n    if (!intersect_volume_box(x, -w, t0, t1)) return miss_color(-w);\n    \n    // Move ray to volume boundary\n    x = x - t0 * w;\n    t1 = t1 - t0;\n    t0 = 0.f;\n        \n    // Note: original algorithm had unlimited bounces. \n    vec3 throughput = vec3(1.f);\n    for (int i = 0; i < MAX_VOLUME_DEPTH; ++i) {\n        int event = 0;\n        float t = 0.f;\n        SampleDeltaTracking(x, w, t1, t, event);\n        x = x - t * w;\n        \n        // A boundary has been hit. Sample the background.\n        if (event == 0) return throughput * miss_color(-w);\n        \n        // An absorption / emission occurred.\n        if (event == 1) return throughput * vec3(sample_volume_emission(x));\n        \n        // A scattering collision occurred.\n        if (event == 2) {            \n            // Sample isotropic phase function to get new ray direction           \n            float phi = TAU * rnd();\n            float cos_theta = 1.0f - 2.0f * rnd();\n            float sin_theta = sqrt (1.0f - cos_theta * cos_theta);\n            w = -vec3(cos(phi) * sin_theta, sin(phi) * sin_theta, cos_theta);\n            \n            // Compute updated boundary\n            if (!intersect_volume_box(x, -w, t0, t1)) return throughput * miss_color(-w);\n        }\n        \n        // A null collision occurred.\n        if (event == 3) {\n            // update boundary in relation to the new collision x, w does not change.\n            t1 = t1 - t;\n        }\n    }\n    \n    // If we got stuck in the volume\n    return vec3(1.0, 0.0, 0.0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    seed = uint(uint(fragCoord.x) * uint(1973) + uint(fragCoord.y) * uint(9277) + uint(iFrame) * uint(26699)) | uint(1);    \n    \n    // Camera Slider\n    float fov = radians(30.0);\n    vec3 camera_pos = (iFrame == 0)? 1.5f*vec3( 1.0, 1.0,  1.0 ) : LoadVec4(camera_pos_uv).xyz;\n    vec3 camera_dir = (iFrame == 0)? vec3(0.0) : LoadVec4(camera_dir_uv).xyz;\n    initCamera(camera_pos, camera_dir, fov, 0.0, 9.2, cameraOld);\n    if(iMouse.z > 0.0) {\n        const vec2 slider_pos = vec2(30.0, 30.0);\n        const float slider_size = 200.0;\n    \tconst float slider_width = 8.0;\n        \n        if (iMouse.x > slider_pos.x &&\n            iMouse.x < slider_pos.x + slider_size &&\n            iMouse.y > slider_pos.y - slider_width &&\n            iMouse.y < slider_pos.y + slider_width ) {\n        \tfloat slider = (iMouse.x - slider_pos.x) / slider_size;\n            \n            slider -= 0.5; //(-0.5, 0.5)\n            \n            camera_pos += vec3( 1.0, 0.0,  0.0 ) * slider * 0.3;\n        }\n    }\n    \n    initCamera(camera_pos, camera_dir, fov, 0.0, 9.2, camera);\n    \n    \n    vec2 uv = (fragCoord.xy + vec2( ( rnd() ), rnd() )) / iResolution.xy;\n    Ray ray = genRay( camera, uv, vec2(rnd(), rnd()) );\n    \n    // Tighter majorants result in more efficient sampling.\n    // Here, I'm testing to make sure \"loose\" majorants converge\n    // to the same result as \"tight\" majorants.\n    if (fragCoord.x < iResolution.x * .5) majorant_extinction *= 10.;\n    \n    vec3 Li = vec3(DeltaTracking(seed, ray.origin, -ray.dir));    \n    vec3 accumulatedColor = Li;\n    \n   \n\t// Save current camera state \n    vec3 col_acc;\n    vec2 coord = floor(fragCoord.xy);\n    if(all(equal(coord.xy, acc_start_uv))) col_acc = vec3(getAccStart());\n\telse if(all(equal(coord.xy, camera_pos_uv))) col_acc = camera_pos;\n    else if(all(equal(coord.xy, camera_dir_uv))) col_acc = camera_dir;\n    else \n    {\n        // Accumulate.\n        vec2 uv = fragCoord / iResolution.xy;\n        vec3 prev = texture(iChannel0,uv).rgb;\n        vec3 col = prev + (accumulatedColor - prev) / (float(iFrame) + 1.0f);\n        \n        if(iFrame == 0) {\n            col_acc = accumulatedColor;\n        } else {            \n            int frame_start = getAccStart();//int(texture( iChannel3, vec2(0.5, 0.5) / iResolution.xy ).x);\n            int spp1 = iMouse.z > 0.0 ? 0 : iFrame - frame_start;\n            int spp2 = 1;\n            vec3 col_new = accumulatedColor;\n            col_acc = texture( iChannel0, fragCoord/iResolution.xy ).xyz;\n            col_acc = mix(col_acc, col_new, float(spp2)/float(spp1+spp2));\n        }\n    }\n        \n    fragColor = vec4( col_acc, 1.0 );\n}\n","name":"Buffer A","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"43lfD7","date":"1728481627","viewed":33,"name":"FXAA 3.11 (w/ AMD test scene)","username":"eliam","description":"Original by effendiian (https://www.shadertoy.com/view/ttXGzn)\nUsed to compare MLAA and FXAA","likes":2,"published":1,"flags":32,"usePreview":0,"tags":["tutorial","fxaa","pc","quality"],"hasliked":0,"parentid":"ttXGzn","parentname":"FXAA 3.11 - PC Quality"},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*****************************************\n * FXAA 3.11 Implementation - effendiian\n * -------------------------------------\n * FXAA implementation based off of the \n * work by Timothy Lottes in the Nvidia white paper:\n * https://developer.download.nvidia.com/assets/gamedev/files/sdk/11/FXAA_WhitePaper.pdf\n *\n * Also used these resources:\n * - https://catlikecoding.com/unity/tutorials/advanced-rendering/fxaa/\n * - https://blog.codinghorror.com/fast-approximate-anti-aliasing-fxaa/\n *****************************************/\n\n// Turn off FXAA.\n// #define FXAA 0\n\n// Turn on FXAA.\n// #define FXAA 1\n\n// Turn on split screen between no-FXAA and FXAA.\n#define FXAA 4\n\n/*\n/\tFXAA setting, defined via preprocessor variables\n*/\n#ifndef FXAA_PRESET\n    #define FXAA_PRESET 5\n    #define FXAA_DEBUG_SKIPPED 0\n    #define FXAA_DEBUG_PASSTHROUGH 0\n    #define FXAA_DEBUG_HORZVERT 0\n    #define FXAA_DEBUG_PAIR 0\n    #define FXAA_DEBUG_NEGPOS 0\n    #define FXAA_DEBUG_OFFSET 0\n\t#define FXAA_DEBUG_HIGHLIGHT 0\n\t#define FXAA_LUMINANCE 1\n#endif\n/*--------------------------------------------------------------------------*/\n#if (FXAA_PRESET == 0)\n    #define FXAA_EDGE_THRESHOLD      (1.0/4.0)\n    #define FXAA_EDGE_THRESHOLD_MIN  (1.0/12.0)\n    #define FXAA_SEARCH_STEPS        2\n    #define FXAA_SEARCH_ACCELERATION 4\n    #define FXAA_SEARCH_THRESHOLD    (1.0/4.0)\n    #define FXAA_SUBPIX              1\n    #define FXAA_SUBPIX_FASTER       1\n    #define FXAA_SUBPIX_CAP          (2.0/3.0)\n    #define FXAA_SUBPIX_TRIM         (1.0/4.0)\n#endif\n/*--------------------------------------------------------------------------*/\n#if (FXAA_PRESET == 1)\n    #define FXAA_EDGE_THRESHOLD      (1.0/8.0)\n    #define FXAA_EDGE_THRESHOLD_MIN  (1.0/16.0)\n    #define FXAA_SEARCH_STEPS        4\n    #define FXAA_SEARCH_ACCELERATION 3\n    #define FXAA_SEARCH_THRESHOLD    (1.0/4.0)\n    #define FXAA_SUBPIX              1\n    #define FXAA_SUBPIX_FASTER       0\n    #define FXAA_SUBPIX_CAP          (3.0/4.0)\n    #define FXAA_SUBPIX_TRIM         (1.0/4.0)\n#endif\n/*--------------------------------------------------------------------------*/\n#if (FXAA_PRESET == 2)\n    #define FXAA_EDGE_THRESHOLD      (1.0/8.0)\n    #define FXAA_EDGE_THRESHOLD_MIN  (1.0/24.0)\n    #define FXAA_SEARCH_STEPS        8\n    #define FXAA_SEARCH_ACCELERATION 2\n    #define FXAA_SEARCH_THRESHOLD    (1.0/4.0)\n    #define FXAA_SUBPIX              1\n    #define FXAA_SUBPIX_FASTER       0\n    #define FXAA_SUBPIX_CAP          (3.0/4.0)\n    #define FXAA_SUBPIX_TRIM         (1.0/4.0)\n#endif\n/*--------------------------------------------------------------------------*/\n#if (FXAA_PRESET == 3)\n    #define FXAA_EDGE_THRESHOLD      (1.0/8.0)\n    #define FXAA_EDGE_THRESHOLD_MIN  (1.0/24.0)\n    #define FXAA_SEARCH_STEPS        16\n    #define FXAA_SEARCH_ACCELERATION 1\n    #define FXAA_SEARCH_THRESHOLD    (1.0/4.0)\n    #define FXAA_SUBPIX              1\n    #define FXAA_SUBPIX_FASTER       0\n    #define FXAA_SUBPIX_CAP          (3.0/4.0)\n    #define FXAA_SUBPIX_TRIM         (1.0/4.0)\n#endif\n/*--------------------------------------------------------------------------*/\n#if (FXAA_PRESET == 4)\n    #define FXAA_EDGE_THRESHOLD      (1.0/8.0)\n    #define FXAA_EDGE_THRESHOLD_MIN  (1.0/24.0)\n    #define FXAA_SEARCH_STEPS        24\n    #define FXAA_SEARCH_ACCELERATION 1\n    #define FXAA_SEARCH_THRESHOLD    (1.0/4.0)\n    #define FXAA_SUBPIX              1\n    #define FXAA_SUBPIX_FASTER       0\n    #define FXAA_SUBPIX_CAP          (3.0/4.0)\n    #define FXAA_SUBPIX_TRIM         (1.0/4.0)\n#endif\n/*--------------------------------------------------------------------------*/\n#if (FXAA_PRESET == 5)\n    #define FXAA_EDGE_THRESHOLD      (1.0/8.0)\n    #define FXAA_EDGE_THRESHOLD_MIN  (1.0/24.0)\n    #define FXAA_SEARCH_STEPS        32\n    #define FXAA_SEARCH_ACCELERATION 1\n    #define FXAA_SEARCH_THRESHOLD    (1.0/4.0)\n    #define FXAA_SUBPIX              1\n    #define FXAA_SUBPIX_FASTER       0\n    #define FXAA_SUBPIX_CAP          (3.0/4.0)\n    #define FXAA_SUBPIX_TRIM         (1.0/4.0)\n#endif\n/*--------------------------------------------------------------------------*/\n#define FXAA_SUBPIX_TRIM_SCALE (1.0/(1.0 - FXAA_SUBPIX_TRIM))\n\n// --------------------------------------\n// Helper functions.\n// --------------------------------------\n\n// ---------------------\n// Conversion functions.\n\n// ToVec2\nvec2 ToVec2( float value ) { return vec2(value, value); }\n\n// ToVec3\nvec3 ToVec3( float value ) { return vec3(value, value, value); }\nvec3 ToVec3( vec2 vector, float z ) { return vec3(vector.x, vector.y, z); }\nvec3 ToVec3( vec2 vector ) { return ToVec3(vector, 0.0); }\n\n// ToVec4\nvec4 ToVec4( vec2 vector, float z, float w ) { return vec4(vector.x, vector.y, z, w); }\nvec4 ToVec4( vec2 vector, float z ) { return ToVec4(vector, z, 0.0); }\nvec4 ToVec4( vec2 vector ) { return ToVec4(vector, 0.0); }\nvec4 ToVec4( vec3 vector, float w ) { return vec4(vector.x, vector.y, vector.z, w); }\nvec4 ToVec4( vec3 vector ) { return ToVec4(vector, 0.0); }\nvec4 ToVec4( float value, float w ) { return vec4(value, value, value, w); }\nvec4 ToVec4( float value ) { return ToVec4(value, 0.0); }\n\n// ---------------------\n// Texture sampler functions.\n\n// Return sampled image from a point + offset texel space.\nvec4 TextureOffset( sampler2D tex, \n                    vec2 uv, \n                    vec2 offset ) {\n\t\n    // Return color from the specified location.\n    return texture(tex, uv + offset); \n        \n}\n\n// ---------------------\n// Grayscale functions.\n\n// Return grayscaled image based off of the selected color channel.\nvec3 Grayscale( vec3 color, int index ) {\n    int selectedChannel = clamp(index, 0, 2); // [0]r, [1]g, [2]b.\n\treturn ToVec3(color[selectedChannel]);\n}\n\n// Return grayscaled image based off of the selected color channel.\nvec4 Grayscale( vec4 color, int index ) {\n    int selectedChannel = clamp(index, 0, 3); // [0]r, [1]g, [2]b, [3]a.\n\treturn ToVec4(color[selectedChannel]);\n}\n\n// Default to green color channel when no index is supplied.\nvec3 Grayscale( vec3 color ) { return Grayscale(color, 1); }\nvec4 Grayscale( vec4 color ) { return Grayscale(color, 1); }\n\n// ---------------------\n// Luminance functions.\n\n// Map RGB to Luminance linearly.\nfloat LinearRGBLuminance( vec3 color ) {\n    \n    // Weights for relative luma from here: https://en.wikipedia.org/wiki/Luma_(video)\n    vec3 weight = vec3(0.2126729, 0.7151522, 0.0721750);\n    \n    // Get the dot product:\n    // - color.r * weight.r + color.g * weight.g + color.b * weight*b.\n\treturn dot(color, weight);\n}\n\n// Luminance based off of the original specification.\nfloat FXAALuminance( vec3 color ) {\n    \n    #if FXAA_LUMINANCE == 0\n    \n    return LinearRGBLuminance( color );\n    \n    #else\n    \n\treturn color.g * (0.587/0.299) + color.r;\n    \n    #endif\n}\n\n// ---------------------\n// Vertical/Horizontal Edge Test functions.\n\nfloat FXAAVerticalEdge( float lumaO,\n                       float lumaN, \n                       float lumaE, \n                       float lumaS, \n                       float lumaW,\n                       float lumaNW,\n                       float lumaNE,\n                       float lumaSW,\n                       float lumaSE ) {\n    \n    // Slices to calculate.\n    float top = (0.25 * lumaNW) + (-0.5 * lumaN) + (0.25 * lumaNE);\n    float middle = (0.50 * lumaW ) + (-1.0 * lumaO) + (0.50 * lumaE );\n    float bottom = (0.25 * lumaSW) + (-0.5 * lumaS) + (0.25 * lumaSE);\n    \n    // Return value.\n    return abs(top) + abs(middle) + abs(bottom);\n}\n\nfloat FXAAHorizontalEdge( float lumaO,\n                       float lumaN, \n                       float lumaE, \n                       float lumaS, \n                       float lumaW,\n                       float lumaNW,\n                       float lumaNE,\n                       float lumaSW,\n                       float lumaSE ) {\n    \n    // Slices to calculate.\n    float top = (0.25 * lumaNW) + (-0.5 * lumaW) + (0.25 * lumaSW);\n    float middle = (0.50 * lumaN ) + (-1.0 * lumaO) + (0.50 * lumaS );\n    float bottom = (0.25 * lumaNE) + (-0.5 * lumaE) + (0.25 * lumaSE);\n    \n    // Return value.\n    return abs(top) + abs(middle) + abs(bottom);\n}\n\n// ------------------------\n// FXAA specific functions.\n// ------------------------\n\n// Entry point for the FXAA process.\nvec3 applyFXAA(sampler2D textureSource, \n               vec2 textureDimensions, \n               vec2 pixelPosition,\n               vec2 screenResolution,\n               bool debug) {\n    \n    // Normalized pixel coordinates (from 0 to 1).\n    vec2 uv = pixelPosition / screenResolution;\n    \n    // Calculate distance between pixels in texture space.\n    vec2 texel = vec2(1.0, 1.0) / textureDimensions;\n    \n    // Caculate the luminance.\n    // float luma = FXAALuminance(rgbO.xyz);\n    // float luma = LinearRGBLuminance(clamp(rgbO.xyz, 0.0, 1.0));\n    \n    //-------------------------\n    // 1. LOCAL CONTRAST CHECK\n    \n    // Sample textures from cardinal directions.\n    vec3 rgbN = TextureOffset(textureSource, uv, vec2(0, -texel.y)).rgb; // NORTH\n    vec3 rgbW = TextureOffset(textureSource, uv, vec2(-texel.x, 0)).rgb; // WEST\n    vec3 rgbO = TextureOffset(textureSource, uv, vec2(0, 0)).rgb; // ORIGIN\n    vec3 rgbE = TextureOffset(textureSource, uv, vec2(texel.x, 0)).rgb; // EAST\n    vec3 rgbS = TextureOffset(textureSource, uv, vec2(0, texel.y)).rgb; // SOUTH\n    \n    #if FXAA == 0\n    return rgbO; // Skip FXAA if it is off.\n    #endif    \n    \n    // Calculate the luminance for each sampled value.\n    float lumaN = FXAALuminance(rgbN);\n    float lumaW = FXAALuminance(rgbW);\n    float lumaO = FXAALuminance(rgbO);\n    float lumaE = FXAALuminance(rgbE);\n    float lumaS = FXAALuminance(rgbS);\n    \n    // Calculate the minimum luma range.\n    float minLuma = min( lumaO, min( min( lumaN, lumaW ), min( lumaS, lumaE ) ) );\n    float maxLuma = max( lumaO, max( max( lumaN, lumaW ), max( lumaS, lumaE ) ) );\n    float localContrast = maxLuma - minLuma;    \n    \n    // Check for early exit.\n    if(localContrast < max( FXAA_EDGE_THRESHOLD_MIN, maxLuma * FXAA_EDGE_THRESHOLD )) {\n        \n        #if FXAA_DEBUG_SKIPPED\n                \n        return vec3(0);\n        \n        #else\n        \n    \treturn rgbO;\n        \n        #endif\n    }\n        \n    //-------------------------\n    // 2. SUB-PIXEL ALIASING TEST\n    \n    // Calculate the pixel contrast ratio.\n    // - Sub-pixel aliasing is detected by taking the ratio of the \n    // pixel contrast over the local contrast. This ratio nears 1.0\n    // in the presence of single pixel dots and otherwise falls off\n    // towards 0.0 as more pixels contribute to an edge. This ratio\n    // is transformed into the amount of lowpass filter to blend in\n    // at the end of the algorithm.\n    \n    #if FXAA_SUBPIX > 0\n    \n    // Calculate sum of local samples for the lowpass.\n    vec3 rgbL = (rgbN + rgbW + rgbO + rgbE + rgbS);\n    \n        #if FXAA_SUBPIX_FASTER\n\n        // Average the lowpass now since this skips the addition of the diagonal neighbors (NW, NE, SW, SE).\n        rgbL *= (1.0/5.0);\n\n        #endif    \n\n    // Calculate the lowpass luma.\n    // - Lowpass luma is calculated as the average between the luma of neigboring pixels.\n\tfloat lumaL = (lumaN + lumaW + lumaS + lumaE) * 0.25;\n\n    // Calculate the pixel contrast.\n    // - Pixel contrast is the abs() difference between origin pixel luma and lowpass luma of neighbors.\n    float pixelContrast = abs(lumaL - lumaO);\n    \n    // Remember: \n    // - pixel contrast is the origin - lowpass(neighbors).\n    // - local contrast is the min(origin + neighbors) - max(origin + neighbors) < threshold.\n   \n    // Calculate the ratio between the pixelContrast and localContrast.\n    float contrastRatio = pixelContrast / localContrast;\n    float lowpassBlend = 0.0; // Default is zero. Will be changed depending on subpixel level.\n    \n    \t#if FXAA_SUBPIX == 1\n    \n    \t// Normal subpixel aliasing. Set based on FXAA algorithm for subpixel aliasing.\n    \tlowpassBlend = max( 0.0, contrastRatio - FXAA_SUBPIX_TRIM ) * FXAA_SUBPIX_TRIM_SCALE;\n    \tlowpassBlend = min( FXAA_SUBPIX_CAP, lowpassBlend );\n    \n    \t#elif FXAA_SUBPIX == 2\n    \n    \t// Full force subpixel aliasing. Set blend to ratio.\n    \tlowpassBlend = contrastRatio;\n    \n    \t#endif\n    \n\t#endif\n    \n    // Show selected pixels if debug mode is active.\n    #if FXAA_DEBUG_PASSTHROUGH\n    \n    \t#if FXAA_SUBPIX > 0    \n    \n    \treturn vec3(localContrast, lowpassBlend, 0.0);\n    \n    \t#else \n    \t\n    \treturn vec3(localContrast, 0.0, 0.0);\t\n    \n    \t#endif\n    \n    #endif\n    \n    //-------------------------\n    // 3. VERTICAL & HORIZONTAL EDGE TEST\n    \n    // Sample the additional diagonal neighbors.\n    vec3 rgbNW = TextureOffset(textureSource, uv, vec2(-texel.x, -texel.y)).rgb; // NORTH-WEST\n    vec3 rgbNE = TextureOffset(textureSource, uv, vec2(texel.x, -texel.y)).rgb; // NORTH-EAST\n    vec3 rgbSW = TextureOffset(textureSource, uv, vec2(-texel.x, texel.y)).rgb; // SOUTH-WEST\n    vec3 rgbSE = TextureOffset(textureSource, uv, vec2(texel.x, texel.y)).rgb; // SOUTH-EAST\n    \n    // Average additional neighbors when sub-pix aliasing is on and it isn't in 'fast' mode.\n    #if FXAA_SUBPIX > 0\n    \t#if FXAA_SUBPIX_FASTER == 0\n    \t\t// Add missing neighbors and average them.\n    \t\trgbL += (rgbNW + rgbNE + rgbSW + rgbSE);  \n    \t\trgbL *= (1.0/9.0);\n    \t#endif\n    #endif\n    \n    // Calculate luma for additional neighbors.\n    float lumaNW = FXAALuminance(rgbNW);\n    float lumaNE = FXAALuminance(rgbNE);\n    float lumaSW = FXAALuminance(rgbSW);\n    float lumaSE = FXAALuminance(rgbSE);\n    \n    // Calculate the vertical and horizontal edges. (Uses algorithm from FXAA white paper).\n    float edgeVert = FXAAVerticalEdge(lumaO, lumaN, lumaE, lumaS, lumaW, lumaNW, lumaNE, lumaSW, lumaSE);\n    float edgeHori = FXAAHorizontalEdge(lumaO, lumaN, lumaE, lumaS, lumaW, lumaNW, lumaNE, lumaSW, lumaSE);\n    \n    // Check if edge is horizontal.\n    bool isHorizontal = edgeHori >= edgeVert;\n    \n    #if FXAA_DEBUG_HORZVERT\n    if(isHorizontal) \n    {\n    \treturn vec3(1.0, 0.75, 0.0);\n    } \n    else \n    {\n        return vec3(0.10, 0.10, 1.0);\n    }\n    #endif\n    \n    //-------------------------\n    // 4. FIND HIGHEST CONTRAST PAIR 90deg TO EDGE\n    \n    // Contain the appropriate sign for the top left.\n    float edgeSign = isHorizontal ? -texel.y : -texel.x; // Note, if isHorizontal == true, -texel.y is applied (not -texel.x).\n    \n    // Calculate the gradients. The luma used changes based on the horizontal edge status.\n    float gradientNeg = isHorizontal ? abs(lumaN - lumaO) : abs(lumaW - lumaO);\n    float gradientPos = isHorizontal ? abs(lumaS - lumaO) : abs(lumaE - lumaO); \n    \n    // Calculate the luma based on its direction.\n    // It is an average of the origin and the luma in the respective direction.\n    float lumaNeg = isHorizontal ? ((lumaN + lumaO) * 0.5) : ((lumaW + lumaO) * 0.5);    \n    float lumaPos = isHorizontal ? ((lumaS + lumaO) * 0.5) : ((lumaE + lumaO) * 0.5);\n    \n    // Select the highest gradient pair.\n    bool isNegative = (gradientNeg >= gradientPos);\n    float gradientHighest = isNegative ? gradientNeg : gradientPos; // Assign higher pair.\n    float lumaHighest = isNegative ? lumaNeg : lumaPos;\n    \n    // If gradient pair in the negative direction is higher, flip the edge sign.\n    if(isNegative) { edgeSign *= -1.0; }\n    \n    #if FXAA_DEBUG_PAIR\n    return isHorizontal ? vec3(0.0, gradientHighest, lumaHighest) : vec3(0.0, lumaHighest, gradientHighest); \n    #endif\n    \n    //-------------------------\n    // 5. END-OF-EDGE SEARCH\n    \n    // Select starting point.\n    vec2 pointN = vec2(0.0, 0.0);\n    pointN.x = uv.x + (isHorizontal ? 0.0 : edgeSign * 0.5);\n    pointN.y = uv.y + (isHorizontal ? edgeSign * 0.5 : 0.0);\n    \n    // Assign search limiting values.\n    gradientHighest *= FXAA_SEARCH_THRESHOLD;\n    \n    // Prepare variables for search.\n    vec2 pointP = pointN; // Start at the same point.\n    vec2 pointOffset = isHorizontal ? vec2(texel.x, 0.0) : vec2(0.0, texel.y);\n    float lumaNegEnd = lumaNeg;\n    float lumaPosEnd = lumaPos;\n    bool searchNeg = false;\n    bool searchPos = false;\n    \n    // Apply values based on FXAA flags.\n    if(FXAA_SEARCH_ACCELERATION == 1) {\n        \n    \tpointN += pointOffset * vec2(-1.0);\n    \tpointP += pointOffset * vec2(1.0);\n        // pointOffset *= vec2(1.0);\n        \n    } else if(FXAA_SEARCH_ACCELERATION == 2) {    \n        \n    \tpointN += pointOffset * vec2(-1.5);\n    \tpointP += pointOffset * vec2(1.5);\n        pointOffset *= vec2(2.0);\n        \n    } else if(FXAA_SEARCH_ACCELERATION == 3) {  \n        \n    \tpointN += pointOffset * vec2(-2.0);\n    \tpointP += pointOffset * vec2(2.0);\n        pointOffset *= vec2(3.0);\n        \n    } else if(FXAA_SEARCH_ACCELERATION == 4) { \n        \n    \tpointN += pointOffset * vec2(-2.5);\n    \tpointP += pointOffset * vec2(2.5);\n        pointOffset *= vec2(4.0);\n        \n    }\n    \n    // Perform the end-of-edge search.\n    for(int i = 0; i < FXAA_SEARCH_STEPS; i++) \n    {\n        if(FXAA_SEARCH_ACCELERATION == 1) {            \n            if(!searchNeg) { lumaNegEnd = FXAALuminance(texture(textureSource, pointN).rgb); }\n            if(!searchPos) { lumaPosEnd = FXAALuminance(texture(textureSource, pointP).rgb); } \n        } \n        else\n        {\n            if(!searchNeg) { lumaNegEnd = FXAALuminance(textureGrad(textureSource, pointN, pointOffset, pointOffset).rgb); }\n            if(!searchPos) { lumaPosEnd = FXAALuminance(textureGrad(textureSource, pointP, pointOffset, pointOffset).rgb); } \n        }\n        \n        // Search for significant change in luma compared to current highest pair.\n        searchNeg = searchNeg || (abs(lumaNegEnd - lumaNeg) >= gradientNeg);\n        searchPos = searchPos || (abs(lumaPosEnd - lumaPos) >= gradientPos);\n        \n        \n        // Display debug information regarding edges.\n        #if FXAA_DEBUG_NEGPOS\n        \n        if(searchNeg) { \n        \treturn vec3(abs(lumaNegEnd - gradientNeg), 0.0, 0.0);  \n        } else if(searchPos) { \n        \treturn vec3(0.0, 0.0, abs(lumaPosEnd - gradientPos));  \n        }\n\n        #endif\n        \n        // Determine if search is over early.\n        if(searchNeg && searchPos) { break; }\n        \n        // If still searching, increment offset.\n        if(!searchNeg) { pointN -= pointOffset; }\n        if(!searchPos) { pointP += pointOffset; }\n    }\n    \n    //-------------------------\n    // 6. SUB-PIXEL SHIFT\n    \n    // Determine if sub-pixel center falls on positive or negative side.\n    float distanceNeg = isHorizontal ? uv.x - pointN.x : uv.y - pointN.y;\n    float distancePos = isHorizontal ? pointP.x - uv.x : pointP.y - uv.y;\n   \tbool isCloserToNegative = distanceNeg < distancePos;\n    \n    // Assign respective luma.\n    float lumaEnd = isCloserToNegative ? lumaNegEnd : lumaPosEnd;\n    \n    // Check if pixel is in area that receives no filtering.\n    if( ((lumaO - lumaNeg) < 0.0) == ((lumaEnd - lumaNeg) < 0.0) ) {\n    \tedgeSign = 0.0;\n    }\n    \n    // Compute sub-pixel offset and filter span.\n    float filterSpanLength = (distancePos + distanceNeg);\n    float filterDistance = isCloserToNegative ? distanceNeg : distancePos;\n    float subpixelOffset = ( 0.5 + ( filterDistance * (-1.0 / filterSpanLength) ) ) * edgeSign;\n    \n    #if FXAA_DEBUG_OFFSET  \n    \n    if(subpixelOffset < 0.0) {\n    \treturn isHorizontal ? vec3(1.0, 0.0, 0.0) : vec3(1.0, 0.7, 0.1); // neg-horizontal (red) : neg-vertical (gold)\n    } \n    \n    if(subpixelOffset > 0.0) {\n    \treturn isHorizontal ? vec3(0.0, 0.0, 1.0) : vec3(0.1, 0.3, 1.0); // pos-horizontal (blue) : pos-vertical (skyblue)\n    }\n        \n    #endif\n    \n    // Resample using the subpixel offset.\n    vec3 rgbOffset = textureLod(textureSource, vec2( uv.x + (isHorizontal ? 0.0 : subpixelOffset), uv.y + (isHorizontal ? subpixelOffset : 0.0)), 0.0).rgb;\n    \n    // return vec3((lumaN + lumaS + lumaE + lumaW + lumaNW + lumaNE + lumaSW + lumaSE) * (1.0/9.0));\n    \n    if(debug) {\n        return isHorizontal ? vec3(1.0, 0.0, 0.0) : vec3(0.0, 1.0, 0.0);\n    }\n\n    // Return the FXAA effect.\n    #if FXAA_SUBPIX == 0\n    \n    return vec3(rgbOffset);\n    \n    #else\n    \n    return mix(rgbOffset, rgbL, lowpassBlend);\n    \n    #endif\n}\n\n// ------------------------\n// Main function.\n// ------------------------\n\nvoid mainImage( out vec4 cOut, in vec2 vXY )\n{ \n    // get mouse, uv\n    vec2 vM = (iMouse.z > .0f) ? abs(iMouse.xy / iResolution.xy) : vec2(0.35f,0.5f);\n    vec2 vUv = vXY.xy / iResolution.xy;\n    vec2 vBorder = vec2(1.f) / iResolution.xy;\n    \n    if (vUv.x > (vM.x + vBorder.x))\n        // apply MLAA\n        cOut.rgb = applyFXAA(iChannel0, iChannelResolution[0].xy, vXY, iResolution.xy, false);\n    else if (vUv.x > (vM.x - vBorder.x))\n        // border color\n        cOut = vec4(1.f, 1.f, 1.0f, 1.f);\n    else if (vUv.y < (vM.y - vBorder.y))\n        // no AA applied\n        cOut = vec4(textureLod(iChannel0,vUv,0.).xyz, 1.);\n    else if (vUv.y > (vM.y + vBorder.y))\n        // show edges (red)\n        cOut.rgb = applyFXAA(iChannel0, iChannelResolution[0].xy, vXY, iResolution.xy, true);\n    else\n        // border color\n        cOut = vec4(1.f, 1.f, 1.0f, 1.f);   \n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"// AMD Morphological Anti-Aliasing (MLAA) Sample\n//\n// https://github.com/GPUOpen-LibrariesAndSDKs/MLAA11\n//\n// Copyright (c) 2016 Advanced Micro Devices, Inc. All rights reserved.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n//\n\n//-----------------------------------------------------------------------------------------\n// File: MLAA11.hlsl\n//\n// Set of shaders used to apply Morphological Anti-Aliasing (MLAA) to a scene\n// as a post-process operation.\n//\n// GLSL-Port 2023 by Denis Reischl\n//-----------------------------------------------------------------------------------------\n\n//-----------------------------------------------------------------------------------------\n// Defines\n//-----------------------------------------------------------------------------------------\n#ifndef MAX_EDGE_COUNT_BITS\n#define MAX_EDGE_COUNT_BITS\t\t\t4\t\t\t// Default edge count bits is 4\n#endif\n\n#ifndef SHOW_EDGES\n#define SHOW_EDGES\t\t\t\t\t0\t\t\t// Disabled by default      \n#endif\n\n#ifndef USE_STENCIL\n#define USE_STENCIL\t\t\t\t\t0\t\t\t// Disabled by default      \n#endif\n\n//#define USE_GATHER                            // Disabled by default\n\n//-----------------------------------------------------------------------------------------\n// Static Constants\n//-----------------------------------------------------------------------------------------\n// Set the number of bits to use when storing the horizontal and vertical counts\n// This number should be half the number of bits in the color channels used\n// E.g. with a RT format of DXGI_R8G8_int this number should be 8/2 = 4\n// Longer edges can be detected by increasing this number; however this requires a \n// larger bit depth format, and also makes the edge length detection function slower\nconst uint kNumCountBits = uint(MAX_EDGE_COUNT_BITS);\n\n// The maximum edge length that can be detected\nconst uint kMaxEdgeLength = ((1u << (kNumCountBits - 1u)) - 1u);\n\n// Various constants used by the shaders below\nconst uint kUpperMask = (1u << 0u);\nconst uint kUpperMask_BitPosition = 0u;\nconst uint kRightMask = (1u << 1u);\nconst uint kRightMask_BitPosition = 1u;\nconst uint kStopBit = (1u << (kNumCountBits - 1u));\nconst uint kStopBit_BitPosition = (kNumCountBits - 1u);\nconst uint kNegCountShift = (kNumCountBits);\nconst uint kPosCountShift = (00u);\nconst uint kCountShiftMask = ((1u << kNumCountBits) - 1u);\n\nconst ivec3 kZero = ivec3(0, 0, 0);\nconst ivec3 kUp = ivec3(0, -1, 0);\nconst ivec3 kDown = ivec3(0, 1, 0);\nconst ivec3 kRight = ivec3(1, 0, 0);\nconst ivec3 kLeft = ivec3(-1, 0, 0);\n\n// This constant defines the luminance intensity difference to check for when testing any \n// two pixels for an edge.\nconst float fInvEdgeDetectionTreshold = 1.f / 32.f;\n\n//-----------------------------------------------------------------------------------------\n// Utility functions\n//-----------------------------------------------------------------------------------------\n//--------------------------------------------------------------------------------------\n// Returns true if the colors are different\n//--------------------------------------------------------------------------------------\nbool CompareColors(float a, float b)\n{\n\treturn (abs(a - b) > fInvEdgeDetectionTreshold);\n}\nbvec2 CompareColors2(vec2 a, vec2 b)\n{\n    return bvec2(abs(a.x - b.x) > fInvEdgeDetectionTreshold, abs(a.y - b.y) > fInvEdgeDetectionTreshold);\n}\n//--------------------------------------------------------------------------------------\n// Check if the specified bit is set\n//--------------------------------------------------------------------------------------\nbool IsBitSet(uint Value, const uint uBitPosition)\n{\n\treturn (((Value & (1u << uBitPosition)) > 0u) ? true : false);\n}\n//--------------------------------------------------------------------------------------\n//--------------------------------------------------------------------------------------\nuint RemoveStopBit(uint a)\n{\n\treturn a & (kStopBit - 1u);\n}\n//--------------------------------------------------------------------------------------\n//--------------------------------------------------------------------------------------\nuint DecodeCountNoStopBit(uint count, uint shift)\n{\n\treturn RemoveStopBit((count >> shift) & kCountShiftMask);\n}\n//--------------------------------------------------------------------------------------\n//--------------------------------------------------------------------------------------\nuint DecodeCount(uint count, uint shift)\n{\n\treturn (count >> shift) & kCountShiftMask;\n}\n//--------------------------------------------------------------------------------------\n//--------------------------------------------------------------------------------------\nuint EncodeCount(uint negCount, uint posCount)\n{\n\treturn ((negCount & kCountShiftMask) << kNegCountShift) | (posCount & kCountShiftMask);\n}\n\n//-----------------------------------------------------------------------------\n// uvec4 <-> FLOAT4 ( B8G8R8A8_UNORM )\n// modified code from \"d3dx_dxgiformatconvert.inl\"\n//-----------------------------------------------------------------------------\nuint D3DX_FLOAT_to_UINT(float _V, float _Scale) { return uint(floor(_V * _Scale + 0.5f)); }\n\nvec4 UINT4_to_FLOAT4_D3DX_B8G8R8A8_UNORM(uvec4 Input)\n{\n\tvec4 Output;\n\tOutput.z = float(Input.x & 0x000000ffu) / 255.f;\n\tOutput.y = float(Input.y & 0x000000ffu) / 255.f;\n\tOutput.x = float(Input.z & 0x000000ffu) / 255.f;\n\tOutput.w = float(Input.w & 0x000000ffu) / 255.f;\n\treturn Output;\n}\n\nuvec4 D3DX_FLOAT4_to_UINT4_B8G8R8A8_UNORM(vec4 Input)\n{\n\tuvec4 Output;\n\tOutput = uvec4(D3DX_FLOAT_to_UINT(clamp(Input.z, 0.f, 1.f), 255.f),\n\t\tD3DX_FLOAT_to_UINT(clamp(Input.y, 0.f, 1.f), 255.f),\n\t\tD3DX_FLOAT_to_UINT(clamp(Input.x, 0.f, 1.f), 255.f),\n\t\tD3DX_FLOAT_to_UINT(clamp(Input.w, 0.f, 1.f), 255.f));\n\treturn Output;\n}\n\n//----------------------------------------------------------------------------\n//\tMLAA pixel shader for edge detection.\n//\tPixel shader used in the first phase of MLAA.\n//\tThis pixel shader is used to detect vertical and horizontal edges.\n//-----------------------------------------------------------------------------\nuint MLAA_SeperatingLines(sampler2D Sampler, ivec2 Offset, ivec2 TextureSize)\n{\n\tvec2 center;\n\tvec2 upright;\n\n\tcenter.xy = texelFetch(Sampler, clamp(Offset, ivec2(0, 0), TextureSize), 0).aa;\n\tupright.y = texelFetch(Sampler, clamp(Offset + kUp.xy, ivec2(0, 0), TextureSize), 0).a;\n\tupright.x = texelFetch(Sampler, clamp(Offset + kRight.xy, ivec2(0, 0), TextureSize), 0).a;\n\n\tuint rVal = 0u;\n\n\tbvec2 result = CompareColors2(center, upright);\n\n\t// Check for seperating lines\n\tif (result.y)\n\t\trVal |= kUpperMask;\n\tif (result.x)\n\t\trVal |= kRightMask;\n\n\treturn rVal;\n}\n\n//-----------------------------------------------------------------------------\n//\tPixel shader for the second phase of the algorithm.\n//\tThis pixel shader calculates the length of edges.\n//-----------------------------------------------------------------------------\nuvec2 MLAA_ComputeLineLength(sampler2D Sampler, ivec2 Offset, ivec2 TextureSize)\n{\n\t// Retrieve edge mask for current pixel\t\n\tuint pixel = MLAA_SeperatingLines(Sampler, Offset, TextureSize);\n\tuvec4 EdgeCount = uvec4(0, 0, 0, 0); // x = Horizontal Count Negative, y = Horizontal Count Positive, z = Vertical Count Negative, w = Vertical Count Positive\t\t\t\t    \n\n\t// We use a single branch for vertical and horizontal edge testing\n\t// Doing this is faster than two different branches (one for vertical, one for horizontal)\n\t// In most case both V and H edges are spatially coherent (apart from purely horizontal or \n\t// vertical edges but those don't happen often compared to other cases).\t\t\t\t\n\t\n    if ((pixel & (kUpperMask | kRightMask)) != 0u)\n    {\n        uvec4 EdgeDirMask = uvec4(kUpperMask, kUpperMask, kRightMask, kRightMask);\n        uvec4 EdgeFound;\n        EdgeFound.x = (pixel & EdgeDirMask.x) != 0u ? 0xFFFFFFFFu : 0u;\n        EdgeFound.y = (pixel & EdgeDirMask.y) != 0u ? 0xFFFFFFFFu : 0u;\n        EdgeFound.z = (pixel & EdgeDirMask.z) != 0u ? 0xFFFFFFFFu : 0u;\n        EdgeFound.w = (pixel & EdgeDirMask.w) != 0u ? 0xFFFFFFFFu : 0u;\n        \n        // Nullify the stopbit if we're not supposed to look at this edge\n        uvec4 StopBit;\n        StopBit.x = (EdgeFound.x != 0u) ? kStopBit : 0u;\n        StopBit.y = (EdgeFound.y != 0u) ? kStopBit : 0u;\n        StopBit.z = (EdgeFound.z != 0u) ? kStopBit : 0u;\n        StopBit.w = (EdgeFound.w != 0u) ? kStopBit : 0u;\n\n        for (int i = 1; i <= int(kMaxEdgeLength); i++)\n        {\n            uvec4 uEdgeMask;\n\n            uEdgeMask.x = MLAA_SeperatingLines(Sampler, clamp(Offset + ivec2(-i, 0), ivec2(0, 0), TextureSize), TextureSize);\n            uEdgeMask.y = MLAA_SeperatingLines(Sampler, clamp(Offset + ivec2(i, 0), ivec2(0, 0), TextureSize), TextureSize);\n            uEdgeMask.z = MLAA_SeperatingLines(Sampler, clamp(Offset + ivec2(0, i), ivec2(0, 0), TextureSize), TextureSize);\n            uEdgeMask.w = MLAA_SeperatingLines(Sampler, clamp(Offset + ivec2(0, -i), ivec2(0, 0), TextureSize), TextureSize);\n\n            EdgeFound = EdgeFound & (uEdgeMask & EdgeDirMask);\n            EdgeCount.x = EdgeFound.x != 0u ? EdgeCount.x + 1u : EdgeCount.x | StopBit.x;\n            EdgeCount.y = EdgeFound.y != 0u ? EdgeCount.y + 1u : EdgeCount.y | StopBit.y;\n            EdgeCount.z = EdgeFound.z != 0u ? EdgeCount.z + 1u : EdgeCount.z | StopBit.z;\n            EdgeCount.w = EdgeFound.w != 0u ? EdgeCount.w + 1u : EdgeCount.w | StopBit.w;\n        }\n    }\n\treturn uvec2(EncodeCount(EdgeCount.x, EdgeCount.y), EncodeCount(EdgeCount.z, EdgeCount.w));\n}\n\n//-----------------------------------------------------------------------------\t\n//\tMain function used in third and final phase of the algorithm\n//\tThis code reads previous inputs and perform anti-aliasing of edges by \n//  blending colors as required.\n//-----------------------------------------------------------------------------\nvoid BlendColor(sampler2D Sampler,\n\tuint count,\n\tivec2 pos,\n\tivec2 dir,\n\tivec2 ortho,\n\tbool _inverse,\n\tinout vec4 color)\n{\n\t// Only process pixel edge if it contains a stop bit\n\tif (IsBitSet(count, kStopBit_BitPosition + kPosCountShift) || IsBitSet(count, kStopBit_BitPosition + kNegCountShift))\n    {\n        // Retrieve edge length\n        uint negCount = DecodeCountNoStopBit(count, kNegCountShift);\n        uint posCount = DecodeCountNoStopBit(count, kPosCountShift);\n\n        // Fetch color adjacent to the edge\n        vec4 adjacentcolor = texelFetch(Sampler, pos + dir, 0);\n\n        if ((negCount + posCount) == 0u)\n        {\n            float weight = 1.0 / 8.0; // Arbitrary\t\t\t\n            // Cheap approximation of gamma to linear and then back again\n            color.xyz = sqrt(mix(color.xyz * color.xyz, adjacentcolor.xyz * adjacentcolor.xyz, weight));\n            return;\n        }\n        else\n        {\n            // If no sign bit is found on either edge then artificially increase the edge length so that\n            // we don't start anti-aliasing pixels for which we don't have valid data.\n            if (!(IsBitSet(count, (kStopBit_BitPosition + kPosCountShift)))) posCount = kMaxEdgeLength + 1u;\n            if (!(IsBitSet(count, (kStopBit_BitPosition + kNegCountShift)))) negCount = kMaxEdgeLength + 1u;\n\n            // Calculate some variables\n            float _length = float(negCount + posCount) + 1.f;\n            float midPoint = _length / 2.f;\n            float _distance = float(negCount);\n\n            const uint upperU = 0x00u;\n            const uint risingZ = 0x01u;\n            const uint fallingZ = 0x02u;\n            const uint lowerU = 0x03u;\n\n            ///////////////////////////////////////////////////////////////////////////////////////\n            // Determining what pixels to blend\n            // 4 possible values for shape - x indicates a blended pixel:\n            //\n            // 0: |xxxxxx| -> (h0 > 0) && (h1 > 0) : upperU     - blend along the entire inverse edge\n            //     ------\n            //\n            //\n            // 1:     xxx| -> (h0 < 0) && (h1 > 0) : risingZ    - blend first half on inverse, \n            //     ------                                         blend second half on non-inverse\n            //    |xxx                                            \n            //\n            // 2: |xxx     -> (h0 > 0) && (h1 < 0) : fallingZ   - blend first half on non-inverse, \n            //     ------                                         blend second half on inverse\n            //        xxx|                                        \n            //\n            // 3:          -> (h0 < 0) && (h1 < 0) : lowerU     - blend along the entire non-inverse edge\n            //     ------\n            //    |xxxxxx|\n            ///////////////////////////////////////////////////////////////////////////////////////\n\n            uint shape = 0x00u;\n            if (CompareColors((texelFetch(Sampler, pos - (ortho * ivec2(int(negCount))), 0).a), \n                              (texelFetch(Sampler, pos - (ortho * (ivec2(int(negCount) + 1))), 0).a)))\n            {\n                shape |= risingZ;\n            }\n\n            if (CompareColors((texelFetch(Sampler, pos + (ortho * ivec2(int(posCount))), 0).a), \n                              (texelFetch(Sampler, pos + (ortho * (ivec2(int(posCount) + 1))), 0).a)))\n            {\n                shape |= fallingZ;\n            }\n\n            // Parameter \"_inverse\" is hard-coded on call so will not generate a dynamic branch condition\n            if ((_inverse && (((shape == fallingZ) && (float(negCount) <= midPoint)) ||\n                ((shape == risingZ) && (float(negCount) >= midPoint)) ||\n                ((shape == upperU))))\n                || (!_inverse && (((shape == fallingZ) && (float(negCount) >= midPoint)) ||\n                    ((shape == risingZ) && (float(negCount) <= midPoint)) ||\n                    ((shape == lowerU)))))\n            {\n                float h0 = abs((1.0 / _length) * (_length - _distance) - 0.5);\n                float h1 = abs((1.0 / _length) * (_length - _distance - 1.0) - 0.5);\n                float area = 0.5f * (h0 + h1);                \n                // Cheap approximation of gamma to linear and then back again\n                color.xyz = sqrt(mix(color.xyz * color.xyz, adjacentcolor.xyz * adjacentcolor.xyz, area));\n            }\n        }\n    }\n}\n\n//-----------------------------------------------------------------------------\n//\tMLAA pixel shader for color blending.\n//\tPixel shader used in third and final phase of the algorithm\n//-----------------------------------------------------------------------------\nvec4 MLAA_BlendColor_PS(sampler2D Sampler, sampler2D SamplerEdges, ivec2 Offset, ivec2 TextureSize, bool bShowEdgesOnly)\n{\n    if (bShowEdgesOnly)\n    {\n        vec4 rVal = texelFetch(Sampler, Offset, 0);\n\n        uint hcount, vcount;\n        uvec2 _count = D3DX_FLOAT4_to_UINT4_B8G8R8A8_UNORM(texelFetch(SamplerEdges, Offset, 0)).xy;\n        hcount = _count.x; vcount = _count.y;\n\n        if ((hcount != 0u) || (vcount != 0u))\n        {\n            if ((IsBitSet(hcount, kStopBit_BitPosition + kPosCountShift) || IsBitSet(hcount, kStopBit_BitPosition + kNegCountShift)) ||\n                (IsBitSet(vcount, kStopBit_BitPosition + kPosCountShift) || IsBitSet(vcount, kStopBit_BitPosition + kNegCountShift)))\n            {\n                uint Count = 0u;\n                Count += DecodeCountNoStopBit(hcount, kNegCountShift);\n                Count += DecodeCountNoStopBit(hcount, kPosCountShift);\n                Count += DecodeCountNoStopBit(vcount, kNegCountShift);\n                Count += DecodeCountNoStopBit(vcount, kPosCountShift);\n                if (Count != 0u)\n                    rVal = vec4(1, 0, 0, 1);\n            }\n        }\n        return rVal;\n    }\n    else\n    {\n        uint hcount, vcount;\n        uint hcountup, vcountright;\n\n        uvec2 _count = D3DX_FLOAT4_to_UINT4_B8G8R8A8_UNORM(texelFetch(SamplerEdges, Offset, 0)).xy;\n        hcount = _count.x; vcount = _count.y;\n        hcountup = D3DX_FLOAT4_to_UINT4_B8G8R8A8_UNORM(texelFetch(SamplerEdges, Offset - kUp.xy, 0)).x;\n        vcountright = D3DX_FLOAT4_to_UINT4_B8G8R8A8_UNORM(texelFetch(SamplerEdges, Offset - kRight.xy, 0)).y;\n\n        // Retrieve pixel from original image\n        vec4 rVal = texelFetch(Sampler, Offset, 0);\n        // Blend pixel colors as required for anti-aliasing edges\n        if (hcount != 0u)\t\tBlendColor(Sampler, hcount, Offset, kUp.xy, kRight.xy, false, rVal);   // H down-up\n        if (hcountup != 0u)\t    BlendColor(Sampler, hcountup, Offset - kUp.xy, -kUp.xy, kRight.xy, true, rVal);   // H up-down    \t\t\t\t    \n        if (vcount != 0u)\t\tBlendColor(Sampler, vcount, Offset, kRight.xy, kUp.xy, false, rVal);   // V left-right\t\t\t\t\n        if (vcountright != 0u)\tBlendColor(Sampler, vcountright, Offset - kRight.xy, -kRight.xy, kUp.xy, true, rVal);   // V right-left    \t\t\t\n        \n        return rVal;\n    }\n}\n\n//-----------------------------------------------------------------------------\n// EOF\n//-----------------------------------------------------------------------------","name":"Common","description":"","type":"common"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// AMD Morphological Anti-Aliasing (MLAA) Sample\n//\n// https://github.com/GPUOpen-LibrariesAndSDKs/MLAA11\n//\n// Copyright (c) 2016 Advanced Micro Devices, Inc. All rights reserved.\n//\n// SPDX-License-Identifier: MIT\n\n// MLAA (provided by AMD)\n// Copyright (c) 2023 by Denis Reischl\n//\n// SPDX-License-Identifier: MIT\n\n/*\n     [X] PASS I   : Render Scene with much artifacts, set\n                    Texel Luma to Alpha channel\n     ----------------------------------------------------------\n     \n     [_] PASS II  : Detect Edges and count their lengths\n     ----------------------------------------------------------\n     \n     [_] PASS III : Blend Colors (right), \n                    show edges (topleft), \n                    present\n     ----------------------------------------------------------\n     \n     Morphological antialiasing (MLAA) provided by AMD\n     [ https://github.com/GPUOpen-LibrariesAndSDKs/MLAA11 ]\n     [ /mlaa11/src/Shaders/MLAA11.hlsl ]\n     \n     ported to GLSL\n     \n     - left top : show edges in red\n     \n     - right : AA applied\n     \n     - left bottom : no AA applied\n    \n     - use Mouse to set border\n    \n     - change \"fInvEdgeDetectionTreshold\" in \"Common\" for the luminance \n       difference when detecting edges\n       \n     - luma is applied to alpha channel when rendering scene (Buffer A)\n     \n     - UINTs stored to FLOATs via helpers uvec4 <-> FLOAT4 ( B8G8R8A8_UNORM ) \n       UINT4_to_FLOAT4_D3DX_B8G8R8A8_UNORM (in Buffer B / mainImage)\n       D3DX_FLOAT4_to_UINT4_B8G8R8A8_UNORM (in Common / MLAA_BlendColor_PS)       \n*/\n\n\n#define PI 3.141592654f\n\n// box intersection by Inigo Quilez : https://www.shadertoy.com/view/ld23DV\n// https://iquilezles.org/articles/boxfunctions\nvec4 iBox( in vec3 ro, in vec3 rd, in mat4 txx, in mat4 txi, in vec3 rad ) \n{\n    // convert from ray to box space\n\tvec3 rdd = (txx*vec4(rd,0.0)).xyz;\n\tvec3 roo = (txx*vec4(ro,1.0)).xyz;\n\n\t// ray-box intersection in box space\n    vec3 m = 1.0/rdd;\n    vec3 n = m*roo;\n    vec3 k = abs(m)*rad;\n    vec3 t1 = -n - k;\n    vec3 t2 = -n + k;\n    float tN = max(max(t1.x,t1.y),t1.z);\n    float tF = min(min(t2.x,t2.y),t2.z);\n    \n    // no intersection\n\tif( tN>tF || tF<0.0 ) return vec4(-1.0);\n\n    // this works as long as the ray origin is not inside the box\n    vec4 res = vec4(tN, step(tN,t1) );\n    \n    // add sign to normal and convert to ray space\n\tres.yzw = (txi * vec4(-sign(rdd)*res.yzw,0.0)).xyz;\n\n\treturn res;\n}\n\n// bottom plane intersection\nvec4 iPlane(in vec3 vOri, in vec3 vDir)\n{\n    // ortho project up-origin/up-dir\n    float fT = -vOri.y/vDir.y;\n    return vec4(fT, vec3(0.f, 1.f, 0.f));\n}\n\n// lookat matrix.. from https://www.shadertoy.com/view/Xtl3W2\nmat3 LookAt(in vec3 vOri, in vec3 vTar, in float fRoll )\n{\n    vec3 vW = normalize( vTar - vOri );\n    vec3 vU = normalize( cross(vW, vec3(sin(fRoll),cos(fRoll),0.0) ) );\n    vec3 vV = normalize( cross(vU,vW));\n    return mat3( vU, vV, vW );\n}\n\n// y rotation matrix\nmat4 Rotate4X(float fAng) \n{\n  float fS = sin(fAng);\n  float fC = cos(fAng);\n\n  return mat4(1.f, 0.f, 0.f, 0.f, 0.f, fC, fS, 0.f, 0.f, -fS, fC, 0.f, 0.f, 0.f, 0.f, 1.f);\n}\n\n// by Inigo Quilez : https://iquilezles.org/articles/palettes\nvec3 pal( in float t, in vec3 a, in vec3 b, in vec3 c, in vec3 d ) { return a + b*cos( 6.28318*(c*t+d) ); }\n\n// simple checkers\nfloat checkers(vec2 vUv, float fDist)\n{\n    return mix(.3f, 1.f, (1. - step(0.995 - fDist * 0.01, max(fract(vUv.x), fract(vUv.y))))) * clamp(max(0.f, 5.f - fDist * .25f), 0.f, 1.f);\n}\n\nvoid mainImage( out vec4 cOut, in vec2 vUv )\n{\n    float fTime = 4.0f;\n    \n\t// create view ray\n    vec2 vP = (-iResolution.xy + 2.0 * vUv.xy) / iResolution.y;\n    vec2 vM = vec2(fTime, 2.4f);\n    vec3 vOri = vec3(sin(vM.x) * vM.y, 1.3f, cos(vM.x) * vM.y);\n\tvec3 vDir = normalize(LookAt(vOri, vec3(0.f, 1.f, 0.f), 0.f) * vec3(vP.xy, 2.f) );\n    \n    // box transform\n    mat4 txi = mat4(1.f, vec4(0.f), 1.f, vec4(0.f), 1.f, 0.f, 0.f, 1.f, 0.f, 1.f) * Rotate4X(fTime);\n    mat4 txx = inverse( txi );\n    \n    // trace box or bottom plane\n    vec3 vPos, vNor, vOpos, sBox = vec3(.4f, .6f, .8f) ;\n\tvec4 vInt = iBox(vOri, vDir, txx, txi, sBox);\n    float fTHit = vInt.x;\n    if ((fTHit <= 0.f) && (vDir.y < 0.f)) { vInt = iPlane(vOri, vDir); fTHit = vInt.x; }\n    \n    if (fTHit > 0.f)\n    {\n        // normal, position\n        vNor = vInt.yzw;\n        vPos = vOri + vDir * fTHit;\n        \n        // box or plane ?\n        if (vPos.y > 0.01f)\n        {\n            // colorize for MLAA\n            vec3 vOpos = (txx*vec4(vPos,1.f)).xyz;\n            cOut = vec4(vec3(max(vec2(.3f, .3f), step(.5f, fract(vOpos.xz))), 0.f), 1.f);\n            cOut.r = cOut.g = cOut.b = mix(cOut.r, cOut.g, .5f);\n            cOut.rgb *= pal( floor(sin(max(abs(fract(vOpos.x) - .5f), abs(fract(vOpos.z) - .5f)) * PI) * 20.f) * .25f,\n                    vec3(0.5,0.5,0.5),vec3(0.5,0.5,0.5),vec3(1.0,1.0,1.0),vec3(0.0,0.33,0.67) );\n        }\n        else\n        {\n            // colorize for MLAA\n            vec2 vC = vec2(floor(vPos.xz) * vec2(.33f, .22f));\n            cOut.rgb = mix( vec3(.3f, 1.f, 1.f),\n                pal(sin(vC.x + vC.y), vec3(0.5,0.5,0.5),vec3(0.5,0.5,0.5),vec3(1.0,1.0,0.5),vec3(0.8,0.90,0.30) ), \n                checkers(vPos.xz, fTHit));\n            cOut.rgb -= - fTHit * .01f;\n        }\n\n        // simple diffuse\n        cOut.xyz *= max(dot(normalize(vec3(-3.f, 5.f, -6.f)), vNor), 0.3f);\n    }\n    else\n        cOut = vec4(pal(floor(fract(abs(vDir.y * 10.f)) * 10.f) * .1f, \n            vec3(0.5,0.5,0.5),vec3(0.5,0.5,0.5),vec3(1.0,1.0,1.0),vec3(0.3,0.20,0.20) ) , 1.f);\n            \n    // compute luma and set as alpha\n\tcOut.a = sqrt(dot(cOut.rgb, vec3(.299f, .587f, .114f)));\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// AMD Morphological Anti-Aliasing (MLAA) Sample\n//\n// https://github.com/GPUOpen-LibrariesAndSDKs/MLAA11\n//\n// Copyright (c) 2016 Advanced Micro Devices, Inc. All rights reserved.\n//\n// SPDX-License-Identifier: MIT\n\n// MLAA (provided by AMD)\n// Copyright (c) 2023 by Denis Reischl\n//\n// SPDX-License-Identifier: MIT\n\n/*\n     [_] PASS I   : Render Scene with much artifacts, set\n                    Texel Luma to Alpha channel\n     ----------------------------------------------------------\n     \n     [X] PASS II  : Detect Edges and count their lengths\n     ----------------------------------------------------------\n     \n     [_] PASS III : Blend Colors (right), \n                    show edges (topleft), \n                    present\n     ----------------------------------------------------------\n     \n     Morphological antialiasing (MLAA) provided by AMD\n     [ https://github.com/GPUOpen-LibrariesAndSDKs/MLAA11 ]\n     [ /mlaa11/src/Shaders/MLAA11.hlsl ]\n     \n     ported to GLSL\n     \n     - left top : show edges in red\n     \n     - right : AA applied\n     \n     - left bottom : no AA applied\n    \n     - use Mouse to set border\n    \n     - change \"fInvEdgeDetectionTreshold\" in \"Common\" for the luminance \n       difference when detecting edges\n       \n     - luma is applied to alpha channel when rendering scene (Buffer A)\n     \n     - UINTs stored to FLOATs via helpers uvec4 <-> FLOAT4 ( B8G8R8A8_UNORM ) \n       UINT4_to_FLOAT4_D3DX_B8G8R8A8_UNORM (in Buffer B / mainImage)\n       D3DX_FLOAT4_to_UINT4_B8G8R8A8_UNORM (in Common / MLAA_BlendColor_PS)       \n*/\n\nvoid mainImage( out vec4 cOut, in vec2 vXY )\n{\n    // detect edges and compute their lengths, convert from UINT4 to FLOAT4\n\tuvec2 auLineL = MLAA_ComputeLineLength(iChannel0, ivec2(vXY), ivec2(iResolution.xy) - 1);\n\tcOut = UINT4_to_FLOAT4_D3DX_B8G8R8A8_UNORM(uvec4(auLineL, 0, 0));\n}","name":"Buffer B","description":"","type":"buffer"}]}
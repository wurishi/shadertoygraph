{"ver":"0.1","info":{"id":"Dlj3zV","date":"1683791641","viewed":201,"name":"Old-school Ray-cast Maze","username":"Hamneggs","description":"USE WASD + LR to move around. \nHave an old laptop and an even older textbook, and decided to try implementing that Wolfenstein path-tracing technique used all throughout the lands in the late 80s-early 90s. Got a little carried away with the lighting.\n","likes":5,"published":1,"flags":48,"usePreview":0,"tags":["2d","oldschool","interactive","old","pathtracing","wolfenstein","school"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XdXGzn","filepath":"/media/a/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","previewfilepath":"/media/ap/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","type":"texture","channel":3,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//==============================================================\n// Main renderbuffer. Does all texture sampling, lighting, and\n// scene composition. (If anyone wants to take a stab at that\n// long distance flickering be my guest.\n//==============================================================\n\n#define MAP iChannel0\n#define MARCH iChannel1\n#define STATE iChannel2\n// Current buffer size for loading data.\n#define BUFF_RES iChannelResolution[0].xy\n\n// Reads a texel. We don't really need component-wise read functions.\nvec4 readTexel(in sampler2D buffer, in vec2 pos )\n{\n    return texture(buffer, (pos+.5)/BUFF_RES);\n}\n\n// Uses an incoming screenspace UV coordinate to sample the depth buffer\n// then combines the two to get a vertical UV coordinate for texturing\n// the walls.\nvec2 getWallUV( in vec2 uv )\n{\n\n    // How many pixels the depth marcher had to step.\n    float offset = texture(MARCH,vec2(uv.x,0)).r;\n    \n    // Sample the maze map at that point on the screen.\n    vec4 intersect = texture(MAP, vec2(uv.x,offset));\n    \n    // Pull out the surface normal and position.\n    vec2 norm = intersect.xy;\n    vec2 pos = intersect.zw;\n    \n    // Depending on the orientation of the wall, the lateral position\n    // might be either the X or Y component of wall column's location.\n    float s = 0.0, t = 0.0;\n    if (abs(norm.x)>abs(norm.y)) s = pos.y;\n    else s = pos.x;\n    \n    // Redo the plane warp math to get a vertical coordinate.\n    t = (uv.y-offset)/(1.0-offset*2.0);\n    return vec2(s,t);\n}\n\n// Samples the various texture generation functions based on\n// material ID.\nvec4 sampleTexture( in vec2 uv, in float mat, in float dist )\n{\n    if ( mat == MAT_WALL ) return wallTex(uv).rgbb;\n    else if ( mat == MAT_FLOOR ) return floorTex(uv).rgbb;\n    else return ceilingTex(uv,dist);\n}\n\n// Samples generative normal functions based on material.\n// This allows us to do bump and normal mapping per material.\nvec3 sampleNormal( in vec3 norm, in vec2 uv, in float mat )\n{\n    vec3 offset = vec3(0), n = vec3(0);\n    if ( mat == MAT_WALL )\n    {\n        // sample the normal map of the wall and offset the nominal normal\n        // by it. Since we're not in the vertical space, we need to do some\n        // quick math to flip things around. (There absolutely has to be a\n        // more elegant way)\n        offset = wallNormal(uv);\n        if ( abs(norm.x) > .5 )\n            n = norm+offset.gbr*vec3(sign(norm.x),-1,-1);\n        else\n            n = norm+offset.rbg*vec3(-1,-1,sign(norm.z));\n        \n    }\n    else if ( mat == MAT_FLOOR ) n = floorNormal(uv);\n    else n = ceilingNormal(uv)*vec3(0,-1,0); // Grab our ceiling normal and flip it.\n    \n    return n;\n}\n\n// Calculates the lighting contribution of a single, directional, conic light.\nfloat calcConeLight( in vec3 norm, in vec3 ldir, in vec3 vdir, in vec3 lpos, in vec3 spos )\n{\n    // Vector from the surface to a light.\n    vec3  toLight = (lpos-spos);\n    \n    // The distance.\n    float dist = length(toLight);\n    \n    // Now we normalize toLight for accurate vector shortcut identities.\n    toLight = normalize(toLight);\n    \n    // Distance based falloff.\n    float falloff = max(0.0,pow(dist,2.0));\n    \n    // Gouraud shading. Uses the dot product of two normalized vectors to calculate\n    // the cosine of the angle between surface normal and light incidence vectors.\n    // Easy normal dependence term for our final product.\n    float gouraud = clamp( dot(toLight, norm), 0.1, 1.0 ); // an ambient term for the clamp.\n    \n    // Does the same dot() trick to calculate the angle between the incidence vector and\n    // light direction. This gives us that conic cast common with can lighting. (I like it.)\n    float conicFalloff = clamp( dot(-toLight,ldir), 0.0, 1.0);\n    \n    // Quick fudge of that coeff to give us something more plausible.\n    conicFalloff = smoothstep(.92,.96,conicFalloff);\n    \n    // Reflect the view incidence vector across the normal, then its another dot for\n    // specularity.\n    vec3 refl = reflect(vdir, norm);\n    refl = normalize(refl);\n    float specular = pow( clamp( dot(toLight,refl), 0.0, 1.0), 8.0);\n    \n    // Direction, lightcast, distance, and ambient term just like that.\n    return gouraud*conicFalloff*falloff + .05;// + specular; // It's ugly.\n}\n\nvec4 lightScene( in vec3 norm, in vec3 pos, in vec3 point, in float dist, in vec2 uv, in float mat)\n{\n    // Get our atenuated normal.\n    vec3 n = sampleNormal(norm,uv,mat);\n    \n    // The eye to surface vec of the point we're trying to light.\n    vec3 viewDir = normalize(point-pos);\n    \n    // Lights point down\n    vec3 lightDir = vec3(0,-1,0);\n    \n    // How often the lights repeat. Doing some modulo stuff to make the lights repeat.\n    vec3 lightPos = vec3(LIGHT_REPEAT.x*.5, 1.5, LIGHT_REPEAT.y*.5); // Where our ligt is in mod space.\n    vec3 modPoint = point; // Generate our mod space point.\n    modPoint.xz = mod(modPoint.xz,LIGHT_REPEAT);\n    \n    // Sample all nearby lights to find the one that's brightest.\n    float maxLight = -9001.0;\n    vec3 curPos;\n    for( int i = -2; i < 3; ++i )\n    {\n        for( int j = -2; j < 3; ++j )\n        {\n            curPos = modPoint;\n            curPos.xz += LIGHT_REPEAT*vec2(i,j);\n            \n            maxLight = max(maxLight, calcConeLight(n,lightDir, viewDir, lightPos, curPos));\n        }\n    }\n    \n    // Return that times a color.\n    return maxLight*LIGHT_COLOR*LIGHT_BRIGHTNESS;\n}\n\n// Main render loop.\nvec4 renderScene( in vec2 uv )\n{\n    // Get state data.\n    vec4 pos_dir = readTexel(STATE, POS_DIR);\n    // Sample the scene.\n    float offset = texture(MARCH,vec2(uv.x,0)).r;\n    vec4 map = texture(MAP, uv);\n    \n    \n    // Create a value centered around uv.y == .5\n    // so that we can more efficiently determine if we're on\n    // a wall pixel or plane pixel.\n    float y = min(uv.y, 1.0-uv.y);\n    \n    // Determine our material, our UV coordinate system, nominal normal, and our distance to surface.\n    float mat = 0.0;\n    vec2 st = uv;\n    vec3 pos = vec3(pos_dir.x,.5,pos_dir.y), point = vec3(0), norm;\n    if ( y < offset && uv.y > .5) { mat=MAT_CEILING; st=map.zw; point=vec3(map.z,1.0,map.w); norm=vec3(0,-1,0);}\n    else if ( y < offset )        { mat=MAT_FLOOR;   st=map.zw; point=vec3(map.z,0.0,map.w); norm=vec3(0,1,0); }\n    else { \n        mat=MAT_WALL;\n        st=getWallUV(uv);\n        vec4 p=texture(MAP,vec2(uv.x,offset)); norm=vec3(p.x,0,p.y); // Redefine this so we get an X-Z value for our wall.\n        point=vec3(p.z,st.y,p.w);\n    }\n    float dist = length(pos-point)*1.-.5;\n    //return point.xyzz;\n    vec4 px = sampleTexture(st, mat, dist);\n    return px*lightScene(norm, pos, point, dist, st, mat);\n    \n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n    fragColor = renderScene(uv);\n    \n    // Do tonemapping and gamma correction.\n    fragColor = pow(clamp(fragColor, 0., 1.), vec4(.4545));\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//==============================================================\n// If you load the prior state of your render target, and only\n// output a change if some factor has changed, you've just added\n// state management to your one way render pipeline.\n// This does that to maintain camera position and direction\n// based on keyboard input.\n//==============================================================\n\n// Buffer definitions\n#define STATE iChannel0\n#define KEYBOARD iChannel1\n// Current buffer size for loading data.\n#define BUFF_RES iChannelResolution[0].xy\n\n// Reads a texel. We don't really need component-wise read functions.\nvec4 readTexel(in sampler2D buffer, in vec2 pos )\n{\n    return texture(buffer, (pos+.5)/BUFF_RES);\n}\n\n// Writes all components of a texel (at once).\nvoid write4( inout vec4 buffer, in vec4 val, in vec2 pos, in vec2 fragCoord)\n{\n    vec2 offset = abs(pos-floor(fragCoord));\n    buffer = mix( val, buffer, step(.01,max(offset.x,offset.y)) );\n}\n\nvoid handleKeyboard( inout vec4 buffer, in vec2 fragCoord )\n{\n\n    // Is it better to store things in vecs with their smaller footprint\n    // but member access, or as floats with their larger footprint?\n    vec4 wasd = vec4(0), udlr = vec4(0);\n    vec4 pos_dir = vec4(0), vel_rot = vec4(0);\n    \n    // Sample the keyboard state buffer.\n    wasd.r = texture(KEYBOARD,vec2(KEY_W, KEY_DOWN)).r;\n    wasd.g = texture(KEYBOARD,vec2(KEY_A, KEY_DOWN)).r;\n    wasd.b = texture(KEYBOARD,vec2(KEY_S, KEY_DOWN)).r;\n    wasd.a = texture(KEYBOARD,vec2(KEY_D, KEY_DOWN)).r;\n    \n    udlr.r = texture(KEYBOARD,vec2(KEY_UP, KEY_DOWN)).r;\n    udlr.g = texture(KEYBOARD,vec2(KEY_DN, KEY_DOWN)).r;\n    udlr.b = texture(KEYBOARD,vec2(KEY_LF, KEY_DOWN)).r;\n    udlr.a = texture(KEYBOARD,vec2(KEY_RH, KEY_DOWN)).r;\n    \n    \n    // Get our previous values for our movement state.\n    pos_dir = readTexel(STATE, POS_DIR);\n    vel_rot = readTexel(STATE, VEL_ROT);\n    \n    // Generate a vector pointed in our current heading.\n    float s = sin(pos_dir.z), c = cos(pos_dir.z);\n    vec2 heading = vec2(0,1)*mat2(c,s,-s,c);\n    vec2 right = heading*mat2(0,1,-1,0);\n    \n    \n    float vel = length(vel_rot.xy);\n    float rot = length(vel_rot.z); // Does this shortcut to abs()?\n    \n    // Fore-aft\n    if      (wasd.r > 0.5) vel_rot.y += MOV_EASING;\n    else if (wasd.b > 0.5) vel_rot.y -= MOV_EASING;\n    else                   vel_rot.y *= MOV_EASING;\n    \n    // Left, right\n    if      (wasd.a > 0.1) vel_rot.x += MOV_EASING;\n    else if (wasd.g > 0.1) vel_rot.x -= MOV_EASING;\n    else                   vel_rot.x *= MOV_EASING;\n    \n    // rotation\n    if      (udlr.b > 0.5) vel_rot.z -= ROT_EASING;\n    else if (udlr.a > 0.5) vel_rot.z += ROT_EASING;\n    else                   vel_rot.z *= ROT_EASING;\n    \n    // Speed capping.\n    if (vel > MAX_VEL) vel_rot.xy *= MAX_VEL/vel;\n    if (rot > MAX_ROT) vel_rot.z *= MAX_ROT/rot;\n    \n    // Now that all our inputs have been dealt with, we can act upon them.\n    pos_dir.xy += vel_rot.x*right + vel_rot.y*heading;\n    pos_dir.z += vel_rot.z;\n    write4(buffer, pos_dir, POS_DIR, fragCoord);\n    write4(buffer, vel_rot, VEL_ROT, fragCoord);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    CULL_PX_OUTSIDE_VEC(MEM_SIZE);\n    // Load the buffer at this fragment's position.\n    vec4 buff = texture(STATE,fragCoord/BUFF_RES);\n    \n    // Startup stuff.\n    if(iFrame < 2)\n        write4(buff, START_POS, POS_DIR, fragCoord);\n    else\n        handleKeyboard(buff, fragCoord);\n        \n    fragColor = buff;\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"//==============================================================\n// This buffer draws the distorted plane that defines the\n// maze field. Look at it on its own and you'll see exactly how\n// this whole thing works.\n//==============================================================\n\n#define EPSILON .0001\n#define SQ2 .707106\n\n// Buffer definitions\n#define STATE iChannel0\n// Current buffer size for loading data.\n#define BUFF_RES iChannelResolution[0].xy\n\n// The same old random function with a different signature.\nvec2 rand(vec2 co){\n    return vec2(fract(cos(dot(co.yx ,vec2(12.44947,45.0974))) * 43758.5453),\n                fract(sin(dot(co.yx ,vec2(8.23946,-39.2193))) * 92732.2634));\n}\n\n// Wikipedia definition of a triangle wave. Kinda neat!\nfloat tri(in float x)\n{\n    return 2.0 * abs( x - floor(x + 0.5) );\n}\n\n\n// Using that 45-degree line can be any maze element if reflected idea\nfloat line(in vec2 uv)\n{\n    return 1.0-tri(uv.x-uv.y);\n}\nvec2 maze(in vec2 uv)\n{\n    mat2 rot45 = mat2(SQ2,-SQ2,SQ2,SQ2);\n    uv*= rot45;\n    vec2 q = fract(uv);\n    vec2 g = floor(uv);\n    \n    vec2 r = rand(g);\n    \n    // A dumb way to ensure that that eventual sign() never returns 0.\n    r *= 3.0;\n    r = floor(r);\n    r -= 1.5;\n    r *= .3333;\n    \n    vec2 swizzler = sign(r);\n    q *= swizzler;\n    \n    vec2 d = vec2(EPSILON,0);\n    float wall = line(q);\n    vec2 norm = vec2(line(q+d.xy*swizzler)-line(q-d.xy*swizzler),\n                     line(q+d.yx*swizzler)-line(q-d.yx*swizzler))/(EPSILON*2.);\n    norm*=rot45;\n    norm.y *= -1.;\n    norm*=wall;\n    \n    return norm.yx*step(2.25, max(abs(norm.y),abs(norm.x))); // Don't know where my math bug is, but this fixes it.\n}\n\n// IQ reference planar definition.\nvec2 hallTransform( in vec2 uv )\n{\n    // Naturalize our coordinate space to (-1,1).\n    uv *= 2.0;\n    uv -= 1.0;\n    uv.y *= 4.0;\n    \n    // Fix aspect ratio.\n\t//uv.x *= iResolution.x/iResolution.y;\n    \n    // Plane deformation.\n    return vec2(uv.x/abs(uv.y), (1.0/abs(uv.y)));\n}\n\n\n// Reads a texel. We don't really need component-wise read functions.\nvec4 readTexel(in sampler2D buffer, in vec2 pos )\n{\n    return texture(buffer, (pos+.5)/BUFF_RES);\n}\n\n// Draws the maze out to buffer.\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    // Pull our state information out for use.\n    vec4 pos_dir = readTexel(STATE, POS_DIR);\n    vec4 vel_rot = readTexel(STATE, VEL_ROT);\n    \n    // Set up camera rotation and position.\n    float s = sin(pos_dir.z), c = cos(pos_dir.z);\n    mat2 rot = mat2(c,s,-s,c);\n    \n    // *mAgIc*\n    uv = hallTransform(uv);\n    uv *= rot;\n    uv += pos_dir.xy;\n    \n    // Generate our maze. Only the normals, but the\n    // rest can be derived.\n    vec2 m = maze(uv);\n    \n    // Output to buffer:\n    // x,y 2D wall surface normal, only present for walls.\n    // z,w: Transformed UV coordinate for texturing planes.\n    fragColor = vec4(m,uv);\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"//==============================================================\n// If you have a drawing of a maze, warped to have that two-plane\n// 3D perspective, you can count from the bottom of the screen\n// the number of pixels it takes to find the first texel of wall\n// in that distorted map to get an analogue of the distance to\n// that wall.\n// Not only that, since you've walked more-or-less forward into\n// the scene in that march, you've implicitly done occlusion\n// culling, determined the position of that column of wall,\n// and if you've encoded any other data into the map, done that\n// sample as well.\n// (Note, this only rendes one row of pixels, since, well,\n// we only need to do this march once per column of pixels.\n//==============================================================\n#define MAP iChannel0\n\n// Determines if we've had a collision by checking\n// if either field of the wall surface normal is\n// populated.\nbool collision( in vec4 texel )\n{\n    return max(abs(texel.x), abs(texel.y)) > .5;\n}\nfloat march( in vec2 fragCoord, out vec4 texel )\n{\n    int yResolution = int(iResolution.y);\n    ivec2 pos = ivec2(fragCoord.x,0);\n    for( int i = 0; i < yResolution; ++i )\n    {\n        texel = texelFetch(MAP, pos, 0);\n        if (collision(texel))\n            return float(pos.y)/iResolution.y;\n        else \n            ++pos.y;\n    }\n    return float(pos.y)/iResolution.y;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{   \n    CULL_PX_ABOVE_Y(1.0)\n    vec4 texel = vec4(0);\n    float offset = march(fragCoord,texel);\n    fragColor = vec4(offset,1,1,1);\n}","name":"Buffer C","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"//==============================================================\n// Constants, definitions and generalized functions oh my.\n//==============================================================\n\n// Locations of different values in our state buffer.\nconst vec2 POS_DIR = vec2(1.0,1.0);\nconst vec2 VEL_ROT = vec2(1.0,3.0);\nconst vec4 START_POS = vec4(0.30,6.0,-2.4,1.0);\n\nconst vec2 MEM_SIZE = vec2(5,5);\n#define CULL_PX_OUTSIDE_XY(X,Y) if(gl_FragCoord.x > X || gl_FragCoord.y > Y) discard;\n#define CULL_PX_OUTSIDE_VEC(V) if(gl_FragCoord.x > V.x || gl_FragCoord.y > V.y) discard;\n#define CULL_PX_IF_NOT(X,Y) if(gl_FragCoord.x != X || gl_FragCoord.y != Y\n#define CULL_PX_ABOVE_Y(Y) if(gl_FragCoord.y > Y) discard;\n\n// Key codes. Columns of the KB buffer that correspond to the keys we\n// care about.\nconst float KEY_W = 87.0/256.0;\nconst float KEY_A = 65.0/256.0;\nconst float KEY_S = 83.0/256.0;\nconst float KEY_D = 68.0/256.0;\nconst float KEY_UP = 38.0/256.0;\nconst float KEY_DN = 40.0/256.0;\nconst float KEY_LF = 37.0/256.0;\nconst float KEY_RH = 39.0/256.0;\n\n// Keyboard constants--row of the KB buffer that signifies key-down events.\n#define KEY_DOWN 0.0\n\n// Movement constants.\n#define ROT_EASING 0.010\n#define MOV_EASING 0.005\n#define MAX_ROT 0.07\n#define MAX_VEL 0.025\n\n// Material IDs.\n#define MAT_WALL 0.0\n#define MAT_FLOOR 1.0\n#define MAT_CEILING 2.0\n\n// Lighting parameters.\nconst vec2 LIGHT_REPEAT = vec2(.707); // lines up with the walls mostly.\nconst vec4 LIGHT_COLOR = vec4(1.0,.98,.96,1.0);\nconst float LIGHT_BRIGHTNESS = 1.6;\n\n// Procedural texture functions, hammered out quickly.\nvec4 floorTex(in vec2 uv)\n{\n    uv *= 10.0; // Scaling.\n    vec2 g = floor(uv); // Grid coordinates of our local float region.\n    float colorID = mod(g.x+g.y, 2.0); // Use that to create a binary pattern.\n    vec4 color = mix( vec4(.01,.012,.02,1.0),\n                      vec4(.2,.196,.19,1.),\n                      colorID ); // Choose between two colors.\n    return color;\n}\n\nfloat floorBump(in vec2 uv)\n{\n    // Just uses the distance to the edge of a integer region to\n    // define a difference in height.\n    uv *= 10.0;\n    vec2 f = fract(uv);\n    f = abs( f*2.0 - 1.0 );\n    \n    float distToEdge = 1.0-max( f.x, f.y );\n    return clamp( distToEdge*20.0, 0.0, 1.0 );\n}\n\nvec3 floorNormal(in vec2 uv)\n{\n    // Differentiates the bumpmap.\n    vec2 d = vec2(.0025, .000);\n    float dx = floorBump(uv+d.xy)-floorBump(uv-d.xy);\n    float dy = floorBump(uv+d.yx)-floorBump(uv-d.yx);\n    return normalize(vec3(-dx,1.0,-dy));\n}\n\nvec4 wallTex(in vec2 uv)\n{\n    return vec4(.8,.8,.6,1.)*.25;\n}\n\nfloat noise(vec2 co)\n{\n    return fract(sin(dot(co,vec2(12.9898,298.234))) * 43758.5453);\n}\n\nfloat wallBump(in vec2 uv)\n{\n    vec2 st = uv * vec2(10,10);\n    st.x += .5*floor(st.y);\n    vec2 f = fract(st);\n    f = abs( f*2.0 - 1.0 );\n    \n    float bumpHeight = 1.0-max( f.x, f.y );\n    bumpHeight = clamp(bumpHeight*10.0,-1.,1.0);\n    bumpHeight -= noise(uv)*.15;\n    return bumpHeight;\n}\n\nvec3 wallNormal(in vec2 uv)\n{\n    vec2 d = vec2(.001, .000);\n    float dx = wallBump(uv+d.xy)-wallBump(uv-d.xy);\n    float dy = wallBump(uv+d.yx)-wallBump(uv-d.yx);\n    return normalize(vec3(dx,1.0,dy));\n}\n\nvec4 ceilingTex(in vec2 uv, in float dist)\n{\n\n    // First: can lights.\n    vec2 m = mod(uv,LIGHT_REPEAT);\n    float distToLight = length(m-LIGHT_REPEAT*.5);\n    float canLight = pow(distToLight*30.0,-4.0);\n    // Now let's go ahead and do weird math to create a \n    // ceiling tile texture.\n    float filt = dist*.1;\n    uv *= vec2(12,6.0);\n    \n    vec2 f = fract(uv);\n    f = abs( f*2.0 - 1.0);\n    \n    float distToEdge = 1.0-max(f.x,f.y);\n    distToEdge = smoothstep(.02-filt, .02+filt, distToEdge)*.7;\n    \n    distToEdge -= noise(uv)*.1;\n    float color = max(distToEdge,0.05)*.4 + canLight;\n    \n    return vec4( color, color, color, 1. );\n}\n\nfloat ceilingBump(in vec2 uv)\n{\n    return noise(uv)*.75;\n}\n\nvec3 ceilingNormal(in vec2 uv)\n{\n    vec2 d = vec2(.0025, .000);\n    float dx = ceilingBump(uv+d.xy)-ceilingBump(uv-d.xy);\n    float dy = ceilingBump(uv+d.yx)-ceilingBump(uv-d.yx);\n    return normalize(vec3(-dx,1.0,-dy));\n}\n","name":"Common","description":"","type":"common"}]}
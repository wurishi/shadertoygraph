{"ver":"0.1","info":{"id":"NsdcRB","date":"1653656812","viewed":158,"name":"Camera Pose Estimation","username":"jt","description":"Given a quad (resulting from a projected square marker) estimate the rotation, position and also focal length.\nQuad visualizes the projected marker. X shape visualizes the reconstructed marker using estimated pose (both should match exactly).","likes":8,"published":1,"flags":0,"usePreview":0,"tags":["camera","projection","estimation","perspective","pose","p4p"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// https://www.shadertoy.com/view/NsdcRB\n\n// Camera Pose Estimation - 2022 by Jakob Thomsen\n// Offset Estimation by pyBlob - thanks!\n// See pyBlob's fork https://www.shadertoy.com/view/7sdczB Colored Pose + Offset Estimation\n// for notes about limitations of this method and more elaborate approach.\n\n// Based on \"Rectification with Visual Sphere perspective: an algebraic alternative for P4P pose estimation\" by J. M. Fober\n// https://arxiv.org/ftp/arxiv/papers/2004/2004.08933.pdf\n\n// Given a quad (resulting from a projected square marker) estimate the rotation matrix.\n// Quad visualizes the projected marker.\n// X shape visualizes the reconstructed marker using estimated rotation (both should match exactly).\n// Small x visualizes the vanishing points.\n\n// tags: camera, pose, estimation, P4P, perspective, projection\n\n#define pi 3.1415926\n\nmat4 ProjMat(float focal_length)\n{\n    return\n        mat4\n        (\n            vec4(focal_length, 0.0, 0.0, 0.0),\n            vec4(0.0, focal_length, 0.0, 0.0),\n            vec4(0.0, 0.0, 0.0, 1.0),\n            vec4(0.0, 0.0, 0.0, 0.0)\n        );\n}\n\nmat4 ProjMat()\n{\n    float f = 1.0 + 0.5 * cos(iTime); // focal length\n    return ProjMat(f);\n}\n\nvec2 Project(mat4 proj, vec3 v)\n{\n    vec4 w = proj * vec4(v, 1.0);\n    return vec2(w) / w.w;\n}\n\nvec2 Project(vec3 v)\n{\n    return Project(ProjMat(), v);\n}\n\nmat4 RotateAroundX(float t)\n{\n    return\n        mat4\n        (\n            vec4(1.0, 0.0, 0.0, 0.0),\n            vec4(0.0, cos(t), sin(t), 0.0),\n            vec4(0.0,-sin(t), cos(t), 0.0),\n            vec4(0.0, 0.0, 0.0, 1.0)\n        );\n}\n\nmat4 RotateAroundY(float t)\n{\n    return\n        mat4\n        (\n            vec4(cos(t), 0.0,-sin(t), 0.0),\n            vec4(0.0, 1.0, 0.0, 0.0),\n            vec4(sin(t), 0.0, cos(t), 0.0),\n            vec4(0.0, 0.0, 0.0, 1.0)\n        );\n}\n\nmat4 RotateAroundZ(float t)\n{\n    return\n        mat4\n        (\n            vec4(cos(t), sin(t), 0.0, 0.0),\n            vec4(-sin(t), cos(t), 0.0, 0.0),\n            vec4(0.0, 0.0, 1.0, 0.0),\n            vec4(0.0, 0.0, 0.0, 1.0)\n        );\n}\n\nmat4 Translate(vec3 v)\n{\n    return\n        mat4\n        (\n            vec4(1.0, 0.0, 0.0, 0.0),\n            vec4(0.0, 1.0, 0.0, 0.0),\n            vec4(0.0, 0.0, 1.0, 0.0),\n            vec4(v, 1.0)\n        );\n}\n\nvec2 Marker(float r, int n)\n{\n    float Phi = (0.5 + float(n)) * 2.0 * pi / 4.0;\n    return r * vec2(cos(Phi), sin(Phi));\n}\n\nmat4x2 TransformQuad(float Size, mat4 Camera)\n{\n    // Transform marker positions to camera coordinates\n    vec3 a = vec3(Camera * vec4(vec3(Marker(Size, 0), 0.0), 1.0));\n    vec3 b = vec3(Camera * vec4(vec3(Marker(Size, 1), 0.0), 1.0));\n    vec3 c = vec3(Camera * vec4(vec3(Marker(Size, 2), 0.0), 1.0));\n    vec3 d = vec3(Camera * vec4(vec3(Marker(Size, 3), 0.0), 1.0));\n\n    // Transform camera coordinates to screen coordinates\n    vec2 A = Project(a);\n    vec2 B = Project(b);\n    vec2 C = Project(c);\n    vec2 D = Project(d);\n\n    return mat4x2(A, B, C, D);\n}\n\nmat4x2 SimulateQuad(float Size)\n{   \n    float Pitch = 0.05 * 2.0 * pi * iTime;\n    float Yaw = 0.2 * 2.0 * pi * iTime;\n    float Roll = 0.3 * 2.0 * pi * iTime;\n\n    //vec3 Offset = vec3(0,0,1);\n    vec3 Offset = vec3(0.5*cos(0.3 * 2.0 * pi * iTime),0.5*sin(0.2 * 2.0 * pi * iTime),1.0);\n    mat4 Camera = Translate(Offset) * RotateAroundX(Pitch) * RotateAroundY(Yaw) * RotateAroundZ(Roll);\n\n    return TransformQuad(Size, Camera);\n}\n\nmat4x2 VerifyQuad(float Size, mat3 Rotation, vec3 Offset)\n{\n    mat4 Camera = Translate(Offset) * mat4(vec4(Rotation[0], 0.0), vec4(Rotation[1], 0.0), vec4(Rotation[2], 0.0), vec4(0.0, 0.0, 0.0, 1.0));\n    \n    return TransformQuad(Size, Camera);\n}\n\n// Implementation of \"Rectification with Visual Sphere perspective: an algebraic alternative for P4P pose estimation\" by J. M. Fober\n// https://arxiv.org/ftp/arxiv/papers/2004/2004.08933.pdf\n// NOTE: Although this function is called GetPose in the article it does NOT contain translation!\n// NOTE: I'm not sure if the first two vectors of this matrix are orthogonal (then this would be the rotation matrix).\n// NOTE (pyBlob): Without noise, GetPose returns a rotation matrix.\n//                With noise, Pose[0] and Pose[1] may not be orthogonal.\n// NOTE: The column vectors of Pose are the vanishing points (see DrawVanishingPoints) in homogeneous coordinates.\n// NOTE: This function expects the quadrilateral as projected on the view-plane (i.e. z = focal length).\n//       The innermost cross-products give the normals to the planes of the view-frustum.\n//       Further cross-products give the directions of the lines along which upper-lower resp. left-right planes intersect,\n//       which are parallel to sides of the marker-square (these intersections always exist, assuming the focal length is finite).\n//       The outermost cross-product is the normal of the marker-square.\nmat3 GetPose(mat4x3 Quad)\n{\n    mat3 Pose;\n    Pose[0] = cross(cross(Quad[0], Quad[1]), cross(Quad[2], Quad[3]));\n    Pose[1] = cross(cross(Quad[0], Quad[3]), cross(Quad[2], Quad[1]));\n    Pose[2] = cross(Pose[0], Pose[1]);\n    Pose[0] = normalize(Pose[0]);\n    Pose[1] = normalize(Pose[1]);\n    Pose[2] = normalize(Pose[2]);\n    return Pose;\n}\n\nvec3 GetOffset(float Size, mat3 Pose, mat4x3 Quad) // from pyBlob's fork (comments jt)\n{\n    // Project \"completed\" points along normal of marker plane.\n    float b = dot(Quad[1], Pose[2]);\n    float c = dot(Quad[2], Pose[2]);\n    float d = dot(Quad[3], Pose[2]);\n    \n    // Positions of markers on marker plane using C as origin.\n    vec3 B = Quad[1] * (c / b);\n    vec3 C = Quad[2];// * (c / c);\n    vec3 D = Quad[3] * (c / d);\n    \n    // Determine scale from length of diagonal and known size of original marker distances:\n    // NOTE: factor sqrt(2) is relation of diagonal of square to side length.\n    float Scale = distance(C, D) / sqrt(2.0);\n    // Get vector from camera to center of the quad, fix scale because we supplied arbitrary z coordinate 1 for quad vectors.\n    vec3 O = (B + D) / 2.0 * Size / Scale;\n    //if (dot(O, Pose[2]) < 0.) // BAD: need to correct for mirrored pose\n    //    O = -O;\n\n    return O;\n}\n\n// This variant uses more instructions than pyBlob's but is more symmetric.\n// It uses all four points of the quad and area instead of diagonal to determine scale\n// (and also uses quad center instead of a vertex as origin of quad coordinate system).\n// Perhaps this could provide additional stability in noisy environment?\n// Symmetric offset estimation, simplified.\n// NOTE: This function expects the quadrilateral as projected on the view-plane (i.e. z = focal length).\nvec3 GetOffsetSymmetric(float Size, mat3 Pose, mat4x3 Quad) // based on pyBlob's fork but changed to be more symmetric\n{\n    // Transform quad from projection-plane to a plane parallel to the marker?\n    vec3 A = Quad[0] / dot(Quad[0], Pose[2]);\n    vec3 B = Quad[1] / dot(Quad[1], Pose[2]);\n    vec3 C = Quad[2] / dot(Quad[2], Pose[2]);\n    vec3 D = Quad[3] / dot(Quad[3], Pose[2]);\n    \n    // Determine scale from area of quad:\n    float Scale = sqrt(length(cross(A - C, B - D))) / 2.0;\n    // Get vector from camera to center of the quad, fix scale.\n    vec3 O = (A + B + C + D) / 4.0 * Size / Scale;\n\n    //if (dot(O, Pose[2]) < 0.) // BAD: need to correct for mirrored pose\n    //    O = -O;\n\n    return O;\n}\n/*\n// Symmetric offset estimation, original.\nvec3 GetOffsetSymmetric(float Size, mat3 Pose, mat4x3 Quad) // based on pyBlob's fork but changed to be more symmetric\n{\n    vec3 M = (Quad[0] + Quad[1] + Quad[2] + Quad[3]) / 4.0;\n\n    // Project \"completed\" points along normal of marker plane.\n    float a = dot(Quad[0], Pose[2]);\n    float b = dot(Quad[1], Pose[2]);\n    float c = dot(Quad[2], Pose[2]);\n    float d = dot(Quad[3], Pose[2]);\n    float m = dot(M, Pose[2]);\n    \n    // Positions of markers on marker plane using center of marker as origin.\n    vec3 A = Quad[0] * (m / a);\n    vec3 B = Quad[1] * (m / b);\n    vec3 C = Quad[2] * (m / c);\n    vec3 D = Quad[3] * (m / d);\n    \n    // Determine scale from area of quad and known size of original marker distances:\n    float Scale = sqrt(length(cross(A - C, B - D))) / 2.0;\n    // Get vector from camera to center of the quad, fix scale because we supplied arbitrary z coordinate 1 for quad vectors.\n    vec3 O = (A + B + C + D) / 4.0 * Size / Scale;\n\n    //if (dot(O, Pose[2]) < 0.) // BAD: need to correct for mirrored pose\n    //    O = -O;\n\n    return O;\n}\n*/\n\n// NOTE: The focal length estimation given a rectangular quadrilateral fails,\n//       since in this case it is not possible to distinguish\n//       how much the size of the projected square\n//       is caused by the distance respectively the focal length.\n//       When the quadrilateral is rectangular then changing focal length\n//       becomes indistinguishable from changing distance (z-offset),\n//       so focal length estimation will inevitably fail in this case.\n// Implementation of \"Rectification with Visual Sphere perspective: an algebraic alternative for P4P pose estimation\" by J. M. Fober\n// https://arxiv.org/ftp/arxiv/papers/2004/2004.08933.pdf\n// Focal length from visible quad in perspective\nfloat GetFocalLength(mat4x2 quad) // WARNING: unstable when quad axis-aligned!\n{\n    vec3 X = cross(cross(vec3(quad[0], 1.0), vec3(quad[1], 1.0)), cross(vec3(quad[2], 1.0), vec3(quad[3], 1.0)));\n    vec3 Y = cross(cross(vec3(quad[0], 1.0), vec3(quad[3], 1.0)), cross(vec3(quad[2], 1.0), vec3(quad[1], 1.0)));\n\n    if(X.z == 0.0 || Y.z == 0.0)\n        return 0.0;\n    \n    return sqrt(abs(dot(vec2(X), vec2(Y)) / (X.z * Y.z)));\n}\n\nfloat DrawLine(vec2 a, vec2 b, vec2 p)\n{\n    vec2 ba = b - a;\n    vec2 pa = p - a;\n    float h = clamp(dot(pa,ba) / dot(ba,ba), 0.0, 1.0);\n    return length(pa - h * ba);\n}\n\nfloat DrawLineExtended(vec2 a, vec2 b, vec2 p)\n{\n    vec2 ba = b - a;\n    vec2 pa = p - a;\n    float h = dot(pa,ba) / dot(ba,ba);\n    return length(pa - h * ba);\n}\n\nfloat DrawQuad(vec2 A, vec2 B, vec2 C, vec2 D, vec2 p)\n{\n    return min(min(DrawLine(A, B, p), DrawLine(B, C, p)), min(DrawLine(C, D, p), DrawLine(D, A, p)));\n}\n\nfloat DrawQuadExtended(vec2 A, vec2 B, vec2 C, vec2 D, vec2 p)\n{\n    return min(min(DrawLineExtended(A, B, p), DrawLineExtended(B, C, p)), min(DrawLineExtended(C, D, p), DrawLineExtended(D, A, p)));\n}\n\nfloat DrawX(vec2 A, vec2 B, vec2 C, vec2 D, vec2 p)\n{\n    return min(DrawLine(A, C, p), DrawLine(B, D, p));\n}\n\nfloat SpotX(float Size, vec2 A, vec2 p) // from pyBlob's fork\n{\n    vec2 a = vec2( Size, Size);\n    vec2 b = vec2(-Size, Size);\n    return DrawX(A-a, A-b, A+a, A+b, p);\n}\n\nfloat DrawVanishingPoints(float focal_length, mat3 Pose, vec2 p)\n{\n    float o = 1.0;\n\n    {\n        // from pyBlob's fork (assuming focal length 1)\n        //vec2 P0 = Pose[0].xy / Pose[0].z;\n        //vec2 P1 = Pose[1].xy / Pose[1].z;\n        //vec2 P2 = Pose[2].xy / Pose[2].z;\n        // using original projection matrix\n        //vec2 P0 = Project(Pose[0]);\n        //vec2 P1 = Project(Pose[1]);\n        //vec2 P2 = Project(Pose[2]);\n        // using estimated focal length\n        vec2 P0 = Project(ProjMat(focal_length), Pose[0]);\n        vec2 P1 = Project(ProjMat(focal_length), Pose[1]);\n        vec2 P2 = Project(ProjMat(focal_length), Pose[2]);\n        o = min(o, SpotX(0.02, P0, p));\n        o = min(o, SpotX(0.02, P1, p));\n        o = min(o, SpotX(0.02, P2, p));\n    }\n    \n    return o;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n\tvec2 p = (2.0 * fragCoord - iResolution.xy) / iResolution.y;\n\n    float o = 1.0;\n    \n    float Size = 0.5;\n    mat4x2 Source = SimulateQuad(Size); // for real use this would be extracted from a fotographed marker\n    \n    o = min(o, DrawQuad(Source[0], Source[1], Source[2], Source[3], p)); // draw original marker\n\n    float focal_length = GetFocalLength(Source); // NOTE: estimation of focal length fails if quad rectangular\n    // complete projected positions to positions on projection plane (assuming some constants to be 1 resp. 0 for simplicity).\n    mat4x3 Quad =\n        mat4x3\n        (\n            vec3(Source[0], focal_length),\n            vec3(Source[1], focal_length),\n            vec3(Source[2], focal_length),\n            vec3(Source[3], focal_length)\n        );\n\n    // Extract the rotation as described in the article \"Rectification with Visual Sphere perspective: an algebraic alternative for P4P pose estimation\"\n    mat3 Pose = GetPose(Quad);\n    vec3 Offset = GetOffsetSymmetric(Size, Pose, Quad);\n\n    o = min(o, DrawVanishingPoints(focal_length, Pose, p));\n\n    mat4x2 verify = VerifyQuad(Size, Pose, Offset); // Confirm estimated rotation is correct: project known 3d marker positions back to plane\n\n    o = min(o, DrawX(verify[0], verify[1], verify[2], verify[3], p)); // draw reconstructed marker (should match original)\n\n\tvec3 col = vec3(0.0);\n    //col = max(col, mix(vec3(0.0), vec3(1.0), smoothstep(0.99, 1.0, 1.0 - o)));\n    col = max(col, mix(vec3(1.0), vec3(0.0), smoothstep(0.00, 0.01, o)));\n    \n    // debug vanishing points\n    //col.g += mix(0.5, 0.0, smoothstep(0.00, 0.01, DrawQuadExtended(Source[0], Source[1], Source[2], Source[3], p)));\n\n\tfragColor = vec4(col,1.0);\n}\n","name":"Image","description":"","type":"image"}]}
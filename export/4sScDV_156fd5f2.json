{"ver":"0.1","info":{"id":"4sScDV","date":"1493782642","viewed":273,"name":"My first cube with phong shading","username":"loolo78","description":"https://www.shadertoy.com/view/Xtd3z7 Thanks to this tutorial","likes":5,"published":1,"flags":0,"usePreview":0,"tags":["sdf"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n    Tutorial used: https://www.shadertoy.com/view/lt33z7\n    I rewrote everything for practice.\n*/\n\n\nconst int MAX_MARCHING_STEPS = 255;\nconst float MIN_DIST         = 0.0;\nconst float MAX_DIST         = 100.0;\nconst float EPSILON          = 0.0001;\n\n/**\n * Signed distance function for a sphere centered at the origin with radius 1.0;\n */\nfloat boxSDF( vec3 p, vec3 b )\n{\n    return length(max(abs(p)-b,0.0));\n}\n\n/**\n * Signed distance function describing the scene.\n * \n * Absolute value of the return value indicates the distance to the surface.\n * Sign indicates whether the point is inside or outside the surface,\n * negative indicating inside.\n */\nfloat sceneSDF(vec3 p)\n{\n    return boxSDF(p, vec3(0.5));\n}\n\nvec3 estimateNormal(vec3 p)\n{\n    return normalize(vec3(\n        sceneSDF(vec3(p.x + EPSILON, p.y, p.z)) - sceneSDF(vec3(p.x - EPSILON, p.y, p.z)),\n        sceneSDF(vec3(p.x, p.y + EPSILON, p.z)) - sceneSDF(vec3(p.x, p.y - EPSILON, p.z)),\n        sceneSDF(vec3(p.x, p.y, p.z  + EPSILON)) - sceneSDF(vec3(p.x, p.y, p.z - EPSILON))\n    ));\n}\n\n/**\n * Lighting contribution of a single point light source via Phong illumination.\n * \n * The vec3 returned is the RGB color of the light's contribution.\n *\n * k_a: Ambient color\n * k_d: Diffuse color\n * k_s: Specular color\n * alpha: Shininess coefficient\n * p: position of point being lit\n * eye: the position of the camera\n * lightPos: the position of the light\n * lightIntensity: color/intensity of the light\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phoneContribForLight(vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye,\n                            vec3 lightPos, vec3 lightIntensity)\n{ \n    vec3 N = estimateNormal(p); // Estimate normal of surface\n    vec3 L = normalize(lightPos - p); // Point from point on surface to light\n    vec3 V = normalize(eye - p); // Viewing vector, used to diffuse reflected light\n    vec3 R = normalize(reflect(-L, N)); // Reflect light to the normal\n\n    float dotLN = dot(L,N); // cosine angle between light direction and normal direction\n    float dotRV = dot(R,V); // cosine angle between reflection direction and viewing direction\n    \n    // Light is coming from behind the normal of the face, pitch black\n    if (dotLN < 0.)\n    {\n        return vec3(0.0);\n    }\n    // Reflected light points away from the camera, so there are no direct light. Only ambient light and diffuse color\n    if (dotRV < 0.)\n    {\n        // This value maxes when dotLN = 1, which is when L(light) and N(normal) are equal. 100% of the light is reflected back\n        return lightIntensity * (k_d * dotLN);\n    }\n    return lightIntensity * (k_d * dotLN + k_s * pow(dotRV, alpha));\n    }\n\n/**\n * Lighting via Phong illumination.\n * \n * The vec3 returned is the RGB color of that point after lighting is applied.\n * k_a: Ambient color\n * k_d: Diffuse color\n * k_s: Specular color\n * alpha: Shininess coefficient\n * p: position of point being lit\n * eye: the position of the camera\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongIllumination(vec3 k_a, vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye) {\n    const vec3 globalAmbentLight = 0.9 * vec3(1.);\n    vec3 color = globalAmbentLight * k_a; // Multiply brightness by color to get ambient color\n\n    // Light 1\n    vec3 light1Pos = vec3(0.,1.,3.);\n    vec3 light1Insentity = vec3(0, 67.1/100., 43.5/100.);\n    color += phoneContribForLight(k_d, k_s, alpha, p, eye, light1Pos, light1Insentity);\n\n\n    // Light 2\n    vec3 light2Pos = vec3(-1.,-1.,1.);\n    vec3 light2Insentity = vec3(100./100., 59.2/100., 0);\n    color += phoneContribForLight(k_d, k_s, alpha, p, eye, light2Pos, light2Insentity);\n\n    // Light 3\n    vec3 light3Pos = vec3(-0.5,2,-3.);\n    vec3 light3Insentity = vec3(4.7/100., 35.3/100., 65.1/100.);\n    color += phoneContribForLight(k_d, k_s, alpha, p, eye, light3Pos, light3Insentity);\n\n    return color;\n}\n\n/**\n * Return the shortest distance from the eyepoint to the scene surface along\n * the marching direction. If no part of the surface is found between start and end,\n * return end.\n * \n * eye: the eye point, acting as the origin of the ray\n * marchingDirection: the normalized direction to march in\n * start: the starting distance away from the eye\n * end: the max distance away from the ey to march before giving up\n */\nfloat shortestDistanceToSurface(vec3 eye, vec3 marchingDirection, float start, float end)\n{\n    // Start depth\n    float depth = start;\n    // Keep looking for where the marching ray hits a surface\n    for (int i = 0; i < MAX_MARCHING_STEPS; ++i)\n    {\n        // Get the distance from marching ray point to surface of box\n        float dist = sceneSDF(eye + marchingDirection * depth);\n        // If we've hit near the surface, return this distance\n        if (dist < EPSILON)\n        {\n            return depth;\n        }\n        // Didn't find anything, let's go to where we found something\n        depth += dist;\n        // We're at the end, stop\n        if (depth > end)\n        {\n            return end;\n        }\n    }\n    // Ran out of steps before we hit the end, just return end\n    return end;\n}\n\n/**\n    fov:         Field of View of camera\n    screen_size: Screen size\n    fragCoord:   Screen coord of pixel\n    return:      Direction of rendering ray of the projection camera\n */\nvec3 rayDirection(float fov, vec2 screen_size, vec2 fragCoord)\n{\n\tvec2 xy = fragCoord - screen_size / 2.0;\n    float z = (screen_size.y / 2.) / tan(radians(fov) / 2.);\n    return normalize(vec3(xy,-z));\n}\n\n/**\n * Return a transform matrix that will transform a ray from view space\n * to world coordinates, given the eye point, the camera target, and an up vector.\n *\n * This assumes that the center of the camera is aligned with the negative z axis in\n * view space when calculating the ray marching direction. See rayDirection.\n */\nmat3 lookAtMatrix(vec3 eye, vec3 center, vec3 up) \n{\n    // Based on gluLookAt man page\n    // Forward/Look at vector\n    vec3 f = normalize(center - eye);\n    // Right vector\n    vec3 v = normalize(cross(f, up));\n    // Camera local up Vector\n    vec3 u = cross(v, f);\n    return mat3(\n        vec3(v),\n        vec3(u),\n        vec3(-f)\n    );\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec3 camera_space_dir = rayDirection(60., iResolution.xy, gl_FragCoord.xy);\n    vec3 eye = \n        vec3(\n            cos(iTime*2.) * 1.,\n            cos(iTime) * 1.,\n            (sin(iTime)+2.) * 1.\n            );\n\n   vec3 world_space_dir = lookAtMatrix(eye, vec3(0.), vec3(0,1,0)) * camera_space_dir;\n    // Find shortest distance surface\n    float dist = shortestDistanceToSurface(\n        eye,\n        world_space_dir, \n        MIN_DIST, \n        MAX_DIST);\n    if (dist > MAX_DIST - EPSILON)\n    {\n        fragColor = vec4(0.07);\n        return;\n    }\n\n    // We've hit a surface\n    // Phong shading time!!\n    // Surface point\n    vec3 p = eye + dist * world_space_dir;\n\n    vec3 K_ambientColor = vec3(0.2, 0.2, 0.2);\n    vec3 K_diffuseColor = vec3(0.7, 0.2, 0.2);\n    vec3 K_specularColor = vec3(1.0, 1.0, 1.0);\n    float shineness = 20.0;\n\n    vec3 color = phongIllumination(K_ambientColor, K_diffuseColor, K_specularColor, shineness, p, eye);\n    fragColor = vec4(color,1.);\n}","name":"Image","description":"","type":"image"}]}
{"ver":"0.1","info":{"id":"43cXzB","date":"1721202032","viewed":78,"name":"CloudLandScape","username":"dmc203","description":"使用鼠标可以拖动视角\nuse mouse to look around\ndescription in imagechannel\n7.19 优化了阴影，更其柔和\n7.20更新色调映射曲线，将色调映射曲线更新为ACES，色调映射在BufferC中。修复了光照信息采样与Raymarching主循环的采样结果不同的Bug","likes":3,"published":1,"flags":32,"usePreview":0,"tags":["raymarching","cloud","volumtric"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//For the theoretical aspects of volume rendering, refer to Chapter 4 of the following dissertation:\n//体积渲染理论部分的知识，可以参考以下文章的第四章内容：\n//Efficient Monte Carlo Methods for Light Transport in Scattering Media\n//https://cs.dartmouth.edu/~wjarosz/publications/dissertation/\n\n//For cloud rendering, refer to:\n//云渲染部分可以参考以下文章：\n//Physically Based Sky, Atmosphere & Cloud Rendering - Frostbite\n//https://www.ea.com/frostbite/news/physically-based-sky-atmosphere-and-cloud-rendering\n\n//For TAA (Temporal Anti-Aliasing), the reference is:\n//TAA（时间抗锯齿）：\n//https://research.nvidia.com/index.php/publication/2017-07_spatiotemporal-variance-guided-filtering-real-time-reconstruction-path-traced\n\n//It can run stably at 144 fps on 1660ti at a resolution of 1760 x 990.\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    vec4 col = textureLod(iChannel1,uv,0.0);\n    fragColor = vec4(col);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[{"id":"Xsf3zn","filepath":"/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"/media/ap/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sf3Rr","filepath":"/media/a/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","previewfilepath":"/media/ap/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Speed of cloud movement\n// 云层移动速度\n#define CLOUDSPEED1 12.0\n//FBMDEEP\n#define FBM_DEEP 2\n// Dynamic light direction based on time\n// 基于时间的动态光照方向\n#define LIGHT_DIR vec3(sin(theta)*sin(alpha+iTime*0.5),cos(theta),sin(theta)*cos(alpha+iTime*0.5))\n\n// Static light direction\n// 静态光照方向\n//#define LIGHT_DIR vec3(sin(theta)*sin(alpha),cos(theta),sin(theta)*cos(alpha))\n\n// Ambient color\n// 环境光颜色\n#define AMBIDENT_COLOR vec3(0.05,0.12,0.25)\n#define FOG_COLOR vec3(0.25,0.61,1.420)\n// Intensity of ambient light\n// 环境光强度\n#define AMBIENT_INDENSITY 1.5\n// Scattering and absorption coefficients for atmospheric scattering\n// 大气散射的散射和吸收系数\nvec3 scattering = 1.34*vec3(1.0);\nvec3 absorption = 0.0 * vec3(0.65,0.5,0.0);\n\n// Extinction coefficient is the sum of scattering and absorption\n// 消光系数是散射和吸收的总和\n#define extinction  (absorption + scattering)\n\n// Sky color\n// 天空颜色\nconst vec3 skycolor = vec3(0.2,0.6,1.4);\n\n// Sun color\n// 太阳颜色\nconst vec3 sun = vec3(1.6,0.8,0.6)*6.0;\n\n// Inner and outer radius of the atmosphere\n// 大气层的内外半径\nconst float atm_in = 6371300.0;\nconst float atm_out = 6372200.0;\n\n//光照方向\n//sunlightDir\n//angle with y\nconst float theta = 1.0;\n//angle with z\nconst float alpha = 0.0;\nfloat hash( float n )\n{\n    return fract(sin(n)*43758.5453);\n}\n\n\nmat3 setCamera( in vec3 ro, in vec3 ta, float cr )\n{\n\tvec3 cw = normalize(ta-ro);\n\tvec3 cp = vec3(sin(cr), cos(cr),0.0);\n\tvec3 cu = normalize( cross(cw,cp) );\n\tvec3 cv = normalize( cross(cu,cw) );\n    return mat3( cu, cv, cw );\n}\n\n\nconst mat3 m = mat3( 0.00,  0.80,  0.60,\n              -0.80,  0.36, -0.48,\n              -0.60, -0.48,  0.64 );\nconst mat3 m1  = mat3( 0.00,  0.80,  0.60,\n                      -0.80,  0.36, -0.48,\n                      -0.60, -0.48,  0.64 );\n\n\nfloat noise_t( in vec3 x )\n{\n    vec3 p = floor(x);\n    vec3 f = fract(x);\n    \n\tf = f*f*(3.0-2.0*f);\n\tvec2 uv = (p.xy+vec2(37.0,239.0)*p.z) + f.xy;\n    vec2 rg = textureLod(iChannel0,(uv+0.5)/256.0,0.0).yx;\n\treturn mix( rg.x, rg.y, f.z )*2.0-1.0;  \n}\nfloat fbmcloud_t( in vec3 x ,int depth)\n{\n    float f = 2.5;\n    float s = 0.45;\n    float a = 0.35;\n    float b = 0.35;\n    vec3  d = vec3(0.0);\n    mat3  m = mat3(1.0,0.0,0.0,\n                   0.0,1.0,0.0,\n                   0.0,0.0,1.0);\n    for( int i=0; i<depth; i++ )\n    {\n        float depthf = float(depth);\n        float n = noise_t(x);\n        a += b*n;          \t\t\n        b *= s;\n        x = f*m1*x+vec3(iTime*float(depth));\n    }\n\treturn abs(a);\n}\nfloat cloudsMap( in vec3 pos ,in vec3 origin,out float height)\n{\n    float distance_pos_origin = length(pos-origin);\n    float atm_thickness = atm_out-atm_in;\n    height =(distance_pos_origin - atm_in)/atm_thickness;\n    pos*=6.0;\n    pos+=6345.0;\n    int depth = int(FBM_DEEP);\n    pos.x+=iTime*CLOUDSPEED1;\n    float cloud = clamp((textureLod(iChannel1, -0.000009*pos.zx, 0.0).x-0.18)*2.0, 0.0, 0.7);\n    pos.z+=iTime*CLOUDSPEED1*8.2;\n    float cloud2 = cloud * max(0.0, textureLod(iChannel1, 0.000015*pos.zx, 0.0).x-0.38)*1.58;\n    pos.x+=iTime*CLOUDSPEED1*2.3;\n    pos.y+=iTime*CLOUDSPEED1*2.8;\n    cloud2 *= smoothstep(0.0,0.3,height)*smoothstep(1.0,0.3,height);\n    if(cloud2<=0.0)\n    return 0.0;\n    float den= max(0.0,cloud2-0.22*clamp(fbmcloud_t(pos*0.001,1),0.0,1.0));\n    if(den<=0.0)\n    return 0.0;\n    pos.x+=iTime*CLOUDSPEED1*3.8;\n    den = max(0.0,den-0.08*clamp(fbmcloud_t(pos*0.0046,depth),0.0,1.0));\n    return den*0.262;\n}\nvoid lightSampler(in vec3 pos,in vec3 origin,float density,float cos_angle,out float intensity,float height,float den)\n{\n    int samplerCount = 2;\n    float maxt =800.0;\n    float dt = maxt/float(samplerCount);\n    float t = dt*hash(dot(pos, vec3(1.151, 1.317, 1.173)) + iTime);\n    float lightden=den;\n    float maxden=8.6;\n    for(int i=1 ; i<=samplerCount;i++)\n    {\n        if(lightden>maxden)\n        {\n            break;\n        }\n        pos += t*LIGHT_DIR;\n        float den = cloudsMap(pos,origin,height);\n        lightden += den*dt;\n        t += dt*(exp(float(samplerCount)*0.02));\n    }\n    //float beers_law = exp(-lightden*(cos_angle*cos_angle*0.5+0.5));\n    //float beers_law = exp(-lightden*(cos_angle+1.0)*(cos_angle+1.0)*1.6);\n    float beers_law = exp(-lightden*(max(0.0,cos_angle*cos_angle*cos_angle))*0.6)*exp(-lightden*0.4);\n    //float beers_law = exp(-lightden);\n    float inG = 0.3;\n    float HenyeyGreenstein =  ((1.0 - inG * inG) / pow((1.0 + inG * inG - 2.0 * inG * cos_angle), 3.0/2.0))\n    / 4.0 * 3.1415; \n    intensity = beers_law * HenyeyGreenstein;\n}\n\n// Ray-sphere intersection detection\n// 射线-球体相交检测\nfloat intersectRaySphere(vec3 rayOrigin, vec3 rayDirection, vec3 sphereCenter, float sphereRadius) {\n    vec3 L = rayOrigin - sphereCenter;\n    \n    float b = 2.0 * dot(rayDirection, L);\n    float c = dot(L, L) - sphereRadius * sphereRadius;\n    float discriminant = b * b - 4.0 * c;\n    if (discriminant < 0.0) {\n        return 0.0;  \n    }\n    float sqrtDiscriminant = sqrt(discriminant);\n    float t1 = (-b - sqrtDiscriminant) / 2.0;\n    float t2 = (-b + sqrtDiscriminant) / 2.0;\n    float t = t1 > 0.0 ? t1 : t2;\n    if (t < 0.0) {\n        return 0.0;  \n    }\n    return t;\n}\n// Sampling function for cone tracing(not be used)\n// 用于锥体追踪的采样函数(没有使用)\nvec3 conesampler(vec3 rd, float angle, float seed)\n{\n    angle = radians(angle);\n    \n    float theta = acos(rd.y);\n    float alpha = atan(rd.x, rd.z);\n    //angle with y axis\n    theta += angle * (hash(seed + 0.1371) - 0.5);\n    //angle with z axis\n    alpha += angle * (hash(seed + 0.3137) - 0.5);\n    return vec3(sin(alpha) * sin(theta),\n                cos(theta),\n                cos(alpha) * sin(theta));\n}\n// Ray marching function for volume clouds\n// 用于体积云的射线步进函数\nvoid raymarchVolumeCloud(in vec3 ro , in vec3 rd,out vec3 color)\n{\n// The Y value of the line of sight intersecting the horizon\n// 视线和地平线相交的视线的y值\nfloat max_y = -(1.0-(6371000.0)/(6371000.0+ro.y)*(6371000.0)/(6371000.0+ro.y));\nif(rd.y >max_y)\n{\n    vec3 rayOrigin = ro;\n    vec3 origin = vec3(ro.x,-6371000.0,ro.z);\n    float atm_thickness = atm_out-atm_in;\n    float atm_norheight = (atm_in+atm_out)*0.5;\n    float tmin = intersectRaySphere(rayOrigin,rd,origin,atm_in);\n    float tmax = intersectRaySphere(rayOrigin,rd,origin,atm_out);\n    int sample_count =32;\n    float t=tmin;\n    float dt = (tmax-tmin)/float(sample_count);\n    vec3 pos;\n    float den;\n    float sample_count_zero=0.0;\n    float thinkness = 0.0;\n    float total_thinkness=0.0;\n    vec3 sunsamplerpos=vec3(0.0);\n    float T = 1.0;\n    float cos_angle = dot(LIGHT_DIR, rd);\n    vec3 scatteredLuminance = vec3(0.0,0.0,0.0);\n    vec3 transmittance = vec3(1.0);\n    pos = ro+t*rd;\n    t += hash(dot(pos, vec3(1.151, 2.317, 1.173)) + iTime)*dt;\n    pos = ro+t*rd;\n    float height;\n    vec4 sum = vec4(0.0);\n    for ( int i = 0; i < sample_count; i++ )\n    {\n        den = cloudsMap(pos,origin,height);\n        if(den>0.0)\n        {\n            float intensity=0.0;\n            lightSampler(pos,origin,den,cos_angle,intensity,height,den);\n            vec3 ambient = den*AMBIENT_INDENSITY*AMBIDENT_COLOR*((1.0+0.4*height));\n            //form: https://www.shadertoy.com/view/MdlyDs#                \n            vec3 sampleExtinction = max(vec3(0.00000001),den * extinction);\n            //Sintegration;\n            vec3 energy = (intensity*sun*scattering*den+ambient);\n            //vec3 energy = ambient;\n            vec3 energyint = (energy - energy* exp(-sampleExtinction*dt)) / sampleExtinction;\n            scatteredLuminance += transmittance * energyint;\n            // Evaluate transmittance to view independentely\n            transmittance *= exp(-sampleExtinction * dt);\n            if(transmittance.b==0.0)\n            break;\n            if(transmittance.b<=0.01)\n            {\n                transmittance=vec3(0.00);\n            }\n        }\n        t += dt;\n        pos = ro + t * rd;\n        if(t > tmax) break;\n    }\n    //scatteredLuminance = mix(scatteredLuminance,vec3(0.1,0.2,0.32)*2.0,0.2);\n    color=transmittance*color + scatteredLuminance;\n    color = mix(FOG_COLOR,color,exp(-0.000015*t));\n    }\nelse color=FOG_COLOR;\n}\n// Camera rendering function\n// 相机渲染函数\nvec4 cameraRender(in vec2 uv)\n{\n    vec2 o = vec2(-0.5, -0.5);\n    vec2 dirpos = (2.0 * (uv) - iResolution.xy) / iResolution.y;\n    float time = iTime;\n    float height = 0.0;\n    vec3 ro = vec3(0.0, height, 0.0);\n    // Convert mouse position to rotation angles\n    // 将鼠标位置转换为旋转角度\n    vec2 m = iMouse.xy / iResolution.xy;\n    float yaw = (m.x - 0.5) * 2.0 * 3.14;\n    float pitch = (m.y - 0.5) * 3.14 + 1.4; \n    vec3 ta;\n    ta.x = cos(pitch) * sin(yaw);\n    ta.y = sin(pitch);\n    ta.z = cos(pitch) * cos(yaw);\n    mat3 ca = setCamera(ro, ta, 0.0);\n    vec3 raydir = ca * normalize(vec3(dirpos, 1.0));\n    vec3 col;\n    col = skycolor;\n    vec3 sun = vec3(1.4,1.0,0.9)*clamp((abs(1.0/sin(dot(LIGHT_DIR,raydir)-1.0))-1.0)*0.06,0.0,12.0);\n    //vec3 sun = vec3(1.4,1.0,0.9)*pow(max(0.0,dot(LIGHT_DIR,raydir)),32.0);\n    col += sun;\n    // Cloud Marching\n    // 云层步进\n    raymarchVolumeCloud(ro,raydir,col);\n    \n    return vec4(col,1);\n}\n\n// Main rendering function\n// 主渲染函数\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = cameraRender(fragCoord);\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// 定义8个方向的偏移量\nivec2 offsets[8] = ivec2[8](\n    ivec2(-1, -1), ivec2(-1, 1),\n    ivec2(1, -1), ivec2(1, 1),\n    ivec2(1, 0), ivec2(0, -1),\n    ivec2(0, 1), ivec2(-1, 0)\n);\n\n// 将RGB颜色转换为YCoCg颜色空间\nvec3 convertRGBToYCoCg(vec3 inputRGB) {\n    float Y = dot(inputRGB, vec3(1, 2, 1)) * 0.25;\n    float Co = dot(inputRGB, vec3(2, 0, -2)) * 0.25 + (0.5 * 256.0 / 255.0);\n    float Cg = dot(inputRGB, vec3(-1, 2, -1)) * 0.25 + (0.5 * 256.0 / 255.0);\n    return vec3(Y, Co, Cg);\n}\n\n// 将YCoCg颜色转换回RGB颜色空间\nvec3 convertYCoCgToRGB(vec3 inputYCoCg) {\n    float Y = inputYCoCg.x;\n    float Co = inputYCoCg.y - (0.5 * 256.0 / 255.0);\n    float Cg = inputYCoCg.z - (0.5 * 256.0 / 255.0);\n    float R = Y + Co - Cg;\n    float G = Y + Cg;\n    float B = Y - Co - Cg;\n    return vec3(R, G, B);\n}\n\nvoid mainImage(out vec4 outputColor, in vec2 pixelCoord) {\n    vec2 normalizedCoord = pixelCoord / iResolution.xy;\n    vec3 currentColor = convertRGBToYCoCg(textureLod(iChannel0, normalizedCoord, 0.0).xyz);\n    vec3 previousColor = convertRGBToYCoCg(textureLod(iChannel1, normalizedCoord, 0.0).xyz);\n    \n    vec3 avgColor = currentColor;\n    vec3 varColor = currentColor * currentColor;\n    \n    for (int i = 0; i < 8; i++) {\n        vec3 neighborColor = convertRGBToYCoCg(texelFetch(iChannel0, ivec2(pixelCoord) + offsets[i], 0).xyz);\n        avgColor += neighborColor;\n        varColor += neighborColor * neighborColor;\n    }\n    avgColor /= 9.0;\n    varColor /= 9.0;\n    float colorBoxSigma = 0.70;\n    //计算方差\n    vec3 colorStdDev = sqrt(max(vec3(0.0), varColor - avgColor * avgColor));\n    vec3 colorMin = avgColor - colorBoxSigma * colorStdDev;\n    vec3 colorMax = avgColor + colorBoxSigma * colorStdDev;\n    \n    previousColor = clamp(previousColor, colorMin, colorMax);\n    outputColor = vec4(convertYCoCgToRGB(mix(currentColor, previousColor, 0.950)), 1.0);\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"vec3 ACESFilm(vec3 x)\n{\nfloat a = 2.41f;\nfloat b = 0.03f;\nfloat c = 2.43f;\nfloat d = 0.59f;\nfloat e = 0.24f;\nreturn (x*(a*x+b))/(x*(c*x+d)+e);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv =  fragCoord/iResolution.xy;\n    \n    \n    vec3 col = ACESFilm(textureLod(iChannel0,uv,0.0).xyz);\n    col = sqrt(col);\n    //col=(col * (2.51 * col + 0.03)) / (col * (2.43 * col + 0.59) + 0.14);\n    //col*=0.9;\n    //col = smoothstep(0.1,0.0,col);\n    fragColor = vec4(1.0*col,1.0);\n}\n","name":"Buffer C","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"clKGWD","date":"1684011586","viewed":104,"name":"Dumb Chat GPT SDF and Sierpinski","username":"aatom","description":"Unedited chatgpt output (other than splittng the sound functions into the sound asset)","likes":1,"published":1,"flags":8,"usePreview":0,"tags":["dumb","ai","chatgpt"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//Was goofing around with ChatGPT and asked it to make this.\n// not great...\n\n//Generate the `mainSound` and `mainImage` functions for a GLSL shader that\n// showcases the integration of visual effects and audio synthesis.\n// The `mainSound` function should have the signature\n//   `vec2 mainSound(int samp, float time)`\n// and return a stereo signal.\n// The `mainImage` function should have the signature\n//   `void mainImage(out vec4 fragColor, in vec2 fragCoord)`\n// and combine the visual effect with the audio signal.\n// The audio synthesis should be based on a filtered Sierpinski triangle waveform\n// modulated to resemble music. The visual effect can be a repeated 3D SDF scene\n// with time-dependent variations. Please ensure the code is concise and modular\n// for easy integration into a larger GLSL shader project.\n\n// Unedited except or this explanation.\n\nfloat sceneSDF(vec3 p)\n{\n    // Define your SDF scene here\n    float sphere = length(p) - 0.5;\n    float box = max(abs(p.x) - 0.3, max(abs(p.y) - 0.3, abs(p.z) - 0.3));\n    \n    return min(sphere, box);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    vec2 uv = (2.0 * fragCoord - iResolution.xy) / iResolution.y;\n    vec2 p = uv - 0.5;\n    \n    // Background gradient\n    vec3 background = vec3(0.1, 0.1, 0.2) * (1.0 - uv.y) + vec3(0.2, 0.0, 0.0) * uv.y;\n    \n    // Time-dependent effect\n    float time = iTime * 0.5;\n    float effect = 0.2 * sin(time + p.x * 10.0) * sin(time + p.y * 10.0);\n    \n    // Repeat the scene\n    vec3 repeatedP = vec3(p, 0.0) + vec3(sin(time * 0.3), cos(time * 0.3), sin(time * 0.5));\n    float sdf = sceneSDF(repeatedP);\n    \n    // Add the effect to the scene\n    float distance = sdf + effect;\n    \n    // Final color based on distance\n    vec3 color = mix(vec3(0.8, 0.2, 0.1), vec3(0.2, 0.8, 0.1), smoothstep(-0.1, 0.1, distance));\n    \n    fragColor = vec4(background + color, 1.0);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"//#define BONUS\n\n/* ok the macro defines i also edited with two versions of audio\n  can you make a mainsound that plays beethoven's ninth symphony in the style of clockwork orange soundtrack\n*/\n\n/*\n  give it a more synthpad vibe with a filter\n*/\n\n#ifndef BONUS\n\nfloat sierpinskiTriangle(float x)\n{\n    float i = floor(x);\n    float f = fract(x);\n    \n    float a = 0.5;\n    \n    for (float j = 0.0; j < 10.0; j++)\n    {\n        if (mod(i, 3.0) > 0.5)\n            f = 1.0 - f;\n        \n        i = floor(i / 3.0);\n        \n        if (mod(i, 3.0) > 0.5)\n            f = 1.0 - f;\n        \n        i = floor(i / 3.0);\n        \n        if (mod(i, 3.0) > 0.5)\n            f = 1.0 - f;\n        \n        i = i / 3.0;\n    }\n    \n    return f - a;\n}\n\nvec2 mainSound(int samp, float time)\n{\n    float baseFreq = 440.0;\n    float freq = baseFreq * (1.0 + sin(time * 0.1));\n    \n    float waveform = sierpinskiTriangle(time * freq);\n    \n    // Low-pass filter\n    float cutoff = 4000.0;\n    float filteredWaveform = (1.0 - exp(-time * cutoff)) * waveform;\n    \n    float leftChannel = filteredWaveform;\n    float rightChannel = filteredWaveform * 0.8; // Adjust the balance of the stereo channels here\n    \n    return vec2(leftChannel, rightChannel);\n}\n\n#endif\n\n#ifdef BONUS\n\nvec2 mainSound(int samp, float time)\n{\n    float frequency = 440.0; // Base frequency (A4)\n    float noteDuration = 0.25; // Duration of each note (in seconds)\n    \n    // Define the melody by specifying the note indices (e.g., 0 for A4, 1 for B4, etc.)\n    int melody[] = int[](0, 4, 7, 0, 2, 5, 7, 4); // Example melody\n    \n    // Calculate the current note index based on the sample position and note duration\n    int noteIndex = samp / int(noteDuration * iSampleRate) % melody.length();\n    \n    // Calculate the frequency of the current note based on the note index and base frequency\n    float currentFrequency = frequency * pow(2.0, float(melody[noteIndex]) / 12.0);\n    \n    // Generate the waveform using a sine function\n    float waveform = sin(2.0 * 3.14159 * currentFrequency * time);\n    \n    // Apply a low-pass filter to the waveform\n    float cutoffFrequency = 1000.0; // Cutoff frequency of the filter\n    float resonance = 0.7; // Resonance of the filter\n    float filteredWaveform = 0.0;\n    \n    // Calculate the filter parameters\n    float omega = 2.0 * 3.14159 * cutoffFrequency / iSampleRate;\n    float alpha = sin(omega) / (2.0 * resonance);\n    \n    // Apply the filter using a simple one-pole low-pass filter algorithm\n    float prevFilteredWaveform = 0.0;\n    filteredWaveform = (1.0 - alpha) * waveform + alpha * prevFilteredWaveform;\n    prevFilteredWaveform = filteredWaveform;\n    \n    // Pan the sound left and right based on the note index\n    float pan = float(noteIndex % 2) * 2.0 - 1.0; // Alternates between -1 and 1\n    vec2 stereoSignal = vec2(filteredWaveform * pan, filteredWaveform * (1.0 - pan));\n    \n    return stereoSignal;\n}\n\n\n#endif","name":"Sound","description":"","type":"sound"}]}
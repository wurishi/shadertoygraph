{"ver":"0.1","info":{"id":"MX3XDf","date":"1719681002","viewed":395,"name":"Better GGX VNDF Sampler","username":"MartyMcFly","description":"Mouse X = roughness","likes":15,"published":1,"flags":0,"usePreview":0,"tags":["ggx"],"hasliked":0,"parentid":"M3tSW7","parentname":"GGX Testbed"},"renderpass":[{"inputs":[{"id":"XsX3zn","filepath":"/media/a/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","previewfilepath":"/media/ap/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","type":"cubemap","channel":1,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"XsBSR3","filepath":"/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","previewfilepath":"/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// The MIT License\n// Copyright © 2023 Pascal Gilcher\n// Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n#if 0\n\n    New Variant of bounded VNDF sampling that can be used with SmithG2/SmithG1 integration\n    \n    VNDF Sampling w/ GGX Microfacets has 2 benefits:\n\n        - fewer wasted rays\n        - BRDF*cosine/PDF simplifies to G2/G1\n        \n    There are 3 VNDF samplers:\n\n    1) Heitz \"Sampling the GGX Distribution of Visible Normals\"\n    \n    2) Dupuy \"Sampling Visible GGX Normals with Spherical Caps\"\n    \n        + less ALU than Heitz\n    \n    3) Eto & Tokuyoshi \"Bounded VNDF Sampling for Smith–GGX Reflections\"\n    \n        + faster convergence\n        - have to use full BRDF*cosine/PDF due to different PDF\n    \n    ----------------------------------------------------------------------------    \n    \n    I extracted the difference between the PDFs of method 3 vs the others\n    and applied it to the sampler. Converges to the same result.    \n    \n    With this method, you get the numerical stability and performance of 1 and 2\n    combined with the fast convergence of 3. \n    \n    ----------------------------------------------------------------------------  \n/*  \n    How it works:\n    \n       RDF*cosine/PDF resolve into G2/G1 _somehow_ in Heitz/Dupuy method,  we just need \n       to figure out what changed in the PDF from 2 to 3 and accomodate for that.\n       \n       Loking at listing 2 in their paper, the clue is in here:\n\n           ...\nA               return ndf / (2.0f * (k * i.z + t));\n           }\n           // Numerically stable form of the previous PDF for i.z < 0\nB          return ndf * ( t - i . z ) / (2.0 f * len2 ) ; // = Eq. 7 * || dm/do ||\n           ...\n\n       Hold up. If I read the comment for line B right, it's the same as A, just restructured?\n       Since k is 1.0 for i.z < 0, this branch is just for numerical stability. We COULD write it as:\n\n               pdf = ndf / (2.0f * (k * i.z + t))\n               \n       I then realized that Method 2 from Dupuy is identical to this method, except the scaling factor\n       k is ALWAYS 1. So...\n       \n       PDF of Dupuy:              ndf / (2.0f * (1.0 * i.z + t))\n       PDF of Eto/Tokuyoshi:      ndf / (2.0f * (k   * i.z + t)) \n       \n       So...\n       \n       let A = ndf / (2.0f * (1.0 * i.z + t)) \n           B = ndf / (2.0f * (k * i.z + t)) \n       \n            BRDF * cosine / PDF\n            \n       =    G2/G1       \n       =    A * [G2/G1 without A]\n       =    correction_term * B * [G2/G1 without A] \n       =    correction_term * B * A/A * [G2/G1 without A]\n       =    correction_term * B/A * [G2/G1]\n       \n       !\n       =    G2/G1\n                                                \n       =>   correction_term = A/B   \n       \n           ndf / (2.0f * (1.0 * i.z + t))    \n       =   ---------------------------------\n            ndf / (2.0f * (k * i.z + t)) \n            \n         \n                   k * i.z + t\n       =          -----------\n                     i.z + t        \n         \n       Which we need to multiply each sample with.    \n*/\n#endif\n\n//I've stolen parts of this framework here from LVutner\n\n#define DISABLE_CORRECTION_TERM 0 //disable my pdf ratio correction\n#define SAMPLES 4u\n\nfloat map(vec3 p)\n{\n    return distance(p, vec3(0,0,4)) - 1.0;\n}\n\nvec3 get_normal(vec3 p)\n{\n    vec2 e = vec2(1.0,-1.0)*0.5773*0.0005;\n    return normalize(e.xyy*map(p + e.xyy) + \n\t\t\t\t\t e.yyx*map(p + e.yyx) + \n\t\t\t\t\t e.yxy*map(p + e.yxy) + \n\t\t\t\t\t e.xxx*map(p + e.xxx));\n}\n\nstruct Ray\n{\n    vec3 origin;\n    vec3 dir;\n    float t;\n};\n\nRay camera_ray(vec2 uv, float fov)\n{\n    uv = uv * 2.0 - 1.0;\n    uv.x *= iResolution.x / iResolution.y;    \n    uv *= tan(radians(fov) * 0.5);\n    \n    Ray ray;\n    ray.origin = vec3(0);\n    ray.dir = normalize(vec3(uv, 1));\n    return ray;    \n}\n\n\nvoid trace_scene(inout Ray ray)\n{\n    ray.t = 0.0;\n    float d = 1.0;\n    for(int i = 0; i < 128 && d > 1e-4; i++)\n    {\n        d = map(ray.origin + ray.dir * ray.t);\n        ray.t += d;\n    }\n}\n\nvec3 get_incident_light(vec3 dir)\n{\n    vec3 L = textureLod(iChannel1, dir, 0.0).rgb;\n    L = to_linear(L);\n    //L = vec3(dot(L, vec3(0.3333)));\n    return L;\n}\n\nfloat lambda_smith(float ndotx, float alpha)\n{    \n    float alpha_sqr = alpha * alpha;\n    float ndotx_sqr = ndotx * ndotx;\n    return (-1.0 + sqrt(alpha_sqr * (1.0 - ndotx_sqr) / ndotx_sqr + 1.0)) * 0.5;\n}\n\nfloat smith_G1(float ndotv, float alpha)\n{\n\tfloat lambda_v = lambda_smith(ndotv, alpha);\n\treturn 1.0 / (1.0 + lambda_v);\n}\n\nfloat smith_G2(float ndotl, float ndotv, float alpha) //height correlated\n{\n\tfloat lambda_v = lambda_smith(ndotv, alpha);\n\tfloat lambda_l = lambda_smith(ndotl, alpha);\n\treturn 1.0 / (1.0 + lambda_v + lambda_l);\n}\n\nfloat fresnel_schlick(float cos_theta, float F0)\n{\n    float f = saturate(1.0 - cos_theta);\n    float f2 = f * f;   \n    return mad(f2 * f2 * f, 1.0 - F0, F0);\n}\n//====================================================================\n//====================================================================\n//\n//     Original VNDF\n//\n//====================================================================\n//====================================================================\n\n// Input Ve: view direction\n// Input alpha_x, alpha_y: roughness parameters\n// Input U1, U2: uniform random numbers\n// Output Ne: normal sampled with PDF D_Ve(Ne) = G1(Ve) * max(0, dot(Ve, Ne)) * D(Ne) / Ve.z\nvec3 sampleGGXVNDF(vec3 Ve, float alpha_x, float alpha_y, float U1, float U2)\n{\n\t// Section 3.2: transforming the view direction to the hemisphere configuration\n\tvec3 Vh = normalize(vec3(alpha_x * Ve.x, alpha_y * Ve.y, Ve.z));\n\t// Section 4.1: orthonormal basis (with special case if cross product is zero)\n\tfloat lensq = Vh.x * Vh.x + Vh.y * Vh.y;\n\tvec3 T1 = lensq > 0.0 ? vec3(-Vh.y, Vh.x, 0) * inversesqrt(lensq) : vec3(1,0,0);\n\tvec3 T2 = cross(Vh, T1);\n\t// Section 4.2: parameterization of the projected area\n\tfloat r = sqrt(U1);\t\n\tfloat phi = TAU * U2;\t\n\tfloat t1 = r * cos(phi);\n\tfloat t2 = r * sin(phi);\n\tfloat s = 0.5 * (1.0 + Vh.z);\n\tt2 = (1.0 - s)*sqrt(1.0 - t1*t1) + s*t2;\n\t// Section 4.3: reprojection onto hemisphere\n\tvec3 Nh = t1*T1 + t2*T2 + sqrt(max(0.0, 1.0 - t1*t1 - t2*t2))*Vh;\n\t// Section 3.4: transforming the normal back to the ellipsoid configuration\n\tvec3 Ne = normalize(vec3(alpha_x * Nh.x, alpha_y * Nh.y, max(0.0, Nh.z)));\t\n\treturn Ne;\n}\n\nvec3 canonical_vndf_heitz(vec3 n, vec3 wo, uvec2 seed)\n{\n    vec3 Lo = vec3(0);    \n    vec3 Le = vec3(0);\n    \n    float alpha = iMouse.x / iResolution.x;   \n    \n    mat3 TBN;  \n    TBN[0] = normalize(wo - n * dot(n, wo));\n    TBN[1] = cross(n, TBN[0]); \n    TBN[2] = n;\n    \n    vec3 V_tangent = -wo * TBN;\n    \n    float NdotV = saturate(V_tangent.z);\n    float G1 = smith_G1(NdotV, alpha);    \n    \n    const uint N = SAMPLES;    \n    \n    for(uint i = 0u; i < N; i++)\n    {\n        vec2 u = r2(i, seed);          \n        vec3 H_tangent = sampleGGXVNDF(V_tangent, alpha, alpha, u.x, u.y);            \n        vec3 L_tangent = reflect(-V_tangent, H_tangent);\n        float VdotH = dot(V_tangent, H_tangent);         \n        float NdotL = saturate(L_tangent.z);\n\n        if(L_tangent.z <= 0.0) continue;              \n\n        vec3 L = TBN * L_tangent;\n        vec3 Li = get_incident_light(L);  \n        \n        float F = fresnel_schlick(VdotH, 0.04);        \n        float G2 = smith_G2(NdotL, NdotV, alpha);        \n        \n        Lo += Li * F * G2/G1;         \n    }\n\n    Lo /= float(N);      \n    return Lo;\n}\n\n//====================================================================\n//====================================================================\n//\n//     New Bounded Spherical Cap Method w/ my correction term\n//\n//====================================================================\n//====================================================================\n\nvec3 SphericalCapBoundedWithPDFRatio(vec2 u, vec3 wi, vec2 alpha, out float pdf_ratio)\n{\n    // warp to the hemisphere configuration\n    \n    //PGilcher: save the length t here for pdf ratio\n    vec3 wiStd = vec3(wi.xy * alpha, wi.z);\n    float t = length(wiStd);\n    wiStd /= t;   \n    \n    // sample a spherical cap in (-wi.z, 1]\n    float phi = (2.0f * u.x - 1.0f) * PI;\n    \n    float a = saturate(min( alpha.x, alpha.y)); // Eq. 6\n    float s = 1.0f + length(wi.xy); // Omit sgn for a <=1\n    float a2 = a * a; \n    float s2 = s * s;\n    float k = (1.0 - a2) * s2 / (s2 + a2 * wi.z * wi.z); \n\n    float b = wiStd.z;\n    b = wi.z > 0.0 ? k * b : b;\n\n   //PGilcher: compute ratio of unchanged pdf to actual pdf (ndf/2 cancels out)\n   //Dupuy's method is identical to this except that \"k\" is always 1, so\n   //we extract the differences of the PDFs (Listing 2 in the paper)\n    pdf_ratio = (k * wi.z + t) / (wi.z + t);    \n    \n    float z = mad((1.0f - u.y), (1.0f + b), -b);\n    float sinTheta = sqrt(clamp(1.0f - z * z, 0.0f, 1.0f));\n    float x = sinTheta * cos(phi);\n    float y = sinTheta * sin(phi);\n    vec3 c = vec3(x, y, z);\n    // compute halfway direction as standard normal\n    vec3 wmStd = c + wiStd;\n    // warp back to the ellipsoid configuration\n    vec3 wm = normalize(vec3(wmStd.xy * alpha, wmStd.z));\n    // return final normal\n    return wm;\n}\n\nvec3 spherical_cap_new_vndf(vec3 n, vec3 wo, uvec2 seed)\n{\n    //return n;\n    vec3 Lo = vec3(0);    \n    vec3 Le = vec3(0);\n    \n    float alpha = iMouse.x / iResolution.x;   \n    \n    mat3 TBN;  \n    TBN[0] = normalize(wo - n * dot(n, wo));\n    TBN[1] = cross(n, TBN[0]); \n    TBN[2] = n;\n    \n    vec3 V_tangent = -wo * TBN;\n    \n    float NdotV = saturate(V_tangent.z);\n    float G1 = smith_G1(NdotV, alpha);    \n    \n    const uint N = SAMPLES;    \n    int accepted_samples = 0;\n    \n    for(uint i = 0u; i < N; i++)\n    {\n        vec2 u = r2(i, seed); \n        float pdf_ratio;\n        vec3 H_tangent = SphericalCapBoundedWithPDFRatio(u.yx, V_tangent, vec2(alpha), pdf_ratio);//sampleGGXVNDF(V_tangent, alpha, alpha, u.x, u.y);            \n        \n        vec3 L_tangent = reflect(-V_tangent, H_tangent);\n        float VdotH = dot(V_tangent, H_tangent);         \n        float NdotL = saturate(L_tangent.z);\n\n        if(L_tangent.z <= 0.0) continue;        \n        accepted_samples++;        \n\n        vec3 L = TBN * L_tangent;\n        vec3 Li = get_incident_light(L);  \n        \n        float F = fresnel_schlick(VdotH, 0.04);        \n        float G2 = smith_G2(NdotL, NdotV, alpha); \n        \n#if DISABLE_CORRECTION_TERM\n        pdf_ratio = 1.0;\n#endif\n        \n        Lo += Li * F * G2/G1 * pdf_ratio;         \n    }    \n\n    Lo /= float(N); \n    return Lo;\n}\n\n//====================================================================\n\nvoid mainImage( out vec4 o, in vec2 vpos )\n{\n    vec2 uv = vpos/iResolution.xy;    \n    Ray camera = camera_ray(uv, 40.0);\n    \n    trace_scene(camera);\n    vec3 hit = camera.origin + camera.dir * camera.t;\n    vec3 normal = get_normal(hit);\n    \n    o = texture(iChannel1, camera.dir);\n    if(camera.t > 10.0 || dot(normal, camera.dir) > 0.0) return;\n    \n    uvec2 seed;\n    seed = uvec2(texelFetch(iChannel0, ivec2(vpos) & 1023, 0).xy * exp2(32.0)); \n    \n    if(uv.x > 0.5)\n    {\n        o.rgb = spherical_cap_new_vndf(normal, camera.dir, seed); \n    }\n    else \n    {\n        o.rgb = canonical_vndf_heitz(normal, camera.dir, seed); \n    }    \n    \n    o.rgb *= 30.0;\n    o.rgb = o.rgb * ACESInputMat;\n    o.rgb = RRTAndODTFit(o.rgb);\n    o.rgb = o.rgb * ACESOutputMat;\n    o.rgb = saturate(o.rgb);\n\n    o.rgb = from_linear(o.rgb);    \n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"#define PI   3.14159\n#define TAU (PI * 2.0)\n#define mad(a,b,c) ((a)*(b)+(c))\n\n\nvec3 uniform_sample_sphere(vec2 u)\n{\n    vec3 dir;\n    dir.x = cos(u.x * TAU);\n    dir.y = sin(u.x * TAU);      \n    dir.z = u.y * 2.0 - 1.0; \n    dir.xy *= sqrt(1.0 - dir.z * dir.z);\n    return dir;\n}\n\nvec3 ray_cosine(vec2 u, vec3 n)\n{\n    return normalize(uniform_sample_sphere(u) + n);\n}\n\nvec3 ray_uniform(vec2 u, vec3 n)\n{\n    vec3 dir = uniform_sample_sphere(u);\n    dir = dot(dir, n) < 0.0 ? -dir : dir;\n    return normalize(dir + n * 0.01);\n}\n\nvec2 r2(in uint idx, in uvec2 useed)\n{\n    uvec2 phi = uvec2(3242174889u, 2447445413u);    \n    uvec2 p = phi * idx + useed;  \n    return vec2(p) * exp2(-32.0);  \n}\n\nfloat saturate(float x){return clamp(x, 0.0, 1.0);}\nvec2 saturate(vec2 x){return clamp(x, 0.0, 1.0);}\nvec3 saturate(vec3 x){return clamp(x, 0.0, 1.0);}\nvec4 saturate(vec4 x){return clamp(x, 0.0, 1.0);}\n\nfloat pow2(float x)\n{\n    return x * x;\n}\n\nvec3 to_linear(vec3 sRGB)\n{\n    bvec3 cutoff = lessThan(sRGB, vec3(0.04045));\n    vec3 higher = pow((sRGB + vec3(0.055)) / vec3(1.055), vec3(2.4));\n    vec3 lower = sRGB / vec3(12.92);\n\n    return mix(higher, lower, cutoff);\n}\n\n//Linear to sRGB\nvec3 from_linear(vec3 linearRGB)\n{\n    bvec3 cutoff = lessThan(linearRGB, vec3(0.0031308));\n    vec3 higher = vec3(1.055) * pow(linearRGB, vec3(1.0 / 2.4)) - vec3(0.055);\n    vec3 lower = linearRGB * vec3(12.92);\n\n    return mix(higher, lower, cutoff);\n}\n\nconst mat3 ACESInputMat = mat3(\n    0.59719, 0.35458, 0.04823,\n    0.07600, 0.90834, 0.01566,\n    0.02840, 0.13383, 0.83777\n);\n\nconst mat3 ACESOutputMat = mat3(\n     1.60475, -0.53108, -0.07367,\n    -0.10208,  1.10813, -0.00605,\n    -0.00327, -0.07276,  1.07602\n);\n\nvec3 RRTAndODTFit(vec3 v) \n{\n    vec3 a = v * (v + 0.0245786);\n    vec3 b = v * (0.983729 * v + 0.4329510) + 0.238081;\n    return a / b;\n}\n\n\n","name":"Common","description":"","type":"common"}]}
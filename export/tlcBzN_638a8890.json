{"ver":"0.1","info":{"id":"tlcBzN","date":"1612738366","viewed":813,"name":"Tilt-Shift Rendering Demo","username":"aek","description":"Self-contained live demonstration for \"Tilt-Shift Rendering Using a Thin Lens Model\" by Andrew Kensler, from Ray Tracing Gems II, Chapter 31.\n\nBook website: https://www.realtimerendering.com/raytracinggems/rtg2/","likes":10,"published":1,"flags":32,"usePreview":0,"tags":["lens","dof","camera","defocus","tiltshift"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Self-contained live demonstration for\n// \"Tilt-Shift Rendering Using a Thin Lens Model\"\n// by Andrew Kensler, from Ray Tracing Gems II, Chapter 31.\n//\n// View this at https://www.shadertoy.com/view/tlcBzN.\n//\n// See Buffer A for the main camera model shown in the chapter\n// and the path tracing code built around it for demonstration.\n// This is a live demonstration: try changing the constants at\n// the top of that buffer to experiment with moving the camera or\n// focus, switching the scene, selecting between the thin lens or\n// tilt shift model, adjusting the camera parameters, etc.  Then\n// recompile and restart the shader to see the effect.\n//\n// Refer to the chapter for an explanation of the camera model.\n\nvoid mainImage(\n    out vec4 fragColor,\n    in vec2 fragCoord)\n{\n    vec2 ndc = fragCoord.xy / vec2(iResolution);\n    vec3 pixel = textureLod(iChannel0, ndc, 0.0).rgb;\n    fragColor = vec4(pixel, 1.0);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Scene parameters.  Change these to select whether to render a\n// scene more like Figure 11a or Figure 12 in the chapter or\n// adjust the position of the spheres (Y-up coordinates).\n\n#define GRID 0 // 0 = diffuse grey grid, 1 = emissive spots\nconst vec3 blue_sphere = vec3(0.75, 0.5, 0.25);\nconst vec3 green_sphere = vec3(-0.5, -0.25, 0.75);\nconst vec3 red_sphere = vec3(0.25, -0.75, -0.5);\n\n// Camera parameters.  Change these to reposition the camera,\n// move the points of focus, or change the lens and camera\n// parameters.  Not all combinations are physically possible.\n\n#define CAMERA tilt_shift // thin_lens or tilt_shift\nconst vec3 eye = vec3(0.0, 0.0, -2.75);\nconst vec3 look_at = vec3(0.0, 0.0, 0.0);\nconst vec3 world_middle = look_at;\nconst vec3 world_focus_a = blue_sphere;\nconst vec3 world_focus_b = green_sphere;\nconst vec3 world_focus_c = red_sphere;\nconst float sensor_size = 1.8;\nconst float f_stop = 5.0;\nconst float focal_length = 1.0;\n\n// Derived constants from above settings.\n\nconst vec3 gaze = normalize(look_at - eye);\nconst vec3 right = normalize(cross(gaze, vec3(0.0, 1.0, 0.0)));\nconst vec3 up = cross(gaze, right);\n\nconst vec3 middle = vec3(dot(right, world_middle - eye),\n                         dot(up, world_middle - eye),\n                         dot(gaze, world_middle - eye));\nconst vec3 focus_a = vec3(dot(right, world_focus_a - eye),\n                          dot(up, world_focus_a - eye),\n                          dot(gaze, world_focus_a - eye));\nconst vec3 focus_b = vec3(dot(right, world_focus_b - eye),\n                          dot(up, world_focus_b - eye),\n                          dot(gaze, world_focus_b - eye));\nconst vec3 focus_c = vec3(dot(right, world_focus_c - eye),\n                          dot(up, world_focus_c - eye),\n                          dot(gaze, world_focus_c - eye));\n\nconst float focal_distance = focus_a.z;\n\nconst float epsilon = 0.001;\n\n// First sample code listing from the chapter.  This function\n// models a simple thin lens projection with a focal plane\n// parallel to the lens and sensor.  It takes in a coordinate in\n// screen space and a pair of random numbers in the unit square\n// to generate a ray origin and direction.\n\nvoid thin_lens(vec2 screen, vec2 random,\n               out vec3 ray_origin, out vec3 ray_direction)\n{\n    // f  : focal_length      p : focal_distance\n    // n  : f_stop            P : focused\n    // s  : image_plane       O : ray_origin\n    // P' : sensor            d : ray_direction\n\n    // Lens values (precomputable)\n    float aperture = focal_length / f_stop;\n    // Image plane values (precomputable)\n    float image_plane = focal_distance * focal_length /\n        (focal_distance - focal_length);\n\n    // Image plane values (render-time)\n    vec3 sensor = vec3(screen * 0.5 * sensor_size, -image_plane);\n    // Lens values (render-time)\n    float theta = 6.28318531 * random.x;\n    float r = aperture * sqrt(random.y);\n    vec3 lens = vec3(cos(theta) * r, sin(theta) * r, 0.0);\n    // Focal plane values (render-time)\n    vec3 focused = sensor * focal_length /\n        (focal_length - image_plane);\n\n    ray_origin = lens;\n    ray_direction = normalize(focused - lens);\n}\n\n// Second sample code listing from the chapter.  This function\n// extends the thin lens model with shift for perspective control\n// and tilt to allow an oblique plane of focus.  Refer to the\n// chapter for details on how it works.\n\nvoid tilt_shift(vec2 screen, vec2 random,\n                out vec3 ray_origin, out vec3 ray_direction)\n{\n    // n  : normal      A : focus_a\n    // t  : tilt        B : focus_b\n    // M  : middle      C : focus_c\n    // M' : shift\n\n    // Focal plane values (precomputable)\n    vec3 normal = normalize(cross(focus_b - focus_a,\n                                  focus_c - focus_a));\n    // Lens values (precomputable)\n    vec3 tilt = vec3(0.0);\n    if (abs(normal.x) > abs(normal.y))\n    {\n        tilt.x = (focus_a.z - focus_b.z) * focal_length /\n            (focus_a.z * focus_b.x - focus_b.z * focus_a.x +\n             (focus_a.z * focus_b.y - focus_b.z * focus_a.y) *\n             normal.y / normal.x);\n        tilt.y = tilt.x * normal.y / normal.x;\n    }\n    else if (abs(normal.y) > 0.0)\n    {\n        tilt.y = (focus_a.z - focus_b.z) * focal_length /\n            (focus_a.z * focus_b.y - focus_b.z * focus_a.y +\n             (focus_a.z * focus_b.x - focus_b.z * focus_a.x) *\n             normal.x / normal.y);\n        tilt.x = tilt.y * normal.x / normal.y;\n    }\n    tilt.z = sqrt(1.0 - tilt.x * tilt.x - tilt.y * tilt.y);\n    vec3 basis_u = normalize(cross(tilt,\n        abs(tilt.x) > abs(tilt.y) ? vec3(0.0, 1.0, 0.0)\n                                  : vec3(1.0, 0.0, 0.0)));\n    vec3 basis_v = cross(tilt, basis_u);\n    float aperture = focal_length / f_stop;\n    // Image plane values (precomputable)\n    float image_plane = focus_a.z * focal_length /\n        (dot(focus_a, tilt) - focal_length);\n    vec2 shift = middle.xy / middle.z * -image_plane;\n\n    // Image plane values (render-time)\n    vec3 sensor = vec3(screen * 0.5 * sensor_size + shift,\n                       -image_plane);\n    // Lens values (render-time)\n    float theta = 6.28318531 * random.x;\n    float r = 0.5 * aperture * sqrt(random.y);\n    vec3 lens = (cos(theta) * basis_u +\n                 sin(theta) * basis_v) * r;\n    // Focal plane values (render-time)\n    vec3 focused = sensor * focal_length /\n        (focal_length + dot(sensor, tilt));\n    float flip = sign(dot(tilt, focused));\n\n    ray_origin = lens;\n    ray_direction = flip * normalize(focused - lens);\n}\n\n// Ray/primitive intersection routines.  Take the ray origin and\n// direction, and the primitive position as input.  If the\n// t-value for the distance to the intersection is closer than\n// the existing t-value passed in, then updates the t-value, the\n// hit coordinates, and surface normal at the intersection.\n\nint plane(\n    vec3 origin,\n    vec3 direction,\n    vec3 orient,\n    float offset,\n    inout float t,\n    inout vec3 hit,\n    inout vec3 normal)\n{\n    float t_plane = (offset - dot(origin, orient)) / dot(direction, orient);\n    if (t_plane < epsilon || t < t_plane)\n        return 0;\n    t = t_plane;\n    hit = origin + direction * t;\n    normal = orient;\n    return 1;\n}\n\nint sphere(\n    vec3 origin,\n    vec3 direction,\n    vec3 center,\n    float radius,\n    inout float t,\n    inout vec3 hit,\n    inout vec3 normal)\n{\n    vec3 offset = origin - center;\n    float b = dot(offset, direction);\n    float c = dot(offset, offset) - radius * radius;\n    float discriminant = b * b - c;\n    if (discriminant <= 0.0)\n        return 0;\n    float t_sphere = -b - sqrt(discriminant);\n    if (t_sphere < epsilon || t < t_sphere)\n        return 0;\n    t = t_sphere;\n    hit = origin + direction * t;\n    normal = normalize(hit - center);\n    return 1;\n}\n\nint cylinder(\n    vec3 origin,\n    vec3 direction,\n    vec3 center,\n    vec3 orient,\n    float radius,\n    inout float t,\n    inout vec3 hit,\n    inout vec3 normal)\n{\n    vec3 approach = cross(direction, orient);\n    float distance = abs(dot(origin - center, normalize(approach)));\n    if (distance > radius)\n        return 0;\n    float t_center = dot(cross(orient, origin - center), approach) /\n        dot(approach, approach);\n    float t_half = sqrt(radius * radius - distance * distance) /\n        dot(direction, normalize(cross(orient, approach)));\n    float t_cylinder = t_center - t_half;\n    if (t_cylinder < epsilon || t < t_cylinder)\n        return 0;\n    t = t_cylinder;\n    hit = origin + direction * t;\n    normal = ((hit - center) - dot(hit - center, orient) * orient) / radius;\n    return 1;\n}\n\n// Shade a 2D position to compute either a grey grid pattern with\n// lines to use for diffuse shading or else a grey pattern with a\n// grid of small dots to use for emissive shading.\n\nfloat grid_diffuse(\n    vec2 position)\n{\n#if GRID == 0\n    vec2 cell = fract(position);\n    vec2 grid_1 = step(0.015, cell) - step(0.985, cell);\n    vec2 grid_2 = 1.0 - step(0.475, cell) + step(0.525, cell);\n    float blend = mod(floor(position.x) + floor(position.y), 2.0);\n    return mix(0.4, grid_1.x * grid_1.y * mix(grid_2.x * grid_2.y, 0.9, blend), 0.6);\n#else\n    return 0.0;\n#endif\n}\n\nfloat grid_emissive(\n    vec2 position)\n{\n#if GRID == 1\n    vec2 cell = fract(position);\n    vec2 centered = cell - vec2(0.5);\n    return 20.0 * (1.0 - step(0.001, dot(centered, centered)));\n#else\n    return 0.0;\n#endif\n}\n\n// Random number generation.  Map a 3D seed value to a group of\n// three pseudorandom each in [0,1].  (I.e., a uniformly\n// distributed sample in the unit 3D cube.)\n\nvec3 rng(\n    vec3 seed)\n{\n    uvec3 v = uvec3(abs(seed) * 1048576.0);\n    v = v * 1664525u + 1013904223u;\n    v.x += v.y * v.z;\n    v.y += v.z * v.x;\n    v.z += v.x * v.y;\n    v ^= v >> 16u;\n    v.x += v.y*v.z;\n    v.y += v.z*v.x;\n    v.z += v.x*v.y;\n    return vec3(v) * (1.0 / float(0xffffffffu));\n}\n\n// Given a ray and a maximum distance t-value, intersect the ray\n// against the scene and get information out about what was hit\n// if anything.  The position and shading values at the hit are\n// output.  Returns 1 if the ray hit anything, or 0 if it missed.\n\nint trace(\n    vec3 origin,\n    vec3 direction,\n    float t,\n    out vec3 hit,\n    out vec3 normal,\n    out vec3 diffuse,\n    out vec3 specular,\n    out vec3 emissive)\n{\n    const vec3 x_axis = vec3(1.0, 0.0, 0.0);\n    const vec3 y_axis = vec3(0.0, 1.0, 0.0);\n    const vec3 z_axis = vec3(0.0, 0.0, 1.0);\n    float original_t = t;\n    if (plane(origin, direction, -z_axis, -1.0, t, hit, normal) > 0)\n    {\n        diffuse = vec3(grid_diffuse(hit.xy * 4.0));\n        specular = vec3(0.0);\n        emissive = vec3(grid_emissive(hit.xy * 4.0));\n    }\n    if (plane(origin, direction,  x_axis, -1.0, t, hit, normal) +\n        plane(origin, direction, -x_axis, -1.0, t, hit, normal) > 0)\n    {\n        diffuse = vec3(grid_diffuse(hit.yz * 4.0));\n        specular = vec3(0.0);\n        emissive = vec3(grid_emissive(hit.yz * 4.0));\n    }\n    if (plane(origin, direction,  y_axis, -1.0, t, hit, normal) +\n        plane(origin, direction, -y_axis, -1.0, t, hit, normal) > 0)\n    {\n        diffuse = vec3(grid_diffuse(hit.xz * vec2(-4.0, 4.0)));\n        specular = vec3(0.0);\n        emissive = vec3(grid_emissive(hit.xz * vec2(-4.0, 4.0)));\n    }\n    if (sphere(origin, direction, red_sphere, 0.1, t, hit, normal) > 0)\n    {\n        diffuse = vec3(1.0, 0.1, 0.1);\n        specular = vec3(0.9, 0.4, 0.4);\n        emissive = vec3(0.0);\n    }\n    if (cylinder(origin, direction, red_sphere, x_axis, 0.01, t, hit, normal) +\n        cylinder(origin, direction, red_sphere, y_axis, 0.01, t, hit, normal) +\n        cylinder(origin, direction, red_sphere, z_axis, 0.01, t, hit, normal) > 0)\n    {\n        diffuse = vec3(1.0, 0.1, 0.1);\n        specular = vec3(0.0);\n        emissive = vec3(0.0);\n    }\n    if (sphere(origin, direction, green_sphere, 0.1, t, hit, normal) > 0)\n    {\n        diffuse = vec3(0.1, 1.0, 0.1);\n        specular = vec3(0.4, 0.9, 0.4);\n        emissive = vec3(0.0);\n    }\n    if (cylinder(origin, direction, green_sphere, x_axis, 0.01, t, hit, normal) +\n        cylinder(origin, direction, green_sphere, y_axis, 0.01, t, hit, normal) +\n        cylinder(origin, direction, green_sphere, z_axis, 0.01, t, hit, normal) > 0)\n    {\n        diffuse = vec3(0.1, 1.0, 0.1);\n        specular = vec3(0.0);\n        emissive = vec3(0.0);\n    }\n    if (sphere(origin, direction, blue_sphere, 0.1, t, hit, normal) > 0)\n    {\n        diffuse = vec3(0.1, 0.1, 1.0);\n        specular = vec3(0.4, 0.4, 0.9);\n        emissive = vec3(0.0);\n    }\n    if (cylinder(origin, direction, blue_sphere, x_axis, 0.01, t, hit, normal) +\n        cylinder(origin, direction, blue_sphere, y_axis, 0.01, t, hit, normal) +\n        cylinder(origin, direction, blue_sphere, z_axis, 0.01, t, hit, normal) > 0)\n    {\n        diffuse = vec3(0.1, 0.1, 1.0);\n        specular = vec3(0.0);\n        emissive = vec3(0.0);\n    }\n    return original_t == t ? 0 : 1;\n}\n\n// Path trace a ray against the scene and return an single sample\n// estimating the radiance arriving at the sensor back along the\n// ray.  This orchestrates intersecting the ray against the\n// scene, shading the ray at the hit point for the surface\n// properties, next-event estimation for direct lighting from an\n// invisible area light on the ceiling, and following several\n// bounces of indirect rays.\n\nvec3 shade(\n    inout vec3 origin,\n    inout vec3 direction)\n{\n    vec3 shaded = vec3(0.0);\n    vec3 throughput = vec3(1.0);\n    for (int bounce = 0; bounce < 3; ++bounce)\n    {\n        float t = 1.0e30;\n        vec3 hit = vec3(0.0);\n        vec3 normal = vec3(0.0);\n        vec3 diffuse = vec3(0.0);\n        vec3 specular = vec3(0.0);\n        vec3 emissive = vec3(0.0);\n        trace(origin, direction, t, hit, normal, diffuse, specular, emissive);\n\n        // Add in emissive contribution.\n\n        shaded += throughput * emissive;\n\n        // Add in direct lighting via next event estimation.\n\n        vec3 xi_1 = rng(hit);\n        vec3 light = vec3((xi_1.x - 0.5) * 0.1, 0.99, (xi_1.z - 0.5) * 0.1);\n        vec3 light_direction = light - hit;\n        if (dot(normal, light_direction) > 0.0)\n        {\n            float light_distance = length(light_direction);\n            light_direction /= light_distance;\n            vec3 shadow_hit = vec3(0.0);\n            vec3 shadow_normal = vec3(0.0);\n            vec3 shadow_diffuse = vec3(0.0);\n            vec3 shadow_specular = vec3(0.0);\n            vec3 shadow_emissive = vec3(0.0);\n            int intersected = trace(hit, light_direction, light_distance,\n                                    shadow_hit, shadow_normal,\n                                    shadow_diffuse, shadow_specular, shadow_emissive);\n            if (intersected == 0)\n            {\n                vec3 halfway = normalize(light_direction + normalize(origin - hit));\n                float lambert = max(0.0, dot(normal, light_direction));\n                float blinn_phong = 3.0 * pow(max(0.0, dot(halfway, normal)), 64.0);\n                shaded += throughput * (diffuse * lambert + specular * blinn_phong);\n            }\n        }\n\n        // Update for indirect lighting: adjust path throughput\n        // and choose new ray for next path segment.\n\n        float diffuse_weight = dot(diffuse, vec3(1.0));\n        float specular_weight = dot(specular, vec3(1.0));\n        if (xi_1.y * (diffuse_weight + specular_weight) <= diffuse_weight)\n        {\n            vec3 xi_2 = rng(hit + vec3(239.0, 491.0, 128.0));\n            float phi = 6.28318531 * xi_2.x;\n            float cos_theta_sq = xi_2.y;\n            float sin_theta = sqrt(1.0 - cos_theta_sq);\n            float sgn = normal.z < 0.0 ? -1.0 : 1.0;\n            float a = -1.0 / (sgn + normal.z);\n            float b = normal.x * normal.y * a;\n            direction =\n                (vec3(b, sgn + normal.y * normal.y * a, -normal.y) * (cos(phi) * sin_theta) +\n                 vec3(1.0 + sgn * normal.x * normal.x * a, sgn * b, -sgn * normal.x) * (sin(phi) * sin_theta) +\n                 normal * sqrt(cos_theta_sq));\n            throughput *= diffuse;\n        }\n        else\n        {\n            direction = reflect(direction, normal);\n            throughput *= specular;\n        }\n\n        origin = hit + direction * 0.001;\n    }\n    return shaded;\n}\n\n// Main driver routine.  Trace a new batch of paths for each\n// pixel and mix it with the average of the previous batches\n// (stored in the render target texture) to get the new average\n// and return it.  One pixel in the corner tracks the current\n// state to reset the accumulation on resolution changes or stop\n// rendering at 32K spp.\n\nvoid mainImage(\n    out vec4 fragColor,\n    in vec2 fragCoord)\n{\n    const float batch = 32.0;\n\n    vec2 ndc = fragCoord.xy / vec2(iResolution);\n    vec3 pixel = textureLod(iChannel0, ndc, 0.0).rgb;\n    vec4 data = textureLod(iChannel0, vec2(0.0), 0.0);\n    vec2 old_resolution = data.xy;\n    float samples = data.z;\n    if (old_resolution != vec2(iResolution))\n        samples = 0.0;\n    if (uvec2(fragCoord) == uvec2(0))\n    {\n        fragColor = vec4(iResolution.x, iResolution.y, samples + batch, 0.0);\n        return;\n    }\n    if (samples >= 32768.0)\n    {\n        fragColor = vec4(pixel, 1.0);\n        return;\n    }\n\n    vec3 shaded = vec3(0.0);\n    for (float ray = 1.0; ray <= batch; ++ray)\n    {\n        vec2 jittered = fragCoord + rng(vec3(fragCoord, iTime * ray)).xy;\n        vec2 screen = (2.0 * jittered - iResolution.xy) / min(iResolution.x, iResolution.y);\n        vec2 random = rng(vec3(screen, iTime)).xy;\n        vec3 origin, direction;\n        CAMERA(screen, random, origin, direction);\n        origin = eye + origin.x * right + origin.y * up + origin.z * gaze;\n        direction = normalize(direction.x * right + direction.y * up + direction.z * gaze);\n        shaded += shade(origin, direction);\n    }\n\n    fragColor = vec4((pixel * samples + shaded) / (samples + batch), 1.0);\n}\n","name":"Buffer A","description":"","type":"buffer"}]}
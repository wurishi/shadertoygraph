{"ver":"0.1","info":{"id":"WlKGzD","date":"1578453468","viewed":219,"name":"Halfpipe Maze","username":"spalmer","description":"I had a crazy idea.  To make a camera ride an amazing infinite halfpipe.  Gnarly!\nWell it doesn't ride, yet, just flies around, and there's lots left to do.  The bowls' corners don't appear very smooth.\nLighting is... sort of working.  Glitchy on OpenGL.","likes":7,"published":1,"flags":48,"usePreview":0,"tags":["curve","maze"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4sfGzn","filepath":"/media/a/793a105653fbdadabdc1325ca08675e1ce48ae5f12e37973829c87bea4be3232.png","previewfilepath":"/media/ap/793a105653fbdadabdc1325ca08675e1ce48ae5f12e37973829c87bea4be3232.png","type":"cubemap","channel":2,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"#define BufferC   iChannel3  \n\nvec3 cameraPosition() \n{\n    return loadValue(BufferC, slotCameraPosition).xyz;\n}\n\nvec3 cameraDirection() \n{\n    return loadValue(BufferC, slotCameraForward).xyz;\n}\n\nvoid ViewRay(vec2 q, out vec3 ro, out vec3 rd, out vec3 vd)\n{\n    // already in main, here\n//    vec2 R = iResolution.xy;\n//    vec2 q = StoQ(p, R);\n    vec3 camera_pos = cameraPosition();\n    vec3 camera_dir = cameraDirection();\n    mat3 M = cameraMatrix(camera_dir);\n    const float hfovy = pi/6.;\n    vd = normalize(vec3(q, 1./sin(hfovy)));\n    ro = camera_pos, rd = normalize(M * vd);\n}\n\n// I just cache maze into BufferA/iChannel0\n \nfloat imaze(ivec2 p)\n{\n    p = ivec2(mod(vec2(p), iChannelResolution[0].xy));\n    if (p.x < 0) p.x += int(iChannelResolution[0].x);\n    if (p.y < 0) p.x += int(iChannelResolution[0].y);\n \treturn texelFetch(iChannel0,\n                      p,\n                      0).x; // MAZE(p)?1.:0.;\n}\n// FIXME hardware texture filtering isn't very accurate; seems only few bits fractional precision\nfloat dmaze(vec2 p)\n{\n    return textureLod(iChannel0, p / iChannelResolution[0].xy, 0.).x;\n}\n\n// software bilinear filtering for quality\nfloat qmaze(vec2 p)\n{\n    p -= .5; // match hw bilinear filter half texel offset\n    ivec2 i = ivec2(floor(p)), x = ivec2(1,0), y = x.yx; p -= vec2(i);\n    return mix(\n        mix(imaze(i  ), imaze(i+x), p.x)\n      , mix(imaze(i+y), imaze(i+1), p.x)\n      , p.y);\n}\n\nfloat dPipe(vec2 q)\n{\n//  q.x = abs(q.x);\n//    if (q.x >= max(1., q.y)) return q.y; // here q.x is always 0..1\n//    if (q.x <= 0. && q.y >= q.x + 1.) return q.y - 1.; // this was already hacked by caller scaling bs\n    if (q.y >= 1.) return distance(q, vec2(0, 1));\n    return 1. - distance(q, vec2(1));\n}\n\nfloat hroundify(float l)\n{\n    float c = l;\n    float s = 1. - sqrt(max(0., 1. - c*c));  // turn to halfpipes\n    return s;\n}\n\n// roundify & makes maze walls appear shorter\n// and thicker relative to bowls \"inside\"\n// so they have a flattened top\nfloat hthicken(float l) \n{\n    if (l >= .5) return .5; // chop tops halfway\n//    return l; // linear ramps\n    return hroundify(l * 2.) / 2.;\n}\n// TODO if had access to some horizontal/vertical offsets,\n// could produce an actual SDF not just height, with a bit more work.\n// well we have essentially the \"height\" already, in c.\n// which is actually (since linear interpolated)\n// also the horizontal \"distance\" from the top of the maze.\n// well the pipe is half that height.\n// easy enough by multiplying by 2 and clipping to bring back to 0..1\n// so where s is involved above, it really is unit.\n// all we'd need is a vertical offset (not available here yet)\n// to convert it to true SDF.  Bit of knowledge about where the \n// point of curvature should be located, and bam, it's just a disc.\n\nfloat sdfround(float x, float y)\n{\n    return dPipe(vec2(1.-x, y));\n    return hthicken(x);\n}\n\nfloat hmaze(vec2 p)\n{\n    float l = dmaze(p); //qmaze(p); //imaze(ivec2(p)); //\n    return hthicken(l);\n}\nfloat hmazeb(vec2 p)\n{\n    float l = qmaze(p); //dmaze(p); //\n    return hthicken(l); //sdfround(l, p.y); // \n}\n\n// fast sdf for the raymarcher\nfloat sdfh(vec3 p)\n{\n\tfloat h = hmaze(p.xz); //\n    return p.y - h; // not a true sdf, just a heightfield\n}\n// higher quality sdf for the normals\nfloat sdfb(vec3 p)\n{\n\tfloat h = hmazeb(p.xz);\n    return p.y - h; // not a true sdf, just a heightfield\n}\n// true sdf?\nfloat sdfq(vec3 p)\n{\n\tfloat h = qmaze(p.xz); // dmaze won't suffice\n    const float w = .5; // wall height, 1.-thickness\n    if (h >= w * .999999) return p.y - w;\n    if (h <= 0.) return p.y;\n\n    return sdfround(h / w, p.y / w) * w; // true sdf, mostly!\n    // FIXME I think it's clipped off wrongly past x>1, y > x+1\n    // or something, up in the sky, but I don't care much\n    // because our pipe walls are always thin\n    // and the bowls are never very wide; think it won't matter.\n} // FIXME I still suspect some scaling problem due to the half-height clipping\n// and btw because of how it's scaled, it's still tracing\n// an empty top half of the 0..1 y slab unnecessarily.\n// Rescaling the sdf properly into 0..1 would help simplify and correct things.\n\nfloat sdf(vec3 p)\n{\n    return sdfq //sdfh //sdfb //\n        (p);\n}\n// for normals, can choose higher quality\nfloat sdfn(vec3 p)\n{\n    return sdf //sdfb //sdfh //sdfq //\n        (p);\n}\n\nvec3 nmaze(vec2 p)\n{\n    float h = .03;\n    vec3 p3 = vec3(p.x,0.,p.y);\n    return normalize((vec3(sdfn(p3 + vec3(h,0.,0.)), sdfn(p3 + vec3(0.,h,0.)), sdfn(p3 + vec3(0.,0.,h))) - sdfn(p3)) / h);\n}\n    \nfloat raymarch(vec3 ro, vec3 rd, int maxsteps)\n{\n    float ret = -1.;\n    if (ro.y < 0.) return 0.;\n    if (rd.y >= 0. && ro.y >= 1.) return ret;\n    float t = 0.0;\n    for (int i = 0; i < maxsteps; ++i) {\n        vec3 p = ro + rd * t;\n        float d = sdf(p);\n        if (d <= 1e-7) {\n          ret = t;\n          break;\n        }\n        if (rd.y >= 0. && p.y >= 1.) // exiting slab?\n            break; // give up - shadow optimization mostly\n        t += max(d * .96, .0001);\n    }\n    if (ret < 0. && rd.y < 0.)\n        ret = ro.y / -rd.y; // HACK pretend this method doesn't suck\n    return ret;\n}\n// clip ray to slab and then march only what's absolutely necessary;\n// fixup result afterward to compensate; improves quality damatically.\nfloat clipmarch(vec3 ro, vec3 rd, int maxsteps)\n{\n    float tt = (ro.y-1.) / -rd.y;\n    bool clip = ro.y > 1. && rd.y < 0.;\n    if (!clip) tt = 0.; else ro += rd * tt;\n    return raymarch(ro, rd, maxsteps) + tt;\n}\n\n\nconst vec3 L = normalize(vec3(1.,1.,2.)); //.1,.2,.9)); //.3,.5,.866));\n\nfloat shadow(vec3 p)\n{\n    float r = raymarch(p, L, 128); //160); //\n    return r > 0. //&& r <= 2.\n        ? 0. : 1.;\n}\n\nvec3 lighting(vec3 d, vec3 n, float r, vec3 p)\n{\n    vec3 cdiff = vec3(.75);\n    float h = p.y; // this color palette is bogus FIXME\n    cdiff.b *= mix(1., .6, step(.5,  fract(h*12.)));\n    cdiff.r *= mix(1., .8, step(.47, fract(h*2.+.2)));\n    cdiff.g *= mix(1., .9, step(.62, fract(h*5.+.3)));\n    float nl = dot(L, n);\n    float shadowatten = shadow(p + n * .017 + nl * .0001 * L); //1.; //\n    nl = max(0., nl);\n    nl *= shadowatten;\n    float diff = mix(nl, 1., .15);  // ambient hax\n    vec3 H = normalize(L+d); // blinn-phong hack\n    float e = 64.; // specpower\n    float spec = nl * pow(max(0., dot(H, n)), e) * e * .038; //0.; //\n    vec3 nr = reflect(n, d); //d, n); //\n    vec3 env = textureLod(iChannel2, nr, 0.).rgb * .1;\n    return //env + \n        clamp(cdiff * diff + .2 * spec, 0., 1.); //mix(diff, 2.*spec, .5);\n}\n\nvec3 draw(vec2 q)\n{\n//    float rotTime = iTime * .1;\n    vec3 campos, camdir;\n    campos = texelFetch(iChannel1, ivec2(0,0), 0).xyz; //vec3(0.,2.5,0.); //\n    camdir = texelFetch(iChannel1, ivec2(1,0), 0).xyz; //vec3(sin(rotTime),-.4,cos(rotTime)); //vec3(0.,0.,1.); //\n    camdir = normalize(camdir);\n    mat3 m = cameraMatrix(camdir);\n    vec3 rp = campos;\n    vec3 rd = normalize(m * vec3(q, 3.5)); // WAY zoomed in\n//    ViewRay(q, rp, rd, camdir);\n    float r = clipmarch(rp, rd, 256); //320); //384); //\n    float vl = max(dot(rd, L), 0.);\n //   if (rd.y >= 0.) r = -1.; // HACK - wut?\n    if (!(r >= 0.))\n        return \n        //textureLod(iChannel2, rd, 0.).rgb\n        + vec3(exp2(-2. * (1.-vl)));\n    vec3 phit = rp + rd * r;\n    vec2 hituv = phit.xz;\n    vec2 uv = hituv; //q*12.; //\n    vec3 n = nmaze(uv);\n    return lighting(-rd, n, r, phit);\n//    return vec3(imaze(uv));\n//    return vec3(dmaze(uv));\n//    return rd * .5 + .5;\n//    return abs(n); //n * .5 + .5; //\n}\n\nvoid mainImage(out vec4 c, vec2 p)\n{\n    vec2 r = iResolution.xy;\n    vec2 uv = (p+p-r)/r; //.y TODO\n    vec2 q = uv * vec2(r.x/r.y, 1.);\n    vec3 v = draw(q);\n    c.rgb += v;\n    c.rgb = pow(c.rgb, vec3(1./2.2)); // to srgb gamma\n\tc.a = 1.;\n}\n\n//    c.b = (((((int(p.x)|int(p.y))>>3)&3)==0) ? 4. : 2.);\n","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// ALU maze by Fabrice Neyret https://www.shadertoy.com/view/lt2cRR\n// small enough I could use it in the main raymarcher loop,\n// but may as well cache to BufferA, but only needed\n// on frame 0 or periodically in case buffer was resized\n\n// I messed with it.  I'm trying to get some areas with tight half pipes,\n// and some with more open areas bounded by quarter pipes.\n// I fear I probably broke the traversability somehow.\n// But it seems more interesting.  Provides more variety.\n#define Z(U)  (((((int(U.x)|int(U.y))>>3)&1)==0) ? 2 : 4)\n\nvoid mainImage(out vec4 O, vec2 U) \n{\n   O = (iFrame & 1023) >= 3 //!= 0\n       ? texelFetch(iChannel0, ivec2(U), 0)\n       : vec4(vec3(\n       ((int((U)[int(1e4*length(ceil((U)/float(Z(U)))))&1])&(Z(U)-1))!=0)\n   ? 0. : 1.),1);\n}\n\n// at some point I should work on actually golfing this maze generator function\n// and not just screwing around with it.  I haven't really unraveled it yet.","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// so far all it does is go in a circle\n\nvoid mainImage(out vec4 c, vec2 p)\n{\n    vec3 campos, camdir;\n    campos = texelFetch(iChannel1, ivec2(0,0), 0).xyz;\n    camdir = texelFetch(iChannel1, ivec2(1,0), 0).xyz;\n    float t = iTimeDelta;\n//  MoveCamera(t);\n    // TODO collision with pipemaze\n    // fwd should be on the tangent vector\n//    camdir.y += t; // gravity\n//    if (campos.y > 1) fwd should align with vertical plane?\n    \n    camdir = normalize(camdir);\n    float speed = .8;\n//    campos = vec3(0.,2.5,0.); //\n    vec3 camlat = camdir; camlat.y = 0.;\n    campos += t * speed * camlat; // move forward!\n    float rotTime = iTime * .1;\n    rotTime -= sin(iTime * .6003) * .4;\n    camdir = vec3(sin(rotTime),-.4,cos(rotTime)); //vec3(0.,0.,1.); //texelFetch(iChannel1, ivec2(1,0), 0).xyz;\n    camdir = normalize(camdir);\n    c = vec4(0.,0.,0.,1.);\n    int q = int(p.x) + 16*int(p.y); // state id\n    switch (q) {\n        case 0: c = vec4(campos, 1.); break;\n        case 1: c = vec4(camdir, 1.); break;\n    }\n    if (iFrame < 3) { //iFrame == 0) {\n        switch (q) {\n            case 0: c = vec4(0.,2.5,0., 1.); break;\n            case 1: c = vec4(0.,1.,0., 1.); break;\n        }\n    }\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"// maze only needed in BufferA\n//#define MAZE(U) \\\n//((int((U)[int(1e4*length(ceil((U)/2.)))&1])&1)!=0)\n\n// TODO consider building a Dijkstra field and making a maze-solver :)\n// ok, see Cheese Sniffer lol  https://www.shadertoy.com/view/3ldXWS\n// could probably implement A* in a Shadertoy! that sounds like a really bad idea.\n\nconst float pi = 3.141592;\n\nvec2 StoQ(vec2 s, vec2 r)\n{\n\treturn (s + s - r) / r.y;\n}\n\n// buffer mapping logic, could wrap to subsequent rows\nint slotid(ivec2 loc) { return loc.x; }\nivec2 slotloc(int id) { return ivec2(id, 0); }\n\nvec4 loadValue(sampler2D buf, int slot_id)\n{\n    return texelFetch(buf, slotloc(slot_id), 0);\n}\n\n// channel allocations can't be done in Common,\n// as the defines for the iChannel# samplers have not yet been set.\n// but we can allocate the slots within BufferC at least.\n\nconst int slotCameraPosition = 0;\nconst int slotCameraForward  = 1;\nconst int slotDesiredForward = 2;\nconst int slotMouseOld       = 3; // iMouse from prior frame\n\n// TODO\nvec2 cossin(float r)\n{\n    const float halfpi = 1.5707963;\n    return cos(vec2(r, r - halfpi));\n}\n\n// cheap rotation transform on p by s=(cos(a),sin(a))\nvoid rot(inout vec2 p, vec2 s) \n{\n\tp = p * s.x + vec2(p.y, -p.x) * s.y;\n} // then can rot(q.xz, vec2(cos(a),sin(a)))\n// as matrix\n//mat2 mrot(vec2 s)\n//{\n//    return mat2(s.x, s.y, -s.y, s.x);\n//} // then can q.xz = mrot(vec2(cos(a),sin(a))) * q.xz;\n// idk yet which I will wind up using\n\n// build a 3x3 camera orientation matrix given forward direction vector, assuming up is +Y\n// not much like what I started with in https://www.shadertoy.com/view/ls3fDr, slightly reversed \nmat3 cameraMatrix(vec3 camFwd)\n{\n    vec3 w = normalize(camFwd)\n       , u = normalize(cross(vec3(0., 1., 0.), w))\n       , v = normalize(cross(w, u));\n    return mat3(u, v, w);\n}\n// then I just transform by pw = MC * pv;\n// I think I should transpose it, as view matrix instead!\n// then it'd be pw = pv * MV;\n\n\nbool asleep(vec2 mouse) // in shadertoy.com shader browser thumbnail? \n{\n    return dot(mouse, mouse) <= 2.;\n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// see https://www.shadertoy.com/view/WlVGDh\n\n// BufferC controls the state, mostly the camera location+direction\n// but wound up needing old mouse state and, for smoothing,\n// the desired facing direction.\n\n#define BufferC   iChannel2  // Buffer C is in iChannel2  (res x rgba32Sfloat) and is also the shader fragColor output\n#define Keyboard  iChannel3  // Keyboard is in iChannel3  (256 x 3 x r8Uint)\n\nconst float moverate = .5; // actually very slow.\nconst float turnratemouse = .02; // since mouse can't go outside window, must be pretty fast\nconst float turnratekbd = 2.6;\n\n\nvec3 cameraPosition() \n{\n    return loadValue(BufferC, slotCameraPosition).xyz;\n}\n\nvec3 cameraDirection() \n{\n    return loadValue(BufferC, slotCameraForward).xyz;\n}\n\nvec3 desiredDirection() \n{\n    return loadValue(BufferC, slotDesiredForward).xyz;\n}\n\nvec4 oldMouse() \n{\n    return loadValue(BufferC, slotMouseOld);\n}\n\n\n// read keyboard key, return 1.0 if down\n// ultimately want to do differencing of negatives from positives\nfloat key(int vk) // key down state value as a float fraction\n{\n    float s = loadValue(Keyboard, vk).x; // read keyboard key state from texture\n    return step(.5, s); // test if down\n}\n\nconst int\n  KEY_SPACE = 32\n, KEY_CTRL  = 17 // DO NOT use control generally as when held, bad things can happen to our window or tab\n, KEY_SHIFT = 16\n, KEY_C     = 67\n// https://en.wikipedia.org/wiki/Arrow_keys#WASD_keys\n, KEY_W     = 87\n, KEY_A     = 65\n, KEY_S     = 83\n, KEY_D     = 68\n// in DVORAK it's ,AOE, in AZERTY it's ZQSD\n, KEY_Z     = 90 // but Image tab is using it for showing depth FIXME\n, KEY_Q     = 81\n, KEY_O     = 79\n, KEY_E     = 69\n, KEY_COMMA = 188 //188 JS, 44 ASCII\n, KEY_X     = 88 // used by Image tab; should keys move to Common tab?\n#if 0 // AZERTY ZQSD\n, KEY_FW    = KEY_Z\n, KEY_LF    = KEY_Q\n, KEY_BW    = KEY_S\n, KEY_RT    = KEY_D\n#elif 0 // DVORAK ,AOE\n, KEY_FW    = KEY_COMMA\n, KEY_LF    = KEY_A\n, KEY_BW    = KEY_O\n, KEY_RT    = KEY_E\n#else // QWERTY\n, KEY_FW    = KEY_W\n, KEY_LF    = KEY_A\n, KEY_BW    = KEY_S\n, KEY_RT    = KEY_D\n#endif\n, KEY_UW    = KEY_SPACE\n, KEY_DW    = KEY_C  // anything but control!\n, KEY_LEFT  = 37 // arrow keys for lookaround\n, KEY_RIGHT = 39\n, KEY_UP    = 38\n, KEY_DOWN  = 40\n;\n\nvec3 cameraMovement(bool shift)\n{\n    vec3 campos = cameraPosition();\n    float\n      fw = key(KEY_FW)\n    , bw = key(KEY_BW)\n    , lf = key(KEY_LF)\n    , rt = key(KEY_RT)\n    , up = key(KEY_UW)\n    , dn = key(KEY_DW);\n    if (asleep(iMouse.xy)) fw = .5; // automate forward in thumbnails\n    vec3 camfwd = cameraDirection();\n    mat3 camori = cameraMatrix(camfwd);\n    vec3 cammove = vec3(rt-lf, up-dn, fw-bw) * iTimeDelta * moverate;\n    if (shift) cammove *= 4.0; // shift key for speed boost\n    campos += camori * cammove;\n    const float camradius = .04;\n//    campos += sdfnormal(campos) * -min(sdf(campos) - camradius, .0); // collision with sdf\n    return campos;\n}\n\nvec3 cameraSteering(bool shift)\n{\n    vec3 desiredRot = desiredDirection();\n    vec4 oMouse = oldMouse();\n    bool lmb = iMouse.z >= 0.;\n    bool olmb = oMouse.z >= 0.;\n    float shiftmod = shift ? .5 : 1.; // shift actually slows rotation down\n    vec2 orbit = vec2(0);\n    if (asleep(iMouse.xy)) {\n    \torbit = vec2(.05*iTimeDelta, 0);   // attract mode slow spin\n\t} else {\n    \tif (lmb && olmb) {\n\t        vec2 m = iMouse.xy - oMouse.xy;\n    \t    orbit += m * turnratemouse * shiftmod;\n    \t} \n    \t{\n    \t\tfloat aL = key(KEY_LEFT), aR = key(KEY_RIGHT), aU = key(KEY_UP), aD = key(KEY_DOWN);\n\t        vec2 m = vec2(aR - aL, aU - aD);\n    \t    orbit += m * iTimeDelta * turnratekbd * shiftmod;\n        }\n    }\n    if (dot(orbit,orbit) != 0.) {\n        // TODO cossin is too nifty not to use\n        rot(desiredRot.xz, vec2(cos(orbit.x),sin(orbit.x)));\n        vec2 vr = vec2(1.,desiredRot.y);\n        rot(vr, vec2(cos(orbit.y),-sin(orbit.y)));\n        desiredRot.xz *= max(1e-1f, vr.x); // do not flip signs here!\n        desiredRot.y = vr.y;\n  \t\tdesiredRot = normalize(desiredRot);\n    }\n    return desiredRot;\n}\n\n// smoothing filter\nvec3 cameraSmoothing()\n{\n    vec3 camfwd = cameraDirection();\n    vec3 desiredFwd = desiredDirection();\n    camfwd = normalize(mix(desiredFwd, camfwd, exp2(-64.*iTimeDelta)));\n    return camfwd;\n}\n\n// implements a debugging fly camera using keyboard WASD + mouse + C/space\n// stores camera position,aim,etc. into c as a \n// color coded vector suitable for output to buffer\nvoid debugFlyCamera(out vec4 c, vec2 p)\n{    \n    ivec2 ip = ivec2(p);\n    c = loadValue(BufferC, ip.x); // passthru by default\n    float elapsed = iTimeDelta; // seconds\n    bool shift = key(KEY_SHIFT) > .5;\n    bool init = iFrame < 3; //iFrame == 0; //iTime == 0.; // thumbnail issues\n    // executes extremely inefficiently on gpu\n    switch (slotid(ip)) {\n      case slotCameraPosition: {\n \t    c.xyz = init ? vec3(.0,1.5,-3.5) : cameraMovement(shift);            \n        break;\n      }\n      case slotCameraForward: {\n        c.xyz = init ? vec3(0.,0.,1.) : cameraSmoothing();\n        break;\n      }\n      case slotDesiredForward: {\n        c.xyz = init ? vec3(0.,0.,1.) : cameraSteering(shift);\n        break;\n      }\n      case slotMouseOld: {\n        c = iMouse;\n        break;\n      }\n      default:\n        break;\n    }\n}\n\n// in this case we output into Buffer C\nvoid mainImage(out vec4 c, vec2 p)\n{    \n    debugFlyCamera(c, p);\n}\n\n\n\n//KEY_CTRL // be careful with control key though; ctrl+W for example closes the window or something\n// iMouse.z is negative if lmb up\n \n\n\n// TODO I hear Ben Quantock has a toy with fly cam!  \n// I should check it out.  Maybe you should too!\n// https://www.shadertoy.com/view/ldyGzW\n// It's interesting but it's based on Euler angles completely.\n// Simpler in some ways.  The walking support and\n// camera flipping complicates it.  There's comments\n// there from Fabrice regarding how WASD sucks for \n// international keyboard users.  idk how to deal with that.\n\n","name":"Buffer C","description":"","type":"buffer"}]}
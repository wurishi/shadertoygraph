{"ver":"0.1","info":{"id":"WlXXzl","date":"1564231169","viewed":151,"name":"Hypertexture raymarcher, try #1","username":"hodapp","description":"Raymarcher like described in \"Hypertexture\". It's slow, and there is no shading yet - just integration along a ray. Mouse has some effect (rotates one, stretches the other). See the #define DENSITY line to change the density function.","likes":3,"published":1,"flags":0,"usePreview":0,"tags":["raymarching","hypertexture"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Chris Hodapp, 2019\n//\n// Most view-transform functions and Phong shading, are from\n// https://www.shadertoy.com/view/4tcGDr and\n// jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/\n//\n// This is also based on \"Hypertexture\" from Ken Perlin, and\n// Chapter 9 of \"Texturing & Modeling: A Procedural Approach\".\n\n// TODO:\n// Actual shading!\n// Bounding boxes to avoid useless stepping\n// Try some of the 'subtractive' solid examples\n// Analytical gradients ('gradient' call now needs 6 calls to density function!)\n\n//#define DENSITY density_simplex\n#define DENSITY density_grid\n#define COLOR(g) (vec3(g/4.0,g/4.0,g))\n//#define COLOR(g) (vec3(pow(g,0.6),g/4.0,g/4.0))\n\nconst int MAX_MARCHING_STEPS = 500;\nconst float MIN_DIST = 2.0;\nconst float EPS = 0.001;\n\n// Rotation matrix around the X axis.\nmat3 rotateX(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(1, 0, 0),\n        vec3(0, c, -s),\n        vec3(0, s, c)\n    );\n}\n\n// Rotation matrix around the Y axis.\nmat3 rotateY(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, 0, s),\n        vec3(0, 1, 0),\n        vec3(-s, 0, c)\n    );\n}\n\n// Rotation matrix around the Z axis.\nmat3 rotateZ(float theta) {\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, -s, 0),\n        vec3(s, c, 0),\n        vec3(0, 0, 1)\n    );\n}\n\n// camera rotation : pitch, yaw\nmat3 rotationXY( vec2 angle ) {\n\tvec2 c = cos( angle );\n\tvec2 s = sin( angle );\n\t\n\treturn mat3(\n\t\tc.y      ,  0.0, -s.y,\n\t\ts.y * s.x,  c.x,  c.y * s.x,\n\t\ts.y * c.x, -s.x,  c.y * c.x\n\t);\n}\n       \n\n/**\n * Return the normalized direction to march in from the eye point for a single pixel.\n * \n * fieldOfView: vertical field of view in degrees\n * size: resolution of the output image\n * fragCoord: the x,y coordinate of the pixel in the output image\n */\nvec3 rayDirection(float fieldOfView, vec2 size, vec2 fragCoord) {\n    vec2 xy = fragCoord - size / 2.0;\n    float z = size.y / tan(radians(fieldOfView) / 2.0);\n    return normalize(vec3(xy, -z));\n}\n\n/**\n * Return a transform matrix that will transform a ray from view space\n * to world coordinates, given the eye point, the camera target, and an up vector.\n *\n * This assumes that the center of the camera is aligned with the negative z axis in\n * view space when calculating the ray marching direction. See rayDirection.\n */\nmat3 viewMatrix(vec3 eye, vec3 center, vec3 up) {\n    // Based on gluLookAt man page\n    vec3 f = normalize(center - eye);\n    vec3 s = normalize(cross(f, up));\n    vec3 u = cross(s, f);\n    return mat3(s, u, -f);\n}\n\nfloat bias(float t, float b)\n{\n    return pow(t, log(b)/log(0.5));\n}\n\nfloat gain(float t, float g)\n{\n    if (t > 0.5) {\n        return bias(2.0*t, 1.0-g) / 2.0;\n    } else {\n        return (2.0 - bias(2.0 - (2.0*t), 1.0-g)) / 2.0;\n    }\n}\n\n// Object Density Function described in hypertexture.\n// Should return density in [0,1].\nfloat density_simplex(in vec3 p)\n{\n    const float F = 1.0;\n    const float G = 0.1;\n    \n    // Allow mouse dragging:\n\tmat3 rot = rotationXY( ( iMouse.xy - iResolution.xy * 0.5 ).yx * vec2( 0.005, -0.005 ));\n\tp = p * rot;\n    \n    float a = (iMouse.x - iResolution.x * 0.5) * 0.005; //2.0 * cos(iTime / 2.0);\n    float c = cos(a*p.y);\n    float s = sin(a*p.y);\n    mat2  m = mat2(c,-s,s,c);\n    p = vec3(m*p.xz,p.y);\n    \n    // radius^2 of full outer edge:\n    const float rad2 = 4.0;\n    // radius^2 of where it begins to transition off:\n    const float rad2_fuzzy = 1.0;\n    \n    float dist2 = dot(p,p);\n    if (dist2 < rad2) {\n        float d = snoise(vec4(p.x*2.0, p.y*5.0, p.z*2.0, iTime)) * F - G;\n        // Make edges fuzzy:\n        float fuzz = 1.0-smoothstep(rad2_fuzzy, rad2, dist2);\n        return clamp(bias(d, 0.7), 0.0, 1.0) * fuzz;\n    } else {\n        return 0.0;\n    }\n}\n\n\nfloat density_grid(in vec3 p)\n{\n    const float S = 0.05;\n    const float PERIOD = 0.5;\n    \n\tmat3 rot = rotationXY( ( iMouse.xy - iResolution.xy * 0.5 ).yx * vec2( 0.005, -0.005 ));\n\tp = p * rot;\n    \n    float a = 2.0 * cos(iTime / 4.0);\n    float c = cos(a*p.y);\n    float s = sin(a*p.y);\n    mat2  m = mat2(c,-s,s,c);\n    p = vec3(m*p.xz,p.y);\n    \n    // radius^2 of full outer edge:\n    const float rad2 = 4.0;\n    // radius^2 of where it begins to transition off:\n    const float rad2_fuzzy = 1.0;\n    \n    float dist2 = dot(p,p);\n    if (dist2 < rad2) {\n        // Make edges fuzzy:\n        float fuzz = 1.0-smoothstep(rad2_fuzzy, rad2, dist2);\n\n        p = mod(p, PERIOD);\n        return (p.x < S || p.y < S || p.z < S) ? fuzz : 0.0;\n        \n    } else {\n        return 0.0;\n    }\n}\n\n\nvec3 gradient(vec3 p) {\n    return normalize(vec3(\n        DENSITY(vec3(p.x + EPS, p.y, p.z)) - DENSITY(vec3(p.x - EPS, p.y, p.z)),\n        DENSITY(vec3(p.x, p.y + EPS, p.z)) - DENSITY(vec3(p.x, p.y - EPS, p.z)),\n        DENSITY(vec3(p.x, p.y, p.z + EPS)) - DENSITY(vec3(p.x, p.y, p.z - EPS))\n    ));\n}\n\n\n/**\n * Lighting contribution of a single point light source via Phong illumination.\n * \n * The vec3 returned is the RGB color of the light's contribution.\n *\n * k_a: Ambient color\n * k_d: Diffuse color\n * k_s: Specular color\n * alpha: Shininess coefficient\n * p: position of point being lit\n * eye: the position of the camera\n * lightPos: the position of the light\n * lightIntensity: color/intensity of the light\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongContribForLight(vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye,\n                          vec3 lightPos, vec3 lightIntensity) {\n    vec3 N = gradient(p);\n    vec3 L = normalize(lightPos - p);\n    vec3 V = normalize(eye - p);\n    vec3 R = normalize(reflect(-L, N));\n    \n    float dotLN = dot(L, N);\n    float dotRV = dot(R, V);\n    \n    if (dotLN < 0.0) {\n        // Light not visible from this point on the surface\n        return vec3(0.0, 0.0, 0.0);\n    } \n    \n    if (dotRV < 0.0) {\n        // Light reflection in opposite direction as viewer, apply only diffuse\n        // component\n        return lightIntensity * (k_d * dotLN);\n    }\n    return lightIntensity * (k_d * dotLN + k_s * pow(dotRV, alpha));\n}\n\n/**\n * Lighting via Phong illumination.\n * \n * The vec3 returned is the RGB color of that point after lighting is applied.\n * k_a: Ambient color\n * k_d: Diffuse color\n * k_s: Specular color\n * alpha: Shininess coefficient\n * p: position of point being lit\n * eye: the position of the camera\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongIllumination(vec3 k_a, vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye) {\n    const vec3 ambientLight = 0.5 * vec3(1.0, 1.0, 1.0);\n    vec3 color = ambientLight * k_a;\n    \n    vec3 light1Pos = vec3(4.0 * sin(iTime),\n                          2.0,\n                          4.0 * cos(iTime));\n    vec3 light1Intensity = vec3(0.4, 0.4, 0.4);\n    \n    color += phongContribForLight(k_d, k_s, alpha, p, eye,\n                                  light1Pos,\n                                  light1Intensity);\n    \n    /*\n    vec3 light2Pos = vec3(2.0 * sin(0.37 * iTime),\n                          2.0 * cos(0.37 * iTime),\n                          2.0);\n    vec3 light2Intensity = vec3(0.4, 0.4, 0.4);\n    \n    color += phongContribForLight(k_d, k_s, alpha, p, eye,\n                                  light2Pos,\n                                  light2Intensity);    \n    */\n    return color;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec3 viewDir = rayDirection(45.0, iResolution.xy, fragCoord);\n\n    vec3 eye = vec3(4.0, 4.0, 4.0); // vec3(8.0, 5.0 * sin(0.2 * iTime), 7.0);\n\n    /*\n\tmat3 rot = rotationXY( ( iMouse.xy - iResolution.xy * 0.5 ).yx * vec2( 0.003, -0.003 ) );\n\tviewDir = rot * viewDir;\n\teye = rot * eye;\n    */\n    \n    mat3 viewToWorld = viewMatrix(eye, vec3(0.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0));\n    \n    vec3 worldDir = viewToWorld * viewDir;\n    \n    //vec3 K_a = vec3(0.5, 0.5, 0.5); // (estimateNormal(p) + vec3(1.0)) / 2.0;\n    //vec3 K_d = K_a;\n    vec3 K_s = vec3(1.0, 1.0, 1.0);\n    float shininess = 10.0;\n    \n    // Paper just calls it a \"normalizing constant\" but how do I set it?\n    float c = 10.0; // / float(iResolution.x * iResolution.y);\n    const float step_size = 0.01;\n\t// Actual raymarching:\n\tfloat a = 0.0;\n\tvec3 color = vec3(0.0, 0.0, 0.0);\n    {\n        // TODO: This depth really needs to start at an actual intersection\n        float depth = MIN_DIST;\n        float d = 0.0;\n        float t = 0.0;\n        float ak = 0.0;\n    \tfor (int i = 0; i < MAX_MARCHING_STEPS; i++) {\n            \n            vec3 p = eye + (depth + float(i)*step_size) * worldDir;\n            \n            d = DENSITY(p);\n            \n            ak = 1.0 - pow(1.0 - d, c * step_size);\n            t = ak*(1.0-a);\n            color += t*COLOR(d);\n            // These are all black:\n            //color += t*phongIllumination(COLOR(d), COLOR(d), K_s, shininess, p, eye);\n            //color += t*phongIllumination(vec3(1.0,1.0,1.0), vec3(1.0,1.0,1.0), K_s, shininess, p, eye);\n            // This gives something:\n            //color = phongIllumination(vec3(1.0,1.0,1.0), vec3(1.0,1.0,1.0), K_s, shininess, p, eye);\n            // This is getting closer but the principle is still wrong:\n            //color = phongIllumination(COLOR(d), COLOR(d), K_s, shininess, p, eye);\n\n            a += t;\n            \n            if (a >= 1.0) {\n                break;\n            }\n    \t}\n    }\n\n    fragColor = vec4(color, 1.0);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"//\n// Description : Array and textureless GLSL 2D/3D/4D simplex \n//               noise functions.\n//      Author : Ian McEwan, Ashima Arts.\n//  Maintainer : stegu\n//     Lastmod : 20110822 (ijm)\n//     License : Copyright (C) 2011 Ashima Arts. All rights reserved.\n//               Distributed under the MIT License. See LICENSE file.\n//               https://github.com/ashima/webgl-noise\n//               https://github.com/stegu/webgl-noise\n// \n\nvec4 mod289(vec4 x) {\n  return x - floor(x * (1.0 / 289.0)) * 289.0; }\n\nfloat mod289(float x) {\n  return x - floor(x * (1.0 / 289.0)) * 289.0; }\n\nvec4 permute(vec4 x) {\n     return mod289(((x*34.0)+1.0)*x);\n}\n\nfloat permute(float x) {\n     return mod289(((x*34.0)+1.0)*x);\n}\n\nvec4 taylorInvSqrt(vec4 r)\n{\n  return 1.79284291400159 - 0.85373472095314 * r;\n}\n\nfloat taylorInvSqrt(float r)\n{\n  return 1.79284291400159 - 0.85373472095314 * r;\n}\n\nvec4 grad4(float j, vec4 ip)\n  {\n  const vec4 ones = vec4(1.0, 1.0, 1.0, -1.0);\n  vec4 p,s;\n\n  p.xyz = floor( fract (vec3(j) * ip.xyz) * 7.0) * ip.z - 1.0;\n  p.w = 1.5 - dot(abs(p.xyz), ones.xyz);\n  s = vec4(lessThan(p, vec4(0.0)));\n  p.xyz = p.xyz + (s.xyz*2.0 - 1.0) * s.www; \n\n  return p;\n  }\n\t\t\t\t\t\t\n// (sqrt(5) - 1)/4 = F4, used once below\n#define F4 0.309016994374947451\n\nfloat snoise(vec4 v)\n  {\n  const vec4  C = vec4( 0.138196601125011,  // (5 - sqrt(5))/20  G4\n                        0.276393202250021,  // 2 * G4\n                        0.414589803375032,  // 3 * G4\n                       -0.447213595499958); // -1 + 4 * G4\n\n// First corner\n  vec4 i  = floor(v + dot(v, vec4(F4)) );\n  vec4 x0 = v -   i + dot(i, C.xxxx);\n\n// Other corners\n\n// Rank sorting originally contributed by Bill Licea-Kane, AMD (formerly ATI)\n  vec4 i0;\n  vec3 isX = step( x0.yzw, x0.xxx );\n  vec3 isYZ = step( x0.zww, x0.yyz );\n//  i0.x = dot( isX, vec3( 1.0 ) );\n  i0.x = isX.x + isX.y + isX.z;\n  i0.yzw = 1.0 - isX;\n//  i0.y += dot( isYZ.xy, vec2( 1.0 ) );\n  i0.y += isYZ.x + isYZ.y;\n  i0.zw += 1.0 - isYZ.xy;\n  i0.z += isYZ.z;\n  i0.w += 1.0 - isYZ.z;\n\n  // i0 now contains the unique values 0,1,2,3 in each channel\n  vec4 i3 = clamp( i0, 0.0, 1.0 );\n  vec4 i2 = clamp( i0-1.0, 0.0, 1.0 );\n  vec4 i1 = clamp( i0-2.0, 0.0, 1.0 );\n\n  //  x0 = x0 - 0.0 + 0.0 * C.xxxx\n  //  x1 = x0 - i1  + 1.0 * C.xxxx\n  //  x2 = x0 - i2  + 2.0 * C.xxxx\n  //  x3 = x0 - i3  + 3.0 * C.xxxx\n  //  x4 = x0 - 1.0 + 4.0 * C.xxxx\n  vec4 x1 = x0 - i1 + C.xxxx;\n  vec4 x2 = x0 - i2 + C.yyyy;\n  vec4 x3 = x0 - i3 + C.zzzz;\n  vec4 x4 = x0 + C.wwww;\n\n// Permutations\n  i = mod289(i); \n  float j0 = permute( permute( permute( permute(i.w) + i.z) + i.y) + i.x);\n  vec4 j1 = permute( permute( permute( permute (\n             i.w + vec4(i1.w, i2.w, i3.w, 1.0 ))\n           + i.z + vec4(i1.z, i2.z, i3.z, 1.0 ))\n           + i.y + vec4(i1.y, i2.y, i3.y, 1.0 ))\n           + i.x + vec4(i1.x, i2.x, i3.x, 1.0 ));\n\n// Gradients: 7x7x6 points over a cube, mapped onto a 4-cross polytope\n// 7*7*6 = 294, which is close to the ring size 17*17 = 289.\n  vec4 ip = vec4(1.0/294.0, 1.0/49.0, 1.0/7.0, 0.0) ;\n\n  vec4 p0 = grad4(j0,   ip);\n  vec4 p1 = grad4(j1.x, ip);\n  vec4 p2 = grad4(j1.y, ip);\n  vec4 p3 = grad4(j1.z, ip);\n  vec4 p4 = grad4(j1.w, ip);\n\n// Normalise gradients\n  vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));\n  p0 *= norm.x;\n  p1 *= norm.y;\n  p2 *= norm.z;\n  p3 *= norm.w;\n  p4 *= taylorInvSqrt(dot(p4,p4));\n\n// Mix contributions from the five corners\n  vec3 m0 = max(0.6 - vec3(dot(x0,x0), dot(x1,x1), dot(x2,x2)), 0.0);\n  vec2 m1 = max(0.6 - vec2(dot(x3,x3), dot(x4,x4)            ), 0.0);\n  m0 = m0 * m0;\n  m1 = m1 * m1;\n  return 49.0 * ( dot(m0*m0, vec3( dot( p0, x0 ), dot( p1, x1 ), dot( p2, x2 )))\n               + dot(m1*m1, vec2( dot( p3, x3 ), dot( p4, x4 ) ) ) ) ;\n\n  }\n","name":"Common","description":"","type":"common"}]}
{"ver":"0.1","info":{"id":"7sV3Rh","date":"1633814594","viewed":1445,"name":"IRIDESCENCE: THIN FILM","username":"alro","description":"Use mouse to move camera","likes":47,"published":1,"flags":32,"usePreview":0,"tags":["interference","bubble","metal","colour","shiny","pbr","wavelength","iridescence","spectral","pearl","opal"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4df3Rr","filepath":"/media/a/3871e838723dd6b166e490664eead8ec60aedd6b8d95bc8e2fe3f882f0fd90f0.jpg","previewfilepath":"/media/ap/3871e838723dd6b166e490664eead8ec60aedd6b8d95bc8e2fe3f882f0fd90f0.jpg","type":"texture","channel":3,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/* \n\n    Investigating thin film iridescence rendering based on the example by Bacterius. This \n    shadertoy uses the PBR+IBL workflow but it's not energy conserving. Main limits are the \n    simplistic modelling of thin film effects as well as the lack of proper handling of \n    roughness, IBL and material conductivity.\n\n    Diffraction grating iridescence: https://www.shadertoy.com/view/7dVGzz\n\n    Based on:\n    https://www.gamedev.net/tutorials/programming/graphics/thin-film-interference-for-computer-graphics-r2962/\n    https://kwsong.github.io/projects/graphics/\n    https://docs.chaosgroup.com/display/OSLShaders/Thin+Film+Shader\n    https://belcour.github.io/blog/slides/2017-brdf-thin-film/slides.html\n    https://en.wikipedia.org/wiki/Thin-film_interference\n    https://light.informatik.uni-bonn.de/papers/HuangEtAl-SoapBubbles-SIGGRAPH2020.pdf\n    https://www.shadertoy.com/view/3tlBW7\n\n    We find the amount of light transmitted through a thin film layer by modelling an infinite\n    number of reflection and transmission events. Light travelling through the thin film has a\n    different phase compared to the incident light due to a different optical path depth and \n    reflections off substance interfaces. The constructive and destructive effects are applied\n    to red, green and blue light separately and they result in a variation in colour based on\n    viewing angle, materials and film thickness.\n\n    Questions (answers and corrections are welcome):\n\n    1) Why does the approach often deal with the external/internal material pair rather than \n    treat the two interfaces separately?\n\n    2) What effects do roughness and conductor/dielectric properties have physically?\n\n    3) What is the nature of a \"beam\" light which is used to explain the ratio modifier?\n    In what sense does the incident wave have a \"surface area\"?\n    Why is there only one modifier when there are two interfaces?\n\n    4) Why does reducing layer thickness to 0 not give old Fresnel result? (bug?)\n\n    5) How to correctly approximate IBL?\n\n*/\n\n//  ----------------------- Uncomment to view buffer outputs -----------------------\n\n// Use the matrices from BufferB to replace the environment map\n//#define DISPLAY_DIFFUSE_SH\n\n\n// The equirectangular projection of the cubemap from BufferB\n//#define DISPLAY_ENVIRONMENT_MAP\n\n\n// Prefiltered maps and BRDF integration map from BufferC\n//#define DISPLAY_SPECULAR_MAPS\n\n\n//  --------------------------------------------------------------------------------\n\n// Variable iterator initializer to stop loop unrolling\n#define ZERO (min(iFrame,0))\n\n// Triplanar mapping\nconst vec3 DETAIL_SCALE = vec3(0.05);\nconst vec3 BLENDING_SHARPNESS = vec3(4.0);\n\n// Raymaching of scene geometry\nconst float EPSILON = 1e-3;\nconst float MIN_DIST = 0.01;\nconst int MAX_STEPS = 128;\nconst float MAX_DIST = 100.0;\n\nconst float CELL = 10.0;\nconst float HALF_CELL = 0.5 * CELL;\n\n//----------------------------- Camera ------------------------------\n\nvec3 rayDirection(float fieldOfView, vec2 fragCoord) {\n    vec2 xy = fragCoord - iResolution.xy / 2.0;\n    float z = (0.5 * iResolution.y) / tan(radians(fieldOfView) / 2.0);\n    return normalize(vec3(xy, -z));\n}\n\n//https://www.geertarien.com/blog/2017/07/30/breakdown-of-the-lookAt-function-in-OpenGL/\nmat3 lookAt(vec3 camera, vec3 targetDir, vec3 up){\n    vec3 zaxis = normalize(targetDir);    \n    vec3 xaxis = normalize(cross(zaxis, up));\n    vec3 yaxis = cross(xaxis, zaxis);\n\n    return mat3(xaxis, yaxis, -zaxis);\n}\n\n//-------------------------- SDF and scene ---------------------------\n\nvec3 rotate(vec3 p, vec4 q){\n    return 2.0 * cross(q.xyz, p * q.w + cross(q.xyz, p)) + p;\n}\n\nvec3 getRotation(vec3 p){\n    float angle = PI;\n    vec3 axis = normalize(vec3(1.0, 1.0, 1.0));\n    return rotate(p, vec4(axis * sin(-angle*0.5), cos(-angle*0.5))); \n}\n\n//https://iquilezles.org/articles/distfunctions\nfloat boxSDF( vec3 p, vec3 b ){\n    vec3 q = abs(p) - b;\n    return length(max(q, 0.0)) + min(max(q.x, max(q.y, q.z)), 0.0);\n}\n\nfloat sphereSDF(vec3 p, float radius) {\n    return length(p) - radius;\n}\n\nfloat torusSDF( vec3 p, vec2 t ){\n  vec2 q = vec2(length(p.xz) - t.x, p.y);\n  return length(q) - t.y;\n}\n\n//The domain is repeated and clamped. Store the cell a point is in to vary materials\nvec3 getIndex(vec3 p){\n    return 1.0 + floor((p+HALF_CELL) / CELL);\n}\n\nfloat getSDF(vec3 position, bool opaque) {\n\n\n    vec3 idx = getIndex(position);\n    if(opaque && idx.x == 2.0){\n        return 1.0;\n    }else if(!opaque && idx.x != 2.0){\n        return 1.0;\n    }\n\n    vec3 l = vec3(1, 0, 1);    \n    position = position - CELL * clamp(round(position / CELL), -l, l);\n\n   \tposition = getRotation(position);\n\n    if(idx.z == 2.0){\n        return sphereSDF(position, 3.0);\n    }else if(idx.z == 1.0){\n        return boxSDF(position, vec3(2.2));\n    }else{\n        return torusSDF(position, vec2(2.0, 1.4));\n    }\n\n}\n\n// Tetrahedral normal technique with a loop to avoid inlining getSDF()\n// This should improve compilation times\n// https://iquilezles.org/articles/normalsSDF\nvec3 getNormal(vec3 p, bool opaque){\n    vec3 n = vec3(0.0);\n    for(int i = ZERO; i < 4; i++){\n        vec3 e = 0.5773*(2.0*vec3((((i+3)>>1)&1),((i>>1)&1),(i&1))-1.0);\n        n += e*getSDF(p+e*EPSILON, opaque);\n    }\n    return normalize(n);\n}\n\n\nvec3 getTriplanar(vec3 position, vec3 normal){\n    position = getRotation(position);\n    normal = getRotation(normal);\n    \n    vec3 xaxis;\n    vec3 yaxis;\n    vec3 zaxis;\n\n    xaxis = texture(iChannel3, DETAIL_SCALE.x * (position.zy)).rgb;\n    yaxis = texture(iChannel3, DETAIL_SCALE.y * (position.zx)).rgb;\n    zaxis = texture(iChannel3, DETAIL_SCALE.z * (position.xy)).rgb;\n\n    vec3 blending = abs(normal);\n\tblending = normalize(max(blending, 1e-5));\n    blending = pow(blending, BLENDING_SHARPNESS);\n\tblending /= (blending.x + blending.y + blending.z);\n    \n    return vec3(xaxis * blending.x + \n                yaxis * blending.y + \n                zaxis * blending.z);\n\n}\n\n//---------------------------- Raymarching ----------------------------\n\nfloat distanceToScene(vec3 cameraPos, vec3 rayDir, float start, float end, bool opaque) {\n\t\n    // Start at a predefined distance from the camera in the ray direction\n    float depth = start;\n    \n    // Variable that tracks the distance to the scene at the current ray endpoint\n    float dist;\n    \n    // For a set number of steps\n    for (int i = 0; i < MAX_STEPS; i++) {\n        \n        // Get the SDF value at the ray endpoint, giving the maximum \n        // safe distance we can travel in any direction without hitting a surface\n        // Reduce to half step for crowded repeated scene\n        dist = 0.5 * getSDF(cameraPos + depth * rayDir, opaque);\n        \n        // If the distance is small enough, we have hit a surface\n        // Return the depth that the ray travelled through the scene\n        if(dist < EPSILON){\n            return depth;\n        }\n        \n        // Else, march the ray by the sdf value\n        depth += dist;\n        \n        // Test if we have left the scene\n        if(depth >= end){\n            return end;\n        }\n    }\n    \n    // Return max value if we hit nothing but remain in the scene after max steps\n    return end;\n}\n\n\n//---------------------------- Iridescence ----------------------------\n\n/*\n   https://en.wikipedia.org/wiki/Polarization_(waves)#s_and_p_designations\n   https://en.wikipedia.org/wiki/Fresnel_equations\n\n   Light waves are polarized. This can be described in the coordinate system of the \n   plane of incidence which holds the surface normal and the view ray. s-polarized is \n   perpendicular and p-polarized is parallel to the plane. The following functions give\n   the Fresnel equations for reflection and transmission of p- and s-polarized light.\n\n   cosI: angle of normal and incident ray\n   cosR: angle of normal and reflected/refracted ray\n\n*/\n\n// Reflection coefficient (s-polarized)\nfloat rs(float n1, float n2, float cosI, float cosR) {\n    return (n1 * cosI - n2 * cosR) / (n1 * cosI + n2 * cosR);\n}\n \n// Reflection coefficient (p-polarized)\nfloat rp(float n1, float n2, float cosI, float cosR) {\n    return (n2 * cosI - n1 * cosR) / (n1 * cosR + n2 * cosI);\n}\n \n// Transmission coefficient (s-polarized)\nfloat ts(float n1, float n2, float cosI, float cosR) {\n    return 2.0 * n1 * cosI / (n1 * cosI + n2 * cosR);\n}\n \n// Transmission coefficient (p-polarized)\nfloat tp(float n1, float n2, float cosI, float cosR) {\n    return 2.0 * n1 * cosI / (n1 * cosR + n2 * cosI);\n}\n\n/*\n\n  We model a thin layer of material between the outer medium (air) and an internal material \n  (can be air for bubbles).\n  External medium index is 0, thin layer index is 1 and the internal index is 2.\n\n  We are interested in how much light at a given weavelength is reflected back into the outer\n  medium (R). We assume nothing is absorbed.\n  It's easier to find how much is transmitted into the internal medium (T) and use the \n  equation R = 1 - T to find the reflected quantity.\n\n*/\n\nfloat thinFilmReflectance(float cos0, float lambda, float thickness, \n                          float n0, float n1, float n2) {\n\n    // Waves reflecting off a denser medium than the current one are phase shifted\n    // by 180 degrees. The reflections occur at the top and bottom of the layer once\n    // the light is inside the layer (i.e. the indices are correct).\n    float d10 = (n1 >= n0) ? 0.0 : PI;\n    float d12 = (n1 >= n2) ? 0.0 : PI;\n    float delta = d10 + d12;\n\n    /*\n    \n      We have the cosine of the incident ray (dot product with normal) and we need the cosine\n      of the refracted ray.\n      First we find the sine of the refracted ray using Snell's law and the Pythagorean \n      identity and then the cosine from the Pythagorean identity\n\n      Snell's law \n      sin(a)/sin(b) = n0/n1 --> sin(b) = (n0/n1) * sin(a)\n    \n      Pythagorean Identity\n      sin(a)^2 + cos(a)^2 = 1 --> sin(a) = sqrt(1 - cos(a)^2)\n\n    */\n\n    // Geometry of top interface\n    float sin1 = pow(n0 / n1, 2.0) * (1.0 - pow(cos0, 2.0));\n    if(sin1 > 1.0){\n        // Total internal reflection\n        return 1.0;\n    }\n    float cos1 = sqrt(1.0 - sin1);\n\n    // Geometry of bottom interface\n    // Original approach uses n0 and cos0 although the problem deals with the second interface\n    // Q: Is this subsitution correct/needed?\n    float sin2 = pow(n1 / n2, 2.0) * (1.0 - pow(cos1, 2.0));\n    if (sin2 > 1.0){\n        // Total internal reflection\n        return 1.0;\n    }\n    float cos2 = sqrt(1.0 - sin2);\n     \n    // Find the reflection (alpha) and transmission (beta) amplitude Fresnel coefficients for\n    // s- and p-polarized light \n    float alpha_s = rs(n1, n0, cos1, cos0) * rs(n1, n2, cos1, cos2);\n    float alpha_p = rp(n1, n0, cos1, cos0) * rp(n1, n2, cos1, cos2);\n     \n    float beta_s = ts(n0, n1, cos0, cos1) * ts(n1, n2, cos1, cos2);\n    float beta_p = tp(n0, n1, cos0, cos1) * tp(n1, n2, cos1, cos2);\n\n    // https://en.wikipedia.org/wiki/Thin-film_interference\n    // Compute the phase change term based on the optical path difference\n    float phi = (2.0 * PI / lambda) * (2.0 * n1 * thickness * cos1) + delta;\n         \n    // Evaluate the transmitted intensity for both polarizations\n    // This is the closed form solution to the geometric series of infinite bounces inside the\n    // layer\n    // https://en.wikipedia.org/wiki/Geometric_series\n    float ts = pow(beta_s, 2.0) / (pow(alpha_s, 2.0) - 2.0 * alpha_s * cos(phi) + 1.0);\n    float tp = pow(beta_p, 2.0) / (pow(alpha_p, 2.0) - 2.0 * alpha_p * cos(phi) + 1.0);\n     \n    // As the ray crosses a material interface, the speed and \"area of the beam of light\" \n    // change and must be included in the intensity calculations.\n    // Q: Why only consider the change between internal and external material and not the \n    // layer?\n    float beamRatio = (n2 * cos2) / (n0 * cos0);\n     \n    // Get the average transmission of s- and p-polarized light, weighted by the change of \n    // light geometry\n    float t = beamRatio * (ts + tp) / 2.0;\n     \n    // Return reflected intensity assuming T + R = 1 (nothing is absorbed)\n    return min(1.0, max(0.0, 1.0 - t));\n}\n\n//---------------------------- PBR ----------------------------\n\n// BufferB writes matrices of the spherical harmonics coefficients for red, green and blue.\n// These can be used to get the channel value in a given direction\nvec3 getSHIrradiance(vec3 normal){\n\n    vec4 n = vec4(normal, 1.0);\n    \n    mat4 redMatrix = mat4(\n        texelFetch(iChannel1, ivec2(0,0), 0),\n        texelFetch(iChannel1, ivec2(0,1), 0),\n        texelFetch(iChannel1, ivec2(0,2), 0),\n        texelFetch(iChannel1, ivec2(0,3), 0));\n    \n    \n    mat4 grnMatrix = mat4(\n        texelFetch(iChannel1, ivec2(1,0), 0),\n        texelFetch(iChannel1, ivec2(1,1), 0),\n        texelFetch(iChannel1, ivec2(1,2), 0),\n        texelFetch(iChannel1, ivec2(1,3), 0));\n    \n    \n    mat4 bluMatrix = mat4(\n        texelFetch(iChannel1, ivec2(2,0), 0),\n        texelFetch(iChannel1, ivec2(2,1), 0),\n        texelFetch(iChannel1, ivec2(2,2), 0),\n        texelFetch(iChannel1, ivec2(2,3), 0));\n    \n    float r = dot(n, redMatrix * n);\n    float g = dot(n, grnMatrix * n);\n    float b = dot(n, bluMatrix * n);\n    \n    return vec3(r, g, b);\n}\n\n// Get the environment colour from the equirectangular projection of the cubemap from bufferB\n// Clamp texture coordinates to reduce the seam artifact\nvec3 getEnvironment(vec3 rayDir, vec2 scaleSize){\n    vec2 texCoord = vec2((atan(rayDir.z, rayDir.x) / TWO_PI) + 0.5, acos(rayDir.y) / PI);\n    texCoord.x = clamp(texCoord.x, 1.e-3, 0.999);\n    texCoord *= scaleSize;\n    return texture(iChannel1, texCoord).rgb;\n}\n\n// Get two prefiltered roughness environment maps and linearly interpolate\n// between them to get the roughness data needed.\nvec3 getEnvironment(vec3 rayDir, float roughness, vec2 scaleSize){\n\n    //There are 5 levels of roughness (0.0, 0.25, 0.5, 0.75, 1.0)\n    float level1 = floor(1.0+(roughness) * 5.0);\n    \n    //Level 0 would give us the entire atlas\n    level1 = max(1.0, level1);\n    \n    float level2 = level1 + 1.0;\n    level2 = min(level2, 5.0);\n    \n    //The dimensions of the projection tile as a fraction of the viewport.\n    float size1 = 1.0/pow(2.0, level1);\n    float size2 = 1.0/pow(2.0, level2);\n    \n    //The offset in the x direction. y offset is always 0\n    float offset1 = 0.0;\n    float i;\n    //The offset of the tile in the atlas is the sum of tiles before it (1/2 + 1/4 + ...)\n    for(i = 1.0; i < level1; i++){\n    \toffset1 += 1.0/pow(2.0, i);\n    }\n    \n    float offset2 = offset1 + 1.0/pow(2.0, i);\n    \n    vec2 texCoord1 = vec2((atan(rayDir.z, rayDir.x) / TWO_PI) + 0.5, acos(rayDir.y) / PI);\n                    \n    vec2 texCoord2 = vec2((atan(rayDir.z, rayDir.x) / TWO_PI) + 0.5, acos(rayDir.y) / PI);\n\n    float f = fract(roughness * 5.0);\n    \n    // Clamp texture coordinates to reduce the seam artifact. Depends on level.\n    texCoord1.x = clamp(texCoord1.x, 0.0 + level1 * 0.005, 1.0 - level1 * 0.005);\n    texCoord2.x = clamp(texCoord2.x, 0.0 + level2 * 0.005, 1.0 - level2 * 0.005);\n    \n    \n    // Scale and offset to correct atlas tile\n    texCoord1 = vec2(offset1, 0.0) + size1 * texCoord1;\n    texCoord2 = vec2(offset2, 0.0) + size2 * texCoord2;\n    \n    // When changing to fullscreen, the atlas is not rerendered. \n    // Find the scaled relative coordinates\n    texCoord1 *= scaleSize;\n    texCoord2 *= scaleSize;\n    \n    return mix(texture(iChannel2, texCoord1).rgb, texture(iChannel2, texCoord2).rgb, f);\n}\n\nvec2 getBRDFIntegrationMap(vec2 coord, vec2 scaleSize){\n    // Avoid reading outside the tile in the atlas\n    coord = clamp(coord, 1e-5, 0.99);\n    vec2 texCoord = vec2(coord.x/2.0, coord.y / 2.0 + 0.5);\n    texCoord *= scaleSize;\n    return texture(iChannel2, texCoord).rg;\n}\n\n//Trowbridge-Reitz\nfloat distribution(vec3 n, vec3 h, float roughness){\n    float a_2 = roughness*roughness;\n\treturn a_2/(PI*pow(pow(dot_c(n, h), 2.0) * (a_2 - 1.0) + 1.0, 2.0));\n}\n\n//GGX and Schlick-Beckmann\nfloat geometry(float cosTheta, float k){\n\treturn (cosTheta)/(cosTheta*(1.0-k)+k);\n}\n\nfloat smiths(vec3 n, vec3 viewDir, vec3 lightDir, float roughness){\n    float k = pow(roughness + 1.0, 2.0)/8.0; \n\treturn geometry(dot_c(n, lightDir), k) * geometry(dot_c(n, viewDir), k);\n}\n\nvec4 getAlbedoAndRoughness(vec3 p, vec3 idx){\n\n    vec3 col = vec3(0.05);\n    float roughness = 0.01;\n\n    // Corner dielectric\n    if(idx.x == 0.0 && idx.z == 0.0){\n        col = vec3(0.15);\n    }\n    \n    // Tinted metal\n    if(idx.x == 1.0 && idx.z == 1.0){\n        col = vec3(0.3, 0.2, 0.1);\n        roughness = 0.15;\n    }\n    \n    // Rough light dielectric\n    if(idx.x == 0.0 && idx.z == 2.0){\n        col = vec3(0.8);\n        roughness = 0.25;\n    }\n    \n    // Rough metal\n    if(idx.x == 1.0 && idx.z == 2.0){\n        col = vec3(0.4);\n        roughness = 0.2;\n    }\n    \n    // Pattern\n    if(idx.x == 0.0 && idx.z == 1.0){\n        col = vec3(0.1);\n        roughness = 0.3;\n    }\n\n    return vec4(col, roughness);\n}\n\nvec3 getIORs(vec3 p, vec3 idx, vec3 n){\n\n    // Indices of refraction\n    float nExternal = 1.0;\n    float nFilm = 1.5;\n    float nInternal = 3.0;\n\n    // Bubbles\n    if(idx.x == 2.0){\n        nInternal = 1.0;\n    }\n\n    return vec3(nExternal, nFilm, nInternal);\n}\n\n// In nanometres\nfloat getLayerThickness(vec3 p, vec3 idx, vec3 n){\n    \n    // Corner dielectric and bubbles\n    if(idx.x == 0.0 && idx.z == 0.0 || idx.x == 2.0){\n        float t = length(getTriplanar(p, n));\n        // Bubbles\n        if(idx.x == 2.0){\n           return mix(400.0, 550.0, t);\n        }\n        return mix(100.0, 250.0, t);\n    }\n\n    // Pattern\n    if(idx.x == 0.0 && idx.z == 1.0){\n        float scale = 4.5;\n        return mix(350.0, 475.0, smoothstep(0.0, 0.2, sin(scale * p.x)));\n    }\n    \n    // Tinted metal\n    if(idx.x == 1.0 && idx.z == 1.0){\n        return 700.0;\n    }\n    \n    // Rough light metal\n    if(idx.x == 1.0 && idx.z == 2.0){\n        return 900.0;\n    }\n\n    return 400.0;\n}\n\nvec3 fresnelIridescentRoughness(vec3 p, vec3 n, float cosTheta, vec3 F0, float roughness){\n\n    vec3 idx = getIndex(p);\n\n    float thickness = getLayerThickness(p, idx, n);\n\n    vec3 IORs = getIORs(p, idx, n);\n\n    float r = thinFilmReflectance(cosTheta, 650.0, thickness, IORs.x, IORs.y, IORs.z);\n    float g = thinFilmReflectance(cosTheta, 510.0, thickness, IORs.x, IORs.y, IORs.z);\n    float b = thinFilmReflectance(cosTheta, 475.0, thickness, IORs.x, IORs.y, IORs.z);\n\n    // Q: What would be the correct way to handle roughness?\n    //    Does F0 change?\n    return F0 + (max(vec3(1.0-roughness), F0) - F0) * vec3(r, g, b);\n}\n\n\n//Cook-Torrance BRDF\nvec3 BRDF(vec3 p, vec3 n, vec3 viewDir, vec3 lightDir, vec3 albedo, float metalness, \n            float roughness, vec3 F0){\n            \n    vec3 h = normalize(viewDir + lightDir);\n    float cosTheta = dot_c(h, viewDir);\n    \n    //Diffuse reflectance\n    vec3 lambertian = albedo / PI;\n    \n    //Normal distribution\n    //What fraction of microfacets are aligned in the correct direction\n    float D;\n\n    //Fresnel term\n    //How reflective are the microfacets viewed from the current angle\n    vec3 F = fresnelIridescentRoughness(p, n, cosTheta, F0, roughness);\n\n    //Geometry term\n    //What fraction of the microfacets are lit and visible\n    float G;\n    \n    //Visibility term. \n    //In Filament it combines the geometry term and the denominator\n    float V;\n    \n    \n    D = distribution(n, h, roughness);\n    G = smiths(n, viewDir, lightDir, roughness);\n    V = G / max(1e-4, (4.0 * dot_c(lightDir, n) * dot_c(viewDir, n)));\n    \n    //Specular reflectance\n    vec3 specular = D * F * V;\n    \n    //Combine diffuse and specular\n    vec3 kD = (1.0 - F) * (1.0 - metalness);\n\n    // If rendering bubbles return only specular reflection\n    if(getIndex(p).x == 2.0){\n        return specular;\n    }\n    return kD * lambertian + specular;\n}\n\nvec3 getIrradiance(vec3 p, vec3 rayDir, vec3 n, vec2 scaleSize, vec3 diffuseTransparent){\n    \n    vec3 idx = getIndex(p);\n    vec4 data = getAlbedoAndRoughness(p, idx);\n    vec3 albedo = data.rgb;\n    float metalness = 0.0;\n    if(idx.x == 1.0){\n        metalness = 1.0;\n    }\n    float roughness = max(0.01, data.a);\n    vec3 F0 = vec3(0.04);\n    //albedo = fresnelIridescentRoughness(p, normal, dot_c(n, -rayDir), F0, 0.01);\n    \n    //Metals tint specular reflections.\n    vec3 tintColour = albedo;\n\n    F0 = mix(F0, tintColour, metalness);\n    vec3 F = fresnelIridescentRoughness(p, n, dot_c(n, -rayDir), F0, roughness);\n\n    vec3 position = vec3(0.0, 10.0, 0.0);\n    vec3 lightDir = normalize(position-p);\n    vec3 lightColour = vec3(2.0);\n    vec3 radiance = 1.0 * lightColour;\n\n    // Find direct lighting component\n    vec3 I = BRDF(p, n, -rayDir, lightDir, albedo, metalness, roughness, F0) \n            * radiance \n            * dot_c(n, lightDir);\n\n    // Find ambient diffuse ambient component\n\tvec3 irradiance = getSHIrradiance(n);\n\tvec3 diffuse    = irradiance * albedo / PI;\n    \n    // When rendering bubbles, diffuse is from cubemap\n    if(idx.x == 2.0){\n        diffuse = diffuseTransparent;\n    }\n\n    // Find ambient specular component\n    vec3 prefilteredColor = getEnvironment(reflect(rayDir, n), roughness, scaleSize);   \n    vec2 envBRDF  = getBRDFIntegrationMap(vec2(dot_c(n, -rayDir), roughness), scaleSize);\n    vec3 specular = prefilteredColor * (F * envBRDF.x + envBRDF.y);\n    \n    // Combine ambient lighting\n\tvec3 kD = 1.0 - F;\n    kD *= 1.0 - metalness;\n\tvec3 ambient  = kD * diffuse + specular;\n    \n    // Combine direct and ambient lighting\n    return ambient + I;\n}\n\n//----------------------- Tonemapping and render ------------------------\n\n//https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/\nvec3 ACESFilm(vec3 x){\n    return clamp((x * (2.51 * x + 0.03)) / (x * (2.43 * x + 0.59) + 0.14), 0.0, 1.0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n\n    //Read the size of the texture atlas and environment map\n    vec2 atlasSize = texelFetch(iChannel2, ivec2(5.5), 0).rg;\n    vec2 scaleSize = 1.0/(iResolution.xy/atlasSize);\n\n    // Get the default direction of the ray (along the negative Z direction)\n    vec3 rayDir = rayDirection(60.0, fragCoord);\n    \n    //----------------- Define a camera -----------------\n\n    vec3 cameraPos = texelFetch(iChannel0, ivec2(0.5, 1.5), 0).xyz;\n\n    vec3 targetDir = -cameraPos;\n\n    vec3 up = vec3(0.0, 1.0, 0.0);\n\n    // Get the view matrix from the camera orientation.\n    mat3 viewMatrix = lookAt(cameraPos, targetDir, up);\n\n    // Transform the ray to point in the correct direction.\n    rayDir = normalize(viewMatrix * rayDir);\n\n    //---------------------------------------------------\n    \n    float dist = distanceToScene(cameraPos, rayDir, MIN_DIST, MAX_DIST, true);\n\n    vec3 col = vec3(0);\n    \n    if(dist < MAX_DIST){\n\n        vec3 position = cameraPos + rayDir * dist;\n        vec3 normal = getNormal(position, true);\n        \n        col = getIrradiance(position, rayDir, normal, scaleSize, vec3(0));\n\n    }else{\n        col = getEnvironment(rayDir, scaleSize);\n        #ifdef DISPLAY_DIFFUSE_SH\n            col = getSHIrradiance(rayDir);\n        #endif\n    }\n    \n    float distTransparent = distanceToScene(cameraPos, rayDir, MIN_DIST, dist, false);\n    \n    if(distTransparent < dist){\n\n        vec3 position = cameraPos + rayDir * distTransparent;\n        vec3 normal = getNormal(position, false);\n        \n        col = getIrradiance(position, rayDir, normal, scaleSize, col);    \n    }\n\n\n    // Tonemapping\n    col = ACESFilm(col);\n\n    vec2 uv = fragCoord.xy/iResolution.xy;\n\n    #ifdef DISPLAY_ENVIRONMENT_MAP\n        col = texture(iChannel1, uv*scaleSize).rgb;\n    #endif\n    \n    #ifdef DISPLAY_SPECULAR_MAPS\n        col = texture(iChannel2, uv*scaleSize).rgb;\n    #endif\n\n    // Gamma\n    col = gamma(col);\n\n    fragColor = vec4(col, 1.0);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"/*\n    Copyright (c) 2021 al-ro\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in all\n    copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    SOFTWARE.\n*/\n\n#define PI 3.14159\n#define TWO_PI (2.0 * PI)\n#define HALF_PI (0.5 * PI)\n\n#define GAMMA 2.2\n#define INV_GAMMA (1.0/GAMMA)\n\n#define ENV_FILTERING 0\n\n#define SPH_SAMPLE_COUNT 256.0\n#define SPH_LOW_SAMPLE_COUNT 128.0\n\n#define BRDF_SAMPLE_COUNT 256\n#define BRDF_LOW_SAMPLE_COUNT 128\n\n#if ENV_FILTERING == 1\n    #define SAMPLE_COUNT 256\n    #define LOW_SAMPLE_COUNT 128\n#else\n    #define SAMPLE_COUNT 256\n    #define LOW_SAMPLE_COUNT 128\n#endif\n\n//  Variable iterator initializer to stop loop unrolling\n#define ZERO (min(iFrame,0))\n\nconst float minDot = 1e-5;\n\n// Clamped dot product\nfloat dot_c(vec3 a, vec3 b){\n\treturn max(dot(a, b), minDot);\n}\n\n// Get orthonormal basis from surface normal\n// https://graphics.pixar.com/library/OrthonormalB/paper.pdf\nvoid pixarONB(vec3 n, out vec3 b1, out vec3 b2){\n\tfloat sign_ = sign(n.z);\n\tfloat a = -1.0 / (sign_ + n.z);\n\tfloat b = n.x * n.y * a;\n\tb1 = vec3(1.0 + sign_ * n.x * n.x * a, sign_ * b, -sign_ * n.x);\n\tb2 = vec3(b, sign_ + n.y * n.y * a, -n.y);\n}\n\nvec3 gamma(vec3 col){\n\treturn pow(col, vec3(INV_GAMMA));\n}\n\nvec3 inv_gamma(vec3 col){\n\treturn pow(col, vec3(GAMMA));\n}\n\nfloat saturate(float x){\n    return max(0.0, min(x, 1.0));\n}\n\nfloat modulo(float m, float n){\n  return mod(mod(m, n) + n, n);\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//  Track mouse movement and resolution change between frames and set camera position.\n\n#define CAMERA_DIST 20.0\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    \n    //Work with just the first four pixels.\n    if((fragCoord.x == 0.5) && (fragCoord.y < 4.0)){\n        \n        vec4 oldData = texelFetch(iChannel0, ivec2(0.5), 0).xyzw;\n\n        vec2 oldPolarAngles = oldData.xy;\n        vec2 oldMouse = oldData.zw;\n\n        vec2 polarAngles = vec2(0);\n        vec2 mouse = iMouse.xy / iResolution.xy; \n        \n        // Stop camera going directly above and below\n        float angleEps = 0.01;\n\n        float mouseDownLastFrame = texelFetch(iChannel0, ivec2(0.5, 3.5), 0).x;\n        \n        // If mouse button is down and was down last frame.\n        if(iMouse.z > 0.0 && mouseDownLastFrame > 0.0){\n            \n            // Difference between mouse position last frame and now.\n            vec2 mouseMove = mouse - oldMouse;\n            polarAngles = oldPolarAngles + vec2(5.0, 3.0) * mouseMove;\n            \n        }else{\n            polarAngles = oldPolarAngles;\n        }\n        \n        polarAngles.x = modulo(polarAngles.x, 2.0 * PI - angleEps);\n        polarAngles.y = min(PI - angleEps, max(angleEps, polarAngles.y));\n\n        // Store mouse data in the first pixel of Buffer A.\n        if(fragCoord == vec2(0.5, 0.5)){\n            // Set value at first frames.\n            if(iFrame < 10){\n                polarAngles = vec2(PI / 4.0, 1.33);\n                mouse = vec2(0);\n            }\n            fragColor = vec4(polarAngles, mouse);\n        }\n\n        // Store camera position in the second pixel of Buffer A.\n        if(fragCoord == vec2(0.5, 1.5)){\n            // Cartesian direction from polar coordinates.\n            vec3 cameraPos = normalize(vec3(-cos(polarAngles.x) * sin(polarAngles.y), \n                                             cos(polarAngles.y), \n                                            -sin(polarAngles.x) * sin(polarAngles.y)));\n\n            fragColor = vec4(CAMERA_DIST * cameraPos, 1.0);\n        }\n        \n        //Store resolution change data in the third pixel of Buffer A.\n        if(fragCoord == vec2(0.5, 2.5)){\n            float resolutionChangeFlag = 0.0;\n            //The resolution last frame.\n            vec2 oldResolution = texelFetch(iChannel0, ivec2(0.5, 2.5), 0).yz;\n            \n            if(iResolution.xy != oldResolution){\n            \tresolutionChangeFlag = 1.0;\n            }\n            \n        \tfragColor = vec4(resolutionChangeFlag, iResolution.xy, 1.0);\n        }\n           \n        //Store whether the mouse button is down in the fourth pixel of Buffer A\n        if(fragCoord == vec2(0.5, 3.5)){\n            if(iMouse.z > 0.0){\n            \tfragColor = vec4(vec3(1.0), 1.0);\n            }else{\n            \tfragColor = vec4(vec3(0.0), 1.0);\n            }\n        }\n        \n    }\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"XsfGzn","filepath":"/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","previewfilepath":"/media/ap/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","type":"cubemap","channel":2,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"/*\n\n    Diffuse IBL using spherical harmonics\n\n    Read the environment map and calculate 9 spherical harmonics coefficients for each channel.\n    The coefficients will describe the low frequency data of the environment. We can use them\n    to construct a matrix which, when multiplied with a view vector, will give the data in \n    that direction. The low frequency data is similar to a convoluted irradiance map and is \n    used for diffuse image based lighting, which gives us the ambient colour for shading. \n\n    Based on:\n    [1] https://cseweb.ucsd.edu/~ravir/papers/envmap/envmap.pdf\n    [2] http://orlandoaguilar.github.io/sh/spherical/harmonics/irradiance/map/2017/02/12/SphericalHarmonics.html\n    [3] https://metashapes.com/blog/realtime-image-based-lighting-using-spherical-harmonics/\n    [4]\thttps://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere/26127012#26127012\n    [5] https://bduvenhage.me/geometry/2019/07/31/generating-equidistant-vectors.html\n    [6] https://andrew-pham.blog/2019/08/26/spherical-harmonics/\n\n    This tab writes the matrix from equation 12 of [1] used in lighting calculations later.\n    We also store an equirectangular projection of the environment map and track cubemap change.\n\n*/\n\n//Constants cn from equation 12 in [1]\nconst float c1 = 0.429043;\nconst float c2 = 0.511664;\nconst float c3 = 0.743125;\nconst float c4 = 0.886227;\nconst float c5 = 0.247708;\n\n//First 9 spherical harmonics coefficients from equation 3 in [1]\nconst float Y00 = 0.282095;\nconst float Y1n = 0.488603; // 3 direction dependent values\nconst float Y2n = 1.092548; // 3 direction dependent values\nconst float Y20 = 0.315392;\nconst float Y22 = 0.546274;\n\nvec3 getRadiance(vec3 dir){\n    //Shadertoy textures are gamma corrected. Undo for lighting calculations.\n    vec3 col = inv_gamma(texture(iChannel2, dir).rgb);\n    // Add some bloom to the environment\n    col += 0.5 * pow(col, vec3(2));\n    return col;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n    vec3 currentColour = texture(iChannel2, vec3(1,1,1)).rgb;\n\n    bool cubemapChangedFlag = texelFetch(iChannel1, ivec2(4.5, 4.5), 0).rgb != currentColour;\n    //bool resolutionChanged = texelFetch(iChannel0, ivec2(0.5, 2.5), 0).r > 0.0;\n    \n    bool run = iFrame == 0 || cubemapChangedFlag;\n    \n    if(run){\n    \n        vec4 col = vec4(0);\n        \n        //  Store an equirectangular projection of the environment map. Subsequent code will\n        //  overwrite specific pixels to store the SPH matrices and state flags but this \n        //  should not be visible in the final render.\n        vec2 texCoord = fragCoord.xy / iResolution.xy;\n        vec2 thetaphi = ((texCoord * 2.0) - vec2(1.0)) * vec2(PI, HALF_PI); \n        vec3 rayDir = vec3( cos(thetaphi.y) * cos(thetaphi.x), \n                           -sin(thetaphi.y), \n                            cos(thetaphi.y) * sin(thetaphi.x));\n\n        col = vec4(getRadiance(rayDir), 1.0);\n        //Ensure radiance is not 0\n        col.x = max(col.x, 1e-5);\n        col.y = max(col.y, 1e-5);\n        col.z = max(col.z, 1e-5);\n\n\n    //------------------------------------------------------------------------------------\n    //----------------------------------- BUG? -------------------------------------------\n    //------- It should be fragCoord.x < 3.0 because we write and read 3 matrices --------\n    //------- But that will give the wrong result and I can't figure out why -------------\n    //------------------------------------------------------------------------------------\n    //------------------------------------------------------------------------------------\n\n        if(fragCoord.x < 4.0 && fragCoord.y < 4.0){\n\n            //Coefficient values to accumulate\n            vec3 L00 = vec3(0);\n            vec3 L1_1 = vec3(0);\n            vec3 L10 = vec3(0);\n            vec3 L11 = vec3(0);\n\n            vec3 L2_2 = vec3(0);\n            vec3 L2_1 = vec3(0);\n            vec3 L20 = vec3(0);\n            vec3 L21 = vec3(0);\n            vec3 L22 = vec3(0);\n\n            //To make the sampling rate scalable and independent of the cubemap dimensions, \n            //we can sample a set number of equidistant directions on a sphere. While this is \n            //not doable for all number of directions, a good approximation is the Fibonacci \n            //spiral on a sphere.\n\n            //From [4]\n            //Golden angle in radians\n            float phi = PI * (3.0 - sqrt(5.0));\n            \n            //The loop should not run every frame but Windows FPS drops anyway. \n            //This seems to have fixed it\n            float sampleCount;\n            if(run){\n                sampleCount = iResolution.x < 2000.0 ? SPH_SAMPLE_COUNT : SPH_LOW_SAMPLE_COUNT;\n            }else{\n                sampleCount = 1.0;\n            }\n\n            for(float i = float(ZERO); i < sampleCount; i++){\n\n                float y = 1.0 - (i / sampleCount) * 2.0;\n                //Radius at y\n                float radius = sqrt(1.0 - y * y);  \n\n                //Golden angle increment\n                float theta = phi * i;\n\n                float x = cos(theta) * radius;\n                float z = sin(theta) * radius;\n\n                //Sample directiion\n                vec3 dir = normalize(vec3(x, y, z));\n\n                //Envronment map value in the direction (interpolated)\n                vec3 radiance = getRadiance(dir);\n\n                //Accumulate value weighted by spherical harmonic coefficient in the direction\n                L00 += radiance * Y00;\n                L1_1 += radiance * Y1n * dir.y;\n                L10 += radiance * Y1n * dir.z;\n                L11 += radiance * Y1n * dir.x;\n                L2_2 += radiance * Y2n * dir.x * dir.y;\n                L2_1 += radiance * Y2n * dir.y * dir.z;\n                L20 += radiance * Y20 * (3.0 * pow(dir.z, 2.0) - 1.0);\n                L21 += radiance * Y2n * dir.x * dir.z;\n                L22 += radiance * Y22 * (pow(dir.x, 2.0) - pow(dir.y, 2.0));\n            }\n\n            //Scale the sum of coefficents on a sphere\n            float factor = 4.0*PI / sampleCount;\n\n            L00 *= factor;\n            L1_1 *= factor;\n            L10 *= factor;\n            L11 *= factor;\n            L2_2 *= factor;\n            L2_1 *= factor;\n            L20 *= factor;\n            L21 *= factor;\n            L22 *= factor;\n\n            //Write three 4x4 matrices to bufferB\n            //GLSL matrices are column major\n            int idxM = int(fragCoord.y-0.5);\n\n            if(fragCoord.x == 0.5){\n                mat4 redMatrix;\n                redMatrix[0] = vec4(c1*L22.r, c1*L2_2.r, c1*L21.r, c2*L11.r);\n                redMatrix[1] = vec4(c1*L2_2.r, -c1*L22.r, c1*L2_1.r, c2*L1_1.r);\n                redMatrix[2] = vec4(c1*L21.r, c1*L2_1.r, c3*L20.r, c2*L10.r);\n                redMatrix[3] = vec4(c2*L11.r, c2*L1_1.r, c2*L10.r, c4*L00.r-c5*L20.r);\n                col = redMatrix[idxM];\n            }\n\n            if(fragCoord.x == 1.5){\n                mat4 grnMatrix;\n                grnMatrix[0] = vec4(c1*L22.g, c1*L2_2.g, c1*L21.g, c2*L11.g);\n                grnMatrix[1] = vec4(c1*L2_2.g, -c1*L22.g, c1*L2_1.g, c2*L1_1.g);\n                grnMatrix[2] = vec4(c1*L21.g, c1*L2_1.g, c3*L20.g, c2*L10.g);\n                grnMatrix[3] = vec4(c2*L11.g, c2*L1_1.g, c2*L10.g, c4*L00.g-c5*L20.g);\n                col = grnMatrix[idxM];\n            }\n\n            if(fragCoord.x == 2.5){\n                mat4 bluMatrix;\n                bluMatrix[0] = vec4(c1*L22.b, c1*L2_2.b, c1*L21.b, c2*L11.b);\n                bluMatrix[1] = vec4(c1*L2_2.b, -c1*L22.b, c1*L2_1.b, c2*L1_1.b);\n                bluMatrix[2] = vec4(c1*L21.b, c1*L2_1.b, c3*L20.b, c2*L10.b);\n                bluMatrix[3] = vec4(c2*L11.b, c2*L1_1.b, c2*L10.b, c4*L00.b-c5*L20.b);\n                col = bluMatrix[idxM];\n            }\n        }\n        \n        //Store a sample colour of the cubemap to detect load and change\n        if(fragCoord.x == 4.5 && fragCoord.y == 4.5){\n              col = vec4(texture(iChannel2, vec3(1,1,1)).rgb, 1.0);\n        }\n        \n        //Store the size of the render\n        if(fragCoord.x == 5.5 && fragCoord.y == 5.5){\n             col = vec4(iResolution.xy, 0.0, 1.0);\n        }\n        \n        fragColor = col;\n    }else{\n        //Reuse data\n        fragColor = texelFetch(iChannel1, ivec2(fragCoord.xy), 0);\n    }\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"/*\n\n    Specular IBL based on:\n\n    https://learnopengl.com/PBR/IBL/Specular-IBL\n    http://holger.dammertz.org/stuff/notes_HammersleyOnHemisphere.html\n    http://www.pbr-book.org/3ed-2018/Sampling_and_Reconstruction/The_Halton_Sampler.html\n    https://google.github.io/filament/Filament.html#annex/choosingimportantdirectionsforsamplingthebrdf\n    https://google.github.io/filament/Filament.html#lighting/imagebasedlights/distantlightprobes\n    https://google.github.io/filament/Filament.html#toc9.5\n\n    Precompute the specular irradiance maps for varying roughness values and lay them out as \n    equirectangular projections in a texture atlas.\n\n    For each roughness level we sample BufferB map in the specular lobe direction using a low \n    discrepancy sequence. The rougher the surface, the larger the specular lobe and the \n    blurrier the final image. \n\n    While the result should depend on both the view direction and the normal, we set these to \n    be equal. This results in wrong reflections especially as the view and normal angle \n    increases but it's an acceptable tradeoff for this approximating approach.\n\n    We also generate a BRDF integration map. This 2 channel image will store the BRDF value \n    based on the roughness of the surface and the angle between the normal and the view ray. \n    This does not depend on the environment map and can be calculated independently of any \n    scene.\n\n*/\n\nvec3 getEnvironment(vec3 rayDir, float level){\n    vec2 texCoord = vec2((atan(rayDir.z, rayDir.x) / TWO_PI) + 0.5, acos(rayDir.y) / PI);\n    return texture(iChannel1, texCoord, level).rgb;\n}\n\n// ------------- Hammersley sequence generation using radical inverse -------------\n\n//  http://holger.dammertz.org/stuff/notes_HammersleyOnHemisphere.html\n//  http://www.pbr-book.org/3ed-2018/Sampling_and_Reconstruction/The_Halton_Sampler.html\n\n//  While it looks like an arcane faerie incantation, it actually makes sense if you follow \n//  the references. Bring some tea.\n\nfloat radicalInverse(uint bits) {\n    bits = (bits << 16u) | (bits >> 16u);\n    bits = ((bits & 0x55555555u) << 1u) | ((bits & 0xAAAAAAAAu) >> 1u);\n    bits = ((bits & 0x33333333u) << 2u) | ((bits & 0xCCCCCCCCu) >> 2u);\n    bits = ((bits & 0x0F0F0F0Fu) << 4u) | ((bits & 0xF0F0F0F0u) >> 4u);\n    bits = ((bits & 0x00FF00FFu) << 8u) | ((bits & 0xFF00FF00u) >> 8u);\n    return float(bits) * 2.3283064365386963e-10; // / 0x100000000\n}\n\nvec2 hammersley(int i, int N){\n    return vec2(float(i)/float(N), radicalInverse(uint(i)));\n}\n\n// -------------------------------------------------------------------------------\n\n//  Return a world space sample vector based on a random hemisphere point, the surface normal\n//  and the roughness of the surface.\n//  https://google.github.io/filament/Filament.html#annex/choosingimportantdirectionsforsamplingthebrdf\n\nvec3 importanceSampleGGX(vec2 randomHemisphere, vec3 N, float roughness){\n    float a = roughness*roughness;\n\t\n    float phi = 2.0 * PI * randomHemisphere.x;\n    float cosTheta = sqrt((1.0 - randomHemisphere.y) / (1.0 + (a*a - 1.0) * randomHemisphere.y));\n    float sinTheta = sqrt(1.0 - cosTheta*cosTheta);\n\t\n    //From spherical coordinates to cartesian coordinates\n    vec3 H = vec3(cos(phi) * sinTheta, sin(phi) * sinTheta, cosTheta);\n\t\n    //From tangent-space vector to world-space sample vector\n    vec3 tangent;\n    vec3 bitangent;\n    \n    pixarONB(N, tangent, bitangent);\n    \n    tangent = normalize(tangent);\n    bitangent = normalize(bitangent);\n\t\n    vec3 sampleDir = tangent * H.x + bitangent * H.y + N * H.z;\n    return normalize(sampleDir);\n}\n\nfloat D_GGX(float NoH, float roughness) {\n    float a = NoH * roughness;\n    float k = roughness / (1.0 - NoH * NoH + a * a);\n    return k * k * (1.0 / PI);\n}\n\nvec3 getPreFilteredColour(vec3 N, float roughness, int sampleCount){\n    vec3 R = N;\n    vec3 V = R;\n    \n    float totalWeight = 0.0;\n    vec3 prefilteredColor = vec3(0.0);    \n    \n    //Generate sampleCount number of a low discrepancy random directions in the \n    //specular lobe and add the environment map data into a weighted sum.\n    for(int i = ZERO; i < sampleCount; i++){\n    \n        vec2 randomHemisphere = hammersley(i, sampleCount);\n        vec3 H  = importanceSampleGGX(randomHemisphere, N, roughness);\n        vec3 L  = normalize(2.0 * dot(V, H) * H - V);\n\n        float NdotL = dot_c(N, L);\n        if(NdotL > 0.0){\n        \n            float level = 0.0;\n            \n        #if ENV_FILTERING == 1\n            // Sample the mip levels of the environment map\n            // https://placeholderart.wordpress.com/2015/07/28/implementation-notes-runtime-environment-map-filtering-for-image-based-lighting/\n            // Vectors to evaluate pdf\n            float NdotH = saturate(dot(N, H));\n            float VdotH = saturate(dot(V, H));\n\n            // Probability distribution function\n            float pdf = D_GGX(NdotH, roughness*roughness) * NdotH / (4.0f * VdotH);\n\n            // Solid angle represented by this sample\n            float omegaS = 1.0 / (float(sampleCount) * pdf);\n            // An arbitrary value from trial and error\n            float envMapSize = 512.0;\n            // Solid angle covered by 1 pixel\n            float omegaP = 4.0 * PI / (6.0 * envMapSize * envMapSize);\n            // Original paper suggests biasing the mip to improve the results\n            float mipBias = 1.0;\n            level = max(0.5 * log2(omegaS / omegaP) + mipBias, 0.0f);\n        #endif\n        \n            prefilteredColor += getEnvironment(L, level) * NdotL;\n            totalWeight      += NdotL;\n        }\n    }\n    prefilteredColor = prefilteredColor / totalWeight;\n\n    return prefilteredColor;\n}\n\n//GGX and Schlick-Beckmann\nfloat geometry(float cosTheta, float k){\n\treturn (cosTheta)/(cosTheta*(1.0-k)+k);\n}\n\n//Geometry for IBL uses a different k than direct lighting\nfloat smithsIBL(float NdotV, float NdotL, float roughness){\n    float k = (roughness * roughness) / 2.0;; \n\treturn geometry(NdotV, k) * geometry(NdotL, k);\n}\n\n//https://google.github.io/filament/Filament.html#toc9.5\nvec2 integrateBRDF(float NdotV, float roughness, int sampleCount){\n\n    vec3 V;\n    V.x = sqrt(1.0 - NdotV*NdotV);\n    V.y = 0.0;\n    V.z = NdotV;\n\n    vec2 result = vec2(0);\n\n    vec3 N = vec3(0.0, 0.0, 1.0);\n    \n    for(int i = ZERO; i < sampleCount; i++){\n    \n        vec2 randomHemisphere = hammersley(i, sampleCount);\n        vec3 H  = importanceSampleGGX(randomHemisphere, N, roughness);\n        vec3 L  = normalize(2.0 * dot(V, H) * H - V);\n\n        float NdotL = max(L.z, 0.0);\n        float NdotH = max(H.z, 0.0);\n        float VdotH = dot_c(V, H);\n\n        if(NdotL > 0.0){\n            float G = smithsIBL(NdotV, NdotL, roughness);\n            float G_Vis = (G * VdotH) / (NdotH * NdotV);\n            float Fc = pow(1.0 - VdotH, 5.0);\n\n            result.x += (1.0 - Fc) * G_Vis;\n            result.y += Fc * G_Vis;\n        }\n    }\n\n    return result / float(sampleCount);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n    vec3 currentColour = texelFetch(iChannel1, ivec2(4.5, 4.5), 0).rgb;\n\n    //If environment map has changed, we need to rerun the convolution\n    bool cubemapChangedFlag = texelFetch(iChannel2, ivec2(4.5, 4.5), 0).rgb != currentColour;\n    \n    //bool resolutionChanged = texelFetch(iChannel0, ivec2(0.5, 2.5), 0).r > 0.0;\n    \n    bool run = iFrame == 0 || iFrame == 10 || cubemapChangedFlag;\n    \n    if(run){\n    \n        //The loop should not run every frame but Windows FPS drops anyway. \n        //This seems to have fixed it\n        int sampleCount;\n        if(run){\n            sampleCount = iResolution.x < 2000.0 ? SAMPLE_COUNT : LOW_SAMPLE_COUNT;\n        }else{\n            sampleCount = 1;\n        }\n    \n        vec3 col = vec3(0);\n        float factor = 1.0/2.0;\n        float roughness = 0.0;\n        \n        if(fragCoord.y < 0.5*iResolution.y){\n            if(fragCoord.x > 0.5*iResolution.x){\n                factor = 1.0/4.0;\n                roughness = 0.25;\n            }    \n            if(fragCoord.x > 0.75*iResolution.x){\n                factor = 1.0/8.0;\n                roughness = 0.5;\n            }\n            if(fragCoord.x > 0.875*iResolution.x){\n                factor = 1.0/16.0;\n                roughness = 0.75;\n            }  \n            if(fragCoord.x > 0.9375*iResolution.x){\n                factor = 1.0/32.0;\n                roughness = 1.0;\n            }\n\n            vec2 texCoord = fragCoord.xy / (iResolution.xy * factor);\n            vec2 thetaphi = ((texCoord * 2.0) - vec2(1.0)) * vec2(PI, HALF_PI); \n            vec3 rayDir = vec3( cos(thetaphi.y) * cos(thetaphi.x), \n                               -sin(thetaphi.y), \n                                cos(thetaphi.y) * sin(thetaphi.x));\n            \n            //Don't do costly prefiltering for roughness 0 and perfect reflection\n            if(fragCoord.x < 0.5*iResolution.x){\n                col = getEnvironment(rayDir, 0.0);\n            }else{\n                col = getPreFilteredColour(rayDir, roughness, sampleCount);\n            }    \n        }else{\n            if(fragCoord.x < 0.5*iResolution.x){\n                //Only render the BRDF in the first frames\n                if(iFrame == 0 || iFrame == 10){\n                    vec2 texCoord = vec2(2.0*fragCoord.x/iResolution.x, \n                                         2.0*(fragCoord.y/iResolution.y - 0.5));\n                    vec2 c = integrateBRDF(texCoord.x, texCoord.y, \n                    iResolution.x < 2000.0 ? BRDF_SAMPLE_COUNT : BRDF_LOW_SAMPLE_COUNT);\n                    col = vec3(c.x, c.y, 0.0);\n                }else{\n                    col = texture(iChannel2, fragCoord.xy/iResolution.xy).rgb;\n                }\n            }\n        }\n        //Store current colour of the environment map from BufferB to detect change\n        if(fragCoord.x == 4.5 && fragCoord.y == 4.5){\n             col = texelFetch(iChannel1, ivec2(4.5, 4.5), 0).rgb;\n        }\n        \n        //Store the size of the render\n        if(fragCoord.x == 5.5 && fragCoord.y == 5.5){\n             col = vec3(iResolution.xy, 0.0);\n        }\n        \n        fragColor = vec4(col, 1.0);\n        \n    }else{\n        fragColor = texture(iChannel2, fragCoord.xy/iResolution.xy);\n    } \n}","name":"Buffer C","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"XlGcRV","date":"1536869458","viewed":717,"name":"Test PT 123","username":"vchizhov","description":"Simple progressive pathtracer with RR and NEE. Interaction through WASDEQ, LMB, Space.","likes":6,"published":1,"flags":48,"usePreview":0,"tags":["pathtracer","mis","progressive","nee"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord.xy / iResolution.xy;\n    vec3 col = vec3(0.0);\n    \n    \n    col = texture( iChannel0, uv ).xyz;\n    // gamma correction:\n    // https://en.wikipedia.org/wiki/Gamma_correction\n    col = pow( col, vec3(0.4545) );\n    \n    fragColor = vec4(col,1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"////////////////////////////////////////////////////////////\n//\t\t\t\t\t\tSAMPLING\n////////////////////////////////////////////////////////////\n\n\n// http://www.reedbeta.com/blog/quick-and-easy-gpu-random-numbers-in-d3d11/\n// http://web.archive.org/web/20071223173210/http://www.concentric.net/%7ETtwang/tech/inthash.htm\nuint wangHash( uint a )\n{\n\ta = (a ^ 61u) ^ (a >> 16u);\n\ta += (a << 3u);\n\ta = a ^ (a >> 4u);\n\ta = a * 0x27d4eb2du;\n\ta = a ^ (a >> 15u);\n\treturn a;\n}\n\nuint rand( inout uint seed )\n{\n    seed += 13u;\n    return wangHash( seed );\n}\n\nfloat fRand( inout uint seed )\n{\n    uint urand = rand( seed );    \n    const uint mantissaMask = (0xffffffffu) >> ( 32u - 23u );\n    return fract(float(urand & mantissaMask) / float(mantissaMask)); \n}\n\nvec2 fRand2(inout uint seed)\n{\n    return vec2(fRand(seed), fRand(seed));\n}\n\n\n\n////////////////////////////////////////////////////////////\n//\t\t\t\t\t\tBasics\n////////////////////////////////////////////////////////////\n#define PI 3.14159265359\n#define PI_2 1.57079632679\n#define PI2 6.28318530718\n#define PI4 12.5663706144\n#define PI_4 0.78539816339\n\n// offset to avoid self-intersection, scene dependent\n#define OFFSET 0.001\n\nstruct Ray\n{\n\tvec3 o; // origin\n    vec3 d; // direction\n};\n    \nstruct Material\n{\n   \tint type; // 0 - diffuse, 1 - perfect mirror, 2 - dielectric\n    vec3 albedo; // albedo = I[Hemisphere]{bsdf*cos(theta)d(omega)} = bsdf/PI\n    float ior; // index of refraction\n    vec3 emission;\n};\n    \n\nstruct Sphere\n{\n    vec3 pos;\n    float radius;\n    Material mat;\n};\n    \n\n//////////////////////////////////////////////////////////////////\n//\t\t\t\t    Mapping and Porbabilities\n//////////////////////////////////////////////////////////////////\n\n// probability of sampling a random point on a sphere\nfloat pdfUniformSphere(in Sphere s)\n{\n    return 1.0/(PI4*s.radius*s.radius);\n}\n\n// map uniformly distributed points in [0,1]^2 to uniformly distributed \n// points on a sphere\nvec3 uniformSphere(vec2 uv, in Sphere s)\n{\n    // generate a point uniformly distributed on the unit hemisphere\n    // 1 = I[Hemisphere]{C d(omega)} = \n    // I[0,2pi]x[0,pi/2]{C*sin(theta)d(theta)d(phi)} = \n    // -2*pi*C(cos(pi/2) - cos(0)) = 2*pi*C -> C = 1/(2*pi)\n    // Then for the whole sphere C' = 1/(4*pi)\n    \n    // p(theta) = I[0,2pi]{C*sin(theta)d(phi)} = sin(theta)\n    // p(omega) = 1/(2*pi), p(phi,theta) = sin(theta)/(2*pi)\n    // p(phi|theta) = p(phi,theta)/p(theta) = 1/(2*pi)\n    \n    // P(theta) = I[0,theta]{p(theta)d(theta)} = 1-cos(theta)\n    // u ~ 1-cos(theta) ~ cos(theta)\n    // To extend this to the whole sphere, cos(theta) must be in [-1,1]\n    // Since uniformly distributed points on a sphere are uniformly distributed\n    // on the hemisphere we can just do u->u' in [-1,1] : u' = 2*u-1\n    \n    // P(phi) = I[0,phi]{p(phi|theta)d(phi)} = phi/(2*pi) -> phi = 2*pi*phi\n    \n    float cosTheta = 2.0*uv.x-1.0;\n    float sinTheta = sqrt(1.0-cosTheta*cosTheta);\n    float phi = PI2*uv.y;\n    \n    vec3 result = s.pos + s.radius*vec3(sinTheta*vec2(cos(phi), sin(phi)), cosTheta);\n    return result;\n}\n    \n// probability of sampling a direction from the unit hemisphere\nfloat pdfUniformHemisphere()\n{\n    // p(omega) = C\n    // I[0,2pi][0,pi/2]{C*sin(theta)d(theta)d(phi)} = 1\n    // C = 1/(2pi)\n \treturn 1.0/PI2;   \n}\n    \n\n\n// map uniformly distributed points in [0,1]^2 to uniformly distributed \n// points on the hemisphere cantered around n\nvec3 uniformHemisphere(vec2 uv, vec3 n)\n{\n    // create tnb:\n    //http://jcgt.org/published/0006/01/01/paper.pdf\n    float signZ = (n.z>=0.0)?1.0:-1.0;     //do not use sign(nor.z), it can produce 0.0\n    float a = -1.0 / (signZ + n.z);\n    float b = n.x * n.y * a;\n    vec3 b1 = vec3(1.0 + signZ * n.x * n.x * a, signZ*b, -signZ*n.x);\n    vec3 b2 = vec3(b, signZ + n.y * n.y * a, -n.y);\n\n    // remap uv to uniformly distributed points on the hemisphere around n\n    float phi = PI2 * uv.x;\n    float cosTheta = sqrt(uv.y);\n    float sinTheta = sqrt(1.0-uv.y);\n    return cosTheta*(cos(phi)*b1 + sin(phi)*b2) + sinTheta*n;\n}\n\n// probability of sampling a cosine weighted direction from the unit hemisphere\nfloat pdfCosHemisphere(float cosTheta)\n{\n    // p(omega) = C*cos(theta)\n    // I[0,2pi][0,pi/2]{C*cos(theta)sin(theta)d(theta)d(phi)} = 1\n    // C = 1/pi\n    return cosTheta/PI;\n}\n\n// map uniformly distributed points in [0,1]^2 to cosine distributed\n// points on the hemisphere centered around n (without building a tnb)\nvec3 cosineHemisphere(vec2 uv, vec3 n)\n{\n    //http://www.amietia.com/lambertnotangent.html\n    float phi = PI2 * uv.x;\n    float cosTheta = 2.0*uv.y - 1.0;\n    return normalize( n + vec3(sqrt(1.0-cosTheta*cosTheta) * vec2(cos(phi), sin(phi)), cosTheta) );\n}\n\n\n//////////////////////////////////////////////////////////////////\n//\t\t\t\t\t\tCamera\n//////////////////////////////////////////////////////////////////\n\nstruct Camera\n{\n    vec3 pos;\n    vec3 x,y,z;\n};\n\nCamera lookAt(vec3 pos, vec3 target, vec3 up)\n{\n    Camera c;\n    c.pos = pos;\n    c.z = normalize(target-pos);\n    c.x = normalize(cross(up,c.z));\n    c.y = cross(c.z,c.x);\n    return c;\n}\n\nCamera lookAt(vec3 pos, vec3 target, vec3 up, float fov)\n{\n    //  |\\ \n    // z| \\   tg(fov/2) = x / z, fix x = y = 1 ->\n    //  |__\\  z = 1/tg(fov/2)\n    //   x\n    Camera c = lookAt(pos, target, up);\n    c.z /= tan(0.5*fov);\n    return c;\n}\n\n// ndc in [-aspectRatio, aspectRatio]x[-1,1]\nRay getRay(Camera c, vec2 ndc)\n{\n    Ray r;\n    r.o = c.pos;\n    r.d = normalize(c.z + c.x*ndc.x + c.y*ndc.y);\n    return r;\n}\n\n\n//////////////////////////////////////////////////////////////////\n//\t\t\t\t\t\tIntersection\n//////////////////////////////////////////////////////////////////\n\nfloat intersect(Ray r, Sphere s)\n{\n    // Canonic sphere equation: (r-pos)^2 = radius^2\n    // Parametric ray equation: r(t) = o + t*d\n    // Plugging in the ray equation in the sphere equation:\n    // (o+t*d-pos)^2 = radius^2\n    // (pos-o)^2 - radius^2 - 2*dot(pos-o,d)*t + d^2*t=0\n    // A = d^2, B = dot(pos-o,d), C = (pos-o)^2 - radius^2\n    // A*t^2 - 2*B*t + C = 0\n    // ray direction d is normalized -> A = 1\n    // t^2 - 2*B*t + C = 0\n    // D = B^2 - C\n    // D>0 -> t1,2 = B -+ sqrt(D)\n    vec3 op = s.pos-r.o;\n    float c = dot(op,op) - s.radius*s.radius;\n    float b = dot(op,r.d);\n    float discr = b*b - c;\n    \n    if(discr<0.0)\n    {\n        return -1.0;\n    }\n    discr = sqrt(discr);\n    \n    // t1\n    float t = b-discr;\n    if(t<0.0) \n    {\n        // t2\n        t=b+discr;\n        t = (t<0.0? -1.0 : t);\n    }\n    return t;\n}\n\n\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"XdX3zn","filepath":"/media/a/488bd40303a2e2b9a71987e48c66ef41f5e937174bf316d3ed0e86410784b919.jpg","previewfilepath":"/media/ap/488bd40303a2e2b9a71987e48c66ef41f5e937174bf316d3ed0e86410784b919.jpg","type":"cubemap","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"Xsf3zn","filepath":"/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"/media/ap/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":2,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"#define MAX_BOUNCES 30\n\n// NEE: 0 - no NEE, 1 - max heuristic NEE, 2 - balance heuristic NEE\n#define NEE 2\n// Roussian Roulette: 0 - disabled, 1 - enabled\n#define RR 1\n// color used to color biased rays (that reached the max number of bounces)\n// note that this is enabled only for when RR is enabled, and the default color below is magenta\n#define RR_COLOR vec3(1.0,0.0,1.0)\n\n// number of spheres\n#define SN 6\n\nstruct HitInfo\n{\n    float dist;   // distance till intersection: <0 -> no intersection\n    vec3 p;\t\t  // intersection point: p = r.o + r.d*dist\n    vec3 n;\t\t  // normal at p\n    Material mat;\n    int index;\t  // index of intersected object\n};\n\n// computes only the normal currently\nHitInfo computeInfo(vec3 p, Sphere s)\n{\n    HitInfo info;\n    info.p = p;\n    info.n = (p-s.pos)/s.radius;\n    info.mat = s.mat;\n    return info;\n}\n\n// finds the closest intersection along the ray in[tmin,tmax] and returns a HitInfo instance as a result\nHitInfo intersectScene(Ray r, Sphere s[SN], float tmin, float tmax)\n{\n    HitInfo info;\n    info.dist = -tmax;\n    int idx = 0;\n    for(int i=0;i<SN;++i)\n    {\n        float t = intersect(r, s[i]);\n        if(t>tmin && t<abs(info.dist))\n        {\n            info.dist = t;\n            idx = i;\n        }\n    }\n    float t = info.dist;\n    info = computeInfo(r.o+r.d*t, s[idx]);\n    info.index = idx;\n    info.dist = t;    \n    return info;\n}\n\n// an optimized version for the visibility function for shadowrays, can exit early\nbool shadowRayIntersect(Ray r, Sphere s[SN], float tmin, float tmax)\n{\n    for(int i=0;i<SN;++i)\n    {\n        float t = intersect(r, s[i]);\n        if(t>tmin && t<tmax)\n        {\n            return true;\n        }\n    }\n    return false;\n}\n\nvec3 backgroundRadiance(vec3 rd)\n{\n    return 0.7*pow( texture(iChannel3, -rd).xyz, vec3(1.0/0.4545));\n    // return vec3(0.0);\n}\n\n// https://en.wikipedia.org/wiki/Grayscale#Colorimetric_(perceptual_luminance-preserving)_conversion_to_grayscale\nfloat luminance(vec3 sRGBLinear)\n{\n    return dot(vec3(0.2126, 0.7152, 0.0722), sRGBLinear);\n}\n\nfloat fresnelDielectric(float ior, float cosThetaI, float cosThetaT)\n{\n\tfloat rParallel = (cosThetaI - ior * cosThetaT) / (cosThetaI + ior * cosThetaT);\n    float rPerpendicular = (ior*cosThetaI - cosThetaT) / (ior*cosThetaI + cosThetaT);\n    return 0.5 * (rParallel*rParallel + rPerpendicular*rPerpendicular);\n}\n\n\nvec3 renderPathtrace(in Ray r, float tmin ,float tmax, inout uint seed)\n{\n    \n    // scene\n    \n    Sphere s[SN];\n    s[0] = Sphere(vec3(0.0, -0.0, 0.0), 1.0,\n                  Material(0, vec3(0.6, 0.2, 0.2)/PI, 0.5,\n                          vec3(0.0)));\n    s[1] = Sphere(vec3(0.0, -1001.0, 0.0), 1000.0, \n                  Material(0, vec3(0.2), 1.0,\n                          vec3(0.0)));\n    s[2] = Sphere(vec3(2.0, 0.0, 0.0), 1.0,\n                  Material(1, vec3(0.2, 0.6, 0.2), 1.0,\n                          vec3(0.0)));\n    s[3] = Sphere(vec3(-2.0, 0.0, 0.0), 1.0,\n                  Material(2, 2.0*vec3(0.2, 0.6, 0.8), 1.0/1.2,\n                          vec3(0.0)));\n    s[4] = Sphere(vec3(0.0, 4.0, -6.0), 3.0,\n                  Material(0, vec3(0.0), 0.8,\n                          vec3(0.3, 0.7, 1.0)));\n    s[5] = Sphere(vec3(6.0, 4.0, -4.0), 0.3, Material(0, vec3(0.0), 0.8,100.0*vec3(1.0, 0.6, 0.3)));\n    \n    // an array of the objects that will be sampled as lights for NEE\n    // note that all emissive objects need to be here, otherwise we would need \n    // an iteration over this array when hitting a light by sampling the bsdf\n    #define LN 2\n    int lights[LN];\n    lights[0] = 4;\n    lights[1] = 5;\n    \n    // we accumulate the color here\n    vec3 color = vec3(0.0f);\n    // the throughoput of the ray (we shoot rays from the eye)\n    vec3 throughput = vec3(1.0);\n    // iteration count (used to check for ray bias)\n    int i = 0;\n    \n    // flag recording whether the last bounce was specular\n    // necessary since NEE is not used at specular surfaces\n    // initially set to true to optimize away (specular || i==0) to (specular) in the if statements\n    bool specular = true;\n    float bsdfPDF;\n    \n    for(;i<MAX_BOUNCES;++i)\n    {\n        // find intersection\n        HitInfo info = intersectScene(r, s, 0.0, tmax);\n        \n        // if no intersection - the ray left the scene, jump to end\n        if(info.dist<0.0)\n        {\n            break;\n        }\n        \n        // emission:\n        // no next event estimation\n        #if NEE == 0\n        color += throughput * info.mat.emission;\n        // max heuristic next event estimation\n        #elif NEE == 1\n        if(specular)\n        {\n            color += throughput * info.mat.emission;\n        }\n        // balance heuristic next event estimation\n        #else //NEE == 2\n        if(specular)\n        {\n            color += info.mat.emission*throughput;\n        }\n        else\n        {\n            // if the light was hit by sampling the bsdf, we need to calculate the mis weight\n            \n            // probability of sampling this point on this light with NEE (with respect to dA)\n            float misLightPDF = pdfUniformSphere(s[info.index])/float(LN);\n            float areaDistSqr = dot(info.p-r.o, info.p-r.o);\n            // probability of sampling this point on the light with the bsdf (with respect to dA)\n            float misBSDFPDF = bsdfPDF * abs(dot(r.d,info.n))/areaDistSqr;\n            float misWeight = misBSDFPDF / (misLightPDF + misBSDFPDF);\n            color += throughput * misWeight * info.mat.emission;\n        }\n        #endif\n        \n        \n        // Russian Roulette\n        #if RR == 1\n        float rr = fRand(seed);\n        // the lower the throughput the lower the probability that the ray lives\n        float probContinue = clamp(luminance(throughput), 0.0, 1.0);\n        if(rr<probContinue)\n        {\n            throughput/=probContinue;\n            \n        }\n        else\n        {\n            throughput = vec3(0.0);\n            break;\n        }\n        #endif\n           \n        \n        // Bounce:\n        \n        \n        // prepare the next ray\n        r.o = info.p;\n        \n        // update the throughput\n        throughput *= info.mat.albedo;\n        \n        // if the ray hits an object from the opposite side ->\n        // flip the normal\n        float cosTheta = -dot(r.d,info.n);\n        bool side = cosTheta>0.0;\n        vec3 n;\n        if(side)\n        {\n            n = info.n;\n        }\n        else\n        {\n            n = -info.n;\n            cosTheta = -cosTheta;\n        }\n        \n        // store whether the vertex is specular\n        specular = info.mat.type==1 || info.mat.type==2;\n        \n        // perfect mirror\n        if(info.mat.type==1)\n        {\n            // reflection around the normal:\n            //v___| n\n            // \\  |\n            //  \\ | -dot(d,n)*n\n            // d \\| \n            \n        \t// v ___|___ v\n            //   \\  |  /\n            //  d \\ | / r\n            //     \\|/\n            //\n            \n            // v = d - dot(d,n)*n\n            // r = -d + 2*v = -d + 2*d -2*dot(d,n)*n = d - 2*dot(d,n)*n\n            //r.d = r.d - 2.0*dot(r.d,info.n)*info.n;\n            r.d = reflect(r.d, n);\n            \n            // avoid self intersection by offseting along the normal\n            r.o += n*OFFSET;\n            \n            // update the throughput:\n            // the probability of sampling this direction is 100%\n            // the division by the pdf reduces to a division by 1.0\n            \n            // note that the cosine term from the rendering eq cancels out for mirror brdf:\n            // f(wi,x,wo) = rho(thetai) * delta(cos(thetai)-cos(thetao))/cos(thetai) * delta(phii-phio+-pi)\n            // rho(thetai) = albedo in our case\n        }\n        else if(info.mat.type==2) // refraction\n        {\n            // refraction:\n            // sin(theta1)*eta1 = sin(theta2)*eta2\n            // sin(theta2) = sin(theta1) * eta1 / eta2\n            // if eta1/eta2>1, it is possible that |sin(theta1)*eta1/eta2|>1\n            // there is no angle theta1 that satisifies this -> total internal reflection\n            // otherwise:\n            //\\  |   eta1\n            // \\ |      \n            //d \\| n          theta1 = angle(-d,n)\n            //---------\n            //   ||   eta2    theta2 = angle(r,-n)\n            //   | |\n            //-n |  | r\n            \n            // r = cos(theta2)*(-n) + sin(theta2)*perp(n)\n            // perp(n) = d - dot(d,n)*n / |d - dot(d,n)*n| = (d - cos(theta1)*n)/sin(theta1)\n            // cos(theta2) = sqrt(1-sin^2(theta2)) = sqrt(1-(eta1/eta2*sin(theta1))^2)\n            // sin(theta2) = eta1/eta2*sin(theta1)\n            // r = cos(theta2)*(-n) + eta1/eta2*sin(theta1)/sin(theta1)* (d - cos(theta1)*n)\n            // r = -sqrt(1-(eta1/eta2*sin(theta1))^2)*n + eta1/eta2*(d-cos(theta1)*n)\n            // r = eta1/eta2*d + (eta1/eta2*dot(d,n)-sqrt(1-(eta1/eta2)^2*(1-dot(d,n)^2)))*n\n            \n            // we additionally need to check whether we are inside of the sphere:\n            // in order to pick the correct ior:\n            float ior = side? info.mat.ior : 1.0/info.mat.ior;\n            float cosThetaT = 1.0 - ior*ior*(1.0-cosTheta*cosTheta);\n            vec3 rf;\n            if(cosThetaT<0.0)\n            {\n                rf = reflect(r.d, n);\n                // avoid self intersection by offseting along the normal\n                r.o += n*OFFSET;\n            }\n            else\n            {\n                cosThetaT = sqrt(cosThetaT);\n                if(fRand(seed) < fresnelDielectric(ior, cosTheta, cosThetaT))\n                {\n                    rf = reflect(r.d, n);\n                    // avoid self intersection by offseting along the normal\n                    r.o += n*OFFSET;\n                }\n                else\n                {\n                    rf =  ior*r.d + (ior*cosTheta-cosThetaT)*n;\n                    //rf = refract(r.d, n, ior);\n                    // avoid self intersection by offseting along the negative normal\n                    // since the ray has to continue on the inside of the object\n                    r.o -= n*OFFSET;\n                }\n                \n            }\n            r.d = rf;\n            \n            // the probability of picking the refraction/reflection direction\n            // is 100%, then the division by the pdf reduces to a division by 1.0\n            \n        }\n        else\n        {\n            // avoid self intersection by offseting along the normal\n            r.o += n*OFFSET;\n            \n            // perform next event estimation\n            #if NEE != 0\n            // sample a light uniformly\n            int lightIdx = lights[int(rand(seed)%uint(LN))];\n            float lightSampleIdxProb = 1.0/float(LN);\n            // sample a sphere uniformly\n       \t\tvec3 lightSample = uniformSphere(fRand2(seed), s[lightIdx]);\n            // compute the normal at the sampled point\n            vec3 ln = (lightSample - s[lightIdx].pos)/s[lightIdx].radius;\n            \n            // compute the shadow ray\n            vec3 shadowRayDir = lightSample - r.o;\n            float srl = length(shadowRayDir);\n            shadowRayDir /= srl;\n            \n            // compute the angle between the shadow ray and the light sample normal\n            // we take the absolute value since even if this is negative, it simply means \n            // that we are sampling the lightsource from the opposite side\n            float cosY = abs(dot(shadowRayDir, ln));\n            \n            // compute the cosine between the shadow ray and the normal of the point \n            // currently being shaded, if that is negative - we sampled a light that\n            // is not in the upper hemisphere around the normal -> no contribution\n            float cosX = dot(shadowRayDir, n);\n            if(cosX>0.0)\n            {\n                // compute the V(x,y) term:\n        \t\tbool visibility = !shadowRayIntersect(Ray(r.o, shadowRayDir), s, 0.0, srl-OFFSET);\n                if(visibility) \n                {\n                    // compute the geometric term\n                    float G = cosX*cosY/(srl*srl);\n                    // bsdf(wi,x,wo)*Le(x, wi)*G(x,y)*V(x,y)/pdf\n                    float misWeight = 1.0;\n                    float lightSampleProbability = pdfUniformSphere(s[lightIdx])*lightSampleIdxProb;\n                    #if NEE == 2\n                    // bsdf probability: cos(thetaX)/PI, in area form: G / PI\n                 \tfloat misBSDFPDF = G / PI;\n                    float misLightPDF = lightSampleProbability;\n                    misWeight = misLightPDF / (misBSDFPDF + misLightPDF);\n                    #endif\n                    //use area formulation: brdf * L * V * G / pdf\n                    color += misWeight * throughput * s[lightIdx].mat.emission * G / lightSampleProbability;\n                }\n            }\n            \n            #endif\n            // sample the bsdf\n            r.d = cosineHemisphere(fRand2(seed),n);\n            bsdfPDF = cosTheta/PI;\n            // we have bsdf(wi,x,wo)*Li(x,wi)*cos(theta)/pdf\n            // pdf = cos(theta)/pi\n            // the cosine cancels out with the cosine from the rendering eq\n            // account for pi\n            throughput *= PI;\n        }\n        r.d = normalize(r.d);\n        \n    }\n    \n    #if RR == 1\n    // color biased paths\n    return i==MAX_BOUNCES?  RR_COLOR : throughput * backgroundRadiance(-r.d) + color;\n    #else\n    return throughput * backgroundRadiance(-r.d) + color;\n    #endif\n}\n\n\nfloat keyClick(int ascii) {\n\treturn float(texture(iChannel1,vec2((.5+float(ascii))/256.,0.25)).x > 0.0);\n}\n\nfloat keyToggle(int ascii) {\n\treturn float(texture(iChannel1,vec2((.5+float(ascii))/256.,0.75)).x > 0.0);\n}\n\n#define SAMPLES 1\n\n// info from the previous frame\nstruct FrameInfo\n{\n    vec2 rot;  // the rotation of the camera for the previous frame\n    bool mouseDown; // was the mouse down in the previous frame\n    int startingFrame; // starting frame for the progressive renderer\n    \n    vec3 dist;\n};\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // extract info from last frame:\n    \n    // info stored in bottom left pixel - used as a substitute for a uniform\n    // frameInfo = (rotationX, rotationY, mouseDown, startingFrame)\n    vec4 frameInfo = texture( iChannel0, vec2(0.5, 0.5)/iResolution.xy );\n    \n    \n    // pixel stored in the neighbour along x - used as a substitute for a uniform\n    // moveInfo = (distX, distY, distZ, 0.0)\n    vec4 moveInfo = texture( iChannel0, vec2(1.5, 0.5)/iResolution.xy );\n    \n    \n    FrameInfo prevFrame = FrameInfo(frameInfo.xy, frameInfo.z>0.0, int(frameInfo.w),\n                                   moveInfo.xyz);\n    \n   \n    \n    // current pixel info\n    // xyz - prev frame color, w - prev frame seed\n    vec4 pixelInfo = texture(iChannel0, fragCoord.xy/iResolution.xy);\n    vec3 oldColor = pixelInfo.xyz;\n    uint seed = uint(pixelInfo.w);\n    // generate initial seed based on a random texture\n    bool textureLoaded = iChannelResolution[2].x>0.0;\n    if(seed==0u) {seed = uint(float(1<<23)*texture(iChannel2,fragCoord.xy/iResolution.xy).x);}\n    \n    \n    \n    // Handle movement and rotation:\n    float aspectRatio = iResolution.x/iResolution.y;\n    \n    // camera mouse rotation sensitivity\n    vec2 rotS = vec2(0.01) * vec2(1.0, 1.0/aspectRatio);\n    \n    bool mouseDown = iMouse.z>0.0;\n    \n    // current rotation\n    vec2 rot = prevFrame.rot + ((mouseDown || prevFrame.mouseDown) ? rotS*(iMouse.xy-abs(iMouse.zw)) : vec2(0.0));\n    \n    // reset camera:\n    bool keySpace = keyClick(32)>0.0;\n    // x: AD, y: QE, z: WS\n    vec3 diff = vec3(keyClick(68) - keyClick(65), keyClick(81) - keyClick(69), keyClick(83) - keyClick(87));\n    bool keyDown = any(greaterThan(abs(diff),vec3(0.5)));\n    // camera translation sensitivity\n    vec3 tS = vec3(0.1);\n    vec3 dist = diff*tS+prevFrame.dist;\n    \n    // Set up the camera\n    if(iFrame==0) \n    {\n        dist.z = 5.0;\n        rot = vec2(0.0);\n    }\n    float cosTheta = cos(rot.y);\n    vec3 cpos = dist.z*vec3(cosTheta*sin(rot.x),\n                          sin(rot.y),\n                        cosTheta*cos(rot.x));\n    \n    Camera cam = lookAt(cpos, vec3(0.0), vec3(0.0, 1.0, 0.0), 2.0/3.0*PI);\n    cam.pos += cam.x*dist.x + cam.y*dist.y;\n    \n    \n    // Shoot rays\n    vec3 newColor;\n    for(int samplesY=0;samplesY<SAMPLES;++samplesY)\n    {\n        for(int samplesX=0;samplesX<SAMPLES;++samplesX)\n        {\n            vec2 uv = (fragCoord+(vec2(float(samplesX), float(samplesY))+fRand2(seed))/vec2(float(SAMPLES)))/iResolution.xy;\n            vec2 ndc = 2.0*uv - 1.0;\n            ndc.x *= aspectRatio;\n            Ray r = getRay(cam, ndc);\n            newColor += renderPathtrace(r, 0.0, 100.0, seed);\n        }\n    }\n    newColor /= float(SAMPLES*SAMPLES);\n    \n    \n    \n    vec4 col_acc;\n    vec2 coord = floor(fragCoord.xy);\n    // Save 'uniforms' in lower left pixels\n    if(all(equal(coord.xy,vec2(0)))) \n    {\n        // while dragging the mouse:\n        // - keep the old absolute rotation\n        // - set the mouse down flag to 1\n        // - set the starting frame to the current one\n        if( mouseDown ) \n        {\n           col_acc = vec4(prevFrame.rot, 1.0, float(iFrame));\n        }\n        // at mouse release ( mouseDown == 0 && prevFrame.mouseDown = 1):\n        // - save the current absolute rotation\n        // - set the mouse down flag to 0\n        // - set the starting frame to the current one\n        \n        // when mouse is up: just copy everything from the previous frame\n        else \n        {\n            col_acc = prevFrame.mouseDown ? vec4(rot, 0.0, float(iFrame)) : frameInfo;\n        }\n        if(keyDown)\n        {\n            col_acc.w = float(iFrame);\n        }\n        \n        if(iFrame==0 || keySpace) \n        {\n            col_acc = vec4(0.0, 0.0, 0.0, float(iFrame));\n        }\n    \n    }\n    else if(coord.x==1.0 && coord.y == 0.0)\n    {\n        if(keyDown)\n        {\n            col_acc = vec4(dist, 0.0);\n        }\n        else\n        {\n            col_acc = moveInfo;\n        }\n        \n        // set the starting distance to 5\n        if(iFrame==0 || keySpace) \n        {\n            col_acc = vec4(vec3(0.0, 0.0, 5.0), 0.0);\n        }\n        \n    }\n    else {\n        \n        // progressively accumulate color\n        if(!textureLoaded || mouseDown || keyDown) \n        {\n            // set pixel seed to 0\n            col_acc = vec4(newColor.xyz,0.0);\n        } \n        else \n        {\n            // the frame number starting at the last frame when the camera was not moving\n            int progressiveIter = 1 + iFrame - prevFrame.startingFrame;\n            col_acc.xyz = mix(oldColor, newColor, float(1.0)/float(progressiveIter));\n            col_acc.w = float(seed);\n        }\n        \n    }\n    \n    // Output to screen\n    fragColor = vec4(col_acc);\n}","name":"Buffer A","description":"","type":"buffer"}]}
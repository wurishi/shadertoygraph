{"ver":"0.1","info":{"id":"wlBcWG","date":"1595217223","viewed":1679,"name":"CRT+NTSC Simulation","username":"Hatchling","description":"Customizable NTSC encoding and decoding, with noise.\nCRT simulation with interlacing scanlines, shadow masking, curvature, vignetting.\nArtifacts are exaggerated.\nCompatability fix by dom1817.","likes":24,"published":1,"flags":32,"usePreview":0,"tags":["crt","scanline","vhs","shadowmask","ntsc"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Taken from https://www.shadertoy.com/view/tdjyzz\nfloat rbgToluminance(vec3 rgb)\n{\n    return (rgb.r * 0.3) + (rgb.g * 0.59) + (rgb.b * 0.11);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    vec2 pixelSize = 1.5/iResolution.xy;\n    \n    vec2 right = vec2(pixelSize.x, 0);\n    vec2 up = vec2(0, pixelSize.y);\n\n    // Input linear image + bloom.\n    vec3 colorC = texture(iChannel0, uv).rgb;\n    \n    //fragColor = vec4(colorC, 1.0);\n    //return;\n    \n    vec3 colorT = textureLod(iChannel0, uv + up, 0.5).rgb;\n    vec3 colorB = textureLod(iChannel0, uv - up, 0.5).rgb;\n    vec3 colorL = textureLod(iChannel0, uv - right, 0.5).rgb;\n    vec3 colorR = textureLod(iChannel0, uv + right, 0.5).rgb;\n    \n    right *= 2.0;\n    up *= 2.0;\n    \n    vec3 colorTR = textureLod(iChannel0, uv + up + right, 1.5).rgb;\n    vec3 colorTL = textureLod(iChannel0, uv + up - right, 1.5).rgb;\n    vec3 colorBR = textureLod(iChannel0, uv - up + right, 1.5).rgb;\n    vec3 colorBL = textureLod(iChannel0, uv - up - right, 1.5).rgb;\n        \n        \n    vec3 color = colorC + (colorT + colorB + colorL + colorR) * 0.03 + (colorTR + colorTL + colorBR + colorBL) * 0.01;    \n    //color = (colorT + colorB + colorL + colorR) * 0.03;   \n    //color = (colorTR + colorTL + colorBR + colorBL) * 0.01;    \n\n    // Tonemap \n    float lum = rbgToluminance(color);\n    color += vec3(lum * 0.01); // Allow colors to whiten when saturated.\n    color = color / (0.5 + mix(vec3(lum), color, 0.95));\n    \n    // Convert to gamma.\n\tcolor = pow(color, vec3(1.0/2.2));\n    \n\tfragColor = vec4(color, 1.0);\n    \n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"const float SHADOWMASK_VERTGAPWIDTH = 0.02;\nconst float SHADOWMASK_VERTHARDNESS = 0.1;\n\nconst float SHADOWMASK_HORIZGAPWIDTH = -1.0;\nconst float SHADOWMASK_HORIZARDNESS = 0.8;\n\nconst float SHADOWMASK_RCOL_OFFSET = 0.0;\nconst float SHADOWMASK_GCOL_OFFSET = -0.3;\nconst float SHADOWMASK_BCOL_OFFSET = -0.6;\n\nconst float SCANLINE_RGAPWIDTH = 2.0;\nconst float SCANLINE_RHARDNESS = 1.0;\nconst float SCANLINE_ROFFSET = 0.0 + 0.08333333;\n\nconst float SCANLINE_GGAPWIDTH = 2.0;\nconst float SCANLINE_GHARDNESS = 0.5;\nconst float SCANLINE_GOFFSET = -0.1 + 0.08333333;\n\nconst float SCANLINE_BGAPWIDTH = 2.0;\nconst float SCANLINE_BHARDNESS = 0.3;\nconst float SCANLINE_BOFFSET = -0.15 + 0.08333333;\n\n// When increasing the overall scale, you may need to reduce the \"HARDNESS\" of the\n// CRT patterns to prevent aliasing.\n//const float OVERALL_SCALE = 240.0;\nconst float SHADOWMASK_UV_SCALE = 0.16;\nconst float SCANLINE_UV_SCALE = 60.0;\n\nconst float SINE_SCALE = 3.14159 * 2.0;\n\n\n// SHADOW MASK\n\nfloat Grille(float x, float offset, float multiplier)\n{\n\treturn smoothstep(0.0, 1.0, sin(x * SINE_SCALE) * multiplier + offset);    \n}\n\nfloat ShadowMaskRows(vec2 uv)\n{\n    // Stagger rows\n    uv.x *= 0.5;\n    uv.x -= round(uv.x);\n    if(uv.x < 0.0)\n        uv.y += 0.5;\n    \n    return Grille(uv.y, -SHADOWMASK_HORIZGAPWIDTH, SHADOWMASK_HORIZARDNESS);\n}\n\nfloat ShadowMaskSingleCol(float x)\n{\n    return Grille(x, -SHADOWMASK_VERTGAPWIDTH, SHADOWMASK_VERTHARDNESS);\n}\n\nvec3 ShadowMaskRGBCols(float x)\n{\n\treturn vec3\n    (\n        ShadowMaskSingleCol(x + SHADOWMASK_RCOL_OFFSET), \n        ShadowMaskSingleCol(x + SHADOWMASK_GCOL_OFFSET), \n        ShadowMaskSingleCol(x + SHADOWMASK_BCOL_OFFSET)\n    );    \n}\n\nvec3 ShadowMask(vec2 uv)\n{\n    return ShadowMaskRGBCols(uv.x) * ShadowMaskRows(uv);\n}\n\n// SCANLINE PATTERN\n\nfloat Scanline(float x, float offset, float multiplier)\n{\n\treturn tanh(sin(x * SINE_SCALE) * multiplier + offset) * 0.5 + 0.5;    \n}\n\nfloat Interlacing()\n{\n    // Add interlacing.\n    int frame = iFrame;\n    \n    // Add the following line to exaggerate interlacing effect.\n    //frame /= 2;\n    \n    return frame % 2 == 0 ? \n        0.5 : 0.0;\n}\n\nvec4 Sample(sampler2D sampler, vec2 uv, float resolution)\n{\n    if(uv.x < 0.0 || uv.x > 1.0) return vec4(0);\n    if(uv.y < 0.0 || uv.y > 1.0) return vec4(0);\n    \n    float interlacing = Interlacing();\n    \n    uv *= resolution;\n    \n    uv.y += interlacing;\n    float uvYFloor = floor(uv.y);\n    \n    vec2 uv1 = vec2(uv.x, uvYFloor+1.0);\n    vec2 uv2 = vec2(uv.x, uvYFloor);\n    \n    float t = uv.y - uvYFloor;\n    \n    t = smoothstep(0.0, 1.0, t);\n    //t = smoothstep(0.0, 1.0, t);\n    //t = smoothstep(0.0, 1.0, t);\n    \n    uv1.y -= interlacing;    \n    uv2.y -= interlacing;\n    \n    vec4 sample1 = texture(sampler, uv1 / resolution);\n    vec4 sample2 = texture(sampler, uv2 / resolution);\n    \n    return mix(sample2, sample1, vec4(t));\n}\n\nvec3 ScanlinesRGB(float y)\n{\n\ty += Interlacing() + 0.25;  \n    \n    // Real CRT images show differences in scattering and alignment\n    // between the RGB beams.\n    return vec3\n    (\n \t    Scanline(y + SCANLINE_ROFFSET, -SCANLINE_RGAPWIDTH, SCANLINE_RHARDNESS)   \n        ,\n \t    Scanline(y + SCANLINE_GOFFSET, -SCANLINE_GGAPWIDTH, SCANLINE_GHARDNESS)   \n        ,\n \t    Scanline(y + SCANLINE_BOFFSET, -SCANLINE_BGAPWIDTH, SCANLINE_BHARDNESS)   \n    );\n}\n\n// COMPOSITE\n// CRT curvature and vignetting credit goes to https://www.shadertoy.com/view/Ms23DR\n\nvec2 curve(vec2 uv)\n{\n\tuv = (uv - 0.5) * 2.0;\n\tuv *= 1.1;\t\n\tuv.x *= 1.0 + pow((abs(uv.y) / 5.0), 2.0);\n\tuv.y *= 1.0 + pow((abs(uv.x) / 4.0), 2.0);\n\tuv  = (uv / 2.0) + 0.5;\n\tuv =  uv *0.92 + 0.04;\n\treturn uv;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy ;\n    \n    vec2 sampleUV = curve(uv);\n    vec2 shadowMaskUV = sampleUV * min(iResolution.xy, vec2(1920, 1080)) * SHADOWMASK_UV_SCALE;\n    vec2 scanlineUV = sampleUV * SCANLINE_UV_SCALE;\n    \n    // Input signal.\n    vec3 color = Sample(iChannel0, sampleUV, SCANLINE_UV_SCALE).rgb;\n    \n    // Convert to linear.\n    color = pow(color, vec3(2.2));\n    \n    // Amplify.\n    color *= 4.0;\n    \n    // Vignette.\n    float vig = abs((1.0*16.0*sampleUV.x*sampleUV.y*(1.0-sampleUV.x)*(1.0-sampleUV.y)));\n\tcolor *= vec3(pow(vig,0.6));\n    \n    // Add scalines.\n    color *= ScanlinesRGB(scanlineUV.y) * 40.0;\n    \n    // Add shadowmask.\n    color *= ShadowMask(shadowMaskUV) * 500.0;\n\n\tfragColor = vec4(color, 1.0);\n    \n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"Xdf3Rn","filepath":"/media/a/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","previewfilepath":"/media/ap/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","type":"video","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[],"code":"#define PI 3.14159265359\n\n// Adjust these values to control the look of the encoding.\n\n// Increasing this value increases ringing artifacts. Careful, higher values are expensive.\nconst int WINDOW_RADIUS = 20;\n\n// Simulated AM signal transmission.\nconst float AM_CARRIERSIGNAL_WAVELENGTH = 1.5;\n\n// Wavelength of the color signal. \nconst float COLORBURST_WAVELENGTH_ENCODER = 4.0;\nconst float COLORBURST_WAVELENGTH_DECODER = 4.0;\n\n// Lowpassing of luminance before encoding.\n// If this value is less than the colorburst wavelength,\n// luminance values will be interpreted as chrominance,\n// resulting in color fringes near edges.\nconst float YLOWPASS_WAVELENGTH = 2.0;\n\n// The higher these values are, the more smeary colors will be.\nconst float ILOWPASS_WAVELENGTH = 20.0;\nconst float QLOWPASS_WAVELENGTH = 40.0;\n\n// The higher this value, the blurrier the image.\nconst float DECODE_LOWPASS_WAVELENGTH = 5.5;\n\n// Change the overall scale of the NTSC-style encoding and decoding artifacts.\nconst float NTSC_SCALE = 2.0;\n\nconst float PHASE_ALTERNATION = 3.1415927;\n\n// Amount of TV static.\nconst float NOISE_STRENGTH = 0.15;\n\n// Saturation control.\nconst float SATURATION = 3.0;\n\n// Offsets shape of window. This can make artifacts smear to one side or the other.\nconst float WINDOW_BIAS = +0.25;\n\nmat3 MatrixRGBToYIQ = mat3(0.299, 0.587, 0.114,\n                           0.595,-0.274,-0.3213,\n                           0.2115,-0.5227, 0.3112);\n\nmat3 MatrixYIQToRGB = mat3(1.0,  0.956,  0.619,\n                           1.0, -0.272, -0.647,\n                           1.0, -1.106, 1.703);\n\n// RNG\nuint wang_hash(inout uint seed)\n{\n    seed = uint(seed ^ uint(61)) ^ uint(seed >> uint(16));\n    seed *= uint(9);\n    seed = seed ^ (seed >> 4);\n    seed *= uint(0x27d4eb2d);\n    seed = seed ^ (seed >> 15);\n    return seed;\n}\n\nfloat RandomFloat01(inout uint state)\n{\n    return float(wang_hash(state)) / 4294967296.0;\n}\n\n// NOTE: Window functions expect a range from -1 to 1.\nfloat Sinc(float x)\n{\n    x *= PI;\n\treturn (x == 0.0) ? 1.0 : sin(x)/x;   \n}\n\nfloat WindowCosine(float x)\n{\n    x = atanh(x);\n    x += WINDOW_BIAS;\n    x = tanh(x);\n    \n\treturn cos(PI * x) * 0.5 + 0.5;    \n}\n\nfloat Encode(sampler2D sampler, in vec2 uv, in float pixelWidth, bool alternatePhase)\n{\n    vec3 yiq = vec3(0);\n\tfor(int i = -WINDOW_RADIUS; i <= WINDOW_RADIUS; i++)\n    {\n\t\t// Extend padding by one since we don't want to include a sample at the very edge, which will be 0.\n        float window = WindowCosine(float(i) / float(WINDOW_RADIUS+1)); \n        float sincY = Sinc(float(i)/YLOWPASS_WAVELENGTH)/YLOWPASS_WAVELENGTH;\n        float sincI = Sinc(float(i)/ILOWPASS_WAVELENGTH)/ILOWPASS_WAVELENGTH;\n        float sincQ = Sinc(float(i)/QLOWPASS_WAVELENGTH)/QLOWPASS_WAVELENGTH;\n        \n        vec2 uvWithOffset = vec2(uv.x + float(i) * pixelWidth, uv.y);\n\n        vec3 yiqSample = MatrixRGBToYIQ * clamp(texture(sampler, uvWithOffset).xyz, vec3(0.0), vec3(1.0));\n        \n    \tyiq.x += yiqSample.x * sincY * window;\n        yiq.y += yiqSample.y * sincI * window;\n        yiq.z += yiqSample.z * sincQ * window;\n    }\n    \n    float phase = uv.x * PI / (COLORBURST_WAVELENGTH_ENCODER * pixelWidth);\n    \n    if(alternatePhase)\n    {\n        phase += PHASE_ALTERNATION;\n    }\n    \n    float phaseAM = uv.x * PI / (AM_CARRIERSIGNAL_WAVELENGTH * pixelWidth);\n    \n    return (yiq.x \n         + sin(phase) * yiq.y\n         + cos(phase) * yiq.z\n         + 1.0) * 0.5  * sin(phaseAM);\n}\n\nvec3 Decode(sampler2D sampler, in vec2 uv, in float pixelWidth, ivec2 rng, bool alternatePhase)\n{\n    uint seed = uint(rng.y);\n    \n    float rowNoiseIntensity = RandomFloat01(seed);\n    rowNoiseIntensity = pow(rowNoiseIntensity, 500.0) * 1.0;\n    \n    float horizOffsetNoise = RandomFloat01(seed) * 2.0 - 1.0;\n    horizOffsetNoise *= rowNoiseIntensity * 0.1 * NOISE_STRENGTH;\n    //uv.x += horizOffsetNoise;\n    \n    float phaseNoise = RandomFloat01(seed) * 2.0 - 1.0;\n    phaseNoise *= rowNoiseIntensity * 0.5 * 3.1415927 * NOISE_STRENGTH;\n\n    float frequencyNoise = RandomFloat01(seed) * 2.0 - 1.0;\n    frequencyNoise *= rowNoiseIntensity * 0.1 * 3.1415927 * NOISE_STRENGTH;\n    \n    float alt = 0.0;  \n    if(alternatePhase)\n    {\n        alt = PHASE_ALTERNATION;\n    }\n    \n    \n    vec3 yiq = vec3(0);\n\tfor(int i = -WINDOW_RADIUS; i <= WINDOW_RADIUS; i++)\n    {\n\t\t// Extend padding by one since we don't want to include a sample at the very edge, which will be 0.\n        float window = WindowCosine(float(i) / float(WINDOW_RADIUS+1)); \n        \n        vec2 uvWithOffset = vec2(uv.x + float(i) * pixelWidth, uv.y);\n    \tfloat phase = uvWithOffset.x * PI / ((COLORBURST_WAVELENGTH_DECODER + frequencyNoise) * pixelWidth) + phaseNoise + alt;\n    \t//float phaseAM = uv.x * PI / (AM_SIGNAL_WAVELENGTH * pixelWidth);\n        \n        \n        float sincY = Sinc(float(i)/DECODE_LOWPASS_WAVELENGTH)/DECODE_LOWPASS_WAVELENGTH;\n        float sinI = sin(phase);\n        float sinQ = cos(phase);\n        //float sincI = Sinc(float(i)/ILOWPASS_WAVELENGTH)/ILOWPASS_WAVELENGTH;\n        //float sincQ = Sinc(float(i)/QLOWPASS_WAVELENGTH)/QLOWPASS_WAVELENGTH;\n        \n        float encodedSample = (max(0.0, texture(sampler, uvWithOffset).x) - 0.175) * 6.0;\n        \n    \tyiq.x += encodedSample * sincY * window;\n        yiq.y += encodedSample * sinI * window;\n        yiq.z += encodedSample * sinQ * window;\n        //yiq.y += yiqSample.y * sincI * window;\n        //yiq.z += yiqSample.z * sincQ * window;\n    }\n    \n    \n    yiq.yz *= SATURATION / float(WINDOW_RADIUS);\n    \n    return max(vec3(0.0), MatrixYIQToRGB * yiq);\n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord / iResolution.xy;\n    vec2 pixelSize = 1.0 / iResolution.xy;\n    \n    \n    uint rngStateRow = uint(uint(fragCoord.y) * uint(9277) + uint(iFrame) * uint(26699)) | uint(1);    \n    uint rngStateCol = uint(uint(fragCoord.x) * uint(1973) + uint(iFrame) * uint(26699)) | uint(1);    \n    \n    fragColor.rgb = Decode(iChannel0, uv, pixelSize.x * NTSC_SCALE, ivec2(rngStateCol, rngStateRow), ((iFrame + 1) + int(fragCoord.y)) % 2 == 0);\n    fragColor.a = 1.0;\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"Xdf3Rn","filepath":"/media/a/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","previewfilepath":"/media/ap/e81e818ac76a8983d746784b423178ee9f6cdcdf7f8e8d719341a6fe2d2ab303.webm","type":"video","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// RNG algorithm credit: https://www.shadertoy.com/view/wtSyWm\n\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // initialize a random number state based on frag coord and frame\n    uint rngState = uint(uint(fragCoord.x) * uint(1973) + uint(fragCoord.y) * uint(9277) + uint(iFrame) * uint(26699)) | uint(1);    \n    uint rngStateRow = uint(uint(fragCoord.y) * uint(9277) + uint(iFrame) * uint(26699)) | uint(1);    \n    \n    \n    vec2 uv = fragCoord / iResolution.xy;\n    vec2 pixelSize = 1.0 / iResolution.xy;\n    \n    float encoded = Encode(iChannel0, uv, pixelSize.x * NTSC_SCALE, (iFrame + int(fragCoord.y)) % 2 == 0);\n    \n    float snowNoise = RandomFloat01(rngState) - 0.5;\n    float sineNoise = sin(uv.x * 200.0 + uv.y * -50.0 + fract(iTime * iTime) * 3.1415927 * 2.0) * 0.065;\n    float saltPepperNoise = RandomFloat01(rngState) * 2.0 - 1.0;\n    saltPepperNoise = sign(saltPepperNoise) * pow(abs(saltPepperNoise), 200.0) * 10.0;\n    float rowNoise = RandomFloat01(rngStateRow) * 2.0 - 1.0;\n    rowNoise *= 0.1;   \n    float rowSaltPepper = RandomFloat01(rngStateRow) * 2.0 - 1.0;\n    rowSaltPepper = sign(rowSaltPepper) * pow(abs(rowSaltPepper), 200.0) * 1.0;\n    \n    encoded += (snowNoise + saltPepperNoise + sineNoise + rowNoise + rowSaltPepper) * NOISE_STRENGTH; \n    \n    fragColor.rgb = vec3(encoded);\n    fragColor.a = 1.0;\n}","name":"Buffer C","description":"","type":"buffer"}]}
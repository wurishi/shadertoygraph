{"ver":"0.1","info":{"id":"l3KSRK","date":"1720369666","viewed":301,"name":"Burley Screen Space SSS","username":"Poisson","description":"Naive implementation of screen space subsurface scattering. I used Burley's diffusion profile because I think it looks good. Next step: IMPORTANCE SAMPLING","likes":32,"published":1,"flags":32,"usePreview":0,"tags":["raymarching","sss","mandelbulb","raymarcher","scattering","bump","subsurface","diffusion","montecarlo","skin","screenspace","disney","burley"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// MOVE THE MOUSE //\n\n// Buffer A: diffuse texture\n// Buffer B: subsurface scattering\n\n// Narkowicz ACES\nvec3 ACES_tonemap(vec3 x) {\n    const float a = 2.51;\n    const float b = 0.03;\n    const float c = 2.43;\n    const float d = 0.59;\n    const float e = 0.14;\n    return (x * (a * x + b)) / (x * (c * x + d) + e);\n}\n\nvoid mainImage(out vec4 frag_color, in vec2 frag_coord) {\n    vec2 uv = frag_coord / iResolution.xy;\n    \n    vec3 diffuse = textureLod(iChannel0, uv, 0.).rgb; // diffuse texture\n    vec3 sss = texture(iChannel1, uv).rgb / texture(iChannel1, uv).a; // subsurface scattering\n    \n    vec3 color = diffuse + sss;\n    \n    // color transformation\n    color = ACES_tonemap(color);\n    color = pow(color, vec3(.4545)); // gamma correction\n        \n    frag_color = vec4(color, 1); // output\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"XsX3Rn","filepath":"/media/a/92d7758c402f0927011ca8d0a7e40251439fba3a1dac26f5b8b62026323501aa.jpg","previewfilepath":"/media/ap/92d7758c402f0927011ca8d0a7e40251439fba3a1dac26f5b8b62026323501aa.jpg","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// ray sphere intersection\nvec2 sphere_intersect(Ray r, float radius) {\n    vec3 oc = r.origin;\n    float b = dot(oc, r.direction);\n    float c = dot(oc, oc) - radius * radius;\n    float h = b*b - c;\n    \n    if (h < 0.) return vec2(-1);\n    \n    h = sqrt(h);\n    float t_front = -b - h;\n    float t_back = -b + h;\n    \n    return vec2(t_front, t_back);\n}\n\n// basic triplanar mapping \nvec3 triplanar_texture(sampler2D tex, vec3 p, vec3 normal) {\n    vec3 x = texture(tex, p.yz).rgb;\n    vec3 y = texture(tex, p.zx).rgb;\n    vec3 z = texture(tex, p.xy).rgb;\n    \n    vec3 m = abs(normal);\n    return mat3(x, y, z) * m / dot(m, vec3(1));\n}\n\n// texture bump, thanks to shane\nvec3 triplanar_bump(sampler2D tex, vec3 p, vec3 normal, float depth) {\n    const vec2 e = vec2(.0001, 0);\n    \n    mat3 tex_normal = mat3(triplanar_texture(tex, p - e.xyy, normal),\n                           triplanar_texture(tex, p - e.yxy, normal),\n                           triplanar_texture(tex, p - e.yyx, normal));\n    \n    vec3 luma = vec3(.299, .587, .114) * tex_normal;\n    float center_luma = dot(triplanar_texture(tex, p, normal), vec3(.299, .587, .114));\n    \n    return depth * (luma - center_luma) / e.x;\n}\n\n// sdf union operator\nvec2 op_union(vec2 a, vec2 b) {\n    return a.x < b.x ? a : b;\n}\n\n// sphere sdf\nfloat sd_sphere(vec3 p, float r) {\n    return length(p) - r;\n}\n\n// box sdf\nfloat sd_box(vec3 p, vec3 box) {\n    vec3 q = abs(p) - box;\n    return length(max(q, 0.)) + min(max(q.x, max(q.y, q.z)), 0.);\n}\n\n// torus sdf\nfloat sd_torus(vec3 p, vec2 torus) {\n    vec2 q = vec2(length(p.xz) - torus.x, p.y);\n    return length(q) - torus.y;\n}\n\n// mandelbulb sdf, thanks to iq: https://iquilezles.org/articles/mandelbulb/\nfloat sd_mandelbulb(vec3 p, float power) {\n    vec3 w = p;\n    float m = dot(w,w);\n\n\tfloat dz = 1.;\n\tfor (int i = 0; i < 2; i++) {\n\t\tdz = power * pow(m, (power-1.)*.5) * dz + 1.;\n      \n        float r = length(w);\n        float b = power * acos(w.y/r);\n        float a = power * atan(w.x, w.z);\n        w = p + pow(r, power) * vec3(sin(b)*sin(a), cos(b), sin(b)*cos(a));\n        \n        m = dot(w, w);\n\t\tif(m > 256.) break;\n    }\n\n    return .25 * log(m) * sqrt(m) / dz;\n}\n\n// scene sdf\nvec2 sd_scene(vec3 p) {\n    vec2 d = vec2(1e10,-1);\n    \n    d = op_union(d, vec2(sd_torus(p, vec2(1.05,.25)), 0));\n    d = op_union(d, vec2(sd_box(p, vec3(.4,.6,.4))-.02, 1));\n    d = op_union(d, vec2(sd_sphere(p-vec3(0,1,0), .2), 2));\n    d = op_union(d, vec2(sd_mandelbulb(p*1.4, 6.)/1.4, 3));\n    \n    return d;\n}\n\n// raymarching\nvec2 raymarch(Ray r, float t_min, float t_max) {\n    float t = t_min;\n    \n    for (int i = 0; i < 512 && t < t_max; i++) {\n        vec3 p = at(r, t);\n        vec2 h = sd_scene(p);\n        if (h.x < .001) return vec2(t, h.y);\n        t += h.x;\n    }\n    return vec2(-1);\n}\n\n// normal estimation using forward difference\nvec3 compute_normal(vec3 p) {\n    float e = .0001;\n    vec2 h = vec2(e,0);\n    return normalize(vec3(sd_scene(p + h.xyy).x,\n                          sd_scene(p + h.yxy).x,\n                          sd_scene(p + h.yyx).x) - sd_scene(p).x);\n}\n\n// soft shadow function, thanks to iq: https://iquilezles.org/articles/rmshadows/\nfloat soft_shadow(Ray r, float t_min, float t_max, float k) {\n    float shadow = 1.;\n    float t = t_min;\n    \n    for(int i = 0; i < 256 && t < t_max; i++) {\n        vec3 p = at(r, t);\n        float h = sd_scene(p).x;\n        shadow = min(shadow, h / (k * t));\n        \n        if (shadow < -1.) break;\n        t += clamp(h, .005, 1.);\n    }\n    return .5 + .5 * max(shadow, -1.);\n}\n\n// point light direct lighting\nvec3 point_light_direct_illumination(vec3 p, vec3 normal, Point_light point_light) {\n    vec3 light_direction = point_light.center - p;\n    float dist_square = dot(light_direction, light_direction);\n    light_direction = normalize(light_direction);\n    \n    Ray r_shadow = Ray(p, light_direction);\n    float shadow = soft_shadow(r_shadow, .001, sqrt(dist_square), point_light.size);\n    \n    float cosine = max(dot(normal, light_direction), 0.);\n    float weight = 1. / dist_square;\n\n    return point_light.color * point_light.power * weight * (cosine * shadow);\n}\n\n// rendering\nvec4 render_scene(Ray r) {\n    // setup the two point lights\n    Point_light point_light_1 = Point_light(vec3(-1.5, -.5, 1.5), .0, vec3(.2,.6,1), 12.);\n    Point_light point_light_2 = Point_light(vec3(1,1.5,-.5), .0, vec3(1), 2.);\n    \n    vec2 bound = sphere_intersect(r, 1.3); // bounding volume\n    vec2 hit_record = raymarch(r, bound.x, bound.y); // distance and material index\n    float t = hit_record.x; // distance\n    if (t < 0.) return vec4(0,0,0, encode(100., -1.)); // no hit\n    int id = int(hit_record.y); // material index\n    \n    vec3 p = at(r, t); // hit point\n    vec3 normal = compute_normal(p); // surface normal\n    normal = normalize(normal + triplanar_bump(iChannel0, p, normal, .01)); // bump mapping\n\n    // direct illumination\n    vec3 color = point_light_direct_illumination(p, normal, point_light_1);\n    color += point_light_direct_illumination(p, normal, point_light_2);\n    \n    return vec4(get_albedo(id) * color, encode(t, float(id)));\n}\n\nvoid mainImage(out vec4 frag_color, in vec2 frag_coord) {    \n    // camera setup\n    vec2 mouse = iMouse.xy/iResolution.xy - .5;\n    \n    vec3 ro = vec3(0,0,5);\n    //if (iResolution.x <= 400.) mouse = vec2(.2,.2);\n    \n    ro.yz *= rotate(mouse.y * pi + .3);\n    ro.xz *= rotate(mouse.x * pi + .3);\n    \n    vec3 ta = vec3(0);\n    \n    main_camera.origin = ro;\n    main_camera.target = ta;\n    main_camera.focal_length = 4.;\n\n    // uv coordinates with aspect ratio correction\n    vec2 uv = (2.*frag_coord - iResolution.xy) / iResolution.y;\n\n    // rendering\n    Ray r = create_ray(uv, main_camera);\n    vec4 color = render_scene(r);\n    frag_color = color;\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"#define SAMPLES 16\n\nconst float sampling_radius = .2; // sampling radius for the diffusion profile\nconst float rotation_speed = 16.; // rotation speed of the sampling direction\n\n// burley diffusion profile: https://graphics.pixar.com/library/ApproxBSSRDF/paper.pdf\nvec3 burley(float r, vec3 s) {\n    return s / (8.*pi*r) * (exp(-s*r) + exp(-s*r/3.));\n}\n\nvoid mainImage(out vec4 frag_color, in vec2 frag_coord) {\n    vec2 uv = frag_coord / iResolution.xy;\n    vec4 base_texture = texture(iChannel0, uv);\n    int id = int(decode(base_texture.a).y); // material id\n    \n    if (id < 0) {\n    \n    frag_color = base_texture;\n    \n    } else {\n    \n    vec3 total = vec3(0);\n    for (int i = 0; i < SAMPLES; i++) {\n        // init seed\n        seed = float(base_hash(floatBitsToUint(frag_coord)))/float(0xffffffffU) + iTime + float(i);\n    \n        // sampling angle\n        float theta = rotation_speed * (iTime + float(i) / float(SAMPLES));\n        \n        // sampling radius\n        float r = sampling_radius * hash1(seed);\n        if (r < .0001) r = sampling_radius * hash1(seed); // prevent fireflies\n        \n        vec2 offset = sqrt(r) * vec2(cos(theta), sin(theta)); // sampling point\n        vec4 sample_texture = texture(iChannel0, uv + offset * vec2(iResolution.y/iResolution.x, 1));\n        \n        // naive depth correction\n        float depth_delta = decode(base_texture.a).x - decode(sample_texture.a).x;\n        float h = clamp(depth_delta, 0., 1.);\n        \n        vec3 weight = sampling_radius * burley(r, get_scattering_coefficient(id));\n        vec3 color = weight * mix(sample_texture.rgb, base_texture.rgb, h);\n        total += color;\n    }\n\n    // accumulate frames\n    vec4 previous_frame = texelFetch(iChannel1, ivec2(frag_coord), 0);\n    frag_color = vec4(total / float(SAMPLES), 1) + previous_frame * step(iMouse.z,0.);\n\n    }\n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"const float pi = 3.14159265; // pi\n\n// encoding a float and an int in one single float\nfloat encode(float a, float b) {\n    return a + 1024.*b;\n}\n\n// decoding\nvec2 decode(float x) {\n    return vec2(mod(x, 1024.), floor(x / 1024.));\n}\n\n// scattering coefficients for different materials\nvec3 get_scattering_coefficient(int id) {\n    if (id == 0) return vec3(4,1.6,.4); // skin\n    else if (id == 1) return vec3(3,1.2,.9); // candy\n    else if (id == 2) return vec3(2,2.2,4); // blue material\n    else if (id == 3) return vec3(3.,2,.5); // green-ish material\n    return vec3(0);\n}\n\n// albedo (surface color) for different materials\nvec3 get_albedo(int id) {\n    if (id == 0) return vec3(.6,.5,.5); // skin\n        else if (id == 1) return vec3(.8,.2,.4); // candy\n    else if (id == 2) return vec3(.3,.5,.8); // blue material\n    else if (id == 3) return vec3(.4,.7,.6); // green_ish material\n}\n\nfloat seed = 0.; // random numbers seed\n\n// hash functions by nimitz: https://www.shadertoy.com/view/Xt3cDn\n\nuint base_hash(uvec2 p) {\n    p = 1103515245U * ((p >> 1U) ^ p.yx);\n    uint h32 = 1103515245U * (p.x ^ (p.y>>3U));\n    return h32 ^ (h32 >> 16);\n}\n\nfloat hash1(inout float seed) {\n    uint n = base_hash(floatBitsToUint(vec2(seed += .1, seed += .1)));\n    return float(n) / float(0xffffffffU);\n}\n\n// camera structure\nstruct Camera {\n    vec3 origin;\n    vec3 target;\n    float focal_length;\n} main_camera;\n\n// ray structure\nstruct Ray {\n    vec3 origin;\n    vec3 direction;\n};\n\n// point light structure\nstruct Point_light {\n    vec3 center;\n    float size;\n    vec3 color;\n    float power;\n};\n\n// point on ray r at time t\nvec3 at(Ray r, float t) {\n    return r.origin + t * r.direction;\n}\n\n// camera matrix\nmat3 set_camera(Camera camera) {\n    vec3 w = normalize(camera.target - camera.origin); // camera view direction\n    vec3 u = normalize(cross(w, vec3(0,1,0)));\n    vec3 v = cross(u, w);\n    return mat3(u, v, w); // orthonormal basis\n}\n\n// create a ray with uv and a camera\nRay create_ray(vec2 uv, Camera camera) {\n    mat3 camera_matrix = set_camera(camera);\n    vec3 ray_direction = camera_matrix * normalize(vec3(uv, camera.focal_length));\n    return Ray(camera.origin, ray_direction);\n}\n\n// 2d rotation matrix\nmat2 rotate(float angle) {\n    float sine = sin(angle);\n    float cosine = cos(angle);\n    return mat2(cosine, sine, -sine, cosine);\n}","name":"Common","description":"","type":"common"}]}
{"ver":"0.1","info":{"id":"XcsGRl","date":"1703366951","viewed":81,"name":"Fractal PathTracer","username":"TheJinxedArtist","description":"A raymarched fractal with pathtraced lighting.\n\nIf anyone knows the reason for why black pixels start appearing, I would love to know!","likes":6,"published":1,"flags":32,"usePreview":0,"tags":["fractal","pathtrace"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"const mat3 ACESInputMat = mat3(\n    0.59719, 0.35458, 0.04823,\n    0.07600, 0.90834, 0.01566,\n    0.02840, 0.13383, 0.83777\n);\n\nconst mat3 ACESOutputMat = mat3(\n     1.60475, -0.53108, -0.07367,\n    -0.10208,  1.10813, -0.00605,\n    -0.00327, -0.07276,  1.07602\n);\n\nvec3 RRTAndODTFit(vec3 v)\n{\n    vec3 a = v * (v + 0.0245786) - 0.000090537;\n    vec3 b = v * (0.983729 * v + 0.4329510) + 0.238081;\n    return a / b;\n}\n\nvec3 ACESFitted(vec3 color)\n{\n    color = color * ACESInputMat;\n\n    color = RRTAndODTFit(color);\n    color = color * ACESOutputMat;\n\n    color = clamp(color, 0.0, 1.0);\n\n    return color;\n}\n\nvec3 hsv2rgb(vec3 c)\n{\n    vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);\n    vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);\n    return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);\n}\n\nvec3 rgb2hsv(vec3 c)\n{\n    vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);\n    vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));\n    vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));\n\n    float d = q.x - min(q.w, q.y);\n    float e = 1.0e-10;\n    return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n\n    vec3 col = texture(iChannel0, uv).rgb;\n    //ACES Tonemap.\n    col = ACESFitted(col);\n    \n    //Colour Adjustments (Decrease Saturation and Make Value More Contrast-y).\n    vec3 hsv = rgb2hsv(col);\n    hsv.g *= 0.9;\n    hsv.b = pow(hsv.b * 1.2, 1.5);\n    col = hsv2rgb(hsv);\n\n    fragColor = vec4(col,1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"//Some Values.\n#define PI 3.14159265359\n#define TWO_PI 6.28318530718\n\n//Uint Based Random Number Generator.\nfloat RandomValue(inout uint state)\n{\n    state = state * 747796405u + 2891336453u;\n    uint result = ((state >> ((state >> 28u) + 4u)) ^ state) * 277803737u;\n    result = (result >> 22u) ^ result;\n    state *= result;\n    return float(result) / 4294967295.0;\n}\n\n//For Random Direction.\nfloat RandomValueNormalDistribution(inout uint n)\n{\n    float theta = 2.0 * PI * RandomValue(n);\n    float rho = sqrt(-2.0 * log(RandomValue(n)));\n    n += uint(rho * cos(theta));\n    return rho * cos(theta);\n}\n\n//For Ray Bounce.\nvec3 RandomDirection(inout uint n)\n{\n    float x = RandomValueNormalDistribution(n);\n    float y = RandomValueNormalDistribution(n);\n    float z = RandomValueNormalDistribution(n);\n    return normalize(vec3(x, y, z));\n}\n\n//For Bokeh.\nvec2 RandomPointInCircle(inout uint n)\n{\n    float angle = RandomValue(n) * 2.0 * PI;\n    vec2 pointOnCircle = vec2(cos(angle), sin(angle));\n    return pointOnCircle * sqrt(RandomValue(n));\n}\n\n//By iq.\nvec4 boxmap( in sampler2D s, in vec3 p, in vec3 n, in float k )\n{\n    // project+fetch\n\tvec4 x = texture( s, p.yz );\n\tvec4 y = texture( s, p.zx );\n\tvec4 z = texture( s, p.xy );\n    \n    // and blend\n    vec3 m = pow( abs(n), vec3(k) );\n\treturn (x*m.x + y*m.y + z*m.z) / (m.x + m.y + m.z);\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"XsXGRn","filepath":"/media/a/cd4c518bc6ef165c39d4405b347b51ba40f8d7a065ab0e8d2e4f422cbc1e8a43.jpg","previewfilepath":"/media/ap/cd4c518bc6ef165c39d4405b347b51ba40f8d7a065ab0e8d2e4f422cbc1e8a43.jpg","type":"texture","channel":2,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsfGzn","filepath":"/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","previewfilepath":"/media/ap/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","type":"cubemap","channel":1,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//Raymarching Constants.\nconst float minDist = 0.001;\nconst float maxDist = 10.0;\nconst int samples = 256;\n\n//Fractal Distance (From iq I think...).\nfloat SphereFractal(vec3 p)\n{\n    if(p.y > 1.0)\n        return maxDist;\n    float scale = 1.0;\n\tfor( int i=0; i<8;i++ )\n\t{\n\t\tp = -1.0 + 2.0 * fract(0.5 * p + 0.5);\n\n\t\tfloat r2 = dot(p,p);\n\n\t\tfloat k = 1.5/r2;\n\t\tp *= k;\n\t\tscale *= k;\n\t}\n\n\treturn 0.25 * abs(p.y) / scale;\n}\n\n//Raymarch Distance To Scene.\nfloat RayMarch(vec3 ro, vec3 rd)\n{\n    float dO = minDist;\n    for(int i = 0; i < samples; i++)\n    {\n        vec3 p = ro + rd * dO;\n        float dS = SphereFractal(p);\n        dO += dS;\n        if(dS < minDist || dO > maxDist) break;\n    }\n    return dO;\n}\n\n//Calculate Normal Vector (probably also from iq).\nvec3 Normal(vec3 p)\n{\n    float d0 = SphereFractal(p);\n    const vec2 epsilon = vec2(.0001,0);\n    vec3 d1 = vec3(\n        SphereFractal(p-epsilon.xyy),\n        SphereFractal(p-epsilon.yxy),\n        SphereFractal(p-epsilon.yyx));\n    return normalize(d0 - d1);\n}\n\nvec3 Sky(vec3 p)\n{\n    //Grab Sky Texture and Push Into HDR With Inverse Tonemaping (For Brighter Lights).\n    vec3 c = texture(iChannel1, p).rgb;\n    c = clamp((c + c) / (2.0 - c), 0.0, 10.0);\n    c *= 2.0;\n    return c;\n}\n\nvec3 Light(vec3 ro, vec3 rd, uint s)\n{\n    vec3 rayColor = vec3(1);\n    vec3 incoming = vec3(0);\n    \n    for(int i = 0; i < 16; i++)\n    {\n        //Calculate Geometry Data.\n        float dst = RayMarch(ro, rd); //Distance To Scene From Camera.\n        vec3 p = ro + rd * dst;       //World Position.\n        vec3 n = Normal(p);           //Normal Vector.\n        \n        if(dst < maxDist)\n        {\n            //Set Ray's Origin To The Ray's Hit Position (With Offset So Lighting Works).\n            ro = p + (n * 0.001);\n            \n            //Calculate New Ray Directions (Diffuse and Reflective).\n            vec3 diffuseDir = normalize(n + RandomDirection(s));\n            vec3 reflDir = reflect(normalize(rd), n);\n            \n            //Apply Ray Direction.\n            rd = mix(diffuseDir, reflDir, 0.7);\n            \n            //Apply Material (Texture In iChannel2).\n            rayColor *= boxmap(iChannel2, p * 10.0, n, 1.0).rgb;\n        }\n        else\n        {\n            //Add Sky Light and Break Out of The Loop If The Ray Doesn't Hit.\n            incoming = Sky(rd) * rayColor;\n            break;\n        }\n    }\n    return incoming;\n}\n\n//I think this is also by iq (probably)\nmat3 camera(vec3 position, vec3 target)\n{\n    vec3 dir = normalize(target - position);\n    vec3 right = normalize(cross(vec3(0, 1, 0), dir));\n    vec3 up = normalize(cross(dir, right));\n    \n    return mat3(-right, up, -dir);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = (fragCoord.xy - 0.5 * iResolution.xy) / iResolution.y;\n    vec2 uv2 = fragCoord.xy / iResolution.xy;\n    \n    //Target and Camera Positions.\n    vec3 target = vec3(0.0, 0.1, 0.0);\n    vec3 camPos = vec3(0, .25, 0);\n    \n    //Edit Camera Position Based On Target.\n    float distFromTarget = 1.1;\n    camPos.x = distFromTarget * cos(1.1) + target.x;\n    camPos.z = distFromTarget * sin(1.0) + target.z;\n    \n    //Calculate View Direction From Camera Position and Target.\n    mat3 cam = camera(camPos, target);\n    vec3 viewDir = camera(camPos, target) * normalize(vec3(uv, -1.75));\n\n    //Create Colour Value.\n    vec3 c = vec3(0);\n    \n    //Random Value Seed.\n    ivec2 pixels = ivec2(iResolution.xy);\n    ivec2 pixelCoord = ivec2(fragCoord.xy);\n    uint pixelIndex = uint(pixelCoord.y * pixels.x + pixelCoord.x);\n    uint rnd = pixelIndex + uint(iFrame * 719393);\n    \n    //Offset Ray Origin for Bokeh Blur.\n    vec2 defocusJitter = RandomPointInCircle(rnd) * 10.0 / iResolution.x;\n    vec3 ro = camPos + cam[0] * defocusJitter.x + cam[1] * defocusJitter.y;\n    vec3 focusPoint = camPos + viewDir * distFromTarget;\n    vec3 rd = normalize(focusPoint - ro);\n    \n    //Apply Lighting and Colour.\n    c = Light(ro, rd, rnd);\n    \n    /*\n    \n    //Distance Based Darkening, Because Background Was Too Bright.\n    float fog = exp(-RayMarch(ro, rd) * 0.7);\n    c *= fog;\n    //Added Exposure, Because Fog Made Everything Too Dark.\n    c *= 1.5;\n    \n    */\n    \n    //Denoise Over Time.\n    float weight = 1.0 / float(iFrame + 1);\n    vec3 average = texture(iChannel0, uv2).rgb * (1.0 - weight) + max(c,vec3(0,0,0)) * weight; //Modification by c0rymcy\n    c = average;\n    \n    fragColor = vec4(c, 1.0);\n}","name":"Buffer A","description":"","type":"buffer"}]}
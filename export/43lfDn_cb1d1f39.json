{"ver":"0.1","info":{"id":"43lfDn","date":"1728318894","viewed":10,"name":"GeoFractals","username":"bears0","description":"Based off of what I think is being done in the Fraksl app for iPhone and Android.\nIf anyone knows of a way to make this work better, please let me know.\n\nIt works by ","likes":0,"published":1,"flags":48,"usePreview":0,"tags":["fractals"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n\n    // Time varying pixel color\n    //vec3 col = 0.5 + 0.5*cos(iTime+uv.xyx+vec3(0,2,4));\n\n    // Output to screen\n    if(uv.x > 0.5){\n        uv.x = 1.0 - uv.x;\n    }\n    //uv.y = -uv.y + 1.0;\n    fragColor = texture(iChannel0, uv);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Buffer A handles the offset, angle and scale values. (pan, rotate, zoom)\n\nconst int KEY_LEFT  = 37;\nconst int KEY_UP    = 38;\nconst int KEY_RIGHT = 39;\nconst int KEY_DOWN  = 40;\n\nconst int KEY_W  = 87;\nconst int KEY_A  = 65;\nconst int KEY_S  = 83;\nconst int KEY_D  = 68;\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\n    // If we are on the initial frame, we want to initialize the scale, angle, and offset values.\n    if(iFrame == 0) {\n        if(storeData(fragCoord, angleAddr)) {\n            fragColor = vec4(0.0, 0.0, 0.0, 0.0);\n            return;\n        }\n        if(storeData(fragCoord, scaleAddr)) {\n            fragColor = vec4(0.8, 0.0, 0.0, 0.0);\n            return;\n        }\n        if(storeData(fragCoord, offsetAddr)) {\n            fragColor = vec4(0.0, 0.0, 0.0, 0.0);\n            return;\n        }\n    }\n    \n    // We really only need to run these sections when the fragCoord matches the address of the corresponding parameter.\n    // This saves a tiny amount of computation time since we aren't pulling this data for every single pixel. (~10ms)\n    // Logic: If we are processing one of the corresponding fragments,\n    // pull the old value, add or subtract an offset, then save the possibly changed value.\n    // ANGLE\n    if(storeData(fragCoord, angleAddr)) {\n        float angle = fetchData(iChannel1, angleAddr).x;\n        if(texelFetch( iChannel0, ivec2(KEY_LEFT,0), 0 ).x > 0.5){\n            angle -= 0.01;\n        }\n        if(texelFetch( iChannel0, ivec2(KEY_RIGHT,0), 0 ).x > 0.5){\n            angle += 0.01;\n        }\n        fragColor = vec4(angle, 0.0, 0.0, 0.0);\n    }\n    \n    // SCALE\n    if(storeData(fragCoord, scaleAddr)) {\n        float scale = fetchData(iChannel1, scaleAddr).x;\n        if(texelFetch( iChannel0, ivec2(KEY_UP,0), 0 ).x > 0.5){\n            scale -= 0.01;\n        }\n        if(texelFetch( iChannel0, ivec2(KEY_DOWN,0), 0 ).x > 0.5){\n            scale += 0.01;\n        }\n        fragColor = vec4(scale, 0.0, 0.0, 0.0);\n    }\n\n    // OFFSET\n    if(storeData(fragCoord, offsetAddr)) {\n        vec2 offset = fetchData(iChannel1, offsetAddr).xy;\n        if(texelFetch( iChannel0, ivec2(KEY_W,0), 0 ).x > 0.5){ // W\n            offset.y += moveSpeed;\n        }\n        if(texelFetch( iChannel0, ivec2(KEY_A,0), 0 ).x > 0.5){ // A\n            offset.x -= moveSpeed;\n        }\n        if(texelFetch( iChannel0, ivec2(KEY_S,0), 0 ).x > 0.5){ // S\n            offset.y -= moveSpeed;\n        }\n        if(texelFetch( iChannel0, ivec2(KEY_D,0), 0 ).x > 0.5){ // D\n            offset.x += moveSpeed;\n        }\n        fragColor = vec4(offset.x, offset.y, 0.0, 0.0);\n    }\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"// Adjust these if you want to adjust the rotation, zoom, and pan speed\n#define moveSpeed 0.003\n#define rotationSpeed = 0.01\n#define zoomSpeed\n\n// Addresses:\n// These should be ivec2s containing the pixel coordinates of where certain data\n// should go. The coordinates are not normalized but can range from (0, 0) to\n// (iResolution.x, iResolution.y).\nconst ivec2 scaleAddr  = ivec2(0, 1);\nconst ivec2 angleAddr  = ivec2(0, 2);\nconst ivec2 offsetAddr = ivec2(0, 3);\n\n// Unfortunately, the only way to define functions that sample iChannels in Common\n// is with #define :(\n\n// buf - iChannel to read from\n// addr - the data address in the form of an ivec2 (vector containing two integers)\n#define fetchData(buf, addr) texelFetch(buf, addr, 0)\n\n// buf_pos - fragment position (fragCoord)\n// addr - the data address in the form of an ivec2\n// storeData() just evaluates if the data address matches the fragment position\n// in which case the data should be stored in fragColor.\n#define storeData(buf_pos, addr) ivec2(buf_pos) == addr\n\n\n///////////////////////////////////////////////////////////////////////////////////////////////////\n/// THE FOLLOWING FUNCTIONS WERE TAKEN FROM HERE: https://www.shadertoy.com/view/4dKcWK\n/// Kudos to tayloia!\nconst float EPSILON = 1e-10;\n\nvec3 HUEtoRGB(in float hue)\n{\n    // Hue [0..1] to RGB [0..1]\n    // See http://www.chilliant.com/rgb2hsv.html\n    vec3 rgb = abs(hue * 6. - vec3(3, 2, 4)) * vec3(1, -1, -1) + vec3(-1, 2, 2);\n    return clamp(rgb, 0., 1.);\n}\n\nvec3 RGBtoHCV(in vec3 rgb)\n{\n    // RGB [0..1] to Hue-Chroma-Value [0..1]\n    // Based on work by Sam Hocevar and Emil Persson\n    vec4 p = (rgb.g < rgb.b) ? vec4(rgb.bg, -1., 2. / 3.) : vec4(rgb.gb, 0., -1. / 3.);\n    vec4 q = (rgb.r < p.x) ? vec4(p.xyw, rgb.r) : vec4(rgb.r, p.yzx);\n    float c = q.x - min(q.w, q.y);\n    float h = abs((q.w - q.y) / (6. * c + EPSILON) + q.z);\n    return vec3(h, c, q.x);\n}\n\nvec3 HSVtoRGB(in vec3 hsv)\n{\n    // Hue-Saturation-Value [0..1] to RGB [0..1]\n    vec3 rgb = HUEtoRGB(hsv.x);\n    return ((rgb - 1.) * hsv.y + 1.) * hsv.z;\n}\n\nvec3 HSLtoRGB(in vec3 hsl)\n{\n    // Hue-Saturation-Lightness [0..1] to RGB [0..1]\n    vec3 rgb = HUEtoRGB(hsl.x);\n    float c = (1. - abs(2. * hsl.z - 1.)) * hsl.y;\n    return (rgb - 0.5) * c + hsl.z;\n}\n\nvec3 RGBtoHSV(in vec3 rgb)\n{\n    // RGB [0..1] to Hue-Saturation-Value [0..1]\n    vec3 hcv = RGBtoHCV(rgb);\n    float s = hcv.y / (hcv.z + EPSILON);\n    return vec3(hcv.x, s, hcv.z);\n}\n\nvec3 RGBtoHSL(in vec3 rgb)\n{\n    // RGB [0..1] to Hue-Saturation-Lightness [0..1]\n    vec3 hcv = RGBtoHCV(rgb);\n    float z = hcv.z - hcv.y * 0.5;\n    float s = hcv.y / (1. - abs(z * 2. - 1.) + EPSILON);\n    return vec3(hcv.x, s, z);\n}\n\n\n///////////////////////////////////////////////////////////////////////////////////////////////////\n/// Custom function to shift the hue of the input color. This creates a gradient of colors.\nvec3 shiftHue(in vec3 rgb, in float shift){\n    vec3 hsv = RGBtoHSV(rgb);\n    hsv.x += shift;\n    return HSVtoRGB(hsv);\n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Initialize the first frame to be blue\n    vec2 initUV = fragCoord/iResolution.y;\n    if(iFrame == 0){\n        if(initUV.x > 0.4 && initUV.x < 0.5){\n            fragColor = vec4(1.0,0.0,0.0,1.0);\n        } else {\n            fragColor = vec4(0.0,0.0,1.0,1.0);\n        }\n        return;\n    }\n        \n    float scale = fetchData(iChannel1, scaleAddr).x;\n    float angle = fetchData(iChannel1, angleAddr).x;\n    vec2 offset = fetchData(iChannel1, offsetAddr).xy;\n    \n    vec2 uv = fragCoord/iResolution.y;\n    uv.x *= iResolution.y/iResolution.x;\n    \n    float halfSize = scale / 2.0;\n    vec2 center = vec2(0.5, 0.5);\n    center += offset;\n    // Determine if the pixel is inside the scaled-down area\n    vec2 delta = uv - center;\n    // Apply rotation\n    float s_angle = sin(angle);\n    float c_angle = cos(angle);\n    vec2 rotatedDelta = vec2(\n        delta.x * c_angle - delta.y * s_angle,\n        delta.x * s_angle + delta.y * c_angle\n    );\n    \n    if (abs(rotatedDelta.x) <= halfSize && abs(rotatedDelta.y) <= halfSize) {\n        // Inside the scaled-down area\n        // Map rotated delta back to texture coordinates\n        vec2 scaledUV = rotatedDelta / scale + center - offset;\n        scaledUV.y = -scaledUV.y + 1.0;\n        if(scaledUV.x > 0.5){\n            scaledUV.x = 1.0 - scaledUV.x;\n        }\n        vec4 prevColor = texture(iChannel0, scaledUV);\n        vec3 invertedColor = 1.0 - prevColor.rgb; // Invert colors\n        vec3 shiftedColor = shiftHue(invertedColor, 0.03);\n        fragColor = vec4(shiftedColor, 1.0); // Output the inverted color\n    } else {\n        // Outside the scaled-down area, output transparent\n        fragColor = vec4(0.0,0.0,1.0,1.0);\n    }\n}","name":"Buffer B","description":"","type":"buffer"}]}
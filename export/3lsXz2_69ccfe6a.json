{"ver":"0.1","info":{"id":"3lsXz2","date":"1563591726","viewed":668,"name":"DXT1 Encoding","username":"doles","description":"Super basic Real-time DXT1 encoding + decoding.\n\nhttps://www.nvidia.com/object/real-time-ycocg-dxt-compression.html","likes":3,"published":1,"flags":0,"usePreview":0,"tags":["texture","compression","dxt1"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4sX3Rn","filepath":"/media/a/c3a071ecf273428bc72fc72b2dd972671de8da420a2d4f917b75d20e1c24b34c.ogv","previewfilepath":"/media/ap/c3a071ecf273428bc72fc72b2dd972671de8da420a2d4f917b75d20e1c24b34c.ogv","type":"video","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// https://www.nvidia.com/object/real-time-ycocg-dxt-compression.html\n\n// If defined we compress iChannel0, otherwise just a gradient to test\n#define SOURCE_TEXTURE\n\n#if defined(SOURCE_TEXTURE)\n\n  vec2 GetSourcePixelCoord() {\n    return iChannelResolution[0].xy;\n  }\n\n  vec4 NearestFetch(in uvec2 pixel_coord) {\n    return texelFetch(iChannel0, ivec2(pixel_coord.xy), 0);\n  }\n\n#else\n\n  vec2 GetSourcePixelCoord() {\n    return iResolution.xy;\n  }\n\n  vec4 NearestFetch(in uvec2 pixel_coord) {\n    return vec4(vec2(pixel_coord) / GetSourcePixelCoord(), 0.0, 1.0);\n  }\n\n#endif\n\nvec4 NearestSample(in vec2 uv) {\n  return NearestFetch(uvec2(uv * GetSourcePixelCoord()));\n}\n\n///////////////////////////////////////////////////////////////////////////////\n\nuint Encode565(inout vec3 color) {\n  uvec3 c    = uvec3(round(color * vec3(31.0, 63.0, 31.0)));\n  uint  bits = (c.r << 11) | (c.g << 5) | c.b;\n  c.rb  = (c.rb << 3) | (c.rb >> 2);\n  c.g   = (c.g << 2) | (c.g >> 4);\n  color = vec3(c) * (1.0 / 255.0);\n  return bits;\n}\n\nvec3 Decode565(in uint bits) {\n  return vec3(\n    float((bits >> 11u) & 31u) * (1.0 / 31.0),\n    float((bits >> 5u)  & 63u) * (1.0 / 64.0),\n    float((bits >> 0u)  & 31u) * (1.0 / 31.0)\n  );\n}\n\nfloat ColorDistance(vec3 c0, vec3 c1) {\n  vec3 d = c0-c1;\n  return dot(d, d);\n}\n\nvoid Swap(inout uint a, inout uint b) {\n  uint t=a;\n  a = b;\n  b = t;\n}\n\nvoid Swap(inout vec3 a, inout vec3 b) {\n  vec3 t=a;\n  a = b;\n  b = t;\n}\n\n// Encodes a DXT1 block given the coordinates of its base pixel...\n// Output pixel-format is assumed to be R16G16B16A16\nuvec4 EncodeDXT1(in uvec2 block_coord) {\n  vec3 block_colors[16];\n  for (int i=0; i<4; i++) {\n    for (int j=0; j<4; j++) {\n      block_colors[i*4+j] = NearestFetch(block_coord + uvec2(j,i)).rgb;\n    }\n  }\n\n  vec3 min_color = block_colors[0];\n  vec3 max_color = block_colors[0];\n  for (int i=1; i<16; i++) {\n    min_color = min(min_color, block_colors[i]);\n    max_color = max(max_color, block_colors[i]);\n  }\n\n  vec3 inset = (max_color - min_color) / 16.0 - (8.0 / 255.0) / 16.0;\n  min_color = clamp(min_color + inset, 0.0, 1.0);\n  max_color = clamp(max_color - inset, 0.0, 1.0);\n\n  uint c0 = Encode565(max_color);\n  uint c1 = Encode565(min_color);\n\n  if (c1 > c0) {\n    Swap(c0, c1);\n    Swap(min_color, max_color);\n  }\n\n  vec3 color0 = max_color;\n  vec3 color1 = min_color;\n  vec3 color2 = mix(color0, color1, 1.0 / 3.0);\n  vec3 color3 = mix(color0, color1, 2.0 / 3.0);\n\n  uint i0 = 0U;\n  for (int i=0; i<8; i++) {\n    vec3 color = block_colors[i];\n    vec4 dist = vec4(\n      ColorDistance(color, color0),\n      ColorDistance(color, color1),\n      ColorDistance(color, color2),\n      ColorDistance(color, color3)\n    );\n    uvec4 b = uvec4(greaterThan(dist.xyxy, dist.wzzw));\n    uint b4 = dist.z > dist.w ? 1u : 0u;\n    uint index = (b.x & b4) | (((b.y & b.z) | (b.x & b.w)) << 1);\n    i0 |= index << (i*2);\n  }\n\n  uint i1 = 0U;\n  for(int i=0; i<8; i++) {\n    vec3 color = block_colors[i+8];\n    vec4 dist = vec4(\n      ColorDistance(color, color0),\n      ColorDistance(color, color1),\n      ColorDistance(color, color2),\n      ColorDistance(color, color3)\n    );\n    uvec4 b = uvec4(greaterThan(dist.xyxy, dist.wzzw));\n    uint b4 = dist.z > dist.w ? 1u : 0u;\n    uint index = (b.x & b4) | (((b.y & b.z) | (b.x & b.w)) << 1);\n    i1 |= index << (i*2);\n  }\n\n  return uvec4(c0, c1, i0, i1);\n}\n\n// Decodes a single pixel from inside a DXT1 block...\n// Input pixel-format is assumed to be R16G16B16A16\nvec3 DecodeDXT1(uvec4 block, uvec2 subpixel_coord) {\n  vec3 c0 = Decode565(block.x);\n  vec3 c1 = Decode565(block.y);\n  vec3 c2 = (2.0 * c0 + c1) / 3.0;\n  vec3 c3 = (2.0 * c1 + c0) / 3.0;\n  mat4x3 colors = mat4x3(c0,c1,c2,c3);\n  uint index = subpixel_coord.x + (subpixel_coord.y & 1u)*4u;\n  if (subpixel_coord.y < 2u) {\n    return colors[(block.z >> (index * 2u)) & 3u];\n  } else {\n    return colors[(block.w >> (index * 2u)) & 3u];\n  }\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n  vec2 uv = fragCoord.xy / iResolution.xy;\n  float split = iMouse.x / iResolution.x;\n\n  if (uv.x > split) {\n    // Fetch the pixel coordinate in the source texture...\n    uvec2 pixel_coord = uvec2(uv * GetSourcePixelCoord());\n\n    // Fetch the base pixel coord for the current block...\n    uvec2 block_coord = pixel_coord & uvec2(~3u, ~3u);\n\n    // Encode the given DXT1 block...\n    uvec4 block = EncodeDXT1(block_coord);\n\n    // Decode the DXT1 block and visualize it...\n    fragColor.rgb = DecodeDXT1(block, pixel_coord - block_coord);\n  } else {\n    // Basic nearest sampling of the source texture...\n    fragColor = NearestSample(uv);\n    // For a fair comparison, this should also be 565\n    fragColor.rgb = Decode565(Encode565(fragColor.rgb));\n  }\n\n  // Add a line along the split\n  if (abs(fragCoord.x - iResolution.x*split) < 1.0) {\n    fragColor *= 0.8;\n  }\n}","name":"Image","description":"","type":"image"}]}
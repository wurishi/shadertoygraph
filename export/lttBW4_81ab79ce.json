{"ver":"0.1","info":{"id":"lttBW4","date":"1539701066","viewed":307,"name":"Pyramydal Distances","username":"liamegan","description":"I just wanted to work out the basic math for the transformation of 3D into eyespace, and then into screenspace (2D). I found it impossible to find a straightforward example of this in GLSL, so I just built it.","likes":15,"published":1,"flags":0,"usePreview":0,"tags":["3d","distancefields","lines","vertexes"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"float distLine(vec3 ro, vec3 rd, vec3 p) {\n  return length(cross(p - ro, rd));\n}\n// This line function is from IQ, amazing man that he is.\nfloat df_line( in vec2 a, in vec2 b, in vec2 p)\n{\n  vec2 pa = p - a;\n  vec2 ba = b - a;\n  float h = clamp(dot(pa,ba) / dot(ba,ba), 0., 1.);\t\n  return length(pa - ba * h);\n}\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n      \n  vec2 uv = (fragCoord.xy - 0.5 * iResolution.xy) / min(iResolution.y, iResolution.x);\n\n  vec3 lookAt = vec3(-0., -.08, 0.);\n  vec3 camera_position = vec3(sin(iTime * .5) * 1.5, .5, cos(iTime * .5) * 1.5); // spinning the camera around the origin\n  camera_position.y = -.5-(iMouse.y - iResolution.y * .5) * .01;\n\n  vec3 forward = normalize(lookAt-camera_position);\n  vec3 right = normalize(vec3(forward.z, 0., -forward.x ));\n  vec3 up = normalize(cross(forward,right));\n\n  float FOV = 0.4;\n\n  vec3 rd = normalize(forward + FOV*uv.x*right + FOV*uv.y*up);\n\n  mat4 eyeSpace = mat4(\n    right, 0,\n    up, 0,\n    rd, 0,\n    0,0,0,1\n  );\n  eyeSpace = mat4(\n    1.,0,0,-camera_position.x,\n    0,1.,0,-camera_position.y,\n    0,0,1.,-camera_position.z,\n    0,0,0,1.\n   ) * eyeSpace;\n\n  // The primary points of the pyramid, denoted in world space\n  float delta = .2;\n  vec3 p1 = vec3(0, delta, 0.);\n  vec3 p2 = vec3(-delta, -delta, -delta);\n  vec3 p3 = vec3(delta, -delta, -delta);\n  vec3 p4 = vec3(delta, -delta, delta);\n  vec3 p5 = vec3(-delta, -delta, delta);\n\n  // Projecting the points into eye space\n  vec3 proj1 = (vec4(p1, 1.) * eyeSpace).xyz;\n  vec3 proj2 = (vec4(p2, 1.) * eyeSpace).xyz;\n  vec3 proj3 = (vec4(p3, 1.) * eyeSpace).xyz;\n  vec3 proj4 = (vec4(p4, 1.) * eyeSpace).xyz;\n  vec3 proj5 = (vec4(p5, 1.) * eyeSpace).xyz;\n\n  float focal_length = 1. / FOV;\n\n  // Projecting the points into screen space\n  vec2 x1 = focal_length * proj1.xy / proj1.z;\n  vec2 x2 = focal_length * proj2.xy / proj2.z;\n  vec2 x3 = focal_length * proj3.xy / proj3.z;\n  vec2 x4 = focal_length * proj4.xy / proj4.z;\n  vec2 x5 = focal_length * proj5.xy / proj5.z;\n\n  float render;\n  float fields;\n    \n  // Rendering the points\n  float pointSDF = distLine(camera_position, rd, p1);\n  pointSDF = min(pointSDF, distLine(camera_position, rd, p2));\n  pointSDF = min(pointSDF, distLine(camera_position, rd, p3));\n  pointSDF = min(pointSDF, distLine(camera_position, rd, p4));\n  pointSDF = min(pointSDF, distLine(camera_position, rd, p5));\n    \n  render = smoothstep(.008, .01, pointSDF);\n\n  // Rendering the wireframe\n  float lineSDF = df_line(x1, x2, uv);\n  lineSDF = min(lineSDF, df_line(x1, x3, uv));\n  lineSDF = min(lineSDF, df_line(x1, x4, uv));\n  lineSDF = min(lineSDF, df_line(x1, x5, uv));\n  lineSDF = min(lineSDF, df_line(x2, x3, uv));\n  lineSDF = min(lineSDF, df_line(x3, x4, uv));\n  lineSDF = min(lineSDF, df_line(x4, x5, uv));\n  lineSDF = min(lineSDF, df_line(x2, x5, uv));\n    \n  pointSDF = min(pointSDF, lineSDF);\n    \n  render = min(render, smoothstep(.003, .007, lineSDF));\n  fields = smoothstep(.4, .6, sin((pointSDF-iTime*.02)*300.) * .5 + .5) * .15 * (1. - clamp(pointSDF*5., 0., 1.));\n\n  fragColor = vec4(fields);\n  fragColor += 1. - render;\n}","name":"Image","description":"","type":"image"}]}
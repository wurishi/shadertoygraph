{"ver":"0.1","info":{"id":"st3yRN","date":"1659892185","viewed":780,"name":"TAA Temporal Anti-Aliasing","username":"GCScholar","description":"Exmple implementation of Temporal Anti-Aliasing for a static scene","likes":11,"published":1,"flags":32,"usePreview":0,"tags":["aliasing","antialiasing","alias","temporal","taa"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// Example implementation of Temporal Anti Aliasing for a static scene\n//\n// Buffer A: copy of buffer B, stores the previous frame\n// Buffer B: compute the current rendering, implements TAA\n//\n// When there is a hit with an object, besides the shading, also the 2D screen coordinate\n// that the 3D hitted point had in the previous frame are computed.\n// This is done using the CameraToWorld matrix of the previus frame that has been stored \n// in the BufferA alongside the previous frame colors.\n// Once computed the previous frame screen coordinate, the color of the corresponding pixel in the previous\n// frame in BufferA is fetched and averaged with the current frame color.\n// This is finally the output of the BufferB.\n//\n// This kind of implementation could work only for static scene. Moving object would require to compute also\n// motion vectors from the old position to the new, to get the previous frame pixel position.\n//\n// The shader shows the TAA active/disabled at intervals of 2 seconds.\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;       \n    fragColor = texture(iChannel1, uv);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Buffer A: save frame from Buffer B\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    fragColor = texture(iChannel0, uv);\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"// When defining this matrices remember that GLSL has column major memory layout\n\nmat4 RotX(float angle) \n{\n    return mat4(\n      1,          0,           0, 0,\n      0, cos(angle),  sin(angle), 0,\n      0, -sin(angle), cos(angle), 0,\n      0,          0,  0         , 1\n    );\n}\n\nmat4 RotY(float angle) \n{\n    return mat4(\n      cos(angle), 0, -sin(angle), 0,\n      0,          1,           0, 0,\n      sin(angle), 0,  cos(angle), 0,\n      0,          0,  0         , 1\n    );\n}\n\nmat4 RotZ(float angle) \n{\n    return mat4(\n      cos(angle),  sin(angle), 0,  0,  \n      -sin(angle),  cos(angle), 0, 0,\n      0,           0,           1, 0,\n      0,           0,  0         , 1\n    );\n}\n\nmat4 Trasl(vec3 t) \n{\n    return mat4(\n      1, 0, 0, 0,\n      0, 1, 0, 0,\n      0, 0, 1, 0,\n      t.x, t.y, t.z, 1\n    );\n}","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"//// BUFFER A: Ray traced scene, implements TAA\n\n#define PI acos(-1.)\n#define INF 1./0.\n#define FOCAL_LENGTH 1.\n\n//// Utils functions\n\nvoid swap(inout float x0, inout float x1) { float tmp = x0; x0=x1; x1=tmp; }\n\nbool solveQuadratic(float a, float b, float c, out float x0, out float x1) \n{ \n    float delta = b*b-4.*a*c; \n    if (delta < 0.) return false; \n    else if (delta == 0.) \n    {\n        x0 = x1 = -0.5*b/a; \n    }\n    else \n    { \n        float q = (b > 0.) ? -0.5 * (b + sqrt(delta)) : -0.5 * (b - sqrt(delta)); \n        x0 = q/a; \n        x1 = c/q; \n    } \n    \n    return true; \n} \n\n\n//// Ray tracing structures and functions\n\nstruct Hit \n{\n    float t;\n    vec3 point;\n    vec3 normal;\n    int objId;\n};\n\nstruct Material \n{\n\tfloat shininess;\n    vec3 fresnelR0;\n    vec3 diffuseAlbedo;\n};\n\n// Tnx IQ for patterns\nvec4 getTexture(in vec2 p, int id)\n{\n    const float N = 20.0;\n    \n    // coordinates\n    vec2 i = step( fract(p), vec2(1.0/N));\n    \n    // patterns\n    if(id==1) \n    {\n        vec2 q = floor(p);\n        return vec4(mod( q.x+q.y, 2.0 ));\n    }\n    else if(id==2) return vec4((1.0-i.x)*(1.0-i.y));\n    else if(id==3) return vec4(1.0-i.x*i.y);   \n    else if(id==4) return vec4(1.0-i.x-i.y+2.0*i.x*i.y); \n}\n\nMaterial getMaterial(Hit hit) \n{\n    Material mat;\n\n    // Plane texture coordinates\n    if(hit.objId==1)\n    {\n        mat.shininess = 0.9;\n    \tmat.fresnelR0 =\tvec3(0.1);\n        mat.diffuseAlbedo = vec3(getTexture(hit.point.xz,1));\n        return mat;\n    } \n    \n    // Sphere texture coordinates\n    float u = (1. + atan(hit.normal.z, hit.normal.x) / PI) * 0.5; \n    float v = acos(hit.normal.y) / PI; \n        \n    if(hit.objId==2)\n    {\n        mat.shininess = 0.1;\n    \tmat.fresnelR0 =\tvec3(0.3);    \n        mat.diffuseAlbedo = vec3(getTexture(vec2(u,v)*128.,1)); \n    } \n    else if(hit.objId==3)\n    {\n        mat.shininess = 0.1;\n    \tmat.fresnelR0 =\tvec3(0.3);\n        mat.diffuseAlbedo = vec3(getTexture(vec2(u,v)*64.,2)); \n    } \n    else if(hit.objId==4)\n    {\n        mat.shininess = 0.1;\n    \tmat.fresnelR0 =\tvec3(0.3);\n        mat.diffuseAlbedo = vec3(getTexture(vec2(u,v)*16.,1)); \n    } \n    else if(hit.objId==5)\n    {\n        mat.shininess = 0.1;\n    \tmat.fresnelR0 =\tvec3(0.3);\n        mat.diffuseAlbedo = vec3(getTexture(vec2(u,v)*16.,4)); \n    } \n\n    return mat;\n}\n\nbool tracePlane(vec3 l0, vec3 l, vec3 n, vec3 p0, out Hit hit) \n{\n    float nl = dot(n,l);\n    if(-nl < 0.000001) return false; // line and plane parallel\n    float t = dot(p0-l0,n)/nl;\n    \n    hit.t = t;\n    hit.point = l0+t*l;\n    hit.normal = n;\n    \n    return true;\n}\n\nbool traceSphere(vec3 eye, vec3 ray, vec3 center, float radius, out Hit hit)\n{ \n    float t0, t1;\n\n    vec3 L = eye-center;\n    float a = dot(ray,ray);\n    float b = 2. * dot(ray,L); \n    float c = dot(L,L) - (radius*radius);\n    if (!solveQuadratic(a, b, c, t0, t1)) return false; \n    \n    if (t0 > t1) swap(t0, t1); \n\n    if (t0 < 0.) \n    { \n        t0 = t1;  //if t0 is negative, let's use t1 instead \n        if (t0 < 0.) return false;  //both t0 and t1 are negative \n    } \n\n    hit.t = t0;\n    hit.point = eye + t0*ray;\n    hit.normal = normalize(hit.point - center);\n    \n    return true; \n} \n\n//// Light model\n\nvec3 SchlickFresnel(vec3 R0, vec3 N, vec3 L)\n{\n\t\n\tfloat f0 = 1.0f - max(dot(N, L), 0.0);\n    return R0 + (1.0f - R0)*(f0*f0*f0*f0*f0);\n}\n\n// Blinn-Phong model\nvec3 BlinnPhong(vec3 lightStrength, vec3 L, vec3 N, vec3 V, Material mat)\n{\n    vec3 H = normalize(L+V);\t// Half vector between View and Light vector\n\t\n    float m = mat.shininess * 256.0;\n    float roughnessFactor = ((m + 8.0)*pow(max(dot(H,N),0.0), m))/8.0;\t// Controls how much smooth is the material, taking into account normalization for energy conservation    \n\tvec3 fresnelFactor = SchlickFresnel(mat.fresnelR0, H, L);\n    vec3 specAlbedo = fresnelFactor*roughnessFactor;\n    specAlbedo = specAlbedo / (specAlbedo + 1.0f);\t// the formula goes outside [0,1]\n    return (mat.diffuseAlbedo.rgb + specAlbedo) * lightStrength;\n}\n\n\n//// Rendering\n\nvec4 render(Hit hit, vec3 eye)\n{\n    // Material properties\n    Material mat = getMaterial(hit);\n   \t\n    vec3 V = normalize(eye - hit.point);\t// Vector from surface point to the camera\n\tvec3 N = hit.normal; \n    vec3 R = reflect(-V,N);\t\t// Reflected light vector respect to N\n\n    vec3 toLight1Dir = normalize(vec3(-0.5, 0.5, 0.5));\n    vec3 toLight2Dir = normalize(vec3(0.5, -0.5, 0.5));\n    vec3 toLight3Dir = normalize(vec3(0.0, 0., -0.5));\n    \n    vec3 light1Color = vec3(0.9);\n    vec3 light2Color = vec3(0.9);\n    vec3 light3Color = vec3(0.5);\n    \n    // Lambert-law attenuation\n    vec3 light1Strength = max(dot(toLight1Dir,N),0.0)*light1Color;\n    vec3 C_light1 = BlinnPhong(light1Strength, toLight1Dir, N, V, mat);\n\n    vec3 light2Strength = max(dot(toLight2Dir,N),0.0)*light2Color;\n    vec3 C_light2 = BlinnPhong(light2Strength, toLight2Dir, N, V, mat);\n    \n    vec3 light3Strength = max(dot(toLight3Dir,N),0.0)*light3Color;\n    vec3 C_light3 = BlinnPhong(light3Strength, toLight3Dir, N, V, mat);\n    \n    return vec4(C_light1+C_light2+C_light3,1.0);\n}\n\n\nvec4 sampleScene(vec3 ray, vec3 eye, out Hit hit) \n{\n    vec3 point;\n    vec4 color;\n    float minT = INF;\n    \n    // Left sphere\n    if(traceSphere(eye, ray, vec3(-4,1,0),2., hit) && hit.t < minT)\n    {\n        minT = hit.t;\n        hit.objId = 2;\n        point = hit.point;\n        color = render(hit, eye);\n    }\n    // Central sphere\n    if(traceSphere(eye, ray, vec3(0,1,0),2., hit) && hit.t < minT)\n    {\n        minT = hit.t;\n        hit.objId = 3;\n        point = hit.point;\n        color = render(hit, eye);\n    }\n    // Right sphere\n    if(traceSphere(eye, ray, vec3(4,1,0),2., hit) && hit.t < minT)\n    {\n        minT = hit.t;\n        hit.objId = 4;\n        point = hit.point;\n        color = render(hit, eye);\n    }\n    \n    if(tracePlane(eye, ray, vec3(0,1,0), vec3(0,-1,0), hit) && hit.t < minT)\n    {\n       minT = hit.t;\n       hit.objId = 1;\n       point = hit.point;\n       color = render(hit, eye);\n    }\n    \n    if(minT == 1./0.) \n    {\n        color = vec4(1); // No hit, background color\n        point = vec3(INF);\n    }\n    \n    hit.point = point;\n    return color;\n}\n\nvoid saveCameraToWorldMtx(vec2 fragCoord, mat4 cameraToWorldMtx, inout vec4 fragColor) \n{\n    if(fragCoord.y != 0.5) return;\n    if(fragCoord.x == 0.5) fragColor = cameraToWorldMtx[0];\n    if(fragCoord.x == 1.5) fragColor = cameraToWorldMtx[1];\n    if(fragCoord.x == 2.5) fragColor = cameraToWorldMtx[2];\n    if(fragCoord.x == 3.5) fragColor = cameraToWorldMtx[3];\n}\n\nmat4 getPreviousFrameCameraToWorldMtx() \n{\n    return mat4(\n        texture(iChannel1, vec2(.5,.5)/iResolution.xy), \n        texture(iChannel1, vec2(1.5,.5)/iResolution.xy), \n        texture(iChannel1, vec2(2.5,.5)/iResolution.xy), \n        texture(iChannel1, vec2(3.5,.5)/iResolution.xy));   \n}\n\n// Get the previous frame color projecting the current 3D point hitted from the ray tracer\n// to the screen coordinate it had in the previous frame, using the previous frame CameraToWorldMatrix.\nvec4 getPreviousFrameColor(vec2 fragCoord, vec3 currentFramePoint)\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    mat4 previousFrameCameraToWorldMtx = getPreviousFrameCameraToWorldMtx();\n    vec4 previousFramePoint = inverse(previousFrameCameraToWorldMtx) * vec4(currentFramePoint,1);\n    vec2 previousFrameFragCoord = vec2( previousFramePoint.x/-previousFramePoint.z, previousFramePoint.y/-previousFramePoint.z);\n    float aspectRatio = iResolution.x / iResolution.y; \n    vec2 previousUV = 0.5*vec2(previousFrameFragCoord.x*1./aspectRatio+1., previousFrameFragCoord.y+1.);\n    \n    return texture(iChannel0, previousUV);\n}\n    \nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    mat4 CameraToWorld;\n\n    // From fragCoord to [-AspectRatio,AspectRatio]x[-1,1]\n    vec2 U = (2.*fragCoord-iResolution.xy)/(iResolution.y); \n    \n    // Camera to World matrix\n    float camAngle = 2.*PI*iTime*0.05;\n    mat4 cameraToWorldMtx;\n    cameraToWorldMtx = RotY(camAngle) * Trasl(vec3(0,0,8));\n    \n    // Build Camera frame\n    vec3 eye = (cameraToWorldMtx * vec4(0,0,0,1)).xyz;\n    vec3 target = vec3(0.,0.,0.);\n    vec3 ww = normalize(eye-target);\n    vec3 vv = normalize(cross(vec3(0.,1.,0.), ww));\n    vec3 uu = normalize(cross(ww, vv));\n    \n    // Render scene\n    Hit hit;\n    vec3 ray = normalize(U.x*vv + U.y*uu - FOCAL_LENGTH*ww);\n    fragColor = sampleScene(ray, eye, hit);\n    \n    if(mod(iTime,4.) > 2. && hit.point.x != INF)\n    {\n        // Apply Temporal Anti-Aliasing\n        float w = 0.1;\n        fragColor = (w*fragColor) + (1.-w)*getPreviousFrameColor(fragCoord, hit.point);\n    }\n    \n    // Reserve some pixels to store the Camera To World Matrix\n    saveCameraToWorldMtx(fragCoord, cameraToWorldMtx, fragColor);\n}","name":"Buffer B","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"3tKXWh","date":"1582614940","viewed":312,"name":"convolve test","username":"zephmann","description":"convolve","likes":2,"published":1,"flags":34,"usePreview":0,"tags":["convolve"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec4 col = texture(iChannel0, fragCoord/iResolution.xy);\n\n    // Output to screen\n    fragColor = vec4(col.rgb, 1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4sf3zn","filepath":"/presets/webcam.png","previewfilepath":"/presets/webcam.png","type":"webcam","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"#define CENTER 9.0\n#define OUTER -1.0\n\nvec4 t(vec2 uv) {\n    uv = uv/iResolution.xy;\n    \n    uv += vec2(sin(iTime) * 0.001, cos(iTime*0.747) * 0.001);\n    uv += vec2(0.001);\n    \n    // center at origin (-0.5, 0.5)\n    uv -= 0.5;\n    \n    // scale up just a little bit\n    //uv *= 0.99;\n    \n    // spiral around origin\n    float d2 = dot(uv, uv);\n    d2 *= 0.01;\n    //d2 += 2.3998277; // 137.5 degrees\n    //d2 += 1.25664;  // 72 degrees\n    \n\tuv = vec2(\n        uv.x*cos(d2) + uv.y*sin(d2),\n        -uv.x*sin(d2) + uv.y*cos(d2)\n    );\n\t\n    \n    // shift back to (0, 1)\n    uv += 0.5;\n    \n    return texture(iChannel0, uv);\n}\n\nvec4 convolve(vec2 uv) {\n    \n    vec4 c = t(uv) * CENTER;\n    \n    vec4 ne = t(uv + vec2(-1.0, -1.0)),\n          n = t(uv + vec2( 0.0, -1.0)),\n         nw = t(uv + vec2( 1.0, -1.0)),\n          e = t(uv + vec2(-1.0,  0.0)),\n          w = t(uv + vec2( 1.0,  0.0)),\n         se = t(uv + vec2(-1.0,  1.0)),\n          s = t(uv + vec2( 0.0,  1.0)),\n         sw = t(uv + vec2( 1.0,  1.0));\n    \n    return c + OUTER*(ne + n + nw + e + w + se + s + sw);\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // get value from web cam\n    vec4 web_cam = texture(iChannel1, fragCoord/iResolution.xy);\n    \n    vec4 prev_frame = convolve(fragCoord);\n    prev_frame = vec4(1.0) - prev_frame;\n    prev_frame *= 0.85;\n    \n    // vec4 col = mix(web_cam, prev_frame, 0.1);\n    vec4 col = web_cam;\n    \n    if (iFrame > 2) {\n        col = mix(web_cam, prev_frame, -1.5);\n        //col = max(col, web_cam);\n        //col = abs(web_cam - prev_frame);\n        col *= web_cam;\n    }\n    \n    //col = min(max(col, 0.0), 1.0);\n    col = min(col, 1.0);\n\n    // Output to screen\n    fragColor = vec4(col.rgb, 1.0);\n}","name":"Buffer A","description":"","type":"buffer"}]}
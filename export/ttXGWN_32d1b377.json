{"ver":"0.1","info":{"id":"ttXGWN","date":"1556327203","viewed":2383,"name":"Edge detection and other filters","username":"xavierseb","description":"edge detection and other filters by working with the channel instead of the raster pixels as is normally done","likes":10,"published":3,"flags":2,"usePreview":0,"tags":["blur","edgedetection","sharpen"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4sf3zn","filepath":"/presets/webcam.png","previewfilepath":"/presets/webcam.png","type":"webcam","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// basic sobel edge detection and other convolution filters\n//\n// horizontal edge detection:\n// [  1  2  1 ]\n// [  0  0  0 ]\n// [ -1 -2 -1 ]\n//\n// vertical edge detection:\n// [  1  0  -1 ]\n// [  2  0  -2 ]\n// [  1  0  -1 ]\n//\n// all\n// [ 0 -1 0 ]\n// [ -1 4 -1 ]\n// [ 0 -1 0 ]\n//\n// sharpen\n// [ -1 -1 -1 ]\n// [ -1 9 -1 ]\n// [ -1 -1 -1 ]\n\n// set the convolution filter 0(none) - 5(blur)\n#define FILTER 3\n\n// adjust the distance used in the filter convolution\n#define STEP .005\n\n#define BOT 1.-STEP\n#define TOP 1.+STEP\n#define CEN 1\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    fragColor = \n#if FILTER==0        \n        // none\n          \t\ttexture(iChannel0, uv*vec2(1));               \n#elif FILTER==1\n       // horizontal\n         \t\ttexture( iChannel0, uv*vec2(BOT, BOT))\n         \t\t+texture(iChannel0, uv*vec2(CEN, BOT)) *2.0\n         \t\t+texture(iChannel0, uv*vec2(TOP, BOT))\n         \t\t-texture(iChannel0, uv*vec2(BOT, TOP))\n         \t\t-texture(iChannel0, uv*vec2(CEN, TOP)) *2.0\n         \t\t-texture(iChannel0, uv*vec2(TOP, TOP));\n#elif FILTER==2\n       // vertical edges\n         \t\ttexture( iChannel0, uv*vec2(BOT, BOT))\n         \t\t+texture(iChannel0, uv*vec2(BOT, CEN)) *2.0\n         \t\t+texture(iChannel0, uv*vec2(BOT, TOP))\n         \t\t-texture(iChannel0, uv*vec2(TOP, BOT))\n         \t\t-texture(iChannel0, uv*vec2(TOP, CEN)) *2.0\n         \t\t-texture(iChannel0, uv*vec2(TOP, TOP));\n#elif FILTER==3\n       // all\n        \t\ttexture( iChannel0, uv) *4.\n         \t\t-texture(iChannel0, uv*vec2(CEN, BOT))\n         \t\t-texture(iChannel0, uv*vec2(BOT, CEN))\n         \t\t-texture(iChannel0, uv*vec2(TOP, CEN))\n         \t\t-texture(iChannel0, uv*vec2(CEN, TOP));\n#elif FILTER==4\n       // sharpen\n        \t\ttexture( iChannel0, uv) *2.\n         \t\t-texture(iChannel0, uv*vec2(BOT, BOT))/8.\n         \t\t-texture(iChannel0, uv*vec2(CEN, BOT))/8.\n         \t\t-texture(iChannel0, uv*vec2(TOP, BOT))/8.\n         \t\t-texture(iChannel0, uv*vec2(BOT, CEN))/8.\n         \t\t-texture(iChannel0, uv*vec2(TOP, CEN))/8.\n         \t\t-texture(iChannel0, uv*vec2(BOT, TOP))/8.\n         \t\t-texture(iChannel0, uv*vec2(CEN, TOP))/8.\n         \t\t-texture(iChannel0, uv*vec2(TOP, TOP))/8.;\n#elif FILTER==5\n       // blur\n    \t\t\ttexture( iChannel0, uv*vec2(BOT, BOT))/8.\n         \t\t+texture(iChannel0, uv*vec2(BOT, BOT))/8.\n         \t\t+texture(iChannel0, uv*vec2(TOP, BOT))/8.\n         \t\t+texture(iChannel0, uv*vec2(BOT, CEN))/8.\n         \t\t+texture(iChannel0, uv*vec2(TOP, CEN))/8.\n         \t\t+texture(iChannel0, uv*vec2(BOT, TOP))/8.\n         \t\t+texture(iChannel0, uv*vec2(CEN, TOP))/8.\n         \t\t+texture(iChannel0, uv*vec2(TOP, TOP))/8.;\n#else \n       // sharpen more\n        \t\ttexture( iChannel0, uv) *5.\n         \t\t-texture(iChannel0, uv*vec2(CEN, BOT))\n         \t\t-texture(iChannel0, uv*vec2(BOT, CEN))\n         \t\t-texture(iChannel0, uv*vec2(TOP, CEN))\n         \t\t-texture(iChannel0, uv*vec2(CEN, TOP));\n\n#endif\n}","name":"Image","description":"","type":"image"}]}
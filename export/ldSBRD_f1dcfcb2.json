{"ver":"0.1","info":{"id":"ldSBRD","date":"1499723426","viewed":277,"name":"TDoA Geolocation HDoP","username":"pziezio","description":"Horizontal Dilution of Precision in Time Difference of Arrival geolocation scenario.\nHDoP calculations are made in ECEF coordinate system. Map projection is EPSG:3395 with orthographic projection to the screen.\nOne of the sensors is moveable with mouse.","likes":2,"published":1,"flags":0,"usePreview":0,"tags":["radar","geolocation","hdop","tdoa"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// -----------------------------------------------------------------------------\n//\n// Horizontal Dilution of Precision in 2D Time Difference of Arrival geolocation.\n// HDoP calculations are made in ECEF coordinate system.\n// Map projection is EPSG:3395 with orthographic projection to the screen.\n//\n// Distances and WGS84 ellipsoid parameters are in kilometers\n// to bring floats closer to the optimal resolution range.\n//\n// Copyright © 2017 Piotr Zięzio\n// piotr.ziezio@gmail.com\n//\n// -----------------------------------------------------------------------------\n\n// uncomment this line to enable sensor A control with the mouse cursor\n#define SENSOR_A_MOUSE_CONTROL\n\n// custom texture loading, thanks to https://www.shadertoy.com/view/lsGGDd\n// paste the line below into JavaScript console window:\n// gShaderToy.SetTexture(0, {mSrc:'https://dl.dropboxusercontent.com/s/39dn9c1jtn6nir2/3_no_ice_clouds_8k.jpg?dl=0', mType:'texture', mID:1, mSampler:{ filter: 'mipmap', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\n\n// calculation area (longitude [deg], latitude [deg])\nconst vec2 AREA_LEFT_BOTTOM = vec2(-65.0, 60.0);\nconst vec2 AREA_RIGHT_TOP   = vec2(-15.0, 80.0);\n\n// sensors (longitude [deg], latitude [deg], height [km], ToA standard deviation [s])\nconst vec4 SENSOR_A         = vec4(-40.0, 60.0, 0.150, 1e-6);\nconst vec4 SENSOR_B         = vec4(-40.0, 70.0, 0.130, 1e-6);\nconst vec4 SENSOR_C         = vec4(-40.0, 75.0, 0.140, 1e-6);\n/*\n// calculation area (longitude [deg], latitude [deg])\nconst vec2 AREA_LEFT_BOTTOM = vec2(12.0, 48.0);\nconst vec2 AREA_RIGHT_TOP   = vec2(25.0, 56.0);\n\n// sensors (longitude [deg], latitude [deg], height [km], ToA standard deviation [s])\nconst vec4 SENSOR_A         = vec4(18.5, 52.0, 0.150, 1e-6);\nconst vec4 SENSOR_B         = vec4(18.0, 51.0, 0.130, 1e-6);\nconst vec4 SENSOR_C         = vec4(19.0, 51.0, 0.140, 1e-6);\n*/\n// [km]\nconst float TARGET_ALTITUDE = 1.0;\nconst float HDOP_RANGE      = 10.0;\n\n// -----------------------------------------------------------------------------\n\nconst float pi = 3.14159265359;\n\nconst float c = 298925.574;               // speed of light [km/s]\nconst float c2 = c * c;\n\n// WGS84 Earth ellipsoid\nconst float wgs84a = 6378.1370;           // semi-major axis\nconst float wgs84a2 = wgs84a * wgs84a;\n\nconst float wgs84b = 6356.752314245;      // semi-minor axis\nconst float wgs84b2 = wgs84b * wgs84b;\n\nconst float wgs84f = 1.0 / 298.257223563; // inverse flattening\nconst float wgs84e = 0.0818191908;        // eccentricity\nconst float wgs84e2 = wgs84e * wgs84e;    // eccentricity^2\nconst float wgs84e4 = wgs84e2 * wgs84e2;  // eccentricity^4\nconst float wgs84e6 = wgs84e4 * wgs84e2;  // eccentricity^6\nconst float wgs84e8 = wgs84e4 * wgs84e4;  // eccentricity^8\n\n// -----------------------------------------------------------------------------\n\nfloat deg2rad(float d) { return d * pi / 180.0; }\nfloat rad2deg(float r) { return r * 180.0 / pi; }\n\nvec2 epsg3395project(vec2 c)\n{\n  float s = wgs84e * sin(deg2rad(c.y));\n\n  return vec2\n  (\n    wgs84a * deg2rad(c.x),\n    wgs84a * log(tan(pi / 4.0 + deg2rad(c.y) / 2.0) * pow((1.0 - s) / (1.0 + s), wgs84e / 2.0))\n  );\n}\n\nvec2 epsg3395unproject(vec2 p)\n{\n  float sigma = pi / 2.0 - 2.0 * atan(exp(-p.y / wgs84a));\n\n  return vec2\n  (\n    rad2deg(p.x / wgs84a),\n    rad2deg(sigma + sin(2.0 * sigma) * (wgs84e2 / 2.0 + 5.0 * wgs84e4 / 24.0 + wgs84e6 / 12.0 + 13.0 * wgs84e8 / 360.0) +\n                    sin(4.0 * sigma) * (7.0 * wgs84e4 / 48.0 + 29.0 * wgs84e6 / 240.0 + 811.0 * wgs84e8 / 11520.0) +\n                    sin(6.0 * sigma) * (7.0 * wgs84e6 / 120.0 + 81.0 * wgs84e8 / 1120.0) +\n                    sin(8.0 * sigma) * (4279.0 * wgs84e8 / 161280.0))\n  );\n}\n\nvec3 lla2ecef(vec3 c)\n{\n  c.x = deg2rad(c.x); \n  c.y = deg2rad(c.y);\n    \n  float latsin = sin(c.y);\n  float latcos = cos(c.y);\n  float n = wgs84a / sqrt(1.0 - wgs84e2 * latsin * latsin);\n\n  return vec3\n  (\n    (n + c.z) * latcos * cos(c.x),\n    (n + c.z) * latcos * sin(c.x),\n    (wgs84b2 / wgs84a2 * n + c.z) * latsin\n  );\n}\n\nmat4 orthographicProjectionInverse(float left, float right, float bottom, float top, float near, float far)\n{\n  return mat4\n  (\n    vec4((right - left) / 2.0, 0.0, 0.0, 0.0),\n    vec4(0.0, (top - bottom) / 2.0, 0.0, 0.0),\n    vec4(0.0, 0.0, (far - near) / 2.0, 0.0),\n    vec4((left + right) / 2.0, (top + bottom) / 2.0, (far + near) / 2.0, 1.0)\n  );\n}\n\n// -----------------------------------------------------------------------------\n\nmat2 toaCovariance2D(float toaVariances[3])\n{\n  return mat2\n  (\n    c2 * (toaVariances[0] * toaVariances[0] + toaVariances[1] * toaVariances[1]),\n    c2 * toaVariances[0] * toaVariances[0],\n    c2 * toaVariances[0] * toaVariances[0],\n    c2 * (toaVariances[0] * toaVariances[0]+ toaVariances[2] * toaVariances[2])\n  );\n}\n\nmat2 information2D(vec2 sensors[3], vec2 target)\n{\n  vec2 r = normalize(sensors[0] - target);\n  vec2 s1 = r - normalize(sensors[1] - target);\n  vec2 s2 = r - normalize(sensors[2] - target);\n  return mat2(s1.x, s2.x, s1.y, s2.y);\n}\n\nmat2 covariance2D(mat2 information, mat2 toaCovarianceInverse)\n{\n  return inverse(transpose(information) * toaCovarianceInverse * information);\n}\n\nfloat hdop(mat2 covariance)\n{\n  float xx = covariance[0][0];\n  float yy = covariance[1][1];\n  return xx + yy > 0.0 ? sqrt(xx + yy) : 0.0;\n}\n\n// -----------------------------------------------------------------------------\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n  // fragCoord to NDC [-1, 1]\n  vec2 ndc = fragCoord.xy / iResolution.xy * 2.0 - 1.0;\n    \n  vec2 leftBottom = epsg3395project(AREA_LEFT_BOTTOM);\n  vec2 rightTop = epsg3395project(AREA_RIGHT_TOP);\n\n  // inverse orthographic projection\n  mat4 projInv = orthographicProjectionInverse(leftBottom.x, rightTop.x, leftBottom.y, rightTop.y, -1.0, 1.0);\n  vec4 ndcUnprojected = projInv * vec4(ndc, 1.0, 1.0);\n\n  // longitude-latitude of the pixel    \n  vec2 ll = epsg3395unproject(ndcUnprojected.xy);\n\n  // ECEF coordinates of the pixel\n  vec3 target = lla2ecef(vec3(ll, TARGET_ALTITUDE));\n    \n  #ifdef SENSOR_A_MOUSE_CONTROL\n  // longitude-latitude of mouse cursor\n  vec2 mouseNdc = iMouse.xy / iResolution.xy * 2.0 - 1.0;\n  vec4 mouseUnprojected = projInv * vec4(mouseNdc, 1.0, 1.0);\n  vec2 mouse = epsg3395unproject(mouseUnprojected.xy);\n  vec3 sa = lla2ecef(vec3(mouse.xy, 0.0));\n  #endif\n\n  #ifndef SENSOR_A_MOUSE_CONTROL\n  vec3 sa = lla2ecef(vec3(SENSOR_A.x + sin(iTime), SENSOR_A.y, SENSOR_A.z));\n  #endif\n    \n  vec3 sb = lla2ecef(SENSOR_B.xyz);\n  vec3 sc = lla2ecef(SENSOR_C.xyz);\n\n  mat2 toaCovariance = inverse(toaCovariance2D(float[3](SENSOR_A.w, SENSOR_B.w, SENSOR_C.w)));\n  mat2 information = information2D(vec2[3](sa.xy, sb.xy, sc.xy), target.xy);\n  mat2 covariance = covariance2D(information, toaCovariance);\n    \n  float d = hdop(covariance);\n    \n  // background texture\n  vec2 uv = vec2((ll.x + 180.0) / 360.0, (ll.y + 90.0) / 180.0);\n  vec4 col = texture(iChannel0, uv);\n  \n  // threshold d by some small value to get rid of NaNs, Infs, etc.\n  if (d > 0.00001 && d < HDOP_RANGE)\n  {\n      col = mix(col, vec4(1.0, 0.0, 0.0, 1.0), 1.0 - d / HDOP_RANGE);\n  }\n    \n  fragColor = col;\n}\n","name":"Image","description":"","type":"image"}]}
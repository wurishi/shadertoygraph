{"ver":"0.1","info":{"id":"fldGRS","date":"1636315472","viewed":1139,"name":"Image Tracking I","username":"oneshade","description":"First attempt at locating feature points, no actual extraction though. Eventually, I want to be able to track rotation to get accelerometer-like information.","likes":30,"published":3,"flags":34,"usePreview":0,"tags":["gradient","image","iterative","tracking","newton","hessian","extrema"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"#define video(x, y) texture(iChannel0, vec2(x, y)).r\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 uv = (fragCoord - 0.5 * iResolution.xy) / iResolution.y;\n    float unit = 1.0 / iResolution.y;\n    vec3 color = vec3(0.0);\n\n    // 2D Newton-Raphson optimization on gaussian blurred video\n    // Each step fits a paraboloid to the image function around\n    // p then steps to the extremum of that paraboloid\n    vec2 p = fragCoord / iResolution.xy;//vec2(0.5);\n    vec2 h = 1.0 / iResolution.xy;\n    for (int i=0; i < 10; i++) {\n        float up = video(p.x, p.y + h.y);\n        float right = video(p.x + h.x, p.y);\n        vec2 grad = vec2(right, up) - video(p.x, p.y);\n\n        float dxx = (video(p.x + 2.0 * h.x, p.y) - right - grad.x) / (h.x * h.x);\n        float dxy = (video(p.x + h.x, p.y + h.y) - right - grad.y) / (h.x * h.y);\n        float dyy = (video(p.x, p.y + 2.0 * h.y) - up    - grad.y) / (h.y * h.y);\n\n        grad /= h;\n        mat2 hessian = mat2(dxx, dxy, dxy, dyy);\n\n        p -= inverse(hessian) * grad;\n    }\n\n    color = texture(iChannel0, fragCoord / iResolution.xy).rrr;\n\n    p -= 0.5;\n    p.x *= iResolution.x / iResolution.y;\n    color = mix(color, vec3(1.0), smoothstep(unit, 0.0, length(uv - p) - 0.01));\n\n    fragColor = vec4(color, 1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4sf3zn","filepath":"/presets/webcam.png","previewfilepath":"/presets/webcam.png","type":"webcam","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"#define WIN_W 40.0\n#define WIN_H 40.0\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    fragColor = vec4(0.0);\n    float total = 0.0;\n    for (float x=-WIN_W; x < WIN_W; x++) {\n        float weight = 0.1 * exp(-0.005 * x * x);\n        fragColor += vec4(texture(iChannel0, (fragCoord + vec2(x, 0.0)) / iResolution.xy).rgb * weight, weight);\n    }\n\n    fragColor.rgb /= fragColor.w;\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"#define WIN_W 40.0\n#define WIN_H 40.0\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    fragColor = vec4(0.0);\n    float total = 0.0;\n    for (float y=-WIN_H; y < WIN_H; y++) {\n        float weight = 0.1 * exp(-0.005 * y * y);\n        fragColor += vec4(texture(iChannel0, (fragCoord + vec2(0.0, y)) / iResolution.xy).rgb * weight, weight);\n    }\n\n    fragColor.rgb /= fragColor.w;\n}","name":"Buffer B","description":"","type":"buffer"}]}
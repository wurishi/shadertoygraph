{"ver":"0.1","info":{"id":"Ns3cDr","date":"1658132871","viewed":539,"name":"Raytracing 6 - Specular Reproj","username":"KylBlz","description":"Only specular algorithms enabled. In this iteration the path length is integrated with the PDF and used to support both direct and indirect specular reprojection. The equations for a spherical mirror are in Buffer C line 144, supports surfaces with K >= 0","likes":26,"published":1,"flags":32,"usePreview":0,"tags":["ray","specular","tracing","path","reprojection","integration","length","pdf"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// [Buffer A] Geometry buffer and camera controls\n// [Buffer B] Diffuse buffer with Geometry reprojection\n// [Buffer C] Specular buffer with Specular reprojection\n\nconst float brightness = 255.0;\n\n// Thanks Paniq\nvec3 linear_srgb(vec3 x) {\n    return mix(1.055*pow(x, vec3(1./2.4)) - 0.055, 12.92*x, step(x, vec3(0.0031308)));\n}\n\nvec3 srgb_linear(vec3 x) {\n    return mix(pow((x + 0.055)/1.055,vec3(2.4)), x / 12.92, step(x, vec3(0.04045)));\n}\n\n// Paniq's ACES fitted from https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl\nvec3 ACESFitted(vec3 color) {\n\t// ODT_SAT => XYZ => D60_2_D65 => sRGB\n    color = color * mat3(\n        0.59719, 0.35458, 0.04823,\n        0.07600, 0.90834, 0.01566,\n        0.02840, 0.13383, 0.83777\n    );\n    // Apply RRT and ODT\n    vec3 a = color * (color + 0.0245786) - 0.000090537;\n    vec3 b = color * (0.983729 * color + 0.4329510) + 0.238081;\n    color = a / b;\n\t// Back to color space\n    color = color * mat3(\n         1.60475, -0.53108, -0.07367,\n        -0.10208,  1.10813, -0.00605,\n        -0.00327, -0.07276,  1.07602\n    );\n    // Clamp to [0, 1]\n    return clamp(color, 0.0, 1.0);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    // defines variables for current ray, last ray, current hit, velocity, etc\n    decodeAll(iChannel0, iChannel1);\n    \n    // decode Diffuse and Specular buffers into color, # samples, object ID, path distance\n    buf bd, bs;\n    decodeBuffer(texelFetch(iChannel1, ivec2(fragCoord), 0), bd);\n    decodeBuffer(texelFetch(iChannel2, ivec2(fragCoord), 0), bs);\n    \n    // apply first surface properties\n    ctb surf = getSurface(h);\n    // surface emissive + diffuse surface / n samples + specular surface / n samples\n    fragColor = vec4(0.0, 0.0, 0.0, 1.0);\n    fragColor.rgb += surf.e;\n    fragColor.rgb += (bd.c.rgb * surf.c.rgb * surf.s.x) / max(1.0, float(bd.n));\n    fragColor.rgb += (bs.c.rgb * surf.c.rgb * surf.s.y) / max(1.0, float(bs.n));\n    \n    // tonemap\n    fragColor.rgb = linear_srgb(ACESFitted(fragColor.rgb * brightness));\n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"//////////////////////////////// Rendering Configuration ////////////////////////////////\n\n// raymarching steps\n#define STEPS 128\n// number of frames to reproject and smooth over time (max 16)\n#define TEMPORALSMOOTHING 16\n\n// direct lit lambert surface\n#define SMP_DIRECT_LAMBERT 0\n// lambert surface lit lambert surface\n#define SMP_LAMBERT_SURFACE_LAMBERT 0\n// phong surface lit lambert surface\n#define SMP_LAMBERT_SURFACE_PHONG 0\n\n// direct lit phong surface\n#define SMP_DIRECT_PHONG 1\n// lambert surface lit phong surface\n#define SMP_PHONG_SURFACE_LAMBERT 1\n// phong surface lit phong surface\n#define SMP_PHONG_SURFACE_PHONG 1\n\n// unbiased light samples\n#define SMP_UNBIAS 0\n// bias sample weight to reduce initial unbiased variance\n#define BIAS_WEIGHT 1\n\n// origin, direction, t\nstruct ray { vec3 o; vec3 d; float t; };\n// location, normal, curvature, object ID\nstruct hit { vec3 l; vec3 n; float c; int o; };\n// normal, t, object ID\nstruct pln { vec3 n; float t; int o; };\n// location, radius, object ID\nstruct sph { vec3 l; float r; int o; };\n// direction, pdf weight, path length\nstruct smp { vec3 d; float w; float l; };\n// color, num samples, object ID, path length\nstruct buf { vec4 c; int n; int o; };\n// normal, object ID, t, curvature\nstruct gbf { vec3 n; int o; float t; float c; };\n// surface color, emission, surface properties, PDF weight, path length\nstruct ctb { vec3 c; vec3 e; vec3 s; float w; float l; };\n\n//////////////////////////////// Math Toolkit ////////////////////////////////\n\nconst float\teps = 0.001,     ieps = 0.999,   SML = 0.01,        zfar = 50.0,       FOV = 2.0,\n            HPI = 1.5707963, PI = 3.1415926, TWOPI = 6.2831853, SQRT2 = 1.4142136, SC45 = 0.7071068;\nconst vec4 INIT_POS = vec4(4.0, 3.5, 3.5, 0.0),\n    \t   INIT_ROT = vec4(-0.05, PI, 0.0, 0.0);\n\n// some global material properties\nfloat rough = 4.0;\nfloat ior = 16.0;\n\n// generate a unique value for each pixel/frame\nint genSeed(in int f, in ivec2 c, in ivec2 r) {\n    return (c.x + c.y*2 + f*17) + (c.x*1155 ^ c.y*2244);\n}\n\n// https://www.shadertoy.com/view/7dByR1\nfloat Weyl1D(int i) {\n    return fract(float(i*10368889) / float(0xffffffU));\n}\nvec2 Weyl2D(int i) {\n    return fract(vec2(i*ivec2(12664745, 9560333)) / float(0xffffffU));\n}\n\n// https://www.pbr-book.org/3ed-2018/Monte_Carlo_Integration/2D_Sampling_with_Multidimensional_Transformations\nvec2 concecntric(in vec2 v) {\n    vec2 w = v * 2.0 - 1.0;\n    float thta, rad;\n    if (abs(w.x) > abs(w.y)) {\n        rad = w.x;\n        thta = PI/4.0 * (w.y / w.x);\n    } else {\n        rad = w.y;\n        thta = PI/2.0 - PI/4.0 * (w.x / w.y);\n    }\n    return rad * vec2(cos(thta), sin(thta));\n}\n\nvoid basis(in vec3 n, out vec3 f, out vec3 r) {\n    float s = (n.z >= 0.0)? 1.0: -1.0;\n    float a = 1.0 / (s + n.z);\n    float b = -n.x*n.y*a;\n    f = vec3(1.0 - n.x*n.x*a*s, b*s, -n.x*s);\n    r = vec3(b, s - n.y*n.y*a, -n.y);\n}\n\nvec3 rotateXY(in vec3 p, in vec2 angle) {\n\tvec2 c = cos(angle), s = sin(angle);\n    vec3 o = p;\n\to.yz *= mat2(c.x, s.x, -s.x, c.x); \n    o.xz *= mat2(c.y, s.y, -s.y, c.y);\n\treturn o;\n}\n\n// linear angle of sphere at distance D with radius R\nfloat linearAngle(float d, float r) {\n    return asin(clamp(r/d, eps, ieps));\n}\n\n// solid angle of sphere given distance squared and radius squared\nfloat solidAngle(float d2, float r2) {\n    return (1.0 - sqrt(1.0 - clamp(r2/d2, 0.0, 1.0))) * TWOPI;\n}\n\nfloat Lambertian(in vec3 hn, in vec3 nlv) {\n    return max(SML, dot(nlv, hn));\n}\n\nfloat Schlick(in vec3 hn, in vec3 rfl, in float r1, in float r2) {\n   \tfloat r0 = (r1 - r2) / (r1 + r2);\n\treturn mix(r0*r0, 1.0, pow(1.0 - max(SML, dot(rfl, hn)), 5.0));\n}\n\nfloat Phong(in vec3 nlv, in vec3 rfl, in float gloss) {\n    return pow(max(SML, dot(nlv, rfl)), gloss) * sqrt(gloss);\n}\n\nfloat SchlickPhong(in vec3 rd, in vec3 hn, in vec3 nlv, in float r1, in float r2, in float gloss) {\n    vec3 rfl = reflect(rd, hn);\n    return Schlick(hn, rfl, r1, r2) * Phong(nlv, rfl, gloss);\n}\n\n// cosine distribution\nvec3 cosHemiDir(in vec3 hn, in int seed) {\n    vec2 w = Weyl2D(seed);\n    vec2 c = concecntric(w);\n    return vec3(c.x, c.y, sqrt(max(0.0, 1.0 - c.x*c.x - c.y*c.y)));\n}\n\n// uniform sample cone\nvec3 uniformConeDir(vec3 lv, float lr, in int seed) {\n    vec2 w = Weyl2D(seed);\n    vec2 c = concecntric(w);\n    float sa = tan(linearAngle(length(lv), lr));\n    vec3 u, r, nlv = normalize(lv);\n    basis(nlv, r, u);\n    return normalize(nlv + sa * (r * c.x + u * c.y));\n}\n\n//////////////////////////////// Scene Modeling ////////////////////////////////\n\nvec2 sdMin(in vec2 a, in vec2 b) {\n    if (a.x < b.x)\n        return a;\n    return b;\n}\n\nconst int\n    LIGHT = 1,\n    FLOOR = 2,\n    WALL1 = 3,\n    BOX = 4,\n    WALL2 = 6,\n    CEIL = 7,\n    SPH = 10;\n    \n// light parameters\nsph light = sph(vec3(4.0, 4.0, -6.0), 1.0, LIGHT);\nvec3 lightColor = vec3(0.10, 0.09, 0.08);\n// plane parameters\npln flr = pln(vec3( 0.0, 1.0, 0.0), 0.0, FLOOR);\npln cil = pln(vec3( 0.0,-1.0, 0.0), 8.0, CEIL);\npln wa1 = pln(vec3(-1.0, 0.0, 0.0), 10.0, WALL1);\npln wa2 = pln(vec3( 0.0, 0.0, 1.0), 10.0, WALL2);\n\nctb getSurface(in hit h) {\n    ctb ret;\n    if (h.o == LIGHT) {\n        ret.c = lightColor; // reflection color\n        ret.e = lightColor; // emission color\n        ret.s = vec3(1.0, 1.0, rough); // diffuse (x) specular (y)\n    } else if (h.o < 1) {\n        \n    } else {\n        float refl = float(int(h.o == FLOOR || h.o == CEIL)) * (0.5 + float(int(floor(h.l.x) + floor(h.l.y) + floor(h.l.z)) & 1)) * 0.333 + 0.666;\n        float matCol = float(h.o);\n        float cm = cos(matCol) * 0.25;\n        float sm = sin(matCol) * 0.25;\n        ret.c = vec3(0.5 + cm, 0.5 + sm, 0.5 - (cm + sm) * 0.5) * 0.333;\n        ret.e = vec3(0.0); // emission color\n        ret.s = vec3(refl, refl, rough); // diffuse (x) specular (y) gloss (z)\n    }\n    \n    // loose the average energy for the material, based on measurements from unbiased rendering * 10\n    ret.w = 0.07 * 10.0;\n\n    return ret;\n}\n\nvec2 sdf(in vec3 l, in int o) {\n    vec2 d = vec2(zfar, 0.);\n    d = (o == FLOOR)? d: sdMin(d, vec2(dot(l, flr.n) + flr.t, FLOOR));\n    d = (o == CEIL )? d: sdMin(d, vec2(dot(l, cil.n) + cil.t, CEIL));\n    d = (o == WALL1)? d: sdMin(d, vec2(dot(l, wa1.n) + wa1.t, WALL1));\n    d = (o == WALL2)? d: sdMin(d, vec2(dot(l, wa2.n) + wa2.t, WALL2));\n    d = (o == LIGHT)? d: sdMin(d, vec2(length(l - light.l) - light.r, LIGHT));\n    d = (o == SPH)?   d: sdMin(d, vec2(length(l - vec3(8.0, 1.0, -8.0)) - 1.0, SPH));\n    d = (o == SPH+1)? d: sdMin(d, vec2(length(l - vec3(6.0, 1.0, -8.0)) - 1.0, SPH+1));\n    d = (o == SPH+2)? d: sdMin(d, vec2(length(l - vec3(4.0, 1.0, -8.0)) - 1.0, SPH+2));\n    d = (o == SPH+3)? d: sdMin(d, vec2(length(l - vec3(2.0, 1.0, -8.0)) - 1.0, SPH+3));\n    d = (o == SPH+4)? d: sdMin(d, vec2(length(l - vec3(0.0, 1.0, -8.0)) - 1.0, SPH+4));\n    return d;\n}\n\nvoid updateScene(in float time) {\n    // update light\n    //light.x += cos(time) * HPI;\n}\n\nvec2 march(in vec3 l, in vec3 rd, in int ignore) {\n    float t = 0.0;\n    vec2 sdSmp;\n    for (int i = 0; i < STEPS; ++i) {\n        sdSmp = sdf(l + rd * t, ignore);\n        t += sdSmp.x;\n        if (sdSmp.x < eps)\n            break;\n        if (t > zfar)\n            return vec2(zfar, 0.0);\n    }\n    return vec2(min(t, zfar), sdSmp.y);\n}\n\n// Thanks Nimitz https://www.shadertoy.com/view/Xts3WM\nvec4 norcurv(in vec3 p, in float ep, int ignore) {\n    vec2 e = vec2(-1., 1.)*ep;\n    float t1 = sdf(p + e.yxx, ignore).x, t2 = sdf(p + e.xxy, ignore).x;\n    float t3 = sdf(p + e.xyx, ignore).x, t4 = sdf(p + e.yyy, ignore).x;\n    return vec4(normalize(e.yxx*t1 + e.xxy*t2 + e.xyx*t3 + e.yyy*t4), (t1+t2+t3+t4 - 4.0*sdf(p, ignore).x)/(ep*ep));\n}\n\n//////////////////////////////// PDF only ////////////////////////////////\n\n// surface illuminated by a sphere light, returns sample direction XYZ, pdf W\nsmp SphereLightPDF(in hit h, in sph l, in int seed) {\n    vec3 lv = l.l - h.l;\n    vec3 lambDir = uniformConeDir(lv, l.r, seed);\n    float lpdf = solidAngle(dot(lv,lv), l.r*l.r);\n    return smp(lambDir, lpdf, length(lv)-l.r);\n}\n\n// surface illuminated by a lambertian surface, returns sample direction XYZ, pdf W\nsmp LambertPlanePDF(in hit h, in sph l, in pln p, in int seed) {\n    // dot project light onto plane\n    vec3 d = l.l - p.n * (dot(l.l, p.n) + p.t);\n    // surface to diffuse point d\n    vec3 dv = d - h.l;\n    float dv2 = dot(dv,dv);\n    float ldv = sqrt(dv2);\n    // diffuse point to light\n    vec3 ld = l.l - d;\n    float ld2 = dot(ld,ld);\n    float lld = sqrt(ld2);\n    // sample disc on ground below\n    vec3 lambDir = uniformConeDir(normalize(dv), 0.8, seed);\n    // PDF book keeping\n    float lpdf = solidAngle(pow(ldv*0.1 + lld*0.5, 2.0), l.r*l.r);\n    float g2pdf = Lambertian(p.n, normalize(ld));\n    return smp(lambDir, lpdf * g2pdf, 0.0);\n}\n\n// surface illuminated by a phong surface, returns sample direction XYZ, pdf W\nsmp PhongPlanePDF(in hit h, in sph l, in pln p, in int seed) {\n    // get distance from each point to the plane\n    float a = dot(h.l, p.n) + p.t;\n    float b = dot(l.l, p.n) + p.t;\n    // similar triangles, just use the ratio of side lengths\n    vec3 s = mix(h.l - a*p.n, l.l - b*p.n, a / (a + b));\n    // surface to specular point s\n    vec3 sv = s - h.l;\n    float lsv = sqrt(dot(sv, sv));\n    // specular point to light\n    vec3 ls = l.l - s;\n    float ls2 = dot(ls, ls);\n    float lls = sqrt(ls2);\n    // sample the image of the specular reflection on the surface\n    vec3 ts = sv * lls;\n    vec3 phongDir = uniformConeDir(ts, l.r * lsv * (TWOPI / rough), seed);\n    // PDF book keeping\n    float lpdf = solidAngle(ls2, l.r*l.r);\n    float spdf = SchlickPhong(normalize(sv), -p.n, normalize(ls), 1.0, ior, rough);\n    return smp(phongDir, lpdf * spdf, lsv); // lsv + lls\n}\n\n//////////////////////////////// sampling only ////////////////////////////////\n\n// marches the light, returns contribution RGB\nctb LightContribution(in hit h, in smp s) {\n    vec2 lm = march(h.l, s.d, h.o);\n    if (int(lm.y) != LIGHT)\n        return ctb(vec3(0.0), vec3(0.0), vec3(0.0), 0.0, 0.0);\n    // surface color, surface properties, emission\n    return ctb(lightColor, lightColor, vec3(1.0, 1.0, rough), s.w, s.l);\n}\n\n// marches the surface and light, returns contribution RGB\nctb PlaneContribution(in smp s, in hit h, in pln p, in sph l, in int seed) {\n    // plane sample\n    vec2 res = march(h.l, s.d, h.o);\n    if (int(res.y) != p.o)\n        return ctb(vec3(0.0), vec3(0.0), vec3(0.0), 0.0, 0.0);\n    // move off the surface a little bit\n    vec3 _hl = h.l + s.d * res.x;\n    vec3 _lv = l.l - _hl;\n    float _lv2 = dot(_lv, _lv);\n    // light sampling\n    vec3 sampleDir = uniformConeDir(_lv, l.r, seed);\n    ctb li = LightContribution(hit(_hl, p.n, 0.0, p.o), smp(sampleDir, s.w, sqrt(_lv2)));\n    ctb surf = getSurface(hit(_hl, p.n, 0.0, p.o));\n    // surface color, material energy, light emission, light energy, pdf\n    return ctb(surf.c * surf.w * li.e * li.w, surf.e, surf.s, s.w, s.l);\n}\n\n//////////////////////////////// Buffers ////////////////////////////////\n\n// from IQ's Normals Compression: https://www.shadertoy.com/view/llfcRl\nvec2 msign(vec2 v) {\n    return vec2((v.x >= 0.0)? 1.0: -1.0, (v.y >= 0.0)? 1.0: -1.0);\n}\n\nuint packSnorm2x8(vec2 v) {\n    uvec2 d = uvec2(round(127.5 + v * 127.5));\n    return d.x | (d.y << 8u);\n}\n\nuint octahedral_16(in vec3 nor) {\n    nor /= ( abs( nor.x ) + abs( nor.y ) + abs( nor.z ) );\n    nor.xy = (nor.z >= 0.0)? nor.xy: (1.0 - abs(nor.yx)) * msign(nor.xy);\n    return packSnorm2x8(nor.xy);\n}\n\nvec2 unpackSnorm2x8(uint d) {\n    return vec2(uvec2(d,d>> 8) & 255u) / 127.5 - 1.0;\n}\n\nvec3 i_octahedral_16(uint data) {\n    vec2 v = unpackSnorm2x8(data);\n    vec3 nor = vec3(v, 1.0 - abs(v.x) - abs(v.y)); // Rune Stubbe's version,\n    float t = max(-nor.z,0.0);                     // much faster than original\n    nor.x += (nor.x>0.0)?-t:t;                     // implementation of this\n    nor.y += (nor.y>0.0)?-t:t;                     // technique\n    return normalize( nor );\n}\n\nvoid encodeGbuffer(in gbf g, out vec4 val) {\n    val = vec4(octahedral_16(g.n), float(g.o)+0.5, g.t, g.c);\n}\n\nvoid decodeGbuffer(in vec4 val, out gbf g) {\n    g = gbf(i_octahedral_16(uint(val.x)), int(val.y), val.z, val.w);\n}\n\nvoid encodeBuffer(in buf b, out vec4 v) {\n    v = vec4(float(packHalf2x16(b.c.rb * 0.001)), b.c.g * 0.001, float(b.n) + float(b.o) * 0.01001, b.c.w);\n}\n\nvoid decodeBuffer(in vec4 v, out buf b) {\n    b = buf(vec4(v.g * 1000.0, unpackHalf2x16(uint(v.r)) * 1000.0, v.a).yxzw, int(v.b), int(fract(v.b) * 100.1));\n}\n\n// use decodeAll macro below instead\nvoid _decodeAll(in vec2 fc, in vec2 res, in int iFrame, in sampler2D g, in sampler2D f, out float asp, out ray r, out vec2 ir, out ray l, out vec2 lr, out hit h) {\n    asp = res.x / res.y;\n    vec2 ndca = (2.0 * fc.xy / res.xy - 1.0) * vec2(asp, 1.0);\n    if (iFrame > 1) {\n        // get current cam\n        r.o = texelFetch(g, ivec2(0, int(res.y) - 1), 0).xyz;\n        ir = texelFetch(g, ivec2(1, int(res.y) - 1), 0).xy;\n        l.o = texelFetch(f, ivec2(0, int(res.y) - 1), 0).xyz;\n        lr = texelFetch(f, ivec2(1, int(res.y) - 1), 0).xy;\n    } else {\n        // get initial cam\n        r.o = INIT_POS.xyz;\n        ir = INIT_ROT.xy;\n        l.o = INIT_POS.xyz;\n        lr = INIT_ROT.xy;\n    }\n    r.d = rotateXY(normalize(vec3(ndca, FOV)), ir);\n    l.d = rotateXY(normalize(vec3(ndca, FOV)), lr);\n    // get last trace\n    gbf gb;\n    decodeGbuffer(texelFetch(g, ivec2(fc.xy), 0), gb);\n    r.t = gb.t;\n    h = hit(r.o + r.d * r.t, gb.n, gb.c, gb.o);\n}\n\n// defines variables for current ray, last ray, current hit, velocity, etc\n#define decodeAll(gBuffer, lastFrame) float asp; vec2 ir = INIT_ROT.xy, lr = INIT_ROT.xy; ray l, r; hit h; _decodeAll(fragCoord.xy, iResolution.xy, iFrame, gBuffer, lastFrame, asp, r, ir, l, lr, h)\n\nvec2 reprojCoords(in vec3 ll, in vec2 lr, in vec3 hl, in float asp, in vec2 iChanRes) {\n    // last camera basis\n    vec3 lf = rotateXY(vec3(0.0, 0.0, 1.0), lr);\n    vec3 r = normalize(cross(lf, vec3(0.0, 1.0, 0.0)));\n    vec3 u = normalize(cross(lf, r));\n    // dir to point\n    vec3 nhl = normalize(ll - hl);\n    // project into last cam basis\n    vec2 luv = vec2(dot(nhl, r), dot(nhl, u));\n    // project onto imaging plane NDC coords\n    luv = (luv * FOV) / (dot(nhl, lf) * vec2(asp, 1.0));\n    // ndc to image pixel coords (minus half pixel, glsl uses 'pixel centers')\n    return (luv * -0.5 + 0.5) * iChanRes - 0.5;\n}\n\n// last loc, last orient, hit loc, hit object, 1/aspect, channel, resolution\nbuf reprojectBuffer(in vec2 uv, in int o, sampler2D iChannel) {\n    ivec2 iuv = ivec2(uv);\n    vec2 a = clamp(uv - vec2(iuv), vec2(0.0), vec2(1.0));\n    // samples with matching materials are considered\n    buf b, bx, by, bxy;\n    decodeBuffer(texelFetch(iChannel, iuv,               0), b);\n    decodeBuffer(texelFetch(iChannel, iuv + ivec2(1, 0), 0), bx);\n    decodeBuffer(texelFetch(iChannel, iuv + ivec2(0, 1), 0), by);\n    decodeBuffer(texelFetch(iChannel, iuv + ivec2(1, 1), 0), bxy);\n    float c = float(int(b.o == o));\n    float cx = float(int(bx.o == o));\n    float cy = float(int(by.o == o));\n    float cxy = float(int(bxy.o == o));\n    // get number of samples that matched\n    float n = c + cx + cy + cxy;\n    // fanciest mixing\n    if (n > 3.0) {\n        float ms = float(min(b.n, min(bx.n, min(by.n, bxy.n))));\n        return buf(\n            mix(mix(b.c  / max(1.0, float(b.n )), bx.c  / max(1.0, float(bx.n )), a.x),\n                mix(by.c / max(1.0, float(by.n)), bxy.c / max(1.0, float(bxy.n)), a.x), a.y) * ms,\n            int(ms), o\n        );\n    }\n    if (n < 1.0)\n        return buf(vec4(0.0), 0, 0);\n    // fallback mixing\n    return buf(\n        vec4(c*b.c + cx*bx.c + cy*by.c + cxy*bxy.c) / n,\n        (int(c)*b.n + int(cx)*bx.n + int(cy)*by.n + int(cxy)*bxy.n) / int(n),\n        o\n    );\n}\n","name":"Common","description":"","type":"common"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"//////////////////////////////// Geometry Buffer ////////////////////////////////\n\nmat3 cameraPoses(in float t) {\n    float time = mod(t, 8.0);\n    if (time < 2.)\n        return mat3(vec3(4.0, 3.5, 3.5), vec3(-0.05, PI, 0.), vec3(0.0));\n    else if (time < 4.)\n        return mat3(vec3(1.0, 1.5, -2.0), vec3(0.55, 2.2, 0.), vec3(0.0));\n    else if (time < 6.)\n        return mat3(vec3(5.0, 5.5, 1.0), vec3(-0.44, 2.8, 0.), vec3(0.0));\n    else if (time < 8.)\n        return mat3(vec3(-5.0, 4.5, -5.0), vec3(-0.4, 2.0, 0.), vec3(0.0));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    \n    updateScene(float(iFrame) * 0.01666);\n    \n    float asp = iResolution.x / iResolution.y;\n    vec2 ndca = (2.0 * fragCoord.xy / iResolution.xy - 1.0) * vec2(asp, 1.0);\n\n    // get current cam\n\tvec3 l = INIT_POS.xyz,\n         o = INIT_ROT.xyz;\n    if (iFrame > 1) {\n        // just smoothstep between some nice angles\n        float t = (float(iFrame) * 0.01666) * 0.5;\n        mat3 cLast = cameraPoses(t);\n        mat3 cNext = cameraPoses(t + 1.0);\n        float ft = fract(t);\n        ft = ft*ft*(3.0-2.0*ft);\n        l = mix(cLast[0], cNext[0], ft);\n        o = mix(cLast[1], cNext[1], ft);\n    }\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(l, 0.0);\n            return;\n        } else if (x == 1) {\n            fragColor = vec4(o, 0.0);\n            return;\n        }\n    }\n    \n    // initial scene march\n    vec3 d = rotateXY(normalize(vec3(ndca, FOV)), o.xy);\n    vec2 h = march(l, d, -1);\n    vec3 hl = l + d * h.x;\n    int ho = int(h.y);\n    // get second closest object to ignore during normal computation\n    int io = int(sdf(hl, ho).y);\n    vec4 nc = norcurv(hl, 0.01, io);\n    // encode normal, object ID, depth, curvature\n    encodeGbuffer(gbf(nc.xyz, ho, h.x, nc.w), fragColor);\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"//////////////////////////////// Diffuse Buffer ////////////////////////////////\n\n// diffuse MIS\nvec4 DMIS(in hit h, in int seed) {\n    ctb contrib = ctb(vec3(0.0), vec3(0.0), vec3(0.0), 0.0, 0.0);\n    vec3 ret = vec3(0.0);\n    int si = seed;\n\n#if SMP_DIRECT_LAMBERT\n    // take direct light samples\n    vec3 smpDirect = vec3(0.0);\n    for (int i = 0; i < SMP_DIRECT_LAMBERT; ++i) {\n        si += 1;\n        // get all PDFs\n        smp dl = SphereLightPDF(h, light, si);\n        // apply lambert pdf\n        dl.w *= Lambertian(h.n, dl.d);\n        // compute CDF\n        //float lightCDF = dl.p;\n        // roulette sampling\n        //float rnd = weyl1(si) * lightCDF;\n        //if (rnd <= lightCDF)\n            contrib = LightContribution(h, dl);\n        // color * power * cdf (omitted)\n        smpDirect += contrib.c * contrib.w; // * lightCDF / max(eps, contrib.w);\n    }\n    ret += smpDirect / float(SMP_DIRECT_LAMBERT);\n#endif\n\n#if SMP_LAMBERT_SURFACE_LAMBERT\n    // take indirect diffuse samples\n    vec3 smpIDD = vec3(0.0);\n    for (int i = 0; i < SMP_LAMBERT_SURFACE_LAMBERT; ++i) {\n        si += 1;\n        // get all PDFs\n        smp fd = LambertPlanePDF(h, light, flr, si);\n        smp cd = LambertPlanePDF(h, light, cil, si);\n        smp w1d = LambertPlanePDF(h, light, wa1, si);\n        smp w2d = LambertPlanePDF(h, light, wa2, si);\n        // apply lambert pdf\n        fd.w *= Lambertian(h.n, fd.d);\n        cd.w *= Lambertian(h.n, cd.d);\n        w1d.w *= Lambertian(h.n, w1d.d);\n        w2d.w *= Lambertian(h.n, w2d.d);\n        // compute CDF\n        float floorDiffCDF = fd.w;\n        float ceilDiffCDF = floorDiffCDF + cd.w;\n        float w1DiffCDF = ceilDiffCDF + w1d.w;\n        float w2DiffCDF = w1DiffCDF + w2d.w;\n        // roulette sampling\n        float rnd = Weyl1D(si) * w2DiffCDF;\n        if (rnd <= floorDiffCDF)\n            contrib = PlaneContribution(fd, h, flr, light, si);\n        else if (rnd <= ceilDiffCDF)\n            contrib = PlaneContribution(cd, h, cil, light, si);\n        else if (rnd <= w1DiffCDF)\n            contrib = PlaneContribution(w1d, h, wa1, light, si);\n        else\n            contrib = PlaneContribution(w2d, h, wa2, light, si);\n        // color * diffuse * cdf + surface emsision\n        smpIDD += (contrib.c * contrib.s.x + contrib.e) * w2DiffCDF / max(eps, contrib.w);\n    }\n    ret += smpIDD / float(SMP_LAMBERT_SURFACE_LAMBERT);\n#endif\n\n#if SMP_LAMBERT_SURFACE_PHONG\n    // take indirect specular samples\n    vec3 smpIDS = vec3(0.0);\n    for (int i = 0; i < SMP_LAMBERT_SURFACE_PHONG; ++i) {\n        si += 1;\n        // get all PDFs\n        smp fs = PhongPlanePDF(h, light, flr, si);\n        smp cs = PhongPlanePDF(h, light, cil, si);\n        smp w1s = PhongPlanePDF(h, light, wa1, si);\n        smp w2s = PhongPlanePDF(h, light, wa2, si);\n        // apply lambert pdf\n        fs.w *= Lambertian(h.n, fs.d);\n        cs.w *= Lambertian(h.n, cs.d);\n        w1s.w *= Lambertian(h.n, w1s.d);\n        w2s.w *= Lambertian(h.n, w2s.d);\n        // compute CDF\n        float floorSpecCDF = fs.w;\n        float ceilSpecCDF = floorSpecCDF + cs.w;\n        float w1SpecCDF = ceilSpecCDF + w1s.w;\n        float w2SpecCDF = w1SpecCDF + w2s.w;\n        // roulette sampling\n        float rnd = Weyl1D(si) * w2SpecCDF;\n        if (rnd <= floorSpecCDF)\n            contrib = PlaneContribution(fs, h, flr, light, si);\n        else if (rnd <= ceilSpecCDF)\n            contrib = PlaneContribution(cs, h, cil, light, si);\n        else if (rnd <= w1SpecCDF)\n            contrib = PlaneContribution(w1s, h, wa1, light, si);\n        else\n            contrib = PlaneContribution(w2s, h, wa2, light, si);\n        // color * specular * cdf + surface emsision\n        smpIDS += (contrib.c * contrib.s.y + contrib.e) * w2SpecCDF / max(eps, contrib.w);\n    }\n    ret += smpIDS / float(SMP_LAMBERT_SURFACE_PHONG);\n#endif\n\n    return vec4(ret, 0.0);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n\n    updateScene(float(iFrame) * 0.01666);\n    \n    // defines variables for current ray, last ray, current hit, velocity, etc\n    decodeAll(iChannel0, iChannel1);\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(r.o, 0.0);\n            return;\n        } else if (x == 1) {\n            fragColor = vec4(ir, 0.0, 0.0);\n            return;\n        }\n    }\n    \n    // get reprojected first surface properties\n    vec2 suv = reprojCoords(l.o, lr, h.l, asp, iResolution.xy);\n    // reproject last surface location onto this one\n    buf lastFrame;\n    if (int(suv.y) != int(iResolution.y) - 1 || int(suv.x) > 2)\n        lastFrame = reprojectBuffer(suv, h.o, iChannel1);\n    \n    // TODO: light reprojection (power)\n    //float diffLightPower = 1.0;\n    // adjust last power to new frame\n    //lastFrame.c *= diffLightPower;\n\n    // temporal smoothing\n    if (lastFrame.n > TEMPORALSMOOTHING) {\n        float s = float(TEMPORALSMOOTHING) / float(lastFrame.n);\n        lastFrame.c *= s;\n        lastFrame.n = TEMPORALSMOOTHING;\n    }\n    \n    // sample from surface\n    vec4 smp = vec4(0.0);\n    // not nothing\n    if (h.o != LIGHT) {\n        int seed = genSeed(iFrame, ivec2(fragCoord.xy), ivec2(iResolution.xy));\n        // do biased sampling\n        smp = DMIS(h, seed);\n    }\n    encodeBuffer(buf(lastFrame.c + smp, lastFrame.n + 1, h.o), fragColor);\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"//////////////////////////////// Specular Buffer ////////////////////////////////\n\n// specular MIS\nvec4 SMIS(in ray r, in hit h, in int seed) {\n    ctb contrib = ctb(vec3(0.0), vec3(0.0), vec3(0.0), 0.0, 0.0);\n    vec3 ret = vec3(0.0);\n    vec2 plen = vec2(0.0);\n    int si = seed;\n\n#if SMP_DIRECT_PHONG\n    // take direct light samples\n    vec3 smpDirect = vec3(0.0);\n    vec2 dirPthLn = vec2(0.0);\n    for (int i = 0; i < SMP_DIRECT_PHONG; ++i) {\n        si += 1;\n        // get all PDFs\n        smp dl = SphereLightPDF(h, light, si);\n        // apply phong pdf\n        dl.w *= SchlickPhong(r.d, h.n, dl.d, 1.0, ior, rough);\n        // compute CDF\n        //float lightCDF = dl.p;\n        // roulette sampling\n        //float rnd = weyl1(si) * lightCDF;\n        //if (rnd <= lightCDF)\n            contrib = LightContribution(h, dl);\n        // color * diffuse energy * cdf (omitted)\n        smpDirect += contrib.c * contrib.w; // * lightCDF / max(eps, contrib.w);\n        contrib.w = contrib.w*contrib.w;\n        dirPthLn += vec2(contrib.l*contrib.w, contrib.w);\n    }\n    ret += smpDirect / float(SMP_DIRECT_PHONG);\n    plen += dirPthLn / float(SMP_DIRECT_PHONG);\n#endif\n\n#if SMP_PHONG_SURFACE_LAMBERT\n    // take indirect diffuse samples\n    vec3 smpIDD = vec3(0.0);\n    vec2 iddPthLn = vec2(0.0);\n    for (int i = 0; i < SMP_PHONG_SURFACE_LAMBERT; ++i) {\n        si += 1;\n        // get all PDFs\n        smp fd = LambertPlanePDF(h, light, flr, si + 1);\n        smp cd = LambertPlanePDF(h, light, cil, si + 2);\n        smp w1d = LambertPlanePDF(h, light, wa1, si + 3);\n        smp w2d = LambertPlanePDF(h, light, wa2, si + 4);\n        // apply phong pdf\n        fd.w *= SchlickPhong(r.d, h.n, fd.d, 1.0, ior, rough);\n        cd.w *= SchlickPhong(r.d, h.n, cd.d, 1.0, ior, rough);\n        w1d.w *= SchlickPhong(r.d, h.n, w1d.d, 1.0, ior, rough);\n        w2d.w *= SchlickPhong(r.d, h.n, w2d.d, 1.0, ior, rough);\n        // compute CDF\n        float floorDiffCDF = fd.w;\n        float ceilDiffCDF = floorDiffCDF + cd.w;\n        float w1DiffCDF = ceilDiffCDF + w1d.w;\n        float w2DiffCDF = w1DiffCDF + w2d.w;\n        // roulette sampling\n        float rnd = Weyl1D(si) * w2DiffCDF;\n        if (rnd <= floorDiffCDF)\n            contrib = PlaneContribution(fd, h, flr, light, si + 1);\n        else if (rnd <= ceilDiffCDF)\n            contrib = PlaneContribution(cd, h, cil, light, si + 2);\n        else if (rnd <= w1DiffCDF)\n            contrib = PlaneContribution(w1d, h, wa1, light, si + 3);\n        else\n            contrib = PlaneContribution(w2d, h, wa2, light, si + 4);\n        // color * diffuse * cdf + surface emsision\n        smpIDD += (contrib.c * contrib.s.x + contrib.e) * w2DiffCDF / max(eps, contrib.w);\n        contrib.w = contrib.w*contrib.w;\n        iddPthLn += vec2(contrib.l*contrib.w, contrib.w);\n    }\n    ret += smpIDD / float(SMP_PHONG_SURFACE_LAMBERT);\n    plen += iddPthLn / float(SMP_PHONG_SURFACE_LAMBERT);\n#endif\n\n#if SMP_PHONG_SURFACE_PHONG\n    // take indirect specular samples\n    vec3 smpIDS = vec3(0.0);\n    vec2 idsPthLn = vec2(0.0);\n    for (int i = 0; i < SMP_PHONG_SURFACE_PHONG; ++i) {\n        si += 1;\n        // get all PDFs\n        smp fs = PhongPlanePDF(h, light, flr, si + 1);\n        smp cs = PhongPlanePDF(h, light, cil, si + 2);\n        smp w1s = PhongPlanePDF(h, light, wa1, si + 3);\n        smp w2s = PhongPlanePDF(h, light, wa2, si + 4);\n        // apply phong pdf\n        fs.w *= SchlickPhong(r.d, h.n, fs.d, 1.0, ior, rough);\n        cs.w *= SchlickPhong(r.d, h.n, cs.d, 1.0, ior, rough);\n        w1s.w *= SchlickPhong(r.d, h.n, w1s.d, 1.0, ior, rough);\n        w2s.w *= SchlickPhong(r.d, h.n, w2s.d, 1.0, ior, rough);\n        // compute CDF\n        float floorSpecCDF = fs.w;\n        float ceilSpecCDF = floorSpecCDF + cs.w;\n        float w1SpecCDF = ceilSpecCDF + w1s.w;\n        float w2SpecCDF = w1SpecCDF + w2s.w;\n        float rnd = Weyl1D(si) * w2SpecCDF;\n        // roulette sampling\n        if (rnd <= floorSpecCDF)\n            contrib = PlaneContribution(fs, h, flr, light, si + 1);\n        else if (rnd <= ceilSpecCDF)\n            contrib = PlaneContribution(cs, h, cil, light, si + 2);\n        else if (rnd <= w1SpecCDF)\n            contrib = PlaneContribution(w1s, h, wa1, light, si + 3);\n        else\n            contrib = PlaneContribution(w2s, h, wa2, light, si + 4);\n        // color * specular * cdf + surface emsision\n        smpIDS += (contrib.c * contrib.s.y + contrib.e) * w2SpecCDF / max(eps, contrib.w);\n        contrib.w = contrib.w*contrib.w;\n        idsPthLn += vec2(contrib.l*contrib.w, contrib.w);\n    }\n    ret += smpIDS / float(SMP_PHONG_SURFACE_PHONG);\n    plen += idsPthLn / float(SMP_PHONG_SURFACE_PHONG);\n#endif\n\n    return vec4(ret, plen.x / max(eps, plen.y));\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n\n    updateScene(float(iFrame) * 0.01666);\n    \n    // defines variables for current ray, last ray, current hit, velocity, etc\n    decodeAll(iChannel0, iChannel1);\n    \n    // save current camera info\n    if (int(fragCoord.y) == int(iResolution.y) - 1) {\n        int x = int(fragCoord.x);\n        if (x == 0) {\n            fragColor = vec4(r.o, 0.0);\n            return;\n        } else if (x == 1) {\n            fragColor = vec4(ir, 0.0, 0.0);\n            return;\n        }\n    }\n    \n    // get reprojected first surface properties\n    buf b;\n    vec2 suv = reprojCoords(l.o, lr, h.l, asp, iResolution.xy);\n    if (int(suv.y) != int(iResolution.y) - 1 || int(suv.x) > 2)\n        decodeBuffer(texelFetch(iChannel1, ivec2(suv), 0), b);\n\n    // light reprojection (space) 'virtual image' coordinate\n    float d_o = b.c.w / max(1.0, float(b.n));\n    float d_c = 1.0 / max(eps, h.c);\n    float d_f = d_c * 0.5;\n    float d_i = (d_f * d_o) / (d_f - d_o);\n    vec2 ruv = reprojCoords(l.o, lr, h.l + r.d * d_i, asp, iResolution.xy);\n    buf lastFrame = reprojectBuffer(ruv, h.o, iChannel1);\n    \n    // TODO: light reprojection (power)\n    //float diffLightPower = 1.0;\n    // adjust last power to new frame\n    //lastFrame.c *= diffLightPower;\n    \n    // temporal smoothing\n    if (lastFrame.n > TEMPORALSMOOTHING) {\n        float s = float(TEMPORALSMOOTHING) / float(lastFrame.n);\n        lastFrame.c *= s;\n        lastFrame.n = TEMPORALSMOOTHING;\n    }\n    \n    // sample from surface\n    vec4 smp = vec4(0.0);\n    // not nothing\n    if (h.o != LIGHT) {\n        int seed = genSeed(iFrame, ivec2(fragCoord.xy), ivec2(iResolution.xy));\n        // do biased sampling\n        smp = SMIS(r, h, seed);\n    }\n    encodeBuffer(buf(lastFrame.c + smp, lastFrame.n + 1, h.o), fragColor);\n}\n","name":"Buffer C","description":"","type":"buffer"}]}
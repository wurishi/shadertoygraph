{"ver":"0.1","info":{"id":"Ml3cWB","date":"1533851453","viewed":163,"name":"Volumetric Surface Rendering","username":"amdg","description":"WIP: A volumetric renderer using triple integrals to store information about models with a sphere projection model (rather than eye point). All geometry is implicitly rendered using equations rather than static (explicit) geometry.","likes":0,"published":1,"flags":0,"usePreview":0,"tags":["volumetricrendering"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n* WORK IN PROGRESS: the progress is simply made public for anyone interested.\n* I have an idea for volumetric rendering by using triple integrals as the\n* means of drawing, and simpler equations where applicable. Instead of ray \n* marching (searching efficiently along a ray), I project a ray and calculate \n* the distance to the nearest surface directly. Instead of distance functions\n* describing, for example, a sphere and the distance from its center, the\n* function provides the distance from the camera to the surface of the sphere \n* based on the radius and position of the sphere.\n*\n* The screen model used here is center as origin, uv(0.0, 0.0).\n*\n* We use a box and clip values outside of the viewing area.  This simulates\n* the viewing area accurately without distorting the image result, as the\n* calculations use a spherical plane model, rather than eye point, to determine\n* the direction of the rays, as well as to calculate perspective. This is more\n* like the human eye, and is more efficient because it combines two operations\n* into one.\n*\n* Specifically, the model uses a sphere segment surface as the means of\n* determining the direction of a ray, and this segment is less than or\n* equal to exactly half of a sphere. The size of this segment, as well as\n* the sphere's radius, determines the field of view. This also means\n* you can break the rules and get 360 degrees of vision by simply changing\n* the sphere radius, but this is outside the intended view, and not\n* practical. Therefore, the highest field of view possible in this model\n* is 180 degrees (for a flat monitor), or half of a circle for both axes.\n* If, in a simulated environment with an esoteric screen, you have 360\n* degrees for yaw, pitch, and roll, you can use a 1:1 ratio with this\n* model supposing the whole screen is a perfect sphere.\n*\n* At all times, the arc touches the box at the extremities. We calculate \n* using the distance along the arc from the center for both circles [that\n* make the sphere] to determine theta. \n*\n* The camera is a rectangle projecting rays into the world using the sphere\n* model to calculate a ray vector. For simplicity, a sphere or cube will be\n* used as the boundary of a particular polyhedron. If we know how to effi-\n* -ciently calculate the intersection of a ray between a sphere or a box,\n* then our polyhedrons can be defined more easily, and calculating the\n* ray hit will just consider the distance from the edge of the boundary\n* at a given point, to the nearest approximation of the surface of the\n* true polyhedron.\n*\n* It seems best to use a sphere as our boundary for polyhedrons since using\n* a cube requires greater effort to calculate distances to the surface of a\n* polyhedron.\n*\n* \n* \n*/\n\n// cotangent\nfloat cot(float a) {\n    return 1.0 / tan(a);\n}\n\nconst vec4 WHITE = vec4(1.0, 1.0, 1.0, 1.0);\nconst vec4 BLACK = vec4(0.0, 0.0, 0.0, 1.0);\n\nconst vec4 RED = vec4(1.0, 0.0, 0.0, 1.0); \nconst vec4 ORANGE = vec4(1.0, 0.5, 0.0, 1.0);\nconst vec4 YELLOW = vec4(1.0, 1.0, 0.0, 1.0);\nconst vec4 GREEN = vec4(0.0, 1.0, 0.0, 1.0);\nconst vec4 BLUE = vec4(0.0, 0.0, 1.0, 1.0);\nconst vec4 INDIGO = vec4(0.5, 0.0, 1.0, 1.0);\nconst vec4 VIOLET = vec4(1.0, 0.0, 1.0, 1.0);\n\n//const float FOV = 135.0; // degrees\nconst mat3x3 m_perspective = mat3(\n        vec3(1.0, 0.0, 0.0),\n        vec3(0.0, 1.0, 0.0),\n        vec3(0.0, 0.0, 1.0)\n    );\n\n// The resolution based on the longest side of the screen\nvec2 resolution;\n\nstruct Camera {\n    // world position, not screen coordinates\n    vec3 position;\n};\n    \nstruct Ray {\n   vec3 vector;\n};\n\n\nvec3 perspective(Ray ray) {\n    return m_perspective * ray.vector;\n}\n    \n/**\n* Calculates the distance from the center of the screen that the current pixel is.\n*\n* uv: the screen coordinates, with origin at the center\n*/\nfloat centerDST(vec2 uv) {\n \treturn distance(uv, vec2(0.0));   \n}\n\n/**\n* Calculates the distance from any edge of the screen that the current pixel is.\n*\n* uv: the screen coordinates, with origin at the center\n*/\nfloat edgeDST(vec2 uv) {\n    return 1.0 - centerDST(uv);\n}\n\n/**\n* Projects a ray from the screen\n*\n* uv: the screen coordinates, with origin at the center\n*/\nRay ray(vec2 uv) {\n\treturn Ray(vec3(uv, tan(edgeDST(uv))));\n}\n\n/**\n* Projects a ray from the screen to the given world position.\n*\n* ray: the original ray projected from a point\n* position: the world position\n* returns: a Ray\n*/\nRay ray(Ray ray, vec3 position) {\n    return Ray(vec3(position.xyz - ray.vector));\n}\n\n//-------------------------------------------------------------------\n\n\n//=====================implicit modeling functions (distance functions)===================\n\nvec3 sphereDST(float radius, Ray direction, vec3 position, vec3 translation, vec3 color, vec3 background) {\n    vec3 l = direction.vector, o = vec3(l.x, l.y, 0.0), c = position + translation;\n    // (o - c)\n    vec3 o_c = (o - c);\n    // l * (o - c)\n    vec3 l_o_c = l * o_c;\n    \n    // calculate the value under the square root\n    o_c = abs(o_c);\n    // the value under the square root\n    vec3 a = l_o_c * l_o_c - (o_c * o_c - radius * radius);\n    \n    if (a.x >= 0.0 && a.y >= 0.0 && a.z >= 0.0) {\n        return color;\n    } else {\n        return background;\n    }\n    //vec2 circleH, circleV;\n    \n    \n    \n    \n    //return vec3(0.0);\n}\n\n//------------------------------------------------------------------\n\n// renders the background a specific color depending on alpha value\nvec4 background(vec4 color, vec4 result) {\n    return color * result.a;\n}\n\n// renders the whole scene\nvec4 render(vec2 uv) {\n    vec4 result = BLACK;\n    result = vec4(sphereDST(1.0, ray(uv), vec3(0.5, 0.5, 10.0), vec3(0.0, 0.0, 0.0), RED.rgb, result.rgb), 1.0);\n    return result;\n}\n\n//------------------------------------------------------------------\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    resolution = vec2(max(1.0, iResolution.y / iResolution.x), max(1.0, iResolution.x / iResolution.y));\n    vec2 uv = fragCoord / (iResolution.xy * resolution) - (1.0 / resolution) * 0.5;\n    fragColor = render(uv);\n}","name":"Image","description":"","type":"image"}]}
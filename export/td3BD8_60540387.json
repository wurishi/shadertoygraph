{"ver":"0.1","info":{"id":"td3BD8","date":"1604936364","viewed":329,"name":"SDF Path Tracer","username":"csabix","description":"This is a general interactive path tracer where surfaces with nonzero 'emission' will emit light.\nIncrease Common/RAYS_PER_FRAME as high as your GPU allows!\nUse mouse drag and WASD to move around. \n","likes":3,"published":1,"flags":48,"usePreview":0,"tags":["sdf","spheretracing","pathtracing","sampling","buffers","importance"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// This shader draws the final image\n// Increase Common/RAYS_PER_FRAME as high as your GPU allows!\n// Turn on Common/DEBUG_MODE and hold numbers 1 to 5 for different visualizations.\n\nvec3 hsv2rgb(vec3 c) {\n  const vec4 K = vec4(1,2./3.,1./3.,3);\n  return c.z * mix(K.xxx, clamp(abs(fract(c.xxx + K.xyz) * 6. - K.www) - K.xxx, 0., 1.), c.y);\n} //fragColor.rgb = hsv2rgb(vec3(fragCoord.x/iResolution.x,1.,fragCoord.y/iResolution.y));\n\nvec3 Uncharted2ToneMapping(vec3 color) { //https://www.shadertoy.com/view/lslGzl\n\tconst float A = 0.15,B = 0.50,C = 0.10,D = 0.20,E = 0.02,F = 0.30,W = 11.2, exposure = 3., gammainv = 1./2.2;\n\tconst float white = (W * (A * W + C * B) + D * E) / (W * (A * W + B) + D * F) - E / F;\n\tcolor *= exposure;\n\tcolor = (color * (A * color + C * B) + D * E) / (color * (A * color + B) + D * F) - E / F;\n\treturn pow(color/white, vec3(gammainv));\n}\n\nfloat iter2Hue(float intsteps, int maxsteps){return (1.-float(floatBitsToInt(intsteps))/float(maxsteps))*0.6667;}\nfloat dist2Val(float dist, float mindist, float maxdist) { return sqrt(sqrt((dist-mindist)/(maxdist-mindist))); }\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    ivec2 pix = ivec2(fragCoord);\n    vec4 col = texelFetch(iChannel1,pix,0);\n        \n#if DEBUG_MODE == 0\n    vec3 sum = col.rgb, ma = col.rgb, tmp; // filter white noise in a '+' shape\n    tmp = texelFetch(iChannel1,pix+ivec2(1,0),0).xyz;\n    ma = max(tmp, ma);    sum += tmp;\n    tmp = texelFetch(iChannel1,pix+ivec2(-1,0),0).xyz;\n    ma = max(tmp, ma);    sum += tmp;\n    tmp = texelFetch(iChannel1,pix+ivec2(0,1),0).xyz;\n    ma = max(tmp, ma);    sum += tmp;\n    tmp = texelFetch(iChannel1,pix+ivec2(0,-1),0).xyz;\n    ma = max(tmp, ma);    sum += tmp;\n    if(col.rgb == ma) col.rgb = sum/5.;\n#endif\n\n    col.rgb = Uncharted2ToneMapping(col.rgb);\n\n#if DEBUG_MODE == 0\n    fragColor.rgb = col.rgb;\n#else\n    vec4 con = texelFetch(iChannel0,pix,0);\n    fragColor = vec4(0);\n    int maxiters = (isKeyHeld(KeyDebug_PrimIter) ? PRIMARY_MAXITER : 0) + (isKeyHeld(KeyDebug_SecoIter) ? SECONDARY_MAXITER * (MAX_TRACE_DEPTH-1) : 0);\n    if(isKeyHeld(KeyDebug_ConeIter)) fragColor += vec4(hsv2rgb(vec3(iter2Hue(con.b,CONE_MAXITER),1,1)),1);\n    if(isKeyHeld(KeyDebug_ConeDist)) fragColor += vec4(vec3(dist2Val(con.r,CONE_MINDIST,CONE_MAXDIST)),1);\n    if(isKeyHeld(KeyDebug_RandSeed)) fragColor += vec4(vec3(con.g),1);\n    if(maxiters != 0) fragColor += vec4(hsv2rgb(vec3(iter2Hue(col.w,RAYS_PER_FRAME*maxiters),1,1)),1);\n    fragColor.rgb = fragColor.w == 0. ? col.rgb : fragColor.rgb/fragColor.w;\n#endif\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"#define RAYS_PER_FRAME 4  // increase this as high as your gpu allows\n#define MAX_TRACE_DEPTH 4 // diminishing difference but visible\n\n#define DEBUG_MODE 1      // 0 normal rendering, 1 debug mode. Use number keys for different debug modes\n#define SAMPLING_METHOD 2 // 0 uniform, 1 cosine, 2 GGX. My playground for sampling: https://www.shadertoy.com/view/tstfRX\n#define TRACE_METHOD 2    // 0 sphere trace, 1 relaxed sphere trace, 2 enhanced sphere trace\n\n#define PRIMARY_EPSILON 0.001\n#define PRIMARY_MAXITER 32\n#define PRIMARY_MAXDIST 1000.\n\n#define SECONDARY_EPSILON 0.01\n#define SECONDARY_MAXITER 40\n#define SECONDARY_MINDIST 0.01\n#define SECONDARY_MAXDIST 40.\n#define SECONDARY_NOFFSET 0.01\n\n#define CONE_EPSILON 0.001\n#define CONE_MAXITER 128\n#define CONE_MINDIST 1.\n#define CONE_MAXDIST 1000.\n\nconst int KeySpace = 32;\nconst int KeyLeft  = 65;\nconst int KeyRight = 68;\nconst int KeyUp    = 87;\nconst int KeyDown  = 83;\nconst int KeyDebug_ConeIter = 48+1; // Enhanced cone trace (Buffer A) iterations in hue (blue: 0, green: 50%, red: max iters)\nconst int KeyDebug_ConeDist = 48+2; // Show cone trace distance\nconst int KeyDebug_RandSeed = 48+3; // Show random seed (not very interesting)\nconst int KeyDebug_PrimIter = 48+4; // Primary ray iterations (significantly reduced by cone tracing)\nconst int KeyDebug_SecoIter = 48+5; // Secondary ray iterations. Tipp: hit both primary and secondary rays to show all\n#define isKeyHeld(k)  (texelFetch(iChannel3, ivec2(k,0), 0).x > 0.)\n\nstruct Material {\n    vec3  color;        // [0, 1/pi]    reflective color\n    float roughness;    // [0, 7]       shininess\n    vec3 emission;\t\t// [0, inf]     light emitting surface if nonzero\n    float metalness;    // [0.02, 0.05] for non-metals, [0.6, 0.9] for metals\n};\n\nstruct Value {float d; int mat;}; // 'SDF' now returns a distance and a material id to the closest object.\n\nstruct Ray {\n\tvec3 P;\tfloat Tmin;\n\tvec3 V;\tfloat Tmax;\n};\n\nstruct SphereTraceDesc {\n    float epsilon;  //Stopping distance to surface\n    int maxiters;   //Maximum iteration count\n};\n\nstruct TraceResult {\n    float T;\t\t// Distance taken on ray\n    int flags;\t\t// flag bit 0:   distance condition:     true if travelled to far t > t_max\n    int steps;      // flag bit 1:   surface condition:      true if distance to surface is small < error threshold\n};                  // flag bit 2:   iteration condition:    true if took too many iterations\n\nstruct Camera {\n    mat3 uvw;\n    vec3 eye;\n    vec2 uv_data;\n    int frame;\n};\n\nconst float pi = 3.1415926535897932384626433832795;\n\nfloat max3(vec3 v){\treturn max(v.x, max(v.y, v.z)); }\nfloat sum(vec3 v){ return v.x + v.y + v.z; }\n\nvec3 brdf(vec3 n, vec3 l, vec3 v, in Material mat) {\n    vec3 F0 = mat.color*mat.metalness;\n    vec3  h = normalize(l + v);\n    //CookTorrenceGeometry\n    float hn = max(dot(h, n), 0.0), vn = max(dot(v, n), 0.01);\n\tfloat ln = max(dot(l, n), 0.01), vh = max(dot(v, h), 0.0);\n    float G = min( 2.*hn*min( vn, ln)/vh, 1.0 );\n    //GGXDistribution\n    float hn2 = hn*hn, m2 = mat.roughness*mat.roughness;\n    float tmp = hn2*(m2-1.)+1.;\n    float D =  m2/(pi*tmp*tmp);\n    //SclickFresnel\n    vec3 F = F0 - (1.-F0)*pow(1.-hn,5.);\n\tvec3 specular  = D*F*G / (4. * vn * ln);\n\t// Lambertian BRDF\n\tvec3 diffuse = (1.-mat.metalness) * mat.color * (1. - F)/pi;\n\treturn max(specular + diffuse,0.);\n}\n\nstruct Sample {     // My take at generalizing importance sampling. Unoptimized compared to embedded solutions.\n    vec3 dir;\t\t// The sample's (random) direction\n    float weight;\t// weight of the sample\n};\t\t\t\t\t// typically multiplied by the domain and derivative of the mapping\n\n#if SAMPLING_METHOD==0\n#define SAMPLE(rand,n,v,roughness) uniformSampling(rand,n)\n#elif SAMPLING_METHOD==1\n#define SAMPLE(rand,n,v,roughness) cosineSampling(rand,n)\n#else\n#define SAMPLE(rand,n,v,roughness) GGXimportanceSampling(rand, n, v, roughness)\n#endif\n\nSample uniformSampling(vec2 rand2d01, vec3 n)\n{\n    // uniform in phi and theta: 'classic' sphere parametrization\n    // thus, sin(theta) * dphi * dtheta is the weight\n    vec2 r = rand2d01*vec2(2.*pi,pi);\n    vec2 s = sin(r), c = cos(r);\n    vec3 d = vec3(s[1]*vec2(c[0],s[0]),c[1]);\n    float dn = dot(d,n);\n    return Sample(d + (dn<0. ? 2.*dn*n : vec3(0)),\n                  s[1]*(pi*pi));\n}\n\nSample cosineSampling(vec2 rand2d01, vec3 n){\n    vec2 r = rand2d01*vec2(2.*pi,2)-vec2(0,1);\n    float s = sqrt(1.-r.y*r.y);\n    vec3 d = vec3(cos(r.x)*s, sin(r.x)*s, r.y);\n    float dn = dot(d,n);\n    return Sample(d + (dn<0. ? 2.*dn*n : vec3(0)),\n                  2.*pi);\n}\n\n//My version for GGX importance sampling. My playground for sampling: https://www.shadertoy.com/view/tstfRX\nSample GGXimportanceSampling(vec2 rand2d01, vec3 n, vec3 v, float m) {\n    vec2 r = rand2d01*vec2(2.*pi,2)-vec2(0,1);\n    float s = sqrt(1.-r.y*r.y);\n    vec3 h = vec3(cos(r.x)*s, sin(r.x)*s, r.y);\n    float hn = dot(h,n);\n    float cb2 = (1.-abs(hn))/(1.+(m*m-1.)*abs(hn));\t//cos(theta)^2\n    vec2 cs = sqrt(vec2(cb2,1.-cb2));    \n    h = normalize(h-hn*n);\n    h = normalize(h*cs.y + n*cs.x);\n    vec3 l = reflect(-v,h);\n    float weight = 8.*pi * cs.x * cs.y * dot(h,l);\n    return Sample(l, max(weight,0.)); //=PDF(m)/D(m)\n}\n\nfloat EnhanceSphereTraceStep(float di, float ri0, float ri){\n    return 0.95*ri*(di-ri0+ri)/max(di+ri0-ri,0.00001);\n}\n\n// SDF Primitives\n\nfloat sphere(vec3 p, float r){\n    return length(p) - r;\n}\nfloat box(vec3 p, vec3 b){ //from\thttps://iquilezles.org/articles/distfunctions\n\tvec3 d = abs(p) - b;\n    return length(max(d,0.))+min(max3(d),0.);\n}\n\n// Infinite cylinders\nfloat cylinderZ(vec3 p, float r){ return length(p.xy) - r; }\nfloat cylinderY(vec3 p, float r){return cylinderZ(p.xzy,r);}\n\n// Finite cylinders\nfloat cylinderZ(vec3 p, vec2 h){\n    vec2 d = abs(vec2(length(p.xy), abs(p.z))) - h;\n    return min(max(d.x, d.y), 0.) + length(max(d,0.));\n}\nfloat cylinderY(vec3 p, vec2 h){return cylinderZ(p.xzy,h);}\n\n// Materials\n#define LIGHTSRC(r,g,b)   Material(vec3(0,0,0)   , 1.     , vec3(r,g,b), 0.  )\n#define METALLIC(r,g,b,m) Material(vec3(r,g,b)/pi,float(m), vec3(0,0,0), 0.9 )\n#define NONMETAL(r,g,b,m) Material(vec3(r,g,b)/pi,float(m), vec3(0,0,0), 0.02)\n\nconst Material colors[] = Material[](\n    METALLIC(.6,.4,.1,0.03),\n    NONMETAL(.15,.01,1,.1),\n    NONMETAL(.1,1,.5,1),\n    NONMETAL(1,1,1,0.3),\n    LIGHTSRC(80,80,80)\n);\n\n\n// The following two functions were generated from an abstract CSG tree\n// The same code generation framework was used in the following paper:\n//  Footvector Representation of Curves and Surfaces - Acta Cybernetica 2021\n//  Gábor Valasek, Csaba Bálint, András Leitereg\n//  https://www.researchgate.net/publication/353709873_Footvector_Representation_of_Curves_and_Surfaces\n\n// Start of generated GLSL code\nfloat sdf(vec3 p) {\n\tfloat r0 = (p).y;\n\tfloat r1 = box(mat3(0.877583,0,0.479426,0,1,0,-0.479426,0,0.877583)*p - vec3(-0.542803,1,0.159263), vec3(0.9,0.9,0.9))-0.25;\n\tr0 = min(r0,r1); //union 1\n\tfloat r2 = box(mat3(-4.37114e-08,0,1,0,1,0,-1,0,-4.37114e-08)*p - vec3(-1.4,1,3.9), vec3(2.9,0.9,0.9))-0.25;\n\tr0 = min(r0,r2); //union 2\n\tfloat r3 = box(mat3(0.992445,0,-0.12269,0,1,0,0.12269,0,0.992445)*p - vec3(0,5,0), vec3(0.9,0.9,0.9))-0.25;\n\tr0 = min(r0,r3); //union 3\n\tfloat r4 = cylinderY(p - vec3(-1.78885,3,3.57771), vec2(0.9,2.9))-0.25;\n\tr0 = min(r0,r4); //union 4\n\tfloat r5 = box(p - vec3(2,3,0), vec3(2.9,0.9,0.9))-0.25;\n\tfloat r6 = cylinderZ(p - vec3(2,0.6,0), 2.6);\n\tr6 *= -1.; //invert\n\tr5 = max(r5,r6); //intersect 1\n\tr5 -= 0.25;\n\tr0 = min(r0,r5); //union 5\n\tfloat r7 = box(mat3(-0.447214,0,-0.894427,0,1,0,0.894427,0,-0.447214)*p - vec3(2,7.5,0), vec3(2.9,0.9,0.9))-0.25;\n\tfloat r8 = cylinderZ(mat3(-0.447214,0,-0.894427,0,1,0,0.894427,0,-0.447214)*p - vec3(2,5,0), vec2(3.3,0.9));\n\tr7 = max(r7,r8); //intersect 1\n\tr7 -= 0.25;\n\tr0 = min(r0,r7); //union 6\n\tfloat r9 = cylinderY(p - vec3(4,5,0), vec2(0.9,0.9))-0.25;\n\tr0 = min(r0,r9); //union 7\n\tfloat r10 = box(mat3(0.992445,0,-0.12269,0,1,0,0.12269,0,0.992445)*p - vec3(8.65663,3,0.743535), vec3(0.9,2.9,0.9))-0.25;\n\tr0 = min(r0,r10); //union 8\n\tfloat r11 = box(mat3(0.921061,0,-0.389418,0,1,0,0.389418,0,0.921061)*p - vec3(6.37631,6.75,-1.61016), vec3(2.9,0.4,0.9))-0.25;\n\tr0 = min(r0,r11); //union 9\n\tfloat r12 = box(mat3(0.913089,0.40776,0,-0.40776,0.913089,0,0,0,1)*p - vec3(5.35888,4.24727,4.036), vec3(2.9,0.4,0.9))-0.25;\n\tr0 = min(r0,r12); //union 10\n\tfloat r13 = sphere(p - vec3(9,8.5,2.7), 1.);\n\tr0 = min(r0,r13); //union 11\n\tfloat r14 = sphere(p - vec3(1.2,1,3.2), 1.);\n\tr0 = min(r0,r14); //union 12\n\tfloat r15 = box(mat3(-0.447214,0,-0.894427,0,1,0,0.894427,0,-0.447214)*p - vec3(4.91935,1,-3.57771), vec3(0.9,0.9,0.9))-0.25;\n\tr0 = min(r0,r15); //union 13\n\treturn r0;\n}\n\nMaterial material(vec3 p) {\n\tValue r0 = Value((p).y, 3);\n\tValue r1 = Value(box(mat3(0.877583,0,0.479426,0,1,0,-0.479426,0,0.877583)*p - vec3(-0.542803,1,0.159263), vec3(0.9,0.9,0.9))-0.25, 1);\n\tif(r1.d < r0.d)r0 = r1; // union 1\n\tValue r2 = Value(box(mat3(-4.37114e-08,0,1,0,1,0,-1,0,-4.37114e-08)*p - vec3(-1.4,1,3.9), vec3(2.9,0.9,0.9))-0.25, 0);\n\tif(r2.d < r0.d)r0 = r2; // union 2\n\tValue r3 = Value(box(mat3(0.992445,0,-0.12269,0,1,0,0.12269,0,0.992445)*p - vec3(0,5,0), vec3(0.9,0.9,0.9))-0.25, 2);\n\tif(r3.d < r0.d)r0 = r3; // union 3\n\tValue r4 = Value(cylinderY(p - vec3(-1.78885,3,3.57771), vec2(0.9,2.9))-0.25, 0);\n\tif(r4.d < r0.d)r0 = r4; // union 4\n\tValue r5 = Value(box(p - vec3(2,3,0), vec3(2.9,0.9,0.9))-0.25, 1);\n\tValue r6 = Value(cylinderZ(p - vec3(2,0.6,0), 2.6), 1);\n\tr6.d *= -1.; //invert\n\tif(r6.d > r5.d)r5 = r6; // intersect 1\n\tr5.d -= 0.25;\n\tif(r5.d < r0.d)r0 = r5; // union 5\n\tValue r7 = Value(box(mat3(-0.447214,0,-0.894427,0,1,0,0.894427,0,-0.447214)*p - vec3(2,7.5,0), vec3(2.9,0.9,0.9))-0.25, 2);\n\tValue r8 = Value(cylinderZ(mat3(-0.447214,0,-0.894427,0,1,0,0.894427,0,-0.447214)*p - vec3(2,5,0), vec2(3.3,0.9)), 2);\n\tif(r8.d > r7.d)r7 = r8; // intersect 1\n\tr7.d -= 0.25;\n\tif(r7.d < r0.d)r0 = r7; // union 6\n\tValue r9 = Value(cylinderY(p - vec3(4,5,0), vec2(0.9,0.9))-0.25, 1);\n\tif(r9.d < r0.d)r0 = r9; // union 7\n\tValue r10 = Value(box(mat3(0.992445,0,-0.12269,0,1,0,0.12269,0,0.992445)*p - vec3(8.65663,3,0.743535), vec3(0.9,2.9,0.9))-0.25, 0);\n\tif(r10.d < r0.d)r0 = r10; // union 8\n\tValue r11 = Value(box(mat3(0.921061,0,-0.389418,0,1,0,0.389418,0,0.921061)*p - vec3(6.37631,6.75,-1.61016), vec3(2.9,0.4,0.9))-0.25, 2);\n\tif(r11.d < r0.d)r0 = r11; // union 9\n\tValue r12 = Value(box(mat3(0.913089,0.40776,0,-0.40776,0.913089,0,0,0,1)*p - vec3(5.35888,4.24727,4.036), vec3(2.9,0.4,0.9))-0.25, 0);\n\tif(r12.d < r0.d)r0 = r12; // union 10\n\tValue r13 = Value(sphere(p - vec3(9,8.5,2.7), 1.), 4);\n\tif(r13.d < r0.d)r0 = r13; // union 11\n\tValue r14 = Value(sphere(p - vec3(1.2,1,3.2), 1.), 4);\n\tif(r14.d < r0.d)r0 = r14; // union 12\n\tValue r15 = Value(box(mat3(-0.447214,0,-0.894427,0,1,0,0.894427,0,-0.447214)*p - vec3(4.91935,1,-3.57771), vec3(0.9,0.9,0.9))-0.25, 1);\n\tif(r15.d < r0.d)r0 = r15; // union 13\n\treturn colors[r0.mat];\n}\n// End of generated GLSL code\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// Buffer A: Cone trace pass for each pixel. Only traces when camera is moved.\n\n// Implementation of the enhanced sphere tracing algorithm from the paper\n//  Accelerating Sphere Tracing - Eurographics 2018\n//  Csaba Bálint, Gábor Valasek\n//  Paper: https://www.researchgate.net/publication/329152815_Accelerating_Sphere_Tracing\n//  Talk: https://www.researchgate.net/publication/329152786_Accelerating_Sphere_Tracing\n// It also employs our safe cone tracing trick where we devide by the Lipschitz constant of the 'variable offset'.\nTraceResult EnhancedConeTracing(in Ray ray, in SphereTraceDesc params, float coneHalfAngleTan)\n{\n    float lipInv = 1./(1.+abs(coneHalfAngleTan));\n    TraceResult ret = TraceResult(ray.Tmin, 0, 0);\n    float di = 0., ri0 = 0., ri = 0., ri1 = 0.;\n    do {        \n        di = ri + (di == 0. ? 0. : EnhanceSphereTraceStep(di,ri0,ri));\n        //if d==0 we are stepping back\n        \n        ri1 = (sdf(ray.P+(ret.T+di)*ray.V)-(ret.T+di)*coneHalfAngleTan)*lipInv; //single sdf eval at t + di\n        ++ret.steps;\n        \n        if(di > ri + ri1) \n        {   // normal step can only occur after enhanced because di==ri when normal step\n            di = 0.; //normal step next cycle\n        }\n        else {   // rotate variables when enhanced stepping\n            ri0 = ri;\n            ri = ri1;\n        }\n        ret.T+=di;\n    }\n    while (ret.T     < ray.Tmax                // miss\n        && ri        > params.epsilon * ret.T  // hit\n        && ret.steps < params.maxiters );      // didn't converge \n    \n    ret.flags = (int(ret.T     >= ray.Tmax)               << 0)  // miss\n              | (int(ri        <= params.epsilon* ret.T)  << 1)  // hit\n              | (int(ret.steps >= params.maxiters)        << 2); // didn't converge\n    return ret;\n}\n\nRay getRay(Camera cam, vec2 fragCoord) { // put in uvw\n    vec2 px = (fragCoord/iResolution.xy*2.-1.)*1.*normalize(iResolution.xy);\n    vec3 v = normalize(cam.uvw * vec3(px,1.));\n    return Ray(cam.eye, CONE_MINDIST, v, CONE_MAXDIST);\n}\n\nconst vec3 cameraEyeAtStart = vec3(7,7.8,14);\nconst vec2 cameraUvAtStart = vec2(-4.4,0.39);\n\nCamera ReadCamera()\n{    /*  We will use the first 2 pixels of the buffer to store the information we need.\n        Every pixel contains 4 channels (floats), for RGBA. We can exploit this in the following way:\n            pixel0 = (empty, cameraX, cameraY, cameraZ)\n            pixel1 = (empty, empty, U, V)\n        where \n            cameraX, cameraY and cameraZ describe the position of the camera respectively\n            U,V give the current rotation of the camera in spherical coordinates\n\t*/\n    Camera cam;\n    cam.eye = iFrame == 0 ? cameraEyeAtStart : texelFetch(iChannel0, ivec2(0,0), 0).yzw;\t\t// camera position\n    vec3 data20 = iFrame == 0 ? vec3(cameraUvAtStart,0) : texelFetch(iChannel0, ivec2(1,0), 0).zwy;\t// spherical coordinates\n    vec2 uv\t= abs(data20.xy);\n    cam.frame = floatBitsToInt(data20.z);\n    cam.uv_data = data20.xy;\n\n   \tif(iMouse.z>0. || data20.x > 0.) { //mouse held or was held last frame\n        uv += (abs(iMouse.zw)-abs(iMouse.xy))*0.01;\n        cam.frame = iFrame;\n    }\n    \n    cam.uvw[2] = vec3(cos(uv.x)*cos(-uv.y),sin(-uv.y),sin(uv.x)*cos(-uv.y));\n    cam.uvw[0] = normalize(cross(vec3(0,1,0),cam.uvw[2]));\n\tcam.uvw[1] = cross(cam.uvw[2],cam.uvw[0]);\n        \n    if(iMouse.z>0.) {\t\t  //mouse held\n        cam.uv_data = abs(data20.xy);\n    }else if(data20.x >= 0.) {//mouse released\n        cam.uv_data = -mod(uv,2.*pi);\n    }    \n    \n    float speed = 10. * iTimeDelta;\n    if (isKeyHeld(KeyLeft )) { cam.eye -= cam.uvw[0]*speed; cam.frame = iFrame; }\n    if (isKeyHeld(KeyRight)) { cam.eye += cam.uvw[0]*speed; cam.frame = iFrame; }\n    if (isKeyHeld(KeyUp   )) { cam.eye += cam.uvw[2]*speed; cam.frame = iFrame; }\n    if (isKeyHeld(KeyDown )) { cam.eye -= cam.uvw[2]*speed; cam.frame = iFrame; }\n    if (isKeyHeld(KeySpace)) { cam.eye = vec3(0);   cam.frame = iFrame; }\n        \n    return cam;\n}\n\nvoid WriteCamera(in vec2 fragCoord, in Camera cam, inout vec4 fragColor) {\n    if(fragCoord.x == 0.5 && fragCoord.y == 0.5) // pixel (0,0)\n        fragColor.yzw = cam.eye;\n    if(fragCoord.x == 1.5 && fragCoord.y == 0.5) // pixel (1,0)\n        fragColor.zwy = vec3(cam.uv_data, intBitsToFloat(cam.frame));\n}\n\nuint base_hash(uvec2 p) {\n    p = 1103515245U*((p >> 1U)^(p.yx));\n    uint h32 = 1103515245U*((p.x)^(p.y>>3U));\n    return h32^(h32 >> 16);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    Camera cam = ReadCamera();\n    int frame = iFrame - cam.frame;\n\n    if (frame == 0 || iMouse.z>=0.) // Cone trace pixel and compute pixel seed\n    {\n        Ray ray = getRay(cam, fragCoord);\n        float pixelAngleTan = sqrt(2.)/length(iResolution.xy);\n        TraceResult result = EnhancedConeTracing(ray, SphereTraceDesc(CONE_EPSILON,CONE_MAXITER), pixelAngleTan);\n        fragColor.x = result.T; //pow((result.T-ray.Tmin)/(ray.Tmax-ray.Tmin),0.25f);\n        fragColor.y = intBitsToFloat(int(base_hash(floatBitsToUint(fragCoord))));\n    #if DEBUG_MODE != 0\n        fragColor.z = intBitsToFloat(result.steps);\n    #endif\n    }\n    else if(frame == 1) // Because of shadertoy double buffering\n    {\n    #if DEBUG_MODE == 0\n        fragColor.rg = texelFetch(iChannel0, ivec2(fragCoord), 0).rg;  \n    #else\n        fragColor.rgb = texelFetch(iChannel0, ivec2(fragCoord), 0).rgb;\n    #endif\n    }\n    else if(fragCoord.x > 2. || fragCoord.y != 0.5)\n    {\n        discard; // todo move to earlier?\n    }\n    \n    WriteCamera(fragCoord, cam, fragColor);\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"XsfGzn","filepath":"/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","previewfilepath":"/media/ap/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","type":"cubemap","channel":2,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"// Buffer B: casts rays starting where Buffer A stopped.\n\n#if TRACE_METHOD == 2\n// Implementation of the enhanced sphere tracing algorithm from the paper\n//  Accelerating Sphere Tracing - Eurographics 2018\n//  Csaba Bálint, Gábor Valasek\n//  Paper: https://www.researchgate.net/publication/329152815_Accelerating_Sphere_Tracing\n//  Talk: https://www.researchgate.net/publication/329152786_Accelerating_Sphere_Tracing\n// This implementation has only a single SDF evaluation to help the GPU.\nTraceResult SphereTrace(in Ray ray, in SphereTraceDesc params)\n{\n    TraceResult ret = TraceResult(ray.Tmin, 0, 0);\n    float di = 0., ri0 = 0., ri = 0., ri1 = 0.;\n    do {        \n        di = ri + (di == 0. ? 0. : EnhanceSphereTraceStep(di,ri0,ri)); // --> Common\n        //if d==0 we are stepping back\n        \n        ri1 = sdf(ray.P+(ret.T+di)*ray.V); // Only SDF evaluation in this function at t + di\n        ++ret.steps;\n        \n        if(di > ri + ri1) // normal step can only occur after enhanced because di==ri when normal step\n            di = 0.;      // fall back to normal step next cycle\n        else {\n            ri0 = ri;     // rotate variables when enhanced stepping\n            ri = ri1;\n        }\n        ret.T+=di;\n    }\n    while (ret.T     < ray.Tmax                // miss\n        && ri        > params.epsilon * ret.T  // hit\n        && ret.steps < params.maxiters );      // didn't converge\n\n    ret.flags = (int(ret.T     >= ray.Tmax)               << 0)  // miss\n              | (int(ri        <= params.epsilon* ret.T)  << 1)  // hit\n              | (int(ret.steps >= params.maxiters)        << 2); // didn't converge\n    return ret;\n}\n#elif TRACE_METHOD == 1\n// Implementation of what we call relaxed sphere tracing but the original call it\n// enhanced sphere tracing. The algorithm is from the paper\n//  Enhanced Sphere Tracing - Eurographics 2014\n//  Benjamin Keinert, Henry Schäfer, Johann Korndörfer, Urs Ganse, Marc Stamminger\n//  https://diglib.eg.org/handle/10.2312/stag.20141233.001-008\n// This implementation has only a single SDF evaluation to help the GPU.\nTraceResult SphereTrace(in Ray ray, in SphereTraceDesc params)\n{\n    TraceResult ret = TraceResult(ray.Tmin, 0, 0);\n    float ri = 0., di = 0.;\n    do {\n        di = ri * (di == 0. ? 1. : 1.6);         // if d==0 we are stepping back\n        float ri1 = sdf(ray.P+(ret.T+di)*ray.V); // single sdf eval at t + di\n        ++ret.steps;\n        \n        if(di > ri + ri1)\n            di = 0.;      // fall back to normal step next cycle\n        else\n            ri = ri1;     // relaxed step\n        \n        ret.T += di;\n    }\n    while (ret.T     < ray.Tmax                // miss\n        && ri        > params.epsilon * ret.T  // hit\n        && ret.steps < params.maxiters );      // didn't converge \n    \n    ret.flags = (int(ret.T     >= ray.Tmax)               << 0)  // miss\n              | (int(ri        <= params.epsilon* ret.T)  << 1)  // hit\n              | (int(ret.steps >= params.maxiters)        << 2); // didn't converge\n    return ret;\n}\n#elif TRACE_METHOD == 0\n// Implementation of the classic sphere tracing algorithm from the paper\n//  Sphere Tracing: A Geometric Method for the Antialiased Ray Tracing of Implicit Surfaces - The Visual Computer 1995\n//  John C. Hart\n//  https://www.researchgate.net/publication/2792108_Sphere_Tracing_A_Geometric_Method_for_the_Antialiased_Ray_Tracing_of_Implicit_Surfaces\nTraceResult SphereTrace(in Ray ray, in SphereTraceDesc params)\n{\n    TraceResult ret = TraceResult(ray.Tmin, 0, 0);\n    float ri = 0.;\n    do {\n        ri = sdf(ray.P+ret.T*ray.V);\n        ret.T += ri;\n        ++ret.steps;\n    }\n    while (ret.T     < ray.Tmax                // miss\n        && ri        > params.epsilon * ret.T  // hit\n        && ret.steps < params.maxiters );      // didn't converge \n    \n    ret.flags = (int(ret.T     >= ray.Tmax)               << 0)  // miss\n              | (int(ri        <= params.epsilon* ret.T)  << 1)  // hit\n              | (int(ret.steps >= params.maxiters)        << 2); // didn't converge\n    return ret;\n}\n#endif\n\nvec3 normal(const in vec3 p) {\n    const vec2 e0=vec2(0.001,0);\n    vec3 plus = vec3(sdf(p+e0.xyy),sdf(p+e0.yxy),sdf(p+e0.yyx));\n    vec3 minu = vec3(sdf(p-e0.xyy),sdf(p-e0.yxy),sdf(p-e0.yyx));\n    return normalize(plus-minu);\n}\n\nvec3 missColor(Ray ray) {\n    vec3 col = texture(iChannel2, ray.V).rgb;\n    return .8*pow(col, vec3(2.2));\n}\n\nRay getRay(Camera cam, vec2 fragCoord, float start) {\n    vec2 px = (fragCoord/iResolution.xy*2.-1.)*1.*normalize(iResolution.xy);\n    vec3 v = normalize(cam.uvw * vec3(px,1.));\n    return Ray(cam.eye, start, v, PRIMARY_MAXDIST);\n}\n\nCamera ReadCamera()\n{    /*  We will use the first 2 pixels of the buffer to store the information we need.\n        Every pixel contains 4 channels (floats), for RGBA. We can exploit this in the following way:\n            pixel0 = (empty, cameraX, cameraY, cameraZ)\n            pixel1 = (empty, empty, U, V)\n        where \n            cameraX, cameraY and cameraZ describe the position of the camera respectively\n            U,V give the current rotation of the camera in spherical coordinates\n\t*/\n    Camera cam;\n    cam.eye = texelFetch(iChannel0, ivec2(0,0), 0).yzw;\t\t// camera position\n    vec3 data20 = texelFetch(iChannel0, ivec2(1,0), 0).zwy;\t// spherical coordinates\n    vec2 uv\t= abs(data20.xy);\n    cam.frame = floatBitsToInt(data20.z);\n    cam.uv_data = data20.xy;\n\n   \tif(iMouse.z>0. || data20.x > 0.)\t//mouse held or was held last frame\n        uv += (abs(iMouse.zw)-abs(iMouse.xy))*0.01;\n    \n    cam.uvw[2] = vec3(cos(uv.x)*cos(-uv.y),sin(-uv.y),sin(uv.x)*cos(-uv.y));\n    cam.uvw[0] = normalize(cross(vec3(0,1,0),cam.uvw[2]));\n\tcam.uvw[1] = cross(cam.uvw[2],cam.uvw[0]);\n    \n    return cam;\n}\n\n// Random generation\n\nint seed;\n\nvec2 PseudoRandom2D(in int i){\n    return fract(vec2(i*ivec2(12664745, 9560333))/exp2(24.0));\n}\n\n// Path Trace\n\n#if DEBUG_MODE != 0\n    int gDebugIters = 0;\n#endif\n\nvec3 PathTrace(Camera cam, vec2 fragCoord, float start)\n{\n    vec3 color = vec3(0);\n    \n    for(int j = 0; j < RAYS_PER_FRAME; ++j)\n    {\n        int ind = seed + j + MAX_TRACE_DEPTH*RAYS_PER_FRAME; //consequtive elements for if j is changed by 1\n        Ray ray = getRay(cam, fragCoord + PseudoRandom2D(ind)-vec2(.5), start);\n        vec3 factor = vec3(1);\n        SphereTraceDesc params = SphereTraceDesc(PRIMARY_EPSILON,PRIMARY_MAXITER);\n\n        for (int i = 0; i < MAX_TRACE_DEPTH; i++)\n        {\n            TraceResult result = SphereTrace(ray, params);\n            \n        #if DEBUG_MODE != 0\n            if(i == 0 && isKeyHeld(KeyDebug_PrimIter)\n             ||i != 0 && isKeyHeld(KeyDebug_SecoIter))\n                 gDebugIters += result.steps;\n        #endif\n            if (bool(result.flags & 1) || max3(factor) < 0.01)\n                break;\n\n            vec3 p = ray.P + ray.V*result.T;\n            vec3 n = normal(p);\n            vec3 v = -ray.V;\n\n            Material mat = material(p);\n            int ind = seed + j + i*RAYS_PER_FRAME; //consequtive elements for if j is changed by 1\n            Sample sam = SAMPLE(PseudoRandom2D(ind),n, v, mat.roughness);\n            float costheta = max(dot(v,sam.dir),0.);\n            float sintheta = max(sqrt(1.-costheta*costheta),0.01);\n            color +=\n                //color / (2.*pi*pi*sintheta) + // Due to path tracing equations\n                factor * costheta * mat.emission;\n            factor *= sam.weight * max(dot(n,sam.dir),0.) * brdf(n, sam.dir, v, mat);\n\n            ray.P    = SECONDARY_NOFFSET*n+p;  ray.V    = sam.dir;\n            ray.Tmin = SECONDARY_MINDIST;      ray.Tmax = SECONDARY_MAXDIST;\n            params   = SphereTraceDesc(SECONDARY_EPSILON, SECONDARY_MAXITER);\n        }\n        color += factor * missColor(ray).rgb; //escape color\n    }\n    return color/float(RAYS_PER_FRAME);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 data = texelFetch(iChannel0, ivec2(fragCoord), 0).rg;\n    vec3 prev = texelFetch(iChannel1, ivec2(fragCoord), 0).rgb;\n    \n    Camera cam = ReadCamera();\n    int frame = iFrame-cam.frame;\n    \n    seed = floatBitsToInt(data.y) + frame * RAYS_PER_FRAME * (MAX_TRACE_DEPTH + 1); // each frame uses up N x (M+1) number of indices \n    \n    fragColor.rgb = PathTrace(cam, fragCoord, data.x);\n    \n    if(frame > 1) fragColor.rgb = mix(prev, fragColor.rgb, 1.0/float(frame));\n    \n#if DEBUG_MODE != 0\n    fragColor.w = intBitsToFloat(gDebugIters);    \n#endif\n}\n","name":"Buffer B","description":"","type":"buffer"}]}
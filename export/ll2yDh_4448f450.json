{"ver":"0.1","info":{"id":"ll2yDh","date":"1508432320","viewed":813,"name":"Classic Maze Screensaver","username":"Hamneggs","description":"It's the ol' maze screensaver. It's my first real ray-traced toy.\nWhen the animation ends, you might feel compelled to complain about how it doesn't flip and reverse\nthe path. In that case, I advise you to play around with WASD and LR.","likes":11,"published":1,"flags":48,"usePreview":0,"tags":["raytracer","ray","interactive","screensaver","trace","quad","quads","microsoft"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/**\n * Everybody misses this maze, so I tried to bring it back.\n * \n * Buffers A-C: Offloaded texture rendering.\n * Buffer D: Computes the camera path and uses a simplified distance\n * \tfield to draw the HUD.\n *\n * AUTHENTIC_MODE: Low resolution and low framerate. This is the way to go.\n * HUD (in buffer D): Enables the Windows (2000? Me?) edition HUD.\n */\n\n// AUTHENTIC MODE!!\n#define AUTHENTIC_MODE\n\n\n// Main marching steps.\n#define V_STEPS 75\n// Maximum successful marching distance.\n#define EPSILON .005\n// Max ray depth.\n#define MAX_DEPTH 8.0\n// Pi.\n#define PI 3.141593\n// Wall width.\n#define WALL_WIDTH .005\n\nconst vec3 UP = vec3(0,1,0); // An up vector.\n\nconst vec2 txCPOS = vec2(2,2); // Texel registers.\nconst vec2 txCDIR = vec2(4,2); //\n\n/*\n\tReads a texel. \n*/\nvec4 readTexel(in sampler2D buffer, in vec2 pos )\n{\n    return texture(buffer, (pos+.5)/iChannelResolution[3].xy);\n}\n\n/*\n\tCreates and orientates ray origin and direction vectors based on a\n\tcamera position and direction, with direction and position encoded as\n\tthe camera's basis coordinates.\n*/\nvoid camera(in vec2 uv, in vec3 cp, in vec3 cd, in float f, out vec3 ro, out vec3 rd)\n{\n\tro = cp;\n\trd = normalize((cp + cd*f - cross(cd, UP)*uv.x + UP*uv.y)-ro);\n}\n\n/*\n\tIntersects a ray <ro, rd> with a plane defined by a normal <pn> and surface point <ps>.\n\tIf the ray does not intersect, d is set to a value that signifies no\n\tintersection occurred.\n*/\nvoid intersectPlane( in vec3 pn, in vec3 ps, in vec3 ro, in vec3 rd, inout vec3 n, inout float d )\n{\n    // If we aren't on the plane, return without changing the current normal or nearest dist.\n    if(dot(ps-ro, rd) == 0.0) return;\n    \n    float dist = dot(pn, (ps-ro)) / dot(pn, rd);\n    if( dist > 0.0 && dist < d )\n    {\n        d = dist;\n        n = pn;\n    }\n}\n    \n/*\n\tA faster version of the plane intersection function meant for use\n\twithin other intersections.\n*/\nvoid fastPlane( in vec3 pn, in vec3 ps, in vec3 ro, in vec3 rd, out float d)\n{\n    if(dot(ps-ro, rd) == 0.0) d=MAX_DEPTH*2.0;\n    d = dot(pn, (ps-ro)) / dot(pn, rd);\n}\n\n/*\n\tIntersects a ray of <ro, rd> with a quadrilateral, defined by\n\ta single corner <anchor> and two full scale edge vectors <u> and <v>.\n\tThe normal of the intersection is stored in <n>, and the distance to it\n\tis written to <d>.\n\t<d> and <n> are only updated if this intersection is nearer than\n\tprevious ones.\n*/\nvoid intersectQuad(in vec3 anchor, \n               \t   in vec3 u, in vec3 v,\n                   in vec3 ro, in vec3 rd,\n                   inout vec3 n, inout float d)\n{\n    // The distance to the current intersection.\n    float dist = 0.0;\n    \n    // Normalized edges.\n    vec3 nU = normalize(u);\n    vec3 nV = normalize(v);\n    \n    // The normal of the current primitive.\n    vec3 norm = normalize(cross(nU,nV));\n    \n    // First we need to intersect the plane.\n    fastPlane(norm,\n             \tanchor,\n                ro,\n                rd,\n                dist);\n   \n    \n    // Shortcut out if we don't even hit the plane.\n    if( dist > d || dist < 0.0 ) return;\n\n  \t// To tell if we're in the quad we need to do two things.\n    // First, we project the anchor-to-intersect vector onto\n    // each edge. If the length of the projection is greater than\n    // the length of the edge, we're beyond the quad.\n    // If the length of the projection is negative, the point exists\n    // before the quad begins.\n    vec3 ap = (ro+rd*dist)-anchor;\n    float lAP = length(ap);\n    vec3 nAP = normalize(ap);\n    \n    float dU = dot(nAP, nU);\n    float dV = dot(nAP, nV);\n    if(dU < 0.0 || dU*lAP > length(u) \n    || dV < 0.0 || dV*lAP > length(v))\n        return;\n    \n    // Finally if we're in the plane and this is the closest yet intersection,\n    // we update the current minimum distance, and that distance's\n    // normal.\n    d = dist;\n    n = norm;\n}\n\nvoid traceScene(in vec3 ro, in vec3 rd, out float d, out vec3 n)\n{\n    d = MAX_DEPTH;\n    n = vec3(0,1,0);\n    intersectPlane(vec3(0,1,0), vec3(0,-.333,0), ro, rd, n, d);\n    intersectPlane(vec3(0,-1,0), vec3(0,.333,0), ro, rd, n,d );\n    \n    float h = min(iTime*.667, .667);\n    #define XWALL(x,z,l) intersectQuad(vec3(x,-.333,z),vec3(l,0,0),vec3(0,h,0),ro,rd,n,d)\n    #define ZWALL(x,z,l) intersectQuad(vec3(x,-.333,z),vec3(0,0,l),vec3(0,h,0),ro,rd,n,d);\n    XWALL(-4,-4,8);\n    XWALL(4,4,-8);\n    ZWALL(-4,-4,8);\n    ZWALL(4,4,-8);\n    \n    XWALL(-4,-3, 1);\n    ZWALL(-2,-4, 2);\n    XWALL(-3,-2, 1);\n    ZWALL(-3,-2, 3);\n    XWALL(-4, 2, 2);\n    ZWALL(-2, 1, 1);\n    XWALL(-2, 1, 1);\n    ZWALL(-1,-3, 4);\n    XWALL(-3, 0, 1);\n    XWALL(-2,-1, 1);\n    XWALL(-1,-3, 1);\n    ZWALL( 1,-4, 2);\n    XWALL( 0,-2, 1);\n    ZWALL( 0,-2, 1);\n    XWALL(-1, 0, 2);\n    XWALL( 1,-1, 2);\n    ZWALL( 2,-3, 2);\n    XWALL( 2,-3, 1);\n    XWALL( 3,-2, 1);\n    XWALL( 2, 0, 2);\n    ZWALL( 2, 0, 2);\n    XWALL( 0, 1, 2);\n    ZWALL( 0, 1, 1);\n    XWALL(-1, 2, 1);\n    ZWALL(-1, 2, 1);\n    XWALL(-3, 3, 2);\n    ZWALL( 0, 3, 1);\n    ZWALL( 1, 2, 1);\n    XWALL( 1, 3, 3);\n    XWALL( 2, 2, 1);\n    ZWALL( 3, 1, 1);\n    \n    #undef XWALL\n    #undef ZWALL\n}\n\n/*\n\tTextures walls. Uses the linear combination method of texturing\n\t3D shapes, which conviently only works on axis-aligned flat surfaces.\n*/\nvec3 texWall(in vec3 p, in vec3 n, in sampler2D t)\n{\n    n = abs(n);\n    p = mod(p,1.0);\n\tvec3 s = n.x*texture(t,p.zy).rgb;\n    s += n.z*texture(t,p.xy).rgb;\n    return clamp(s,0.0,1.0);\n}\n\n/*\n\tReturns a texel of the ground surface, or the ceiling, depending\n\ton the sign of normal.y\n*/\nvec3 texGround(in vec3 p, in vec3 n, in sampler2D ground, in sampler2D ceiling)\n{\n    p = mod(p,1.0);\n    return mix(texture(ground,p.xz).rgb, texture(ceiling,p.xz).rgb, step(n.y,0.0));\n}\n\n/*\n\tTextures everything, mixiing between the three based on the surface normal.\n*/\nvec3 tex(in vec3 p, in vec3 n)\n{\n    vec3 t = mix(texWall(p, n, iChannel0),\n               texGround(p, n, iChannel1, iChannel2),\n               step(.5,abs(n.y)));\n    return t*t*t*t;\n}\n\n/*\n\tShades a point, giving it lighting and taking into account distance.\n*/\nvec3 shade(vec3 p, float d, vec3 n)\n{\n    // Let's get the appropriate texel.\n    vec3 tex = tex(p, n); \n    // Smooth out the transition between geometry and emptiness.\n\treturn abs(tex);\n}\n\n/*\n\tPerforms some quick post-processing. Does gamma correction\n\tand adds a soft vignette just to make whatever you're doing\n\tlook pretty.\n*/\nvec3 postProcess( vec2 uv, vec3 c )\n{\n    return pow(c,vec3(1.0/2.2));\n}\n\n/*\n\tMain function.\n*/\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    //fragColor = texture(iChannel3,.1*(fragCoord/iResolution.xy));return;\n    // Position, direction, and eye.\n    // Notice that it spells out the Processing file extension?\n    vec3 ro,rd,p,n;\n    \n    // Assume that we're not going to hit anything.\n    fragColor = vec4(0,0,0,1);\n    \n    // Set up the screen coordinates.\n    vec2 uv = fragCoord / iResolution.xy - 0.5;\n\tuv.x *= iResolution.x/iResolution.y; //fix aspect ratio\n    \n    // Shrink the resolution down to 240xWhatever 240p is in widescreen.\n    // AND DESTROY THE FRAMERATE.\n    #ifdef AUTHENTIC_MODE\n    uv = floor(uv*240.0)/240.0;\n    if(mod(float(iFrame),4.0)<2.0) discard;\n    #endif\n    \n    // Get the camera's position along the path.\n    ro = readTexel(iChannel3, txCPOS).xyz;\n    rd = readTexel(iChannel3, txCDIR).xyz;\n    \n    // Set up the camera.\n    camera(uv, ro, rd, 1.0, ro, rd);\n    \n    // It's time to trace!\n    float d = MAX_DEPTH;\n    traceScene(ro,rd,d,n);\n    \n    // If we hit anything, we shade the geometry.\n    if(d < MAX_DEPTH)\n        fragColor = postProcess(uv,shade(ro+rd*d,d,n)).rgbb;\n    \n    // Calculate the point of intersection.\n    #ifdef AUTHENTIC_MODE\n    fragColor = mix(fragColor, \n                    texture(iChannel3,floor( (fragCoord*240.0) / iResolution.xy )/240.0), \n                    texture(iChannel3, fragCoord/iResolution.xy).a);\n    #else\n    fragColor = mix(fragColor, \n                    texture(iChannel3,fragCoord/iResolution.xy), \n                    texture(iChannel3, fragCoord/iResolution.xy).a);\n    #endif\n\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4sf3Rn","filepath":"/media/a/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","previewfilepath":"/media/ap/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","type":"texture","channel":0,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"/**\n * This buffer generates the brick texture, the most complicated\n * of the bunch. It's originally from a scene with a cobblestone\n * path I was working on.\n * Anyhow the stones are generated by creating a heightmap, then\n * using that to map to colors.\n * The shadows use a static light and a normal map generated from\n * a smooth version of the heightmap.\\\n */\n\n#define RAND_NOISE_TEX iChannel0\nconst vec3 BRICK_LIGHT = vec3(.8, .03921, .04313);\nconst vec3 BRICK_DARK = vec3(.62647, .03921, .04313);\nconst vec3 BRICK_MORTAR = vec3(.925);\nconst vec2 BRICK_SCALE = vec2(4,6);\n\n\n/*\n\t3-octave FBM.\n*/\nfloat fbm(vec2 p)\n{\n    float r = texture(RAND_NOISE_TEX,p).r*.5;\n    r += texture(RAND_NOISE_TEX,p*2.0).r*.25;\n    r += texture(RAND_NOISE_TEX,p*4.0).r*.125;\n    return r * 1.14285714;\n}\n\n/*\n\tThe brick heightmap that does add in a lil' more noise.\n*/\nfloat brickHeight(vec2 p)\n{\n    // Do the classic scale->mod->offset->[-1,1] space\n    // dealio to get a basic brick.\n    p.x *= .5;\n    p.x += mod(floor(p.y),2.0)*.5;\n    vec2 f = fract(p);\n    f = (f*2.0)-1.0;\n    \n    // Now instead of just using max(x,y) we get the length\n    // of the current position from the center of its home\n    // brick space. But we do it as in length8() from IQ's\n    // Modeling with Distance Functions article so we get\n    // not a circle, but something that formerly looked like\n    // a cobblestone but now is a microsoft brick.\n    float r = pow(pow(f.x,8.0)+pow(f.y,8.0),.125);\n    \n    // Do some blending.\n    r = smoothstep(.975,.875,r);\n    \n    // Add in some fbm fun.\n    r -=pow(fbm(p*.125),1.0)*1.0;\n    return clamp(r,0.0,1.0);\n}\n\n/*\n\tThe brick heightmap that doesn't use FBM.\n*/\nfloat brickHeightSmooth(vec2 p)\n{\n    p.x *= .5;\n    p.x += mod(floor(p.y),2.0)*.5;\n    vec2 f = fract(p);\n    f = (f*2.0)-1.0;\n    float r = pow(pow(f.x,8.0)+pow(f.y,8.0),.125);\n    r = smoothstep(.953,.89,r);\n    return clamp(r,0.0,1.0);\n}\n\n/*\n\tThe standard differentiate-and-cross method of getting a surface normal.\n*/\nvec3 brickNorm(vec2 p)\n{\n    vec3 d = vec3(.001, .001, 0);\n    vec3 dx = vec3(0,brickHeightSmooth(p+d.xz)-brickHeightSmooth(p-d.xz), d.x);\n    vec3 dy = vec3(d.x, brickHeightSmooth(p+d.zy)-brickHeightSmooth(p-d.zy),0);\n    return normalize(cross(normalize(dx),normalize(dy))).rbg;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    //if(iFrame > 1) discard;\n    vec2 uv = fragCoord / iResolution.xy;\n    \n    uv = floor(uv*iChannelResolution[0].xy*2.0)/(iChannelResolution[0].xy*2.0);\n    uv *= BRICK_SCALE;\n    \n    float h = brickHeight(uv);\n    vec3 n = brickNorm(uv);\n    vec3 c = mix(BRICK_DARK, BRICK_LIGHT, h);\n    c = mix(BRICK_MORTAR, c, step(.0001, h));\n    fragColor.rgb = mix(c*.05, c, smoothstep(-.5,-.0,dot(n,normalize(vec3(4,1,1)))));\n    fragColor.a = 1.0;\n}","name":"Buf A","description":"","type":"buffer"},{"inputs":[{"id":"4sf3Rn","filepath":"/media/a/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","previewfilepath":"/media/ap/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","type":"texture","channel":0,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"/**\n * The carpet buffer. This is up for contention. Is the ground wood \n * or carpet? I remember it being carpet, and it's easier to do, so...\n * It's just a random noise deal.\n */\n\n#define RAND_NOISE_TEX iChannel0\n#define CARPET_SCALE 1.5\n\n// Since these divides are used to define a const, they're only\n// evalutated once and have no impact on performance right?\n#define RGB(r,g,b) vec3(float(r)/255.0,float(g)/255.0,float(b)/255.0)\nconst vec3 CARPET_LIGHT = RGB(240, 200, 0);\nconst vec3 CARPET_DARK = RGB(220, 170, 0);\n\n/*\n\tNoise wrapper. It would probably be better if I just unwrapped\n \tthis one.\n*/\nfloat n(vec2 p, sampler2D tex)\n{\n    return texture(tex, p).r;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    //if(iFrame > 1) discard;\n    vec2 uv = fragCoord*CARPET_SCALE / iResolution.xy;\n    \n    // Random noise value.\n    float v = texture(RAND_NOISE_TEX,uv).r;\n    \n    // If that value is above a threshold, we make the texel\n    // one color. If not, we don't.\n    fragColor.rgb = mix(CARPET_DARK, CARPET_LIGHT,step(v,.4));\n    \n    fragColor.a = 1.0;\n}","name":"Buf B","description":"","type":"buffer"},{"inputs":[{"id":"4sf3Rn","filepath":"/media/a/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","previewfilepath":"/media/ap/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","type":"texture","channel":0,"sampler":{"filter":"nearest","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"/**\n * This buffer generates the ceiling texture. It's a much simpler \n * brick-esque texture, with lighting that can be faked without\n * needing to do the whole actually-calculate-it-with-normal-maps\n * method, which saves time.\n */\n\n#define RAND_NOISE_TEX iChannel0\nconst vec2 CEIL_SCALE = vec2(2,4);\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    //if(iFrame > 1) discard;\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n    \n    \n    // Scale the UV coordinates.\n    uv *= CEIL_SCALE;\n    \n    // Do the classsic brick-row offset.\n    uv.x += mod(floor(uv.y),2.0)*.5;\n    \n    // We need one fractional space that we don't\n    // transform to -1,1 so we can use it to draw\n    // the lighting highlight. The other one we\n    // use to just draw the border as normal.\n    vec2 q = fract(uv);\n    vec2 r = fract(uv);\n    \n    // Transform q to [=1,1].\n    q = abs(q*2.0 - 1.0);\n    \n    // Calculate the border and highlight.\n    float base = smoothstep(1.,.9,max(q.x,q.y));\n    float hlight = smoothstep(.94,.98,max(r.x,r.y));\n    hlight = mod(hlight,.99);\n    \n    // Give the standard color a bit of pizazz.\n    base -= texture(RAND_NOISE_TEX,uv*.5).r*.2;\n    \n    \n\tfragColor.rgb = vec3(clamp(base+hlight, 0.7, .95));\n    fragColor.a = 1.0;\n}","name":"Buf C","description":"","type":"buffer"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XdfGR8","filepath":"/media/previz/buffer03.png","previewfilepath":"/media/previz/buffer03.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XdfGR8","channel":0}],"code":"/**\n * Okay, this one is important. So our main marcher shader doesn't get\n * too bloated and take forever to compile, we render the HUD here, and\n * also use the opportunity to use positional buffer writing to calcluate\n * the camera position here, then store it in a texel in the buffer so\n * the main shader can just read the results and act accordingly.\n * This is also the crappiest camera system I've made. It consists of two\n * kinds of paths--straight and circular turn--that are strung together\n * into a path generated offline.\n */\n//#define DRAW_HUD\n#define BUFFER iChannel0\n#define KEYBOARD iChannel1\n#define KEY_DOWN_POS 0.0\n\nconst vec2 txCPOS = vec2(2,2);\t// Where the position will be stored.\nconst vec2 txCDIR = vec2(4,2);\t// Where the direction will be stored.\nconst vec2 txWAS  = vec2(6,2);  // The current state of WAS.\nconst vec2 txDLR  = vec2(8,2);  // The current state of DLR.\nconst vec3 UP = vec3(0,1,0);\t// An up vector.\n\n// Key codes.\nconst float KEY_W = 87.5/256.0;\nconst float KEY_A = 65.5/256.0;\nconst float KEY_S = 83.5/256.0;\nconst float KEY_D = 68.5/256.0;\nconst float KEY_L = 37.5/256.0;\nconst float KEY_R = 39.5/256.0;\n\n#define HUD_SCALE 10.0\n\n#define LINE_WIDTH .02\n\n// Current buffer size for loading data.\n#define BUFF_RES iChannelResolution[0].xy\n\n// Reads a texel. We don't really need component-wise read functions.\nvec4 readTexel(in sampler2D buffer, in vec2 pos )\n{\n    return texture(buffer, (pos+.5)/BUFF_RES);\n}\n\n// This function checks to see if the current fragment is\n// at the position of the pixel we want to save to.\n// Why? Because we can load from any pixel, but only write to \n// the one at the current fragment's position.\n// Writes three of the components.\nvoid write3( inout vec3 buffer, in vec3 val, in vec2 pos, in vec2 fragCoord)\n{\n    vec2 offset = abs(pos-floor(fragCoord));\n    buffer = mix( val, buffer, step(.01,max(offset.x,offset.y)) );\n}\nvoid write4( inout vec4 buffer, in vec4 val, in vec2 pos, in vec2 fragCoord)\n{\n    vec2 offset = abs(pos-floor(fragCoord));\n    buffer = mix( val, buffer, step(.01,max(offset.x,offset.y)) );\n}\n\n/*\n\tOlinde Rodrigues' vector rotation formula for rotating a vector <a>\n\taround a vector <b> <t> radians.\n*/\nvec3 rodRot( in vec3 a, in vec3 b, in float t )\n{\n    // Straight from wikipedia.\n\treturn normalize(a*cos(t) + cross(b, a)*sin(t) + b*dot(b,a)*(1.0-cos(t)));\n}\n\n/*\n\tA camera path that interpolates between a starting position and an\n\tending position between times t0 and t1 given the current time.\n\tIf the time is not between t0 and t1, p and d are unaffected.\n*/\nvoid camStraightPath( inout vec3 p, inout vec3 d,\n                      in vec3 p0, in vec3 p1, \n                      in float t0, in float t1,\n                      in float t )\n{\n    if(t < t0 || t > t1) return;\n    p = p0+(p1-p0)*(t-t0)/(t1-t0);\n    if( length(p1-p0) > .004 ) \n    d = normalize(p1-p0);\n}\n\n/*\n\tA camera path that rotates <r> radians around a center <c> from\n\ta starting point <p0>, given the current time <t>, start time\n\t<t0>, an end time <t1> and an initial direction <p0>.\n*/\nvoid camCirclePath( inout vec3 p, inout vec3 d, \n                    in vec3 p0, in vec3 d0,\n                    in vec3 c,in float r,\n                    in float t0, in float t1,\n                    in float t )\n{\n    // Don't modify p and d if it's not our turn.\n    if(t < t0 || t > t1) return;\n    \n    // Scale those radians by pi.\n\tr *= 3.14;\n    \n    // Get fractional time.\n    t = (t-t0)/(t1-t0);\n\n    // Translate center to origin.\n    p0 -= c;\n    \n    // Rotate.\n    if( length(p0) > .1 ) p0 = rodRot(p0,vec3(0,1,0),r*t)*.5;\n    \n    // Translate back.\n    p0 += c;\n    p = p0;\n    \n    // Also take care of the direction.\n    d = rodRot(d0,vec3(0,1,0),r*t);\n    \n}\n\n/*\n\tThe least inspired camera system there ever was.\n\tBased on the time choose an interpolating path.\n*/\nvoid camPath( out vec3 p, out vec3 d, in float t )\n{\n    p = vec3(2.5,0, .5);\n    d = vec3(0,0,1);\n    \n    // This was generated by some code elsewhere.\n    camStraightPath(p,d,vec3(-3.5025,0,-3.5),vec3(-3.4975,0,-3.5),0.0,1.0,t);\n    camStraightPath(p,d,vec3(-3.5,0,-3.5),vec3(-3.0,0,-3.5),1.0,1.5,t);\n    camCirclePath(p,d,vec3(-3.0,0,-3.5),vec3(1.0,0,-0.0),vec3(-3.0,0,-3.0),-1.0,1.5,3.07079632679,t);\n    camCirclePath(p,d,vec3(-3.0,0,-2.5),vec3(-1.0,0,-0.0),vec3(-3.0,0,-2.0),0.5,3.07079632679,3.85619449019,t);\n    camStraightPath(p,d,vec3(-3.5,0,-2.0),vec3(-3.5,0,1.0),3.85619449019,6.85619449019,t);\n    camCirclePath(p,d,vec3(-3.5,0,1.0),vec3(0.0,0,1.0),vec3(-3.0,0,1.0),1.0,6.85619449019,8.42699081699,t);\n    camCirclePath(p,d,vec3(-2.5,0,1.0),vec3(0.0,0,-1.0),vec3(-2.0,0,1.0),-0.5,8.42699081699,9.21238898038,t);\n    camCirclePath(p,d,vec3(-2.0,0,0.5),vec3(1.0,0,-0.0),vec3(-2.0,0,-0.0),1.0,9.21238898038,10.7831853072,t);\n    camCirclePath(p,d,vec3(-2.0,0,-0.5),vec3(-1.0,0,-0.0),vec3(-2.0,0,-1.0),-1.0,10.7831853072,12.353981634,t);\n    camCirclePath(p,d,vec3(-2.0,0,-1.5),vec3(1.0,0,-0.0),vec3(-2.0,0,-2.0),0.5,12.353981634,13.1393797974,t);\n    camStraightPath(p,d,vec3(-1.5,0,-2.0),vec3(-1.5,0,-3.0),13.1393797974,14.1393797974,t);\n    camCirclePath(p,d,vec3(-1.5,0,-3.0),vec3(0.0,0,-1.0),vec3(-1.0,0,-3.0),-0.5,14.1393797974,14.9247779608,t);\n    camStraightPath(p,d,vec3(-1.0,0,-3.5),vec3(0.0,0,-3.5),14.9247779608,15.9247779608,t);\n    camCirclePath(p,d,vec3(0.0,0,-3.5),vec3(1.0,0,-0.0),vec3(0.0,0,-3.0),-1.0,15.9247779608,17.4955742876,t);\n    camCirclePath(p,d,vec3(0.0,0,-2.5),vec3(-1.0,0,-0.0),vec3(0.0,0,-2.0),0.5,17.4955742876,18.280972451,t);\n    camStraightPath(p,d,vec3(-0.5,0,-2.0),vec3(-0.5,0,-1.0),18.280972451,19.280972451,t);\n    camCirclePath(p,d,vec3(-0.5,0,-1.0),vec3(0.0,0,1.0),vec3(0.0,0,-1.0),1.0,19.280972451,20.8517687778,t);\n    camCirclePath(p,d,vec3(0.5,0,-1.0),vec3(0.0,0,-1.0),vec3(1.0,0,-1.0),-0.5,20.8517687778,21.6371669412,t);\n    camCirclePath(p,d,vec3(1.0,0,-1.5),vec3(1.0,0,-0.0),vec3(1.0,0,-2.0),0.5,21.6371669412,22.4225651046,t);\n    camStraightPath(p,d,vec3(1.5,0,-2.0),vec3(1.5,0,-3.0),22.4225651046,23.4225651046,t);\n    camCirclePath(p,d,vec3(1.5,0,-3.0),vec3(0.0,0,-1.0),vec3(2.0,0,-3.0),-0.5,23.4225651046,24.2079632679,t);\n    camStraightPath(p,d,vec3(2.0,0,-3.5),vec3(3.0,0,-3.5),24.2079632679,25.2079632679,t);\n    camCirclePath(p,d,vec3(3.0,0,-3.5),vec3(1.0,0,-0.0),vec3(3.0,0,-3.0),-1.0,25.2079632679,26.7787595947,t);\n    camCirclePath(p,d,vec3(3.0,0,-2.5),vec3(-1.0,0,-0.0),vec3(3.0,0,-2.0),1.0,26.7787595947,28.3495559215,t);\n    camCirclePath(p,d,vec3(3.0,0,-1.5),vec3(1.0,0,-0.0),vec3(3.0,0,-1.0),-1.0,28.3495559215,29.9203522483,t);\n    camStraightPath(p,d,vec3(3.0,0,-0.5),vec3(2.0,0,-0.5),29.9203522483,30.9203522483,t);\n    camCirclePath(p,d,vec3(2.0,0,-0.5),vec3(-1.0,0,-0.0),vec3(2.0,0,-0.0),0.5,30.9203522483,31.7057504117,t);\n    camCirclePath(p,d,vec3(1.5,0,-0.0),vec3(0.0,0,1.0),vec3(1.0,0,-0.0),-0.5,31.7057504117,32.4911485751,t);\n    camStraightPath(p,d,vec3(1.0,0,0.5),vec3(0.0,0,0.5),32.4911485751,33.4911485751,t);\n    camCirclePath(p,d,vec3(0.0,0,0.5),vec3(-1.0,0,-0.0),vec3(0.0,0,1.0),0.5,33.4911485751,34.2765467385,t);\n    camCirclePath(p,d,vec3(-0.5,0,1.0),vec3(0.0,0,1.0),vec3(-1.0,0,1.0),-0.5,34.2765467385,35.0619449019,t);\n    camCirclePath(p,d,vec3(-1.0,0,1.5),vec3(-1.0,0,-0.0),vec3(-1.0,0,2.0),0.5,35.0619449019,35.8473430653,t);\n    camCirclePath(p,d,vec3(-1.5,0,2.0),vec3(0.0,0,1.0),vec3(-2.0,0,2.0),-0.5,35.8473430653,36.6327412287,t);\n    camStraightPath(p,d,vec3(-2.0,0,2.5),vec3(-3.0,0,2.5),36.6327412287,37.6327412287,t);\n    camCirclePath(p,d,vec3(-3.0,0,2.5),vec3(-1.0,0,-0.0),vec3(-3.0,0,3.0),1.0,37.6327412287,39.2035375555,t);\n    camStraightPath(p,d,vec3(-3.0,0,3.5),vec3(-1.0,0,3.5),39.2035375555,41.2035375555,t);\n    camCirclePath(p,d,vec3(-1.0,0,3.5),vec3(1.0,0,-0.0),vec3(-1.0,0,3.0),0.5,41.2035375555,41.9889357189,t);\n    camCirclePath(p,d,vec3(-0.5,0,3.0),vec3(0.0,0,-1.0),vec3(0.0,0,3.0),-1.0,41.9889357189,43.5597320457,t);\n    camCirclePath(p,d,vec3(0.5,0,3.0),vec3(0.0,0,1.0),vec3(1.0,0,3.0),0.5,43.5597320457,44.3451302091,t);\n    camStraightPath(p,d,vec3(1.0,0,3.5),vec3(3.5,0,3.5),44.3451302091,46.8451302091,t);\n    camCirclePath(p,d,vec3(3.5,0,3.5),vec3(1.0,0,-0.0),vec3(3.5,0,3.5),1.0,46.8451302091,49.9867228627,t);\n    camStraightPath(p,d,vec3(3.5,0,3.5),vec3(1.0,0,3.5),49.9867228627,52.4867228627,t);\n    camCirclePath(p,d,vec3(1.0,0,3.5),vec3(-1.0,0,-0.0),vec3(1.0,0,3.0),-0.5,52.4867228627,53.2721210261,t);\n    camStraightPath(p,d,vec3(0.5,0,3.0),vec3(0.5,0,2.0),53.2721210261,54.2721210261,t);\n    camCirclePath(p,d,vec3(0.5,0,2.0),vec3(0.0,0,-1.0),vec3(1.0,0,2.0),-1.0,54.2721210261,55.8429173529,t);\n    camCirclePath(p,d,vec3(1.5,0,2.0),vec3(0.0,0,1.0),vec3(2.0,0,2.0),0.5,55.8429173529,56.6283155163,t);\n    camStraightPath(p,d,vec3(2.0,0,2.5),vec3(3.0,0,2.5),56.6283155163,57.6283155163,t);\n    camCirclePath(p,d,vec3(3.0,0,2.5),vec3(1.0,0,-0.0),vec3(3.0,0,2.0),0.5,57.6283155163,58.4137136797,t);\n    camStraightPath(p,d,vec3(3.5,0,2.0),vec3(3.5,0,1.0),58.4137136797,59.4137136797,t);\n    camCirclePath(p,d,vec3(3.5,0,1.0),vec3(0.0,0,-1.0),vec3(3.0,0,1.0),1.0,59.4137136797,60.9845100065,t);\n    camStraightPath(p,d,vec3(2.5,0,1.0),vec3(2.5,0,1.5),60.9845100065,61.4845100065,t);\n    camStraightPath(p,d,vec3(2.5,0,1.4975),vec3(2.5,0,1.5025),61.4845100065,62.4845100065,t);\n\n}\n\n#ifdef DRAW_HUD\n/*\n\tIQ's signed box, now in 2D!\n*/\nfloat sBox( in vec2 p, in vec2 b )\n{\n  vec2 d = abs(p) - b;\n  return min(max(d.x,d.y),0.0) + length(max(d,0.0));\n}\n\n/*\n\tDraws the hud.\n*/\nvec4 HUD( in vec2 uv, in vec2 p, in vec2 d )\n{\n    vec2 up = normalize(d);\n    vec2 right = normalize(mat2(0,-1,1,0)*d);\n    uv = uv.y * up + uv.x * right;\n    uv *= HUD_SCALE;\n    uv += p;\n    // Exterior.\n    float v = max( sBox(uv, vec2(4.0+LINE_WIDTH,4.0+LINE_WIDTH)),\n                  -sBox(uv, vec2(4.0-LINE_WIDTH,4.0-LINE_WIDTH)));\n\n    #define HWALL(x,y,w) sBox(uv+vec2(x,y),vec2(w,LINE_WIDTH))\n    #define VWALL(x,y,w) sBox(uv+vec2(x,y),vec2(LINE_WIDTH,w))\n    // Internal bits. These are the width-1 horizontal walls.\n    v = min(v,HWALL(3.5, 3, .5));\n    v = min(v,HWALL(2.5, 2, .5));\n    v = min(v,HWALL(2.5, 0, .5));\n    v = min(v,HWALL(1.5, 1, .5));\n    v = min(v,HWALL(1.5, 1, .5));\n    v = min(v,HWALL(0.5, 3, .5));\n    v = min(v,HWALL(-0.5, 2, .5));\n    v = min(v,HWALL(-2.5, 3, .5));\n    v = min(v,HWALL(-3.5, 2, .5));\n    v = min(v,HWALL(1.5, -1, .5));\n    v = min(v,HWALL(0.5, -2, .5));\n    v = min(v,HWALL(-2.5, -2, .5));\n    \n    // Time for the lengthy horizontal walls.\n    v = min(v,HWALL(-2,   1, 1 ));\n    v = min(v,HWALL(-0,   0, 1 ));\n    v = min(v,HWALL(-3,   0, 1 ));\n    v = min(v,HWALL( 3,  -2, 1 ));\n    v = min(v,HWALL(-1,  -1, 1 ));\n    v = min(v,HWALL( 2,  -3, 1 ));\n    v = min(v,HWALL(-2.5,-3, 1.5));\n    \n    // And now for the height-1 vertical walls. (Looking from above)\n    v = min(v,VWALL(-0,  1.5, .5));\n    v = min(v,VWALL( 2, -1.5, .5));\n    v = min(v,VWALL(-0, -1.5, .5));\n    v = min(v,VWALL(-3, -1.5, .5));\n    v = min(v,VWALL( 1, -2.5, .5));\n    v = min(v,VWALL(-1, -2.5, .5));\n    v = min(v,VWALL(-0, -3.5, .5));\n    \n    // Without further adu, the lengthy vertical walls.\n    v = min(v,VWALL( 2, 3,1));\n    v = min(v,VWALL( 3,.5,1.5));\n    v = min(v,VWALL( 1, 1,2));\n    v = min(v,VWALL(-1, 3,1));\n    v = min(v,VWALL(-2, 2,1));\n    v = min(v,VWALL(-2,-1,1));\n    \n    v = min(v, length(uv-p)-.125);\n    \n    vec4 r = vec4(0);\n    r.a = step(v,LINE_WIDTH);\n    r.rgb = vec3(step(v,.0));\n    return r;\n}\n#endif\n\n/*\n\tThe key state handler.\n*/\nvoid handleKeys( inout vec4 buffer, in vec2 fragCoord )\n{\n    // Load keypress data from the buffer.\n    vec4 WAS = readTexel(BUFFER, txWAS);\n    vec4 DLR = readTexel(BUFFER, txDLR);\n    \n    // If a key is down, update the position accordingly.\n    vec3 was, dlr;\n    was.r = texture(KEYBOARD,vec2(KEY_W, KEY_DOWN_POS)).r;\n    was.g = texture(KEYBOARD,vec2(KEY_A, KEY_DOWN_POS)).r;\n    was.b = texture(KEYBOARD,vec2(KEY_S, KEY_DOWN_POS)).r;\n    dlr.r = texture(KEYBOARD,vec2(KEY_D, KEY_DOWN_POS)).r;\n    dlr.g = texture(KEYBOARD,vec2(KEY_L, KEY_DOWN_POS)).r;\n    dlr.b = texture(KEYBOARD,vec2(KEY_R, KEY_DOWN_POS)).r;\n    \n    // Store the keys value. That mix eases between full up and\n    // full down states, so that the velocity of the camera\n    // isn't as jarring.\n    write3(buffer.rgb,mix(WAS.rgb,was,.5),txWAS,fragCoord);\n    write3(buffer.rgb,mix(DLR.rgb,dlr,.5),txDLR,fragCoord);\n}\n\n/*\n\tThe camera behavior handler.\n*/\nvoid handleCamera( inout vec4 buffer, in vec2 fragCoord, out vec3 p, out vec3 d)\n{\n    // The time the last camera animation ends.\n    if(iTime < 62.4845100065)\n    {\n        camPath(p,d,iTime);\n    }\n    else\n    {\n        vec3 pPos = readTexel(BUFFER, txCPOS).rgb;\n        vec3 pDir = readTexel(BUFFER, txCDIR).rgb;\n    \tvec4 WAS = readTexel(BUFFER, txWAS);\n    \tvec4 DLR = readTexel(BUFFER, txDLR);\n        d = rodRot(pDir, vec3(0,1,0), (-DLR.g + DLR.b)*.055);\n        d.y = 0.0;\n        d = normalize(d);\n        \n        vec3 nPos = pPos + pDir*(-WAS.b + WAS.r)*.025\n          + cross(vec3(0,1,0),pDir)*(-WAS.g + DLR.r)*.025;\n        \n        if(max(abs(nPos.x),abs(nPos.z))<3.99) p = nPos;\n        else p = pPos;\n        p.y = 0.0;\n    }\n    write4(buffer, vec4(p,1.0), txCPOS, fragCoord);\n    write4(buffer, vec4(d,1.0), txCDIR, fragCoord);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{ \n    // Read the current buffer value.adad\n    vec4 buff = texture(BUFFER, fragCoord/iResolution.xy);\n    \n    // Since we mix the HUD and the maze based on alpha,\n    // let's start off the buffer's alpha at zero.\n    buff.a = 0.;    \n    \n    // Calculate the camera path.\n    vec3 p,d;\n    handleKeys(buff, fragCoord);\n    handleCamera(buff, fragCoord, p,d);\n    //write4(buff, vec4(p,1.0), txCPOS, fragCoord);\n    //write4(buff, vec4(d,1.0), txCDIR, fragCoord);\n    \n    // Get the normalized UV coordinates.\n    vec2 uv = fragCoord / iResolution.xy - 0.5;\n\tuv.x *= iResolution.x/iResolution.y; //fix aspect ratio\n\n    // Render the HUD.\n    #ifdef DRAW_HUD\n    vec4 hud = HUD(uv,p.xz, d.xz);\n    #else\n    vec4 hud = vec4(0);\n    #endif\n    \n    // Mix based on alpha.\n    buff = mix(buff, hud, hud.a);\n    fragColor = buff;\n}","name":"Buf D","description":"","type":"buffer"}]}
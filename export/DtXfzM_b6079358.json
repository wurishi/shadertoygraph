{"ver":"0.1","info":{"id":"DtXfzM","date":"1692721609","viewed":276,"name":"Raytraced glass","username":"Nazlbit","description":"Raytraced glass with dispersion.","likes":13,"published":1,"flags":32,"usePreview":0,"tags":["raytracing","reflection","refraction","dof","spheres","glass","icosahedron","dispersion"],"hasliked":0,"parentid":"cl33z2","parentname":"Raytraced glass (private)"},"renderpass":[{"inputs":[{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// You can rotate the camera with the mouse and change the focus distance by clicking on a surface.\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec4 result = read_buffer(iChannel0, ivec2(fragCoord));\n    fragColor = vec4(linear2gamma(result.rgb), 1.0);\n\n    // Noise detection debug view overlay. This line can be uncommented to show the overlay.\n    //fragColor.rgb *= 0.5 + 0.5 * float(result.a < noise_threshold);\n}\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"const float PI = 3.14159265359;\nconst float middle_sphere_r = 1.0;\nconst float satellite_sphere_r = middle_sphere_r / 2.5;\nconst float sphere_offset = middle_sphere_r * 1.2 + satellite_sphere_r;\nconst float distance_limit = 1000000.0;\nconst float fov = 20.; // Horizontal field of view\nconst float camera_distance = middle_sphere_r * 7.0;\nconst vec2 camera_orientation_offset = PI * vec2(0.5, 0.0);\nconst vec3 camera_pos_offset = vec3(0);\nconst float camera_rotation_speed_coeff = 3.0;\nconst float aperture_size = middle_sphere_r * 0.2; // The bigger the aperture, the bigger the DOF effect.\nconst float init_focus_distance = camera_distance * 1.1;\nconst float skybox_contrast = 3.3;\nconst float skybox_intensity = 50.0;\nconst float skybox_saturation = 1.3;\nconst float pos_offset = 0.0001; // New ray surface offset.\nconst int num_passes_per_frame = 1;\nconst int rays_stack_size = 20;\nconst float ray_importance_threshold = 1e-5;\n// Noise added to rays to smooth out the result. Value in the range of [0:1] is within a pixel.\n// Setting the value to zero means that there is no smoothing and num_passes_per_frame should be 1.\nconst float ray_noise_coeff = 1.0;\nconst float noise_threshold = 0.001;\nconst float noise_power = 5.0;\nconst int noise_sample_size = 9;\nconst float noise_mix_coeff = 0.8;\nconst float dark_area_noise_coeff = 0.2;\nconst float visible_range_min = 380.0;\nconst float visible_range_max = 700.0;\nconst vec3 spectrum_sum_inv = vec3(2.828829, 2.954591, 2.891669);\nconst float air_ior = 1.0;\nconst float glass_ior = 1.54;\nconst float glass_ior_coeff = 0.005;\n\nconst ivec2 frame_num_uv = ivec2(0, 0);\nconst ivec2 mouse_uv = ivec2(1, 0);\nconst ivec2 orientation_uv = ivec2(2, 0);\nconst ivec2 resolution_uv = ivec2(3, 0);\nconst ivec2 focus_distance_uv = ivec2(4, 0);\n\nstruct sphere_t\n{\n    vec3 pos;\n    vec3 color;\n    float r;\n};\n\nconst float pentagon_angle = 72.0 / 180.0 * PI;\nsphere_t spheres[] = sphere_t[](\n    //sphere_t(vec3(0), vec3(0.4, 0.7, 0.6), middle_sphere_r),\n    sphere_t(vec3(cos(pentagon_angle * 0.5), 0, sin(pentagon_angle * 0.5)) * sphere_offset, vec3(0.2, 0.01, 0.2), satellite_sphere_r), //purple\n    sphere_t(vec3(cos(pentagon_angle * 1.5), 0, sin(pentagon_angle * 1.5)) * sphere_offset, vec3(0.002, 0.02, 0.2), satellite_sphere_r), // blue\n    sphere_t(vec3(cos(pentagon_angle * 2.5), 0, sin(pentagon_angle * 2.5)) * sphere_offset, vec3(0.2, 0.01, 0.01), satellite_sphere_r), //red\n    sphere_t(vec3(cos(pentagon_angle * 3.5), 0, sin(pentagon_angle * 3.5)) * sphere_offset, vec3(0.01, 0.2, 0.01), satellite_sphere_r), // green\n    sphere_t(vec3(cos(pentagon_angle * 4.5), 0, sin(pentagon_angle * 4.5)) * sphere_offset, vec3(0.2, 0.05, 0.01), satellite_sphere_r) // orange\n);\n\nconst sphere_t bounding_sphere = sphere_t(vec3(0), vec3(0), middle_sphere_r);\nconst vec3 icosahedron_color = vec3(0.5, 0.55, 0.5);\n\nconst vec3 ico_verts[12] = vec3[](\n    vec3(0.0, -1.0, 0.0) * middle_sphere_r,\n    vec3(0.7235999703407288, -0.4472149908542633, -0.5257200002670288) * middle_sphere_r,\n    vec3(-0.27638500928878784, -0.4472149908542633, -0.8506399989128113) * middle_sphere_r,\n    vec3(-0.8944249749183655, -0.4472149908542633, 0.0) * middle_sphere_r,\n    vec3(-0.27638500928878784, -0.4472149908542633, 0.8506399989128113) * middle_sphere_r,\n    vec3(0.7235999703407288, -0.4472149908542633, 0.5257200002670288) * middle_sphere_r,\n    vec3(0.27638500928878784, 0.4472149908542633, -0.8506399989128113) * middle_sphere_r,\n    vec3(-0.7235999703407288, 0.4472149908542633, -0.5257200002670288) * middle_sphere_r,\n    vec3(-0.7235999703407288, 0.4472149908542633, 0.5257200002670288) * middle_sphere_r,\n    vec3(0.27638500928878784, 0.4472149908542633, 0.8506399989128113) * middle_sphere_r,\n    vec3(0.8944249749183655, 0.4472149908542633, 0.0) * middle_sphere_r,\n    vec3(0.0, 1.0, 0.0) * middle_sphere_r\n);\n\nconst uvec3 ico_ind[20] = uvec3[](\n    uvec3(0, 1, 2),\n    uvec3(1, 0, 5),\n    uvec3(0, 2, 3),\n    uvec3(0, 3, 4),\n    uvec3(0, 4, 5),\n    uvec3(1, 5, 10),\n    uvec3(2, 1, 6),\n    uvec3(3, 2, 7),\n    uvec3(4, 3, 8),\n    uvec3(5, 4, 9),\n    uvec3(1, 10, 6),\n    uvec3(2, 6, 7),\n    uvec3(3, 7, 8),\n    uvec3(4, 8, 9),\n    uvec3(5, 9, 10),\n    uvec3(6, 10, 11),\n    uvec3(7, 6, 11),\n    uvec3(8, 7, 11),\n    uvec3(9, 8, 11),\n    uvec3(10, 9, 11)\n);\n\nstruct ray_t\n{\n    vec3 pos;\n    vec3 dir;\n    vec3 color;\n    int triangle_index;\n};\n\nstruct intersection_t\n{\n    vec3 pos;\n    vec3 normal;\n    vec3 color;\n    int triangle_index;\n    bool inside;\n    bool sphere;\n};\n\nstruct camera_t\n{\n    vec3 pos;\n    vec3 right;\n    vec3 up;\n    vec3 forward;\n    float fov_ctg;\n    float ratio;\n};\n\nconst mat3 XYZ2RGB = mat3( 1.463355, -0.197212, -0.266143, -0.535260, 1.476829, 0.058431, 0.026246, -0.081495, 1.055249 );\n\n// A single iteration of Bob Jenkins' One-At-A-Time hashing algorithm.\nuint hash( uint x ) {\n    x += ( x << 10u );\n    x ^= ( x >>  6u );\n    x += ( x <<  3u );\n    x ^= ( x >> 11u );\n    x += ( x << 15u );\n    return x;\n}\n\n// Compound versions of the hashing algorithm I whipped together.\nuint hash( const uvec2 v ) { return hash( v.x ^ hash(v.y)                         ); }\nuint hash( const uvec3 v ) { return hash( v.x ^ hash(v.y) ^ hash(v.z)             ); }\nuint hash( const uvec4 v ) { return hash( v.x ^ hash(v.y) ^ hash(v.z) ^ hash(v.w) ); }\n\n// Construct a float with half-open range [0:1] using low 23 bits.\n// All zeroes yields 0.0, all ones yields the next smallest representable value below 1.0.\nfloat floatConstruct( uint m ) {\n    const uint ieeeMantissa = 0x007FFFFFu; // binary32 mantissa bitmask\n    const uint ieeeOne      = 0x3F800000u; // 1.0 in IEEE binary32\n\n    m &= ieeeMantissa;                     // Keep only mantissa bits (fractional part)\n    m |= ieeeOne;                          // Add fractional part to 1.0\n\n    float  f = uintBitsToFloat( m );       // Range [1:2]\n    return f - 1.0;                        // Range [0:1]\n}\n\n// Pseudo-random value in half-open range [0:1].\nfloat random( const float x ) { return floatConstruct(hash(floatBitsToUint(x))); }\nfloat random( const vec2  v ) { return floatConstruct(hash(floatBitsToUint(v))); }\nfloat random( const vec3  v ) { return floatConstruct(hash(floatBitsToUint(v))); }\nfloat random( const vec4  v ) { return floatConstruct(hash(floatBitsToUint(v))); }\n\nfloat noise(const vec2 uv, const int frame, inout int seed)\n{\n    return random(vec4(uv, vec2(frame + 1, ++seed)));\n}\n\nvec2 noise2(const vec2 uv, const int frame, inout int seed)\n{\n    return vec2(noise(uv, frame, seed), noise(uv, frame, seed));\n}\n\nfloat erf_inv(const float x) // https://en.wikipedia.org/wiki/Error_function\n{\n    const float a = 6.802721;\n    const float b = 4.330747;\n\n    float u = log(1.0 - x*x);\n    float c = u * 0.5 + b;\n    return sqrt(sqrt(c*c - u*a) - c) * sign(x);\n}\n\nfloat rgb2grayscale(const vec3 rgb)\n{\n    const vec3 rgb_weights = vec3(0.3, 0.59, 0.11);\n    return dot(rgb, rgb_weights);\n}\n\nvec3 saturation(const vec3 color, const float a)\n{\n    float avg = rgb2grayscale(color);\n    return max(mix(vec3(avg), color, a), 0.0);\n}\n\nfloat linear2gamma(const float x)\n{\n    return x > 0.0031308 ? 1.055 * pow(x, 1.0/2.4) - 0.055 : 12.92 * x;\n}\n\nvec3 linear2gamma(const vec3 x)\n{\n    return vec3(linear2gamma(x.r), linear2gamma(x.g), linear2gamma(x.b));\n}\n\nfloat gamma2linear(const float x)\n{\n    return x > 0.04045 ? pow((x + 0.055) / 1.055, 2.4) : x / 12.92;\n}\n\nvec3 gamma2linear(const vec3 x)\n{\n    return vec3(gamma2linear(x.r), gamma2linear(x.g), gamma2linear(x.b));\n}\n\nvec4 read_buffer(sampler2D buffer, ivec2 uv)\n{\n    return texelFetch(buffer, uv, 0);\n}\n\nint get_frame_index(int iframe, sampler2D buf_a)\n{\n    return iframe - int(read_buffer(buf_a, frame_num_uv).r);\n}\n\nbool sphere_hit(const vec2 t)\n{\n    return t[1] > pos_offset; // The sphere is not behind\n}\n\nvec2 sphere_intersection(const ray_t ray, const sphere_t sphere)\n{\n    vec3 r_min_o = ray.pos - sphere.pos;\n    float b = 2.0 * dot(r_min_o, ray.dir);\n    float c = dot(r_min_o, ray.pos) - dot(r_min_o, sphere.pos) - sphere.r * sphere.r;\n    float d = b * b - 4.0 * c;\n    if(d <= 0.0)\n    {\n        // The ray missed the sphere.\n        return vec2(-1.0);\n    }\n\n    // First intersection\n    float t0 = (-b - sqrt(d)) * 0.5;\n    // Second intersection\n    float t1 = (-b + sqrt(d)) * 0.5;\n\n    return vec2(t0, t1);\n}\n\nintersection_t build_intersection_s(const ray_t ray, const sphere_t sphere, const vec2 t)\n{\n    intersection_t intersection;\n    intersection.sphere = true;\n    intersection.inside = t[0] < pos_offset;\n\n    if(intersection.inside)\n    {\n        intersection.color = pow(sphere.color, vec3(t[1] - t[0]));\n        intersection.pos = ray.pos + ray.dir * t[1];\n        intersection.normal = normalize(sphere.pos - intersection.pos);\n    }\n    else\n    {\n        intersection.color = vec3(1.0);\n        intersection.pos = ray.pos + ray.dir * t[0];\n        intersection.normal = normalize(intersection.pos - sphere.pos);\n    }\n    return intersection;\n}\n\nbool triangle_hit(const vec4 b)\n{\n    return b.x >= 0.0 &&\n           b.y >= 0.0 &&\n           b.z >= 0.0 &&\n           b.w > 0.0;\n}\nvec4 triangle_intersection(const ray_t ray, const mat3 triangle)\n{\n    return inverse(mat4(vec4(triangle[0], 1.0),\n                        vec4(triangle[1], 1.0),\n                        vec4(triangle[2], 1.0),\n                        vec4(-ray.dir, 0))) * vec4(ray.pos, 1.0);\n}\n\nintersection_t build_intersection_t(const ray_t ray, const mat3 triangle, const float d)\n{\n    intersection_t intersection;\n    intersection.sphere = false;\n    intersection.pos = ray.pos + ray.dir * d;\n    intersection.normal = normalize(cross(triangle[2] - triangle[0],\n                                          triangle[1] - triangle[0]));\n    intersection.inside = dot(intersection.normal, ray.dir) > 0.0;\n    if(intersection.inside)\n    {\n        intersection.normal *= -1.0;\n        intersection.color = pow(icosahedron_color, vec3(d));\n    }\n    else\n    {\n        intersection.color = vec3(1.0);\n    }\n\n    return intersection;\n}\n\nbool find_closest_intersection(const ray_t ray, out intersection_t intersection)\n{\n    // Find the closest sphere the ray intersects by iterating through all spheres.\n    float sphere_distance = distance_limit;\n\n    int sphere_hit_index = -1;\n    vec2 t;\n    for(int i = 0; i < spheres.length(); ++i)\n    {\n        vec2 t_tmp = sphere_intersection(ray, spheres[i]);\n        if(sphere_hit(t_tmp))\n        {\n            if(sphere_distance > t_tmp[1])\n            {\n                // This sphere is closer to the ray origin.\n                sphere_hit_index = i;\n                sphere_distance = t_tmp[1];\n                t = t_tmp;\n            }\n        }\n    }\n    \n    float triangle_distance = sphere_distance;\n    vec2 bounding_sphere_t = sphere_intersection(ray, bounding_sphere);\n    int triangle_hit_index = -1;\n    if(sphere_hit(bounding_sphere_t) && bounding_sphere_t[0] < sphere_distance)\n    {\n        for(int i = 0; i < ico_ind.length(); ++i)\n        {\n            if(i == ray.triangle_index)\n            {\n                continue;\n            }\n            vec3 p0 = ico_verts[ico_ind[i][0]];\n            vec3 p1 = ico_verts[ico_ind[i][1]];\n            vec3 p2 = ico_verts[ico_ind[i][2]];\n            mat3 triangle = mat3(p0, p1, p2);\n            vec4 barycentric = triangle_intersection(ray, triangle);\n            if(triangle_hit(barycentric))\n            {\n                if(triangle_distance > barycentric.w)\n                {\n                    // This triangle is closer to the ray origin.\n                    triangle_hit_index = i;\n                    triangle_distance = barycentric.w;\n                }\n            }\n        }\n    }\n\n    bool ray_hit = triangle_hit_index > -1 || sphere_hit_index > -1;\n\n    if(ray_hit)\n    {\n        if(sphere_distance <= triangle_distance)\n        {\n            intersection = build_intersection_s(ray, spheres[sphere_hit_index], t);\n            intersection.triangle_index = -1;\n        }\n        else\n        {\n            vec3 p0 = ico_verts[ico_ind[triangle_hit_index][0]];\n            vec3 p1 = ico_verts[ico_ind[triangle_hit_index][1]];\n            vec3 p2 = ico_verts[ico_ind[triangle_hit_index][2]];\n            mat3 triangle = mat3(p0, p1, p2);\n            intersection = build_intersection_t(ray, triangle, triangle_distance);\n            intersection.triangle_index = triangle_hit_index;\n        }\n    }\n    return ray_hit;\n}\n\ncamera_t get_camera(vec2 resolution, sampler2D data_channel)\n{\n    camera_t cam;\n    float fov_rad = PI / 180.0 * fov;\n    cam.fov_ctg = 1.0 / tan(fov_rad);\n    cam.ratio = resolution.x / resolution.y;\n\n    vec2 orientation = read_buffer(data_channel, orientation_uv).xy;\n\n    // Define and rotate basis vectors vertically.\n    cam.right = vec3(cos(orientation.x), 0, sin(orientation.x));\n    cam.forward = vec3(-sin(orientation.x), 0, cos(orientation.x));\n    cam.up = vec3(0, cos(orientation.y), 0) + cam.forward * sin(orientation.y);\n    cam.forward = cam.forward * cos(orientation.y) + vec3(0, -sin(orientation.y), 0);\n\n    // Camera is always looking at the first sphere.\n    cam.pos = camera_pos_offset - cam.forward * camera_distance;\n    return cam;\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec2 coord = ivec2(fragCoord);\n    bool mb = iMouse.z > 0.0;\n    vec4 prev_frame = read_buffer(iChannel0, coord);\n\n    if(coord == frame_num_uv)\n    {\n        vec2 prev_res = read_buffer(iChannel0, resolution_uv).xy;\n        if(mb || prev_res != iResolution.xy)\n        {\n            fragColor = vec4(iFrame);\n        }\n        else\n        {\n            fragColor = prev_frame;\n        }\n    }\n    else if(coord == mouse_uv)\n    {\n        fragColor = iMouse;\n    }\n    else if(coord == orientation_uv)\n    {\n        if(iFrame == 0)\n        {\n            fragColor = vec4(camera_orientation_offset, 0, 0);\n        }\n        else\n        {\n            vec2 pos_delta = vec2(0);\n            vec4 prev_mouse = read_buffer(iChannel0, mouse_uv);\n            if(prev_mouse.z > 0.0 && iMouse.z > 0.0)\n            {\n                pos_delta = iMouse.xy - prev_mouse.xy;\n            }\n            vec2 new_orientation = prev_frame.xy - pos_delta / iResolution.y * camera_rotation_speed_coeff;\n            if(new_orientation.x > PI * 2.0)\n            {\n                new_orientation.x -= PI * 2.0;\n            }\n            else if(new_orientation.x < 0.0)\n            {\n                new_orientation.x += PI * 2.0;\n            }\n\n            new_orientation.y = clamp(new_orientation.y, -PI * 0.5, PI * 0.5);\n\n            fragColor = vec4(new_orientation, 0, 0);\n        }\n    }\n    else if(coord == resolution_uv)\n    {\n        fragColor = vec4(iResolution, 0);\n    }\n    else if(coord == focus_distance_uv)\n    {\n        if(iFrame == 0)\n        {\n            fragColor = vec4(init_focus_distance);\n        }\n        else\n        {\n            if(iMouse.z > 0.0)\n            {\n                camera_t cam = get_camera(iResolution.xy, iChannel0);\n\n                vec2 normalized_coords = iMouse.xy / iResolution.xy * 2.0 - 1.0;\n                vec3 ray_dir = cam.forward * cam.fov_ctg +\n                               cam.right * normalized_coords.x +\n                               cam.up * normalized_coords.y / cam.ratio;\n\n                ray_t ray = ray_t(cam.pos, normalize(ray_dir), vec3(1.0), -1);\n                intersection_t intersection;\n                bool index = find_closest_intersection(ray, intersection);\n                if(index)\n                {\n                    float distance = dot(cam.forward, intersection.pos - cam.pos);\n                    fragColor = vec4(distance);\n                }\n                else\n                {\n                    fragColor = prev_frame;\n                }\n            }\n            else\n            {\n                fragColor = prev_frame;\n            }\n        }\n    }\n    else\n    {\n        fragColor = vec4(0);\n    }\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"XsfGzn","filepath":"/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","previewfilepath":"/media/ap/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","type":"cubemap","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"\nint seed = 0;\n\nfloat fresnel_schlick(float cos_theta, float ior1, float ior2)\n{\n    float r0 = (ior1 - ior2) / (ior1 + ior2);\n    r0 = r0 * r0;\n    float a = 1.0 - cos_theta;\n    float a5 = a * a;\n    a5 *= a5 * a;\n    return r0 + (1.0 - r0) * a5;\n}\n\nvec3 reflect_ray(vec3 v, vec3 n)\n{\n    return normalize(reflect(v, n));\n}\n\nvec3 sky_box(vec3 v)\n{\n    vec3 linear = gamma2linear(textureLod(iChannel0, v, 0.0).rgb);\n\n    // Apply fake hdr effect by increasing contrast and scaling the values.\n    vec3 hdr = pow(saturation(linear, skybox_saturation), vec3(skybox_contrast)) * skybox_intensity;\n    return hdr;\n}\n\nfloat g(const float x, const float a, const float b, const float c)\n{\n    float d = x - a;\n    return exp(-0.5 * d * d / ((x < a) ? (b * b) : (c * c)));\n}\n\nvec3 wl2xyz_CIE1931(const float w){\n    float x = 1.056 * g(w, 599.8, 37.9, 31.0) + 0.362 * g(w, 442.0, 16.0, 26.7) - 0.065 * g(w, 501.1, 20.4, 26.2);\n    float y = 0.821 * g(w, 568.8, 46.9, 40.5) + 0.286 * g(w, 530.9, 16.3, 31.1);\n    float z = 1.217 * g(w, 437.0, 11.8, 36.0) + 0.681 * g(w, 459.0, 26.0, 13.8);\n    return vec3(x,y,z);\n}\n\n// https://en.wikipedia.org/wiki/Cauchy%27s_equation\nfloat wl2ior(const float w, const float a, const float b)\n{\n    return a + b / (w * w);\n}\n\nray_t init_ray(const camera_t cam, const vec3 color)\n{\n    vec2 uv = gl_FragCoord.xy / iResolution.xy;\n\n    // Shape of the noise defines the bokeh shape. In this case it's a circle.\n    vec2 square_noise = noise2(uv, iFrame, seed);\n    vec2 dof_noise = vec2(sqrt(square_noise.x) * 0.5, square_noise.y * 2.0 * PI);\n    vec3 dof = (cam.right * cos(dof_noise.y) + cam.up * sin(dof_noise.y)) * dof_noise.x * aperture_size;\n\n    vec2 pixel_noise = (noise2(uv, iFrame, seed) - 0.5) / iResolution.xy * ray_noise_coeff;\n    vec2 normalized_coords = (uv + pixel_noise) * 2.0 - 1.0;\n    // Initial ray direction based on the normalized fragment coordinates and camera orientation.\n    vec3 ray_dir = cam.forward +\n                   cam.right * normalized_coords.x / cam.fov_ctg +\n                   cam.up * normalized_coords.y / (cam.ratio * cam.fov_ctg);\n    ray_dir *= read_buffer(iChannel1, focus_distance_uv).x;\n    ray_dir += dof;\n\n    return ray_t(cam.pos - dof, normalize(ray_dir), color, -1);\n}\n\nfloat get_noise()\n{\n    return read_buffer(iChannel3, ivec2(gl_FragCoord.xy)).a;\n}\n\nvec4 get_prev_result()\n{\n    return read_buffer(iChannel2, ivec2(gl_FragCoord.xy));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord / iResolution.xy;\n    int frame = get_frame_index(iFrame, iChannel1);\n\n    if(frame != 0 && get_noise() < noise_threshold)\n    {\n        fragColor = get_prev_result();\n        return;\n    }\n\n    camera_t cam = get_camera(iResolution.xy, iChannel1);\n\n    ray_t rays_stack[rays_stack_size + 2];\n\n    // The final color is accumulated with rays interacting the scene.\n    vec3 result = vec3(0);\n\n    for(int pass = 0; pass < num_passes_per_frame; ++pass)\n    {\n        float wl = mix(visible_range_min, visible_range_max, noise(uv, iFrame, seed));\n        vec3 color = max(wl2xyz_CIE1931(wl) * XYZ2RGB, 0.0);\n        float ior = wl2ior(wl * 0.001, glass_ior, glass_ior_coeff);\n\n        rays_stack[0] = init_ray(cam, color);\n        int num_rays = 1;\n\n        while(num_rays > 0)\n        {\n            // Get the next ray.\n            --num_rays;\n            ray_t ray = rays_stack[num_rays];\n\n            intersection_t intersection;\n            if(!find_closest_intersection(ray, intersection))\n            {\n                // The ray doesn't intersect any surfaces, so it hits the skybox.\n                result += sky_box(ray.dir) * ray.color;\n            }\n            else if(num_rays > rays_stack_size)\n            {\n                // We can't emit new rays.\n                continue;\n            }\n            else\n            {\n                float ior_pair[2];\n                ior_pair[int(intersection.inside)] = air_ior;\n                ior_pair[int(!intersection.inside)] = ior;\n\n                vec3 next_color = ray.color * intersection.color;\n\n                vec3 refraction = refract(ray.dir, intersection.normal, ior_pair[0] / ior_pair[1]);\n                bool tir = vec3(0.0) == refraction;\n\n                if(!tir)\n                {\n                    refraction = normalize(refraction);\n                    float fresnel_refraction = 1.0 - fresnel_schlick(dot(-intersection.normal, refraction), ior_pair[1], ior_pair[0]);\n                    vec3 next_color_refraction = next_color * fresnel_refraction;\n\n                    if(rgb2grayscale(next_color_refraction) >= ray_importance_threshold)\n                    {\n                        // Emit refraction ray (add it to the list).\n                        rays_stack[num_rays] = ray_t(intersection.pos, refraction, next_color_refraction, intersection.triangle_index);\n                        ++num_rays;\n                    }\n                }\n\n                bool skip_reflection = tir && intersection.sphere && intersection.inside;\n                if(!skip_reflection)\n                {\n                    float fresnel_reflection = tir ? 1.0 : fresnel_schlick(dot(intersection.normal, -ray.dir), ior_pair[0], ior_pair[1]);\n                    vec3 next_color_reflection = next_color * fresnel_reflection;\n                    if(rgb2grayscale(next_color_reflection) >= ray_importance_threshold)\n                    {\n                        // Emit reflection ray (add it to the list).\n                        vec3 reflection = reflect_ray(ray.dir, intersection.normal);\n                        rays_stack[num_rays] = ray_t(intersection.pos, reflection, next_color_reflection, intersection.triangle_index);\n                        ++num_rays;\n                    }\n                }\n            }\n        }\n    }\n\n    result *= spectrum_sum_inv / float(num_passes_per_frame);\n    result = (get_prev_result().rgb * float(frame) + result) / (float(frame) + 1.0);\n    fragColor = vec4(result, 1.0);\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"\nconst float gaussian [noise_sample_size*noise_sample_size] = float[](\n0.000051, 0.000446, 0.002085, 0.005264, 0.007167, 0.005264, 0.002085, 0.000446, 0.000051,\n0.000446, 0.003866, 0.018091, 0.045665, 0.062177, 0.045665, 0.018091, 0.003866, 0.000446,\n0.002085, 0.018091, 0.084658, 0.213694, 0.290960, 0.213694, 0.084658, 0.018091, 0.002085,\n0.005264, 0.045665, 0.213694, 0.539407, 0.734444, 0.539407, 0.213694, 0.045665, 0.005264,\n0.007167, 0.062177, 0.290960, 0.734444, 1.000000, 0.734444, 0.290960, 0.062177, 0.007167,\n0.005264, 0.045665, 0.213694, 0.539407, 0.734444, 0.539407, 0.213694, 0.045665, 0.005264,\n0.002085, 0.018091, 0.084658, 0.213694, 0.290960, 0.213694, 0.084658, 0.018091, 0.002085,\n0.000446, 0.003866, 0.018091, 0.045665, 0.062177, 0.045665, 0.018091, 0.003866, 0.000446,\n0.000051, 0.000446, 0.002085, 0.005264, 0.007167, 0.005264, 0.002085, 0.000446, 0.000051\n);\n\nconst float gaussian_volume = 10.172879;\n\nfloat tonemap_ACES(const float x) {\n    // Narkowicz 2015, \"ACES Filmic Tone Mapping Curve\"\n    const float a = 2.51;\n    const float b = 0.03;\n    const float c = 2.43;\n    const float d = 0.59;\n    const float e = 0.14;\n    return (x * (a * x + b)) / (x * (c * x + d) + e);\n}\n\nvec3 tonemap_ACES(const vec3 val)\n{\n    return vec3(tonemap_ACES(val.x), tonemap_ACES(val.y), tonemap_ACES(val.z));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec2 int_frag_coord = ivec2(fragCoord);\n    vec3 result = read_buffer(iChannel0, int_frag_coord).rgb;\n    // Apply tone mapping to the final result to turn hdr into sdr.\n    result = tonemap_ACES(result);\n\n    int frame = get_frame_index(iFrame, iChannel2);\n    if(frame == 0)\n    {\n        fragColor = vec4(result, 1.0);\n        return;\n    }\n\n    const int middle = noise_sample_size / 2;\n    float noise = 0.0;\n    for(int i = 0; i < noise_sample_size; ++i)\n    {\n        for(int j = 0; j < noise_sample_size; ++j)\n        {\n            ivec2 offset = ivec2(i, j) - middle;\n            ivec2 uv_sub = int_frag_coord + offset;\n            float value = read_buffer(iChannel1, uv_sub).a;\n            float g = gaussian[i * noise_sample_size + j];\n            noise += pow(value, noise_power) * g;\n        }\n    }\n\n    noise /= gaussian_volume;\n    noise = pow(noise, 1.0 / noise_power);\n\n    vec4 prev = read_buffer(iChannel1, int_frag_coord);\n    float prev_gray = rgb2grayscale(prev.rgb);\n    float new_gray = rgb2grayscale(result);\n    float diff = abs(prev_gray - new_gray);\n    diff /= prev_gray + dark_area_noise_coeff;\n    noise = diff + noise * noise_mix_coeff;\n\n    fragColor = vec4(result, noise);\n}\n","name":"Buffer C","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"const float PI = 3.14159265359;\nconst float middle_sphere_r = 1.0;\nconst float satellite_sphere_r = middle_sphere_r / 2.5;\nconst float sphere_offset = middle_sphere_r * 1.2 + satellite_sphere_r;\nconst float distance_limit = 1000000.0;\nconst float fov = 20.; // Horizontal field of view\nconst float camera_distance = middle_sphere_r * 7.0;\nconst vec2 camera_orientation_offset = PI * vec2(0.5, 0.0);\nconst vec3 camera_pos_offset = vec3(0);\nconst float camera_rotation_speed_coeff = 3.0;\nconst float aperture_size = middle_sphere_r * 0.2; // The bigger the aperture, the bigger the DOF effect.\nconst float init_focus_distance = camera_distance * 1.1;\nconst float skybox_contrast = 3.2;\nconst float skybox_intensity = 50.0;\nconst float skybox_saturation = 1.3;\nconst float pos_offset = 0.0001; // New ray surface offset.\nconst int num_passes_per_frame = 1;\nconst int rays_stack_size = 20;\nconst float ray_importance_threshold = 1e-5;\n// Noise added to rays to smooth out the result. Value in the range of [0:1] is within a pixel.\n// Setting the value to zero means that there is no smoothing and num_passes_per_frame should be 1.\nconst float ray_noise_coeff = 1.0;\nconst float noise_threshold = 0.001;\nconst float noise_power = 5.0;\nconst int noise_sample_size = 9;\nconst float noise_mix_coeff = 0.8;\nconst float dark_area_noise_coeff = 0.2;\nconst float visible_range_min = 380.0;\nconst float visible_range_max = 700.0;\nconst vec3 spectrum_sum_inv = vec3(2.828829, 2.954591, 2.891669);\nconst float air_ior = 1.0;\nconst float glass_ior = 1.54;\nconst float glass_ior_coeff = 0.005;\n\nconst ivec2 frame_num_uv = ivec2(0, 0);\nconst ivec2 mouse_uv = ivec2(1, 0);\nconst ivec2 orientation_uv = ivec2(2, 0);\nconst ivec2 resolution_uv = ivec2(3, 0);\nconst ivec2 focus_distance_uv = ivec2(4, 0);\n\nstruct sphere_t\n{\n    vec3 pos;\n    vec3 color;\n    float r;\n};\n\nconst float pentagon_angle = 72.0 / 180.0 * PI;\nsphere_t spheres[] = sphere_t[](\n    //sphere_t(vec3(0), vec3(0.4, 0.7, 0.6), middle_sphere_r),\n    sphere_t(vec3(cos(pentagon_angle * 0.5), 0, sin(pentagon_angle * 0.5)) * sphere_offset, vec3(0.2, 0.01, 0.2), satellite_sphere_r), //purple\n    sphere_t(vec3(cos(pentagon_angle * 1.5), 0, sin(pentagon_angle * 1.5)) * sphere_offset, vec3(0.002, 0.02, 0.2), satellite_sphere_r), // blue\n    sphere_t(vec3(cos(pentagon_angle * 2.5), 0, sin(pentagon_angle * 2.5)) * sphere_offset, vec3(0.2, 0.01, 0.01), satellite_sphere_r), //red\n    sphere_t(vec3(cos(pentagon_angle * 3.5), 0, sin(pentagon_angle * 3.5)) * sphere_offset, vec3(0.01, 0.2, 0.01), satellite_sphere_r), // green\n    sphere_t(vec3(cos(pentagon_angle * 4.5), 0, sin(pentagon_angle * 4.5)) * sphere_offset, vec3(0.2, 0.05, 0.01), satellite_sphere_r) // orange\n);\n\nconst sphere_t bounding_sphere = sphere_t(vec3(0), vec3(0), middle_sphere_r);\nconst vec3 icosahedron_color = vec3(0.5, 0.55, 0.5);\n\nconst vec3 ico_verts[12] = vec3[](\n    vec3(0.0, -1.0, 0.0) * middle_sphere_r,\n    vec3(0.7235999703407288, -0.4472149908542633, -0.5257200002670288) * middle_sphere_r,\n    vec3(-0.27638500928878784, -0.4472149908542633, -0.8506399989128113) * middle_sphere_r,\n    vec3(-0.8944249749183655, -0.4472149908542633, 0.0) * middle_sphere_r,\n    vec3(-0.27638500928878784, -0.4472149908542633, 0.8506399989128113) * middle_sphere_r,\n    vec3(0.7235999703407288, -0.4472149908542633, 0.5257200002670288) * middle_sphere_r,\n    vec3(0.27638500928878784, 0.4472149908542633, -0.8506399989128113) * middle_sphere_r,\n    vec3(-0.7235999703407288, 0.4472149908542633, -0.5257200002670288) * middle_sphere_r,\n    vec3(-0.7235999703407288, 0.4472149908542633, 0.5257200002670288) * middle_sphere_r,\n    vec3(0.27638500928878784, 0.4472149908542633, 0.8506399989128113) * middle_sphere_r,\n    vec3(0.8944249749183655, 0.4472149908542633, 0.0) * middle_sphere_r,\n    vec3(0.0, 1.0, 0.0) * middle_sphere_r\n);\n\nconst uvec3 ico_ind[20] = uvec3[](\n    uvec3(0, 1, 2),\n    uvec3(1, 0, 5),\n    uvec3(0, 2, 3),\n    uvec3(0, 3, 4),\n    uvec3(0, 4, 5),\n    uvec3(1, 5, 10),\n    uvec3(2, 1, 6),\n    uvec3(3, 2, 7),\n    uvec3(4, 3, 8),\n    uvec3(5, 4, 9),\n    uvec3(1, 10, 6),\n    uvec3(2, 6, 7),\n    uvec3(3, 7, 8),\n    uvec3(4, 8, 9),\n    uvec3(5, 9, 10),\n    uvec3(6, 10, 11),\n    uvec3(7, 6, 11),\n    uvec3(8, 7, 11),\n    uvec3(9, 8, 11),\n    uvec3(10, 9, 11)\n);\n\nstruct ray_t\n{\n    vec3 pos;\n    vec3 dir;\n    vec3 color;\n    int triangle_index;\n};\n\nstruct intersection_t\n{\n    vec3 pos;\n    vec3 normal;\n    vec3 color;\n    int triangle_index;\n    bool inside;\n    bool sphere;\n};\n\nstruct camera_t\n{\n    vec3 pos;\n    vec3 right;\n    vec3 up;\n    vec3 forward;\n    float fov_ctg;\n    float ratio;\n};\n\nconst mat3 XYZ2RGB = mat3( 1.463355, -0.197212, -0.266143, -0.535260, 1.476829, 0.058431, 0.026246, -0.081495, 1.055249 );\n\n// A single iteration of Bob Jenkins' One-At-A-Time hashing algorithm.\nuint hash( uint x ) {\n    x += ( x << 10u );\n    x ^= ( x >>  6u );\n    x += ( x <<  3u );\n    x ^= ( x >> 11u );\n    x += ( x << 15u );\n    return x;\n}\n\n// Compound versions of the hashing algorithm I whipped together.\nuint hash( const uvec2 v ) { return hash( v.x ^ hash(v.y)                         ); }\nuint hash( const uvec3 v ) { return hash( v.x ^ hash(v.y) ^ hash(v.z)             ); }\nuint hash( const uvec4 v ) { return hash( v.x ^ hash(v.y) ^ hash(v.z) ^ hash(v.w) ); }\n\n// Construct a float with half-open range [0:1] using low 23 bits.\n// All zeroes yields 0.0, all ones yields the next smallest representable value below 1.0.\nfloat floatConstruct( uint m ) {\n    const uint ieeeMantissa = 0x007FFFFFu; // binary32 mantissa bitmask\n    const uint ieeeOne      = 0x3F800000u; // 1.0 in IEEE binary32\n\n    m &= ieeeMantissa;                     // Keep only mantissa bits (fractional part)\n    m |= ieeeOne;                          // Add fractional part to 1.0\n\n    float  f = uintBitsToFloat( m );       // Range [1:2]\n    return f - 1.0;                        // Range [0:1]\n}\n\n// Pseudo-random value in half-open range [0:1].\nfloat random( const float x ) { return floatConstruct(hash(floatBitsToUint(x))); }\nfloat random( const vec2  v ) { return floatConstruct(hash(floatBitsToUint(v))); }\nfloat random( const vec3  v ) { return floatConstruct(hash(floatBitsToUint(v))); }\nfloat random( const vec4  v ) { return floatConstruct(hash(floatBitsToUint(v))); }\n\nfloat noise(const vec2 uv, const int frame, inout int seed)\n{\n    return random(vec4(uv, vec2(frame + 1, ++seed)));\n}\n\nvec2 noise2(const vec2 uv, const int frame, inout int seed)\n{\n    return vec2(noise(uv, frame, seed), noise(uv, frame, seed));\n}\n\nfloat erf_inv(const float x) // https://en.wikipedia.org/wiki/Error_function\n{\n    const float a = 6.802721;\n    const float b = 4.330747;\n\n    float u = log(1.0 - x*x);\n    float c = u * 0.5 + b;\n    return sqrt(sqrt(c*c - u*a) - c) * sign(x);\n}\n\nfloat rgb2grayscale(const vec3 rgb)\n{\n    const vec3 rgb_weights = vec3(0.3, 0.59, 0.11);\n    return dot(rgb, rgb_weights);\n}\n\nvec3 saturation(const vec3 color, const float a)\n{\n    float avg = rgb2grayscale(color);\n    return max(mix(vec3(avg), color, a), 0.0);\n}\n\nfloat linear2gamma(const float x)\n{\n    return x > 0.0031308 ? 1.055 * pow(x, 1.0/2.4) - 0.055 : 12.92 * x;\n}\n\nvec3 linear2gamma(const vec3 x)\n{\n    return vec3(linear2gamma(x.r), linear2gamma(x.g), linear2gamma(x.b));\n}\n\nfloat gamma2linear(const float x)\n{\n    return x > 0.04045 ? pow((x + 0.055) / 1.055, 2.4) : x / 12.92;\n}\n\nvec3 gamma2linear(const vec3 x)\n{\n    return vec3(gamma2linear(x.r), gamma2linear(x.g), gamma2linear(x.b));\n}\n\nvec4 read_buffer(sampler2D buffer, ivec2 uv)\n{\n    return texelFetch(buffer, uv, 0);\n}\n\nint get_frame_index(int iframe, sampler2D buf_a)\n{\n    return iframe - int(read_buffer(buf_a, frame_num_uv).r);\n}\n\nbool sphere_hit(const vec2 t)\n{\n    return t[1] > pos_offset; // The sphere is not behind\n}\n\nvec2 sphere_intersection(const ray_t ray, const sphere_t sphere)\n{\n    vec3 r_min_o = ray.pos - sphere.pos;\n    float b = 2.0 * dot(r_min_o, ray.dir);\n    float c = dot(r_min_o, ray.pos) - dot(r_min_o, sphere.pos) - sphere.r * sphere.r;\n    float d = b * b - 4.0 * c;\n    if(d <= 0.0)\n    {\n        // The ray missed the sphere.\n        return vec2(-1.0);\n    }\n\n    // First intersection\n    float t0 = (-b - sqrt(d)) * 0.5;\n    // Second intersection\n    float t1 = (-b + sqrt(d)) * 0.5;\n\n    return vec2(t0, t1);\n}\n\nintersection_t build_intersection_s(const ray_t ray, const sphere_t sphere, const vec2 t)\n{\n    intersection_t intersection;\n    intersection.sphere = true;\n    intersection.inside = t[0] < pos_offset;\n\n    if(intersection.inside)\n    {\n        intersection.color = pow(sphere.color, vec3(t[1] - t[0]));\n        intersection.pos = ray.pos + ray.dir * t[1];\n        intersection.normal = normalize(sphere.pos - intersection.pos);\n    }\n    else\n    {\n        intersection.color = vec3(1.0);\n        intersection.pos = ray.pos + ray.dir * t[0];\n        intersection.normal = normalize(intersection.pos - sphere.pos);\n    }\n    return intersection;\n}\n\nbool triangle_hit(const vec4 b)\n{\n    return b.x >= 0.0 &&\n           b.y >= 0.0 &&\n           b.z >= 0.0 &&\n           b.w > 0.0;\n}\nvec4 triangle_intersection(const ray_t ray, const mat3 triangle)\n{\n    return inverse(mat4(vec4(triangle[0], 1.0),\n                        vec4(triangle[1], 1.0),\n                        vec4(triangle[2], 1.0),\n                        vec4(-ray.dir, 0))) * vec4(ray.pos, 1.0);\n}\n\nintersection_t build_intersection_t(const ray_t ray, const mat3 triangle, const float d)\n{\n    intersection_t intersection;\n    intersection.sphere = false;\n    intersection.pos = ray.pos + ray.dir * d;\n    intersection.normal = normalize(cross(triangle[2] - triangle[0],\n                                          triangle[1] - triangle[0]));\n    intersection.inside = dot(intersection.normal, ray.dir) > 0.0;\n    if(intersection.inside)\n    {\n        intersection.normal *= -1.0;\n        intersection.color = pow(icosahedron_color, vec3(d));\n    }\n    else\n    {\n        intersection.color = vec3(1.0);\n    }\n\n    return intersection;\n}\n\nbool find_closest_intersection(const ray_t ray, out intersection_t intersection)\n{\n    // Find the closest sphere the ray intersects by iterating through all spheres.\n    float sphere_distance = distance_limit;\n\n    int sphere_hit_index = -1;\n    vec2 t;\n    for(int i = 0; i < spheres.length(); ++i)\n    {\n        vec2 t_tmp = sphere_intersection(ray, spheres[i]);\n        if(sphere_hit(t_tmp))\n        {\n            if(sphere_distance > t_tmp[1])\n            {\n                // This sphere is closer to the ray origin.\n                sphere_hit_index = i;\n                sphere_distance = t_tmp[1];\n                t = t_tmp;\n            }\n        }\n    }\n    \n    float triangle_distance = sphere_distance;\n    vec2 bounding_sphere_t = sphere_intersection(ray, bounding_sphere);\n    int triangle_hit_index = -1;\n    if(sphere_hit(bounding_sphere_t) && bounding_sphere_t[0] < sphere_distance)\n    {\n        for(int i = 0; i < ico_ind.length(); ++i)\n        {\n            if(i == ray.triangle_index)\n            {\n                continue;\n            }\n            vec3 p0 = ico_verts[ico_ind[i][0]];\n            vec3 p1 = ico_verts[ico_ind[i][1]];\n            vec3 p2 = ico_verts[ico_ind[i][2]];\n            mat3 triangle = mat3(p0, p1, p2);\n            vec4 barycentric = triangle_intersection(ray, triangle);\n            if(triangle_hit(barycentric))\n            {\n                if(triangle_distance > barycentric.w)\n                {\n                    // This triangle is closer to the ray origin.\n                    triangle_hit_index = i;\n                    triangle_distance = barycentric.w;\n                }\n            }\n        }\n    }\n\n    bool ray_hit = triangle_hit_index > -1 || sphere_hit_index > -1;\n\n    if(ray_hit)\n    {\n        if(sphere_distance <= triangle_distance)\n        {\n            intersection = build_intersection_s(ray, spheres[sphere_hit_index], t);\n            intersection.triangle_index = -1;\n        }\n        else\n        {\n            vec3 p0 = ico_verts[ico_ind[triangle_hit_index][0]];\n            vec3 p1 = ico_verts[ico_ind[triangle_hit_index][1]];\n            vec3 p2 = ico_verts[ico_ind[triangle_hit_index][2]];\n            mat3 triangle = mat3(p0, p1, p2);\n            intersection = build_intersection_t(ray, triangle, triangle_distance);\n            intersection.triangle_index = triangle_hit_index;\n        }\n    }\n    return ray_hit;\n}\n\ncamera_t get_camera(vec2 resolution, sampler2D data_channel)\n{\n    camera_t cam;\n    float fov_rad = PI / 180.0 * fov;\n    cam.fov_ctg = 1.0 / tan(fov_rad);\n    cam.ratio = resolution.x / resolution.y;\n\n    vec2 orientation = read_buffer(data_channel, orientation_uv).xy;\n\n    // Define and rotate basis vectors vertically.\n    cam.right = vec3(cos(orientation.x), 0, sin(orientation.x));\n    cam.forward = vec3(-sin(orientation.x), 0, cos(orientation.x));\n    cam.up = vec3(0, cos(orientation.y), 0) + cam.forward * sin(orientation.y);\n    cam.forward = cam.forward * cos(orientation.y) + vec3(0, -sin(orientation.y), 0);\n\n    // Camera is always looking at the first sphere.\n    cam.pos = camera_pos_offset - cam.forward * camera_distance;\n    return cam;\n}\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec2 coord = ivec2(fragCoord);\n    bool mb = iMouse.z > 0.0;\n    vec4 prev_frame = read_buffer(iChannel0, coord);\n\n    if(coord == frame_num_uv)\n    {\n        vec2 prev_res = read_buffer(iChannel0, resolution_uv).xy;\n        if(mb || prev_res != iResolution.xy)\n        {\n            fragColor = vec4(iFrame);\n        }\n        else\n        {\n            fragColor = prev_frame;\n        }\n    }\n    else if(coord == mouse_uv)\n    {\n        fragColor = iMouse;\n    }\n    else if(coord == orientation_uv)\n    {\n        if(iFrame == 0)\n        {\n            fragColor = vec4(camera_orientation_offset, 0, 0);\n        }\n        else\n        {\n            vec2 pos_delta = vec2(0);\n            vec4 prev_mouse = read_buffer(iChannel0, mouse_uv);\n            if(prev_mouse.z > 0.0 && iMouse.z > 0.0)\n            {\n                pos_delta = iMouse.xy - prev_mouse.xy;\n            }\n            vec2 new_orientation = prev_frame.xy - pos_delta / iResolution.y * camera_rotation_speed_coeff;\n            if(new_orientation.x > PI * 2.0)\n            {\n                new_orientation.x -= PI * 2.0;\n            }\n            else if(new_orientation.x < 0.0)\n            {\n                new_orientation.x += PI * 2.0;\n            }\n\n            new_orientation.y = clamp(new_orientation.y, -PI * 0.5, PI * 0.5);\n\n            fragColor = vec4(new_orientation, 0, 0);\n        }\n    }\n    else if(coord == resolution_uv)\n    {\n        fragColor = vec4(iResolution, 0);\n    }\n    else if(coord == focus_distance_uv)\n    {\n        if(iFrame == 0)\n        {\n            fragColor = vec4(init_focus_distance);\n        }\n        else\n        {\n            if(iMouse.z > 0.0)\n            {\n                camera_t cam = get_camera(iResolution.xy, iChannel0);\n\n                vec2 normalized_coords = iMouse.xy / iResolution.xy * 2.0 - 1.0;\n                vec3 ray_dir = cam.forward * cam.fov_ctg +\n                               cam.right * normalized_coords.x +\n                               cam.up * normalized_coords.y / cam.ratio;\n\n                ray_t ray = ray_t(cam.pos, normalize(ray_dir), vec3(1.0), -1);\n                intersection_t intersection;\n                bool index = find_closest_intersection(ray, intersection);\n                if(index)\n                {\n                    float distance = dot(cam.forward, intersection.pos - cam.pos);\n                    fragColor = vec4(distance);\n                }\n                else\n                {\n                    fragColor = prev_frame;\n                }\n            }\n            else\n            {\n                fragColor = prev_frame;\n            }\n        }\n    }\n    else\n    {\n        fragColor = vec4(0);\n    }\n}\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"XsfGzn","filepath":"/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","previewfilepath":"/media/ap/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","type":"cubemap","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"\nint seed = 0;\n\nfloat fresnel_schlick(float cos_theta, float ior1, float ior2)\n{\n    float r0 = (ior1 - ior2) / (ior1 + ior2);\n    r0 = r0 * r0;\n    float a = 1.0 - cos_theta;\n    float a5 = a * a;\n    a5 *= a5 * a;\n    return r0 + (1.0 - r0) * a5;\n}\n\nvec3 reflect_ray(vec3 v, vec3 n)\n{\n    return normalize(reflect(v, n));\n}\n\nvec3 sky_box(vec3 v)\n{\n    vec3 linear = gamma2linear(textureLod(iChannel0, v, 0.0).rgb);\n\n    // Apply fake hdr effect by increasing contrast and scaling the values.\n    vec3 hdr = pow(saturation(linear, skybox_saturation), vec3(skybox_contrast)) * skybox_intensity;\n    return hdr;\n}\n\nfloat g(const float x, const float a, const float b, const float c)\n{\n    float d = x - a;\n    return exp(-0.5 * d * d / ((x < a) ? (b * b) : (c * c)));\n}\n\nvec3 wl2xyz_CIE1931(const float w){\n    float x = 1.056 * g(w, 599.8, 37.9, 31.0) + 0.362 * g(w, 442.0, 16.0, 26.7) - 0.065 * g(w, 501.1, 20.4, 26.2);\n    float y = 0.821 * g(w, 568.8, 46.9, 40.5) + 0.286 * g(w, 530.9, 16.3, 31.1);\n    float z = 1.217 * g(w, 437.0, 11.8, 36.0) + 0.681 * g(w, 459.0, 26.0, 13.8);\n    return vec3(x,y,z);\n}\n\n// https://en.wikipedia.org/wiki/Cauchy%27s_equation\nfloat wl2ior(const float w, const float a, const float b)\n{\n    return a + b / (w * w);\n}\n\nray_t init_ray(const camera_t cam, const vec3 color)\n{\n    vec2 uv = gl_FragCoord.xy / iResolution.xy;\n\n    // Shape of the noise defines the bokeh shape. In this case it's a circle.\n    vec2 square_noise = noise2(uv, iFrame, seed);\n    vec2 dof_noise = vec2(sqrt(square_noise.x) * 0.5, square_noise.y * 2.0 * PI);\n    vec3 dof = (cam.right * cos(dof_noise.y) + cam.up * sin(dof_noise.y)) * dof_noise.x * aperture_size;\n\n    vec2 pixel_noise = (noise2(uv, iFrame, seed) - 0.5) / iResolution.xy * ray_noise_coeff;\n    vec2 normalized_coords = (uv + pixel_noise) * 2.0 - 1.0;\n    // Initial ray direction based on the normalized fragment coordinates and camera orientation.\n    vec3 ray_dir = cam.forward +\n                   cam.right * normalized_coords.x / cam.fov_ctg +\n                   cam.up * normalized_coords.y / (cam.ratio * cam.fov_ctg);\n    ray_dir *= read_buffer(iChannel1, focus_distance_uv).x;\n    ray_dir += dof;\n\n    return ray_t(cam.pos - dof, normalize(ray_dir), color, -1);\n}\n\nfloat get_noise()\n{\n    return read_buffer(iChannel3, ivec2(gl_FragCoord.xy)).a;\n}\n\nvec4 get_prev_result()\n{\n    return read_buffer(iChannel2, ivec2(gl_FragCoord.xy));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord / iResolution.xy;\n    int frame = get_frame_index(iFrame, iChannel1);\n\n    if(frame != 0 && get_noise() < noise_threshold)\n    {\n        fragColor = get_prev_result();\n        return;\n    }\n\n    camera_t cam = get_camera(iResolution.xy, iChannel1);\n\n    ray_t rays_stack[rays_stack_size + 2];\n\n    // The final color is accumulated with rays interacting the scene.\n    vec3 result = vec3(0);\n\n    for(int pass = 0; pass < num_passes_per_frame; ++pass)\n    {\n        float wl = mix(visible_range_min, visible_range_max, noise(uv, iFrame, seed));\n        vec3 color = max(wl2xyz_CIE1931(wl) * XYZ2RGB, 0.0);\n        float ior = wl2ior(wl * 0.001, glass_ior, glass_ior_coeff);\n\n        rays_stack[0] = init_ray(cam, color);\n        int num_rays = 1;\n\n        while(num_rays > 0)\n        {\n            // Get the next ray.\n            --num_rays;\n            ray_t ray = rays_stack[num_rays];\n\n            intersection_t intersection;\n            if(!find_closest_intersection(ray, intersection))\n            {\n                // The ray doesn't intersect any surfaces, so it hits the skybox.\n                result += sky_box(ray.dir) * ray.color;\n            }\n            else if(num_rays > rays_stack_size)\n            {\n                // We can't emit new rays.\n                continue;\n            }\n            else\n            {\n                float ior_pair[2];\n                ior_pair[int(intersection.inside)] = air_ior;\n                ior_pair[int(!intersection.inside)] = ior;\n\n                vec3 next_color = ray.color * intersection.color;\n\n                vec3 refraction = refract(ray.dir, intersection.normal, ior_pair[0] / ior_pair[1]);\n                bool tir = vec3(0.0) == refraction;\n\n                if(!tir)\n                {\n                    refraction = normalize(refraction);\n                    float fresnel_refraction = 1.0 - fresnel_schlick(dot(-intersection.normal, refraction), ior_pair[1], ior_pair[0]);\n                    vec3 next_color_refraction = next_color * fresnel_refraction;\n\n                    if(rgb2grayscale(next_color_refraction) >= ray_importance_threshold)\n                    {\n                        // Emit refraction ray (add it to the list).\n                        rays_stack[num_rays] = ray_t(intersection.pos, refraction, next_color_refraction, intersection.triangle_index);\n                        ++num_rays;\n                    }\n                }\n\n                bool skip_reflection = tir && intersection.sphere && intersection.inside;\n                if(!skip_reflection)\n                {\n                    float fresnel_reflection = tir ? 1.0 : fresnel_schlick(dot(intersection.normal, -ray.dir), ior_pair[0], ior_pair[1]);\n                    vec3 next_color_reflection = next_color * fresnel_reflection;\n                    if(rgb2grayscale(next_color_reflection) >= ray_importance_threshold)\n                    {\n                        // Emit reflection ray (add it to the list).\n                        vec3 reflection = reflect_ray(ray.dir, intersection.normal);\n                        rays_stack[num_rays] = ray_t(intersection.pos, reflection, next_color_reflection, intersection.triangle_index);\n                        ++num_rays;\n                    }\n                }\n            }\n        }\n    }\n\n    result *= spectrum_sum_inv / float(num_passes_per_frame);\n    result = (get_prev_result().rgb * float(frame) + result) / (float(frame) + 1.0);\n    fragColor = vec4(result, 1.0);\n}\n","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":2,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"/media/previz/buffer01.png","previewfilepath":"/media/previz/buffer01.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"\nconst float gaussian [noise_sample_size*noise_sample_size] = float[](\n0.000051, 0.000446, 0.002085, 0.005264, 0.007167, 0.005264, 0.002085, 0.000446, 0.000051,\n0.000446, 0.003866, 0.018091, 0.045665, 0.062177, 0.045665, 0.018091, 0.003866, 0.000446,\n0.002085, 0.018091, 0.084658, 0.213694, 0.290960, 0.213694, 0.084658, 0.018091, 0.002085,\n0.005264, 0.045665, 0.213694, 0.539407, 0.734444, 0.539407, 0.213694, 0.045665, 0.005264,\n0.007167, 0.062177, 0.290960, 0.734444, 1.000000, 0.734444, 0.290960, 0.062177, 0.007167,\n0.005264, 0.045665, 0.213694, 0.539407, 0.734444, 0.539407, 0.213694, 0.045665, 0.005264,\n0.002085, 0.018091, 0.084658, 0.213694, 0.290960, 0.213694, 0.084658, 0.018091, 0.002085,\n0.000446, 0.003866, 0.018091, 0.045665, 0.062177, 0.045665, 0.018091, 0.003866, 0.000446,\n0.000051, 0.000446, 0.002085, 0.005264, 0.007167, 0.005264, 0.002085, 0.000446, 0.000051\n);\n\nconst float gaussian_volume = 10.172879;\n\nfloat tonemap_ACES(const float x) {\n    // Narkowicz 2015, \"ACES Filmic Tone Mapping Curve\"\n    const float a = 2.51;\n    const float b = 0.03;\n    const float c = 2.43;\n    const float d = 0.59;\n    const float e = 0.14;\n    return (x * (a * x + b)) / (x * (c * x + d) + e);\n}\n\nvec3 tonemap_ACES(const vec3 val)\n{\n    return vec3(tonemap_ACES(val.x), tonemap_ACES(val.y), tonemap_ACES(val.z));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec2 int_frag_coord = ivec2(fragCoord);\n    vec3 result = read_buffer(iChannel0, int_frag_coord).rgb;\n    // Apply tone mapping to the final result to turn hdr into sdr.\n    result = tonemap_ACES(result);\n\n    int frame = get_frame_index(iFrame, iChannel2);\n    if(frame == 0)\n    {\n        fragColor = vec4(result, 1.0);\n        return;\n    }\n\n    const int middle = noise_sample_size / 2;\n    float noise = 0.0;\n    for(int i = 0; i < noise_sample_size; ++i)\n    {\n        for(int j = 0; j < noise_sample_size; ++j)\n        {\n            ivec2 offset = ivec2(i, j) - middle;\n            ivec2 uv_sub = int_frag_coord + offset;\n            float value = read_buffer(iChannel1, uv_sub).a;\n            float g = gaussian[i * noise_sample_size + j];\n            noise += pow(value, noise_power) * g;\n        }\n    }\n\n    noise /= gaussian_volume;\n    noise = pow(noise, 1.0 / noise_power);\n\n    vec4 prev = read_buffer(iChannel1, int_frag_coord);\n    float prev_gray = rgb2grayscale(prev.rgb);\n    float new_gray = rgb2grayscale(result);\n    float diff = abs(prev_gray - new_gray);\n    diff /= prev_gray + dark_area_noise_coeff;\n    noise = diff + noise * noise_mix_coeff;\n\n    fragColor = vec4(result, noise);\n}\n","name":"Buffer C","description":"","type":"buffer"}]}
{"ver":"0.1","renderpass":[{"outputs":[],"inputs":[],"code":"//Constants\nfloat PI = 2.0 * asin(1.0);\n\n//Define your camera properties\nfloat verticalFov;\nvec3 cameraPosition = vec3(0,0,2);\nvec3 cameraTarget = vec3(0,0,0);\nvec3 cameraUp = vec3(0,1.0,0);\n\n//Define your plane\n//X axis of your plane\nvec3 planeX = vec3(1, 0, 0);\n//Y axis of your plane\nvec3 planeY = vec3(0, 1, 0);\n//Plane normal derived from x and y axes\nvec3 normalToPlane;\n//Center point on plane to position the plane in space and for using in determining ray intersection\nvec3 centerPointOnPlane = vec3(2,4,0);\n//Width of the plane\nfloat planeWidth = 1.0;\n//Height of the plane\nfloat planeHeight = 1.0;\nfloat rotationPerFrame;\n\nmat4 getViewMatrix(vec3 eye, vec3 target, vec3 up) \n{\n\tvec3 zaxis = normalize(eye - target);    // The \"forward\" vector.\n    vec3 xaxis = normalize(cross(up, zaxis));// The \"right\" vector.\n    vec3 yaxis = cross(zaxis, xaxis);     // The \"up\" vector.\n\t\n\t// Create a 4x4 view matrix from the right, up, forward and eye position vectors\n    mat4 viewMatrix = mat4(\n             xaxis.x,           yaxis.x,             zaxis.x,       0,\n             xaxis.y,           yaxis.y,             zaxis.y,       0,\n             xaxis.z,           yaxis.z,             zaxis.z,       0,\n       -dot( xaxis, eye ), -dot( yaxis, eye ), -dot( zaxis, eye ),  1\n    );\n     \n    return viewMatrix;\n}\n\nmat4 getInverseViewMatrix(vec3 eye, vec3 target, vec3 up)\n{\n\tvec3 zaxis = normalize(eye - target);    // The \"forward\" vector.\n    vec3 xaxis = normalize(cross(up, zaxis));// The \"right\" vector.\n    vec3 yaxis = cross(zaxis, xaxis);     // The \"up\" vector.\n\t\n\t//Translate to camera position from the origin\n    mat4 inverseTranslationViewMatrix = mat4(\n                        1,                 0,                 0,       0,\n                        0,                 1,                 0,       0,\n                        0,                 0,                 1,       0,\n                    eye.x,             eye.y,             eye.z,       1\n    );\n\t\n\t//Unrotate\n\tmat4 inverseRotationViewMatrix = mat4(\n\t\t xaxis.x,           xaxis.y,             xaxis.z,       0,\n         yaxis.x,           yaxis.y,             yaxis.z,       0,\n         zaxis.x,           zaxis.y,             zaxis.z,       0,\n\t\t\t   0,                 0,                   0,       1\n\t);\n\t\n\t//(RT)-1 = (T-1)(R-1)\n     \n    return inverseTranslationViewMatrix * inverseRotationViewMatrix;\n}\n\n//Axis/angle to rotation matrix based on mouse position for camera rotation\nmat3 getMouseRotationMatrix()\n{\n\t//Current mouse position in NDC\n\tvec2 mousePosition = vec2(2.0 * (iMouse.x / iResolution.x) - 1.0, 2.0 * (iMouse.y / iResolution.y) - 1.0);\n\n\t//Let's determine the axis\n\tvec3 axis = normalize(cross(vec3(mousePosition, 0.0), vec3(0,0,1.0)));\n\t\n\tfloat angle = length(mousePosition) * PI;\n\n\tfloat c = cos(angle);\n\tfloat t = 1.0 - cos(angle);\n\tfloat s = sin(angle);\n\tfloat x = axis.x;\n\tfloat y = axis.y;\n\tfloat z = axis.z;\n\tfloat x2 = pow(x,2.0);\n\tfloat y2 = pow(y,2.0);\n\tfloat z2 = pow(z,2.0);\n\t\n\tmat3 rotationMatrix = mat3(\n\t\tt*x2 + c, t*x*y - s*z, t*x*z + s*y,\n\t\tt*x*y + s*z, t*y2 + c, t*y*z - s*x,\n\t\tt*x*z - s*y, t*y*z +s*x, t*z2 + c);\n\t\n\treturn rotationMatrix;\n\t\t\t\t\t\t \n}\n\nvec4 getSampleAt(vec2 uv, mat4 viewMatrix, mat4 inverseViewMatrix, int row, int col)\n{\n\tconst int gridWidth = 8;\n\tconst int gridHeight = gridWidth;\n\tfloat subPixelWidth = 1.0 / (iResolution.y * float(gridWidth));\n\tfloat subPixelHeight = subPixelWidth;\n\t\n\tfloat xDisplacement = subPixelWidth * (float(col) - (float(gridWidth - 1) / 2.0));\n\tfloat yDisplacement = subPixelHeight * (float(row) - (float(gridHeight - 1) / 2.0));\n\t\t\t\t\n\t//This is a vector from the camera to the near plane\n\tvec3 cameraToNear = vec3(0, 0, (1.0 / tan(verticalFov)));\n\t\n\t//Direction of line from camera to near plane in eye coordinates, this is the \"ray\"\n\tvec3 lineDirection = vec3(uv.x + xDisplacement, uv.y + yDisplacement, 0) - cameraToNear;\n\t\n\t//Plane point in eye coordinates\n\tvec3 transformedCenterPointOnPlane = vec3(viewMatrix * vec4(centerPointOnPlane, 1.0));\n\t\n\t//Plane normal in eye coordinates\n\tvec3 transformedNormalToPlane = vec3(viewMatrix * vec4(normalToPlane, 0.0));\n\t\n\t//Distance to line/plane intersection \n\tfloat distanceAlongLine = dot(transformedCenterPointOnPlane, transformedNormalToPlane) / (dot(lineDirection, transformedNormalToPlane));\n\t\n\t//Convert point on plane in eye coordinates to object coordinates\n\tvec4 pointInBasis = inverseViewMatrix * vec4(distanceAlongLine * lineDirection, 1.0);\n\n\tvec4 color = vec4(0,0,0,0);\n\t//If the point is inside the plane boundaries\n\tif(abs(pointInBasis.x) <= (planeWidth / 2.0) && abs(pointInBasis.y) <= (planeHeight / 2.0))\n\t{\n\t\tfloat value = 1.0 / 16.0;\n\t\tcolor = vec4(value, value, value, 0);\t\n\t}\n\t\n\treturn color;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    verticalFov = 45.0 * PI / 180.0;\n    normalToPlane = normalize(cross(planeX, planeY));\n    rotationPerFrame = iTime * 2.0 * PI / 60.0;\n    \n\t//Get a rotation matrix based on the mouse position\n\tmat3 mouseRotationMatrix = getMouseRotationMatrix();\n\t\n\t//rotate the camera by that matrix\n\tcameraPosition = mouseRotationMatrix * cameraPosition;\n\t\n\t//Convert uv to normalized device coordinates\n\tvec2 uv = 2.0 * (fragCoord.xy / iResolution.xy) - 1.0;\n\t\n\t//Convert to world coordinates of viewing frustum's near plane with height 1\n\tuv.x *= iResolution.x / iResolution.y;\n\n\t//View matrix according to camera\n\tmat4 viewMatrix = getViewMatrix(cameraPosition, cameraTarget, cameraUp);\n\t\n\t//Inverse of view matrix\n\tmat4 inverseViewMatrix = getInverseViewMatrix(cameraPosition, cameraTarget, cameraUp);\n\t\n\tvec4 color = vec4(0,0,0,1);\n\t\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 0, 1);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 1, 3);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 2, 0);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 3, 2);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 0, 5);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 1, 7);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 2, 4);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 3, 6);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 4, 1);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 5, 3);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 6, 0);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 7, 2);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 4, 5);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 5, 7);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 6, 4);\n\tcolor += getSampleAt(uv, viewMatrix, inverseViewMatrix, 7, 6);\n\n\tfragColor = color;\n}","name":"Image","description":"","type":"image"}],"flags":{"mFlagVR":false,"mFlagWebcam":false,"mFlagSoundInput":false,"mFlagSoundOutput":false,"mFlagKeyboard":false,"mFlagMultipass":false,"mFlagMusicStream":false},"info":{"id":"4dj3zG","date":"1390124027","viewed":488,"name":"B.2 Rotated Grid MSAA","username":"overgroove","description":"A simple 16 sample grid-based multisample antialiasing technique. Splitting each pixel into a regular grid of 64 subpixels and choosing 16 samples in a rotated grid pattern. Compare to A.1 Raycast Plane, and B.1 Grid MSAA Plane","likes":0,"published":1,"flags":0,"usePreview":0,"tags":["grid","tutorial","antialiasing","msaa","multisample"],"hasliked":0,"parentid":"","parentname":""}}
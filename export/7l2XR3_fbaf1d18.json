{"ver":"0.1","info":{"id":"7l2XR3","date":"1628265085","viewed":229,"name":"Nonlinear Raymarching","username":"elitewalrus","description":"Non-linear sphere tracing for rendering deformed signed distance fields (https://cs.dartmouth.edu/~wjarosz/publications/seyb19nonlinear.pdf) details how we can apply arbitrary deformations to geometry represented by signed distance fields. ","likes":19,"published":1,"flags":0,"usePreview":0,"tags":["raymarch","nonlinear"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n* This is based on the amazing paper Non-linear sphere tracing for rendering deformed signed distance fields \n* https://cs.dartmouth.edu/~wjarosz/publications/seyb19nonlinear.pdf\n*\n* The point of this is just to provide a concrete implementation of the method described in the paper. I couldn't find\n* an implementation anywhere on the internet and the math is a bit involved. I obviously got it working in the end so\n* hopefully this helps anyone else who is trying to understand it.\n*\n* If you're here I'm going to assume you have a good understanding of raymarching already so I'll gloss over all that stuff.\n* This is forked from a personal template so there is a lot going on but everything related to non linear sphere tracing \n* is in the image tab.\n*\n* If some smarter people than me can come up with an efficient way to compute the initial inverse efficiently in a fragment shader,\n* this could open the doors for standard animation tools to be applied to all the cool sdf animations that get made here.\n*/\n\n//raymarching parameters\n#define MAX_STEPS 400\n#define THRESHOLD 0.001f\n#define MAX_DISTANCE 100.0f\n#define NORMAL_DIFFERENTIAL 0.001f\n\n\n//you can use this to force the raymarcher to take smaller steps than the radius of the unbounding sphere. \n//we can shrink this to account for an inaccurate ode solver. Runge Kutta is accurate enough that this can stay at 1.0\n#define UNDERESTIMATION_FACTOR 1.0f\n\n\n//adjust this to change how twisty the space transformation is\n//edit: this now gets set programatically in the mainImage function\nfloat DEFORMATION_ANGLE = 0.8f;\n\n\n/*\n* As the paper explains, you can implement any ODE solver you like. I've included two for demonstration.\n* \n* Euler: This is basically what your standard raymarcher is doing. Easy to understand but not accurate enough for \n* non linear raymarching\n*\n* Runge Kutta: More complicated but it's accurate to a fourth degree taylor series approximation. Works great here.\n*/\n#define EULER_ODE_SOLVER 0\n#define RUNGE_KUTTA_ODE_SOLVER 1\n#define ODE_SOLVER_TO_USE RUNGE_KUTTA_ODE_SOLVER\n\n\n//just some scene parameters, not important to the non linear sphere tracing method\n#define MATERIAL_COUNT 1\nMaterial materials[MATERIAL_COUNT];\n#define LIGHT_COUNT 2\nLight lights[LIGHT_COUNT];\n\n\n//initializes the object color and the lights\nvoid initScene() {\n    //the material for the box we will render\n    materials[0] = Material(vec3(0.909, 0.549, 0.172), 1.0, 0.6, 4.0);\n\n    {//the sky \n        vec3 position = vec3(0.0), direction = vec3(0.0, -1.0, 0.0);\n        vec3 diffuseColor = gammaCorrectInverse(vec3(0.588, 0.878, 0.909)), ambientColor = vec3(0.0), specularColor = vec3(0.0);\n        float intensity = 0.1, attenuationLinear = 1.0, attenuationQuadratic = 1.0;\n        lights[0] = Light(position, direction, diffuseColor, ambientColor, specularColor, intensity, attenuationLinear, attenuationQuadratic);\n    }\n    {//the sun\n        vec3 position = vec3(0.0, 0.0, 0.0), direction = vec3(0.8, -0.4, 0.2);\n        vec3 diffuseColor = gammaCorrectInverse(vec3(1.0)), ambientColor = 0.2*diffuseColor, specularColor = diffuseColor;\n        float intensity = 1.0, attenuationLinear = 1.0, attenuationQuadratic = 1.0;\n        lights[1] = Light(position, direction, diffuseColor, ambientColor, specularColor, intensity, attenuationLinear, attenuationQuadratic);\n    }\n}\n\n/*\n* The scene contains just a box. This is essentially just the signed distance field for the scene but\n* a material (no material for empty space of course) is assigned to each point in space as well.\n*\n* I don't even use the material property in this program but I am too lazy to change things\n*\n* You can see the structs in the common tab.\n*/\nSceneHit getScene (vec3 pos) {\n    float boxDist = sdBox(pos, vec3(1.0, 1.0, 2.0));\n    \n    float minDist = boxDist;\n    int materialID = 0;\n    \n    return SceneHit(minDist, materialID);\n}\n\n/*\n* This defines the transformation that we wish we could apply directly to the geometry in the scene.\n* You can imagine that if the scene was composed of meshes, we would apply the transformation \n* to each vertex to yield the transformed scene geometry.\n*\n* Unfortunately, our scene is represented by a signed distance function which must transform in a\n* inverse sort of way to the transformation we define here.\n*/\nvec3 deformation(vec3 pos) {\n    float alpha = DEFORMATION_ANGLE;\n    float c = cos(alpha*pos.z);\n    float s = sin(alpha*pos.z);\n    mat3 mat =  mat3 (\n        c, -s, 0.0f,\n        s, c, 0.0f,\n        0.0f, 0.0f, 1.0f\n    ); \n    return mat*pos;\n}\n\n/*\n* This is the inverse of the transformation we would like to apply to the geometry. The whole point\n* of non linear sphere tracing is that we never have to evaluate this (this inverse deformation will\n* not even exist for a lot of the common deformations used in computer graphics). The problem is that\n* the inverse must be explicitly calculated at the start of the non linear raymarching algorithm. The\n* paper provides an clever method for approximating this accurately but it requires multiple stages\n* of the graphics pipeline that can not be efficiently emulated in a fragment shader.\n* \n* If you want to use non linear raymarching for a deformation without a known inverse, you need to provide \n* method like this to approximate it. \n\n* The most practical solution for shadertoy might be to provide a low \n* resolution flat mesh that sits between the camera and the geometry of the scene, transform the vertices with the \n* deformation and raytrace against that to approximate the inverted starting position.\n*/\nvec3 deformationInv(vec3 pos) {\n    float alpha = DEFORMATION_ANGLE;\n    float c = cos(alpha*pos.z);\n    float s = sin(alpha*pos.z);\n    mat3 mat =  mat3 (\n        c, -s, 0.0f,\n        s, c, 0.0f,\n        0.0f, 0.0f, 1.0f\n    ); \n    return inverse(mat)*pos;\n}\n\n/*\n* The genius of non linear raymarching is that although we can't expect the inverse transformation to exist, \n* we can expect the inverse of the jacobian to exist for any transformation of practical use in computer graphics.\n*\n* Just as the deformation is defined at each point, so too is the jacobian. You need to know how to derive the jacobian \n* from your deformation or be able to approximate it numerically. \n*\n* We can just use glsl's invert() to find the inverse but I decided to do it analytically.\n*\n* https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant\n*/\nmat3 jacobianInv(vec3 pos) {\n    float alpha = DEFORMATION_ANGLE;\n    float c = cos(alpha*pos.z);\n    float s = sin(alpha*pos.z);\n    return mat3 (\n        c, s, 0.0f,\n        -s, c, 0.0f,\n        -alpha*pos.y, alpha*pos.x, 1.0f\n    ); \n}\n\n/*\n* This uses the central differences method to numerically calculate the normals to the scene.\n*\n* I think the reason for the transpose of the inverse jacobian here is that if the tangent space (along which our ray travels) \n* transforms according to the inverse jacobian, then our cotangent/normal space (which is dual to our tangent space) should\n* transform contravariantly to our tangent space. To get the components of the contravariant transformation in cartesian coordinates, \n* we can just take the transpose.\n*\n* To be honest I don't really know if that is the right explanation but the formula is given in the paper and it clearly works.\n*/\nvec3 getNormal(vec3 pos) {\n    vec3 h = vec3 (NORMAL_DIFFERENTIAL, 0, 0);\n    \n    vec3 normal = vec3(\n        getScene(pos + h.xyy).dist - getScene(pos - h.xyy).dist,\n        getScene(pos + h.yxy).dist - getScene(pos - h.yxy).dist,\n        getScene(pos + h.yyx).dist - getScene(pos - h.yyx).dist\n    );\n    normal = normalize(normal);\n    \n    mat3 JInv = jacobianInv(pos);\n    normal = transpose(JInv)*normal;\n    return normalize(normal);\n}\n\n/*\n* omega is the inverse jacobian at x composed with a vector omega0 which is always the static ray direction that we would\n* use in a standard raymarcher. I've modified the notation in the paper because I can't type the tilde so that: omega^~ -> omega and \n* omega -> omega0.\n*\n* To be clear I'm just saying im using slightly different variable names than the paper.\n*/\nvec3 omega(vec3 x, vec3 omega0) {\n    mat3 JInv = jacobianInv(x);\n    vec3 result = JInv*omega0;\n    return normalize(result);\n}\n\n/*\n* An implementation of Euler's method with initial condition x0 and duration sd.\n*\n* You need to read the paper to make sense of this.\n*\n* https://en.wikipedia.org/wiki/Euler_method\n*/\nvec3 euler(vec3 x0, vec3 omega0, float sd) {\n    vec3 k = omega(x0, omega0);\n    return x0 + sd*k;\n}\n\n/*\n* An implementation of the Runge Kutta method with initial condition x0 and duration sd.\n*\n* You need to read the paper to make sense of this.\n*\n* https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods\n*/\nvec3 rungeKutta(vec3 x0, vec3 omega0, float sd) {\n    float h = sd;\n    \n    vec3 k1 = omega(x0, omega0);\n    vec3 k2 = omega(x0 + 0.5f*h*k1, omega0);\n    vec3 k3 = omega(x0 + 0.5f*h*k2, omega0);\n    vec3 k4 = omega(x0 + h*k3, omega0);\n    \n    return x0 + (h/6.0f)*(k1 + 2.0f*k2 + 2.0f*k3 + k4);\n}\n\n/*\n* Implement your favourite ode solver here.\n*/\nvec3 odeSolver(vec3 x0, vec3 omega0, float sd) {\n    #if(ODE_SOLVER_TO_USE == EULER_ODE_SOLVER)\n        return euler(x0, omega0, sd);\n    #else\n        return rungeKutta(x0, omega0, sd);\n    #endif\n}\n\n/*\n* This is the new raymarching method that allows us to march a non linear ray.\n*\n* There is some calculus going on here (the inverse function theorem is at the heart of the method) so\n* you need to read the paper to make sense of this.\n*/ \nvec3 nonlinearRaymarch(vec3 ro, vec3 rd) {\n    float arclengthTraveled = 0.0;\n    vec3 ray = ro;\n    \n    //if we hit nothing then an invalid ray is output\n    vec3 outRay = 2.0*rd*MAX_DISTANCE;\n    \n    for(int i = 0; i < MAX_STEPS; i++ ) {\n        SceneHit localScene = getScene(ray);\n        \n        float unboundingSphereRadius = localScene.dist*UNDERESTIMATION_FACTOR;\n        ray = odeSolver(ray, rd, unboundingSphereRadius);\n        \n        arclengthTraveled += unboundingSphereRadius;\n\n        if(unboundingSphereRadius < THRESHOLD) {\n            outRay = ray;\n            break;\n        }\n        if(arclengthTraveled > MAX_DISTANCE) {\n            break;\n        }\n    }\n\n    return outRay;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    //init lights and materials and stuff\n    initScene();\n    \n    //temporal space transformation to make things interesting\n    DEFORMATION_ANGLE = 2.0f*(sin(iTime + 1.0f));\n\n    //use a camera transform to generate the ray origin and ray direction like any old raymarcher\n    float cameraDist = 4.0;\n    float anglex = iMouse.xy==vec2(0) ? -0.2 : 10.0*iMouse.x/iResolution.x;\n    float angley = iMouse.xy==vec2(0) ? 5.75 : 10.0*iMouse.y/iResolution.y;\n    vec3 cameraPosition = vec3(cameraDist*sin(anglex), angley, cameraDist*cos(anglex));\n    \n    mat4 cameraToWorld = getViewMatrix(cameraPosition, vec3(0.0, 0.0, 1.0), vec3(0.0, 1.0, 0.0), iResolution);\n    vec3 cameraSpace = to_CameraSpace(fragCoord, 1.0472, iResolution);\n    cameraSpace = (cameraToWorld * vec4(cameraSpace, 1.0)).xyz;\n    \n    vec3 ro = (cameraToWorld * vec4(0.0, 0.0, 0.0, 1.0)).xyz;\n    vec3 rd = normalize(cameraSpace - ro);\n    \n    //this will be the color we output. Initially a sky gradient for the background\n    vec3 col = vec3(0.4, 0.75, 1.0) - 1.0*rd.y;\n    \n    //we begin our march at the ray origin deformed so it exists in inversely transformed space\n    ro = deformationInv(ro);\n    \n    //now we apply our nonlinear method rather than a typical raymarch method\n    vec3 hitPosition = nonlinearRaymarch(ro, rd);\n    \n    //this is all stuff you've seen before\n    if(length(hitPosition) < MAX_DISTANCE) {\n        vec3 hitNormal = getNormal(hitPosition);\n        Material material = materials[0];\n        material.color = gammaCorrectInverse(material.color);\n        \n        Light lightSky = lights[0];\n        Light lightSun = lights[1];\n    \n        vec3 diffuseSky = calcDirectionalLight(hitPosition, hitNormal, rd, material, lightSky);\n        vec3 diffuseSun = calcDirectionalLight(hitPosition, hitNormal, rd, material, lightSun);\n\n        col = material.color*(diffuseSky + diffuseSun);\n    }\n    \n    col = gammaCorrect(col);\n    fragColor = vec4(col, 1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"/*------------------------------------------\n-- structs ---------------------------------\n/*----------------------------------------*/\nstruct SceneHit {\n    float dist;\n    int materialID;\n};\n\nstruct Material {\n    vec3 color;\n    float diffusivity;\n    float specularity;\n    float specularPower;\n};\n\nstruct Light {\n    vec3 position;\n    vec3 direction;\n    \n    vec3 diffuseColor;\n    vec3 ambientColor;\n    vec3 specularColor;\n    \n    float intensity;\n    float attenuationLinear;\n    float attenuationQuadratic;\n};\n\n/*------------------------------------------\n-- coordinates transformations -------------\n/*----------------------------------------*/\nfloat getAspectRatio(vec3 iResolution) {\n    return iResolution.x/iResolution.y;\n}\n\nvec2 to_NDC(vec2 fragCoord, vec3 iResolution) {\n    vec2 NDC = fragCoord;\n    NDC /= iResolution.xy;\n    \n    return NDC;\n}\n\nvec2 NDC_to_fragCoord(vec2 NDC, vec3 iResolution) {\n    vec2 fragCoord = NDC;\n    fragCoord *= iResolution.xy;\n    \n    return fragCoord;\n}\n\nvec2 to_ScreenSpace(vec2 fragCoord, vec3 iResolution) {\n    vec2 screenSpace = to_NDC(fragCoord, iResolution);\n    screenSpace *= 2.0;\n    screenSpace -= vec2(1.0, 1.0);\n        \n    return screenSpace;\n}\n\nvec2 screenSpace_to_fragCoord(vec2 screenSpace, vec3 iResolution) {\n    vec2 fragCoord = screenSpace;\n    fragCoord += vec2(1.0, 1.0);\n    fragCoord /= 2.0;\n    fragCoord = NDC_to_fragCoord(fragCoord, iResolution);\n\n    return fragCoord;\n}\n\nvec3 to_CameraSpace(vec2 fragCoord, float fov, vec3 iResolution) {\n    vec2 cameraSpace = to_ScreenSpace(fragCoord, iResolution);\n    cameraSpace.x *= getAspectRatio(iResolution);\n    cameraSpace *= tan(0.5*fov);\n    \n    return vec3 (cameraSpace, -1.0);\n}\n\nvec2 cameraSpace_to_fragCoord(vec3 cameraSpace, float fov, vec3 iResolution) {\n    vec2 fragCoord = cameraSpace.xy;\n    fragCoord /= tan(0.5*fov);\n    fragCoord.x /= getAspectRatio(iResolution);\n    fragCoord = screenSpace_to_fragCoord(fragCoord, iResolution);\n    \n    return fragCoord;\n}\n\nmat4 getViewMatrix(vec3 eye, vec3 center, vec3 up, vec3 iResolution) {\n\tvec3 f = normalize(center - eye);\n\tvec3 s = normalize(cross(f, up));\n\tvec3 u = cross(s, f);\n    \n\tmat4 m = mat4(\n\t\tvec4(s, 0.0),\n\t\tvec4(u, 0.0),\n\t\tvec4(-f, 0.0),\n\t\tvec4(0.0, 0.0, 0.0, 1)\n\t);\n    m[3] = vec4(eye, 1.0);\n    \n    return m;\n}\n\nmat4 getProjectionMatrix(float fov) {\n    float s = 1.0/tan(0.5*fov);\n    float aspect = 1.0;\n    float near = 1.0;\n    float far = 10.0;\n    return mat4(\n       s, 0.0, 0.0, 0.0,\n       0.0, aspect*s, 0.0, 0.0,\n       0.0, 0.0, -(near + far)/(near - far), -(2.0f*near*far)/(near - far),\n       0.0, 0.0, -1.0, 0.0\n    );\n}\n\n\n/*------------------------------------------\n-- lighting --------------------------------\n/*----------------------------------------*/\nvec3 calcPointLight(vec3 hitPosition, vec3 hitNormal, vec3 rayDirection, Material material, Light light) {\n    vec3 lightDirection = normalize(light.position - hitPosition);\n    float lightDistance = length(light.position - hitPosition);\n    float attenuation = 1.0 / (1.0 + lightDistance*(light.attenuationLinear + light.attenuationQuadratic*lightDistance));\n    \n    float diffuse = clamp(dot(hitNormal, lightDirection), 1.0 - material.diffusivity, 1.0);\n    \n    vec3 refl = reflect(lightDirection, hitNormal);\n    float specular = material.specularity*pow(max(dot(rayDirection, refl), 0.0), material.specularPower);\n    \n    vec3 lightColor = light.intensity*(light.ambientColor + light.diffuseColor*diffuse + light.specularColor*specular);\n    \n    return lightColor;\n}\n\nvec3 calcDirectionalLight(vec3 hitPosition, vec3 hitNormal, vec3 rayDirection, Material material, Light light) {\n    float diffuse = clamp(dot(hitNormal, -light.direction), 1.0 - material.diffusivity, 1.0);\n    \n    vec3 refl = reflect(-light.direction, hitNormal);\n    float specular = material.specularity*pow(max(dot(rayDirection, refl), 0.0), material.specularPower);\n    \n    vec3 lightColor = light.intensity*(light.ambientColor + light.diffuseColor*diffuse + light.specularColor*specular);\n    \n    return lightColor;\n}\n\nvec3 calcAmbientLight(vec3 hitPosition, vec3 hitNormal, Material material, Light light) {\n    vec3 lightColor = light.intensity*light.ambientColor;\n    \n    return lightColor;\n}\n\n/*------------------------------------------\n-- color utilities -------------------------\n/*----------------------------------------*/\nvec3 gammaCorrect(vec3 color) {\n    color = pow(color, vec3(0.4545));\n    return color;\n}\n\nvec3 gammaCorrectInverse(vec3 color) {\n    color = pow(color, vec3(2.2)); \n    return color;\n}\n\n/*------------------------------------------\n-- quaternions -----------------------------\n/*----------------------------------------*/\nvec4 quaternionAdd(vec4 left, vec4 right) {\n    return left + right;\n}\n\nvec4 quaternionSubtract(vec4 left, vec4 right) {\n    return left - right;\n}\n\nvec4 quaternionMultiply(vec4 left, vec4 right) {\n    vec4 q;\n    q.x = (left.w * right.x) + (left.x * right.w) + (left.y * right.z) - (left.z * right.y);\n    q.y = (left.w * right.y) - (left.x * right.z) + (left.y * right.w) + (left.z * right.x);\n    q.z = (left.w * right.z) + (left.x * right.y) - (left.y * right.x) + (left.z * right.w);\n    q.w = (left.w * right.w) - (left.x * right.x) - (left.y * right.y) - (left.z * right.z);\n    return q;\n}\n\nvec4 quaternionConjugate(vec4 quaternion) {\n    return vec4(-quaternion.xyz, quaternion.w);\n}\n\nvec4 quaternionInverse(vec4 quaternion) {\n    float mag = length(quaternion);\n    return quaternionConjugate(quaternion)/mag;\n}\n\nvec4 quaternionUnitInverse(vec4 quaternion) {\n    return quaternionConjugate(quaternion);\n}\n\nvec4 quaternionFromRotation(vec3 axis, float angle) {\n    float halfAngle =0.5*angle;\n    float sinTerm = sin(halfAngle);\n    float cosTerm = cos(halfAngle);\n    return vec4(axis, 1.0)*vec4(sinTerm, sinTerm, sinTerm, cosTerm);\n}\n\nvec4 quaternionFromPosition(vec3 position) {\n    return vec4(position, 0.0);\n}\n\n/*------------------------------------------\n-- sdf transformations ---------------------\n/*----------------------------------------*/\nfloat sdUnion(float sdf1, float sdf2) {\n    return min(sdf1, sdf2);\n}\n\nfloat sdIntersection(float sdf1, float sdf2) {\n    return max(sdf1, sdf2);\n}\n\nvec3 sdTranslate(vec3 pos, vec3 translation) {\n    return pos - translation;\n}\n\nvec3 sdRotate(vec3 pos, vec3 unitAxis, float angle) {\n    vec4 qrot = quaternionFromRotation(unitAxis, angle);\n    vec4 qconj = quaternionConjugate(qrot);\n    vec4 qpos = quaternionFromPosition(pos);\n    \n    return quaternionMultiply(qconj, quaternionMultiply(qpos, qrot)).xyz;\n}\n\nvec3 sdScale(vec3 pos, float scale, out float scaleCorrection) {\n    scaleCorrection = scale;\n    return pos/scale;\n}\n\nvec3 sdScale(vec3 pos, vec3 scale, out float scaleCorrection) {\n    scaleCorrection = min(scale.x, min(scale.y, scale.z));\n    return pos/scale;\n}\n\nvec3 sdTransform(vec3 pos, vec3 translation, vec3 unitAxis, float angle) {\n    vec3 transform = sdTranslate(pos, translation);\n    transform = sdRotate(transform, unitAxis, angle);\n    return transform;\n}\n\nvec3 sdTransform(vec3 pos, vec3 translation, vec3 unitAxis, float angle, float scale, out float scaleCorrection) {\n    vec3 transform = sdTranslate(pos, translation);\n    transform = sdRotate(transform, unitAxis, angle);\n    transform = sdScale(transform, scale, scaleCorrection);\n    return transform;\n}\n\nvec3 sdTransform(vec3 pos, vec3 translation, vec3 unitAxis, float angle, vec3 scale, out float scaleCorrection) {\n    vec3 transform = sdTranslate(pos, translation);\n    transform = sdRotate(transform, unitAxis, angle);\n    transform = sdScale(transform, scale, scaleCorrection);\n    return transform;\n}\n\n/*------------------------------------------\n-- sdf functions ---------------------------\n/*----------------------------------------*/\nfloat sdSphere(vec3 pos, float R) {\n    return length(pos) - R;\n}\n\nfloat sdPlane(vec3 pos, vec3 norm, float height) {\n  return dot(pos,norm) + height;\n}\n\nfloat sdPlaneAbs(vec3 pos, vec3 norm, float height) {\n  return max (sdPlane(pos, norm, height), sdPlane(pos, -norm, -height));\n}\n\nfloat sdBox(vec3 pos, vec3 dimensions) {\n  vec3 q = abs(pos) - dimensions;\n  return length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n}\n\nfloat sdTorus(vec3 pos, float holeRadius, float crossSectionRadius) {\n  vec2 q = vec2(length(pos.xz)-holeRadius,pos.y);\n  return length(q)-crossSectionRadius;\n}\n\nfloat sdBoxFrame(vec3 pos, vec3 dimensions, float thickness ){\n    vec3 p = pos;\n    vec3 b = dimensions;\n    float e = thickness;\n  p = abs(p  )-b;\n  vec3 q = abs(p+e)-e;\n  return min(min(\n      length(max(vec3(p.x,q.y,q.z),0.0))+min(max(p.x,max(q.y,q.z)),0.0),\n      length(max(vec3(q.x,p.y,q.z),0.0))+min(max(q.x,max(p.y,q.z)),0.0)),\n      length(max(vec3(q.x,q.y,p.z),0.0))+min(max(q.x,max(q.y,p.z)),0.0));\n}\n\nfloat sdCylinder(vec3 p, vec3 a, vec3 b, float r) {\n  vec3  ba = b - a;\n  vec3  pa = p - a;\n  float baba = dot(ba,ba);\n  float paba = dot(pa,ba);\n  float x = length(pa*baba-ba*paba) - r*baba;\n  float y = abs(paba-baba*0.5)-baba*0.5;\n  float x2 = x*x;\n  float y2 = y*y*baba;\n  float d = (max(x,y)<0.0)?-min(x2,y2):(((x>0.0)?x2:0.0)+((y>0.0)?y2:0.0));\n  return sign(d)*sqrt(abs(d))/baba;\n}\n\nfloat sdCone( vec3 p, vec2 c, float h ) {\n  float q = length(p.xz);\n  return max(dot(c.xy,vec2(q,p.y)),-h-p.y);\n}\n\nfloat sdHexPrism( vec3 p, vec2 h ) {\n  const vec3 k = vec3(-0.8660254, 0.5, 0.57735);\n  p = abs(p);\n  p.xy -= 2.0*min(dot(k.xy, p.xy), 0.0)*k.xy;\n  vec2 d = vec2(\n       length(p.xy-vec2(clamp(p.x,-k.z*h.x,k.z*h.x), h.x))*sign(p.y-h.x),\n       p.z-h.y );\n  return min(max(d.x,d.y),0.0) + length(max(d,0.0));\n}","name":"Common","description":"","type":"common"}]}
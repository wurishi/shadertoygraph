{"ver":"0.1","info":{"id":"tstcD2","date":"1601814168","viewed":147,"name":"Gaussian error diffusion dither","username":"copperbotte","description":"Performs a simple raytrace, then performs three quantizations to perform a single error diffusion step.\nMultiple steps likely requires multiple buffers, or a compute shader.\nBased on a previous raytracer.","likes":0,"published":1,"flags":32,"usePreview":0,"tags":["raytracing","dither"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"//changelog\n//2020-10-05: Removed two-buffer dependency, added multi-sample quantization, and path quantization. This technique feels like more raytracing.\n//2020-10-04: Initial release\n\n\n// random number generator **\n// taken from iq :)\nfloat seed;    //seed initialized in main\nfloat rnd() { return fract(sin(seed++)*43758.5453123); }\n\n//color space transforms\nfloat lsrgb2srgb(float lsrgb)\n{\n    if(lsrgb < 0.0031308)\n        return lsrgb * 12.92;\n    float a = 1.055;\n    return a * pow(lsrgb, 1.0/2.4) - (a - 1.0);\n}\n\nvec3 lsrgb2srgb(vec3 lsrgb)\n{\n    return vec3(lsrgb2srgb(lsrgb.x),lsrgb2srgb(lsrgb.y),lsrgb2srgb(lsrgb.z));\n}\n\nvec2 randGauss(float sigma)\n{\n    float xi1 = rnd();\n    float xi2 = rnd();\n    \n    float rad = sigma * sqrt(-log(xi1));\n    float theta = xi2 * 2.0 * 3.141592;\n    \n\treturn rad * vec2(cos(theta), sin(theta));\n}\n\n\nvec3 quantize(vec3 col, int bits)\n{\n    float bitrange = float(1<<bits) - 1.0;\n    \n    vec3 col_out = clamp(col,0.0,1.0)*bitrange;\n    int r = int(round(col_out.x));\n    int g = int(round(col_out.g));\n    int b = int(round(col_out.b));\n    \n    return vec3(float(r), float(g), float(b)) / bitrange;\n}\n\n//quantization error\nvec3 quanterr(vec2 uv, out vec3 col, vec3 i_err)\n{\n    //load pixel at coordanite\n    col = texture(iChannel0, uv).xyz;\n    \n    //convert color space from lsrgb to srgb\n    col = lsrgb2srgb(col);\n    \n    //add incoming error\n    col += i_err;\n    \n    //quantize to pixel target (naiive, linear color approach)\n    vec3 col_out = quantize(col, 4);\n    \n    //find quantization error\n    vec3 err = col - col_out;\n    \n    return err;\n}\n\nvec3 quanterr(vec2 uv, out vec3 col)\n{\n    return quanterr(uv, col, vec3(0,0,0));\n}\n\nvec3 quanterr(vec2 uv)\n{\n    vec3 col = vec3(0,0,0);\n    return quanterr(uv, col, vec3(0,0,0));\n}\n\n//quantization texture jump\nvec3 quantex(vec2 uv, float sigma)\n{\n    const int n = 1; // this should never be more than one for \"path traced\" diffusion\n    vec3 err = vec3(0,0,0);\n    for(int i=0; i<n; i++)\n    {\n    \tvec2 euv = uv + randGauss(sigma) * vec2(1.0, iResolution.x / iResolution.y);\n    \terr += quanterr(euv) / float(n);\n    }\n        \n    return err;\n}\n\nvec3 quantex_path(vec2 uv, float sigma)\n{\n\t//generate a sequence of uvs\n    //metropolis?\n    const int n = 10;\n    vec2 uvs[n];\n    uvs[0] = uv;\n    for(int i=1; i<n; i++)\n        uvs[i] = uvs[i-1] + randGauss(sigma) * vec2(1.0, iResolution.x / iResolution.y);\n    \n    vec3 col;\n    vec3 err = vec3(0,0,0);\n    \n    for(int i=n-1; 0<=i; i--)\n        err = quanterr(uvs[i], col, err);\n    \n    return col - err;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    seed = fract(iTime) + iResolution.y * uv.x + uv.y;\n    //seed = iResolution.y * fragCoord.x / iResolution.x + fragCoord.y / iResolution.y;\n    \n    vec3 col = vec3(0,0,0);\n    vec3 err = quanterr(uv, col);\n    \n    //un-yeet quantization error somewhere random nearby\n    //vec3 err2 = quantex(uv, 0.05);\n    \n    //vec3 col_out2 = quantize(col + err2, 4);\n    \n    vec3 col_out2 = quantex_path(uv, 0.05);\n    \n\t//output image\n    if(uv.x < 0.5)\n    \tfragColor = vec4(col_out2,1.0);\n    else\n        fragColor = vec4(col, 1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// random number generator **\n// taken from iq :)\nfloat seed;    //seed initialized in main\nfloat rnd() { return fract(sin(seed++)*43758.5453123); }\n\nstruct Material\n{\n    vec3 emission;\n    vec3 albedo;\n    vec3 reflectivity;\n    float power; // vec3 requires 1 sample per color\n} Materials[2];\n\nstruct Sphere\n{\n    vec3 position;\n    float radius;\n} Spheres[2];\n\nstruct Ray\n{\n\tvec3 src;\n    vec3 dir;\n};\n    \nstruct tvHit\n{\n\tRay ray;\n    vec3 normal;\n    int id;\n};\n\n//taken from earlier raytracer project\n//https://www.shadertoy.com/view/3tffRN\nvoid tvSphere(Ray rIn, out tvHit hit, inout float rayDist, int id, float sRad, vec3 sPos)\n{\n    vec3 sOffset = sPos - rIn.src;\n\n    //ray points toward sphere\n    if(0.0 < dot(sOffset, rIn.dir))\n    {\n        float sRayClosest = dot(sOffset, rIn.dir);\n        float sRayClosestDist2 = dot(sOffset, sOffset) - sRayClosest*sRayClosest;\n        float sInnerOffset2 = sRad * sRad - sRayClosestDist2;\n        if(0.0 < sInnerOffset2)\n        {\n            //hit sphere, calculate intersection\n            float rDist = sRayClosest - sqrt(sInnerOffset2);\n            if(rDist < rayDist)\n            {\n                rayDist = rDist;\n                hit.ray.src = rIn.src + rIn.dir * rDist;\n                hit.normal = normalize(hit.ray.src - sPos);\n                //hit.normal /= sqrt(dot(hit.normal, hit.normal));\n                hit.id = id;\n            }\n        }\n    }\n}\n\ntvHit traverse(Ray rIn, int inid) // normal is required to prevent the ray from going backwards from its surface\n{\n    tvHit hit;\n    hit.ray = rIn;\n    hit.normal = vec3(0,0,0);\n    hit.id = 0; // id of the sky\n    float rayDist = 1.0e30;\n    \n    //raytrace subject sphere\n    if(inid != 1)\n        tvSphere(rIn, hit, rayDist, 1, Spheres[0].radius, Spheres[0].position);\n    \t\n    //raytrace light sphere\n    if(inid != 2)\n    \ttvSphere(rIn, hit, rayDist, 2, Spheres[1].radius, Spheres[1].position);\n    \n    return hit;\n}\n\n//to World\nvec3 toWorld(vec3 dir, vec3 normOut)\n{\n    //todo: do this properly using quaternions\n    vec3 normDir = vec3(0,0,1);\n    if(1.0 - 1e-5 < dot(normDir, normOut))\n        return dir;\n    \n    //make a pair of bases that are orthogonal to the output normal\n    vec3 a = cross(normDir, normOut);\n    a = normalize(a);\n    \n    vec3 b = cross(a, normOut);\n    b = normalize(b);\n    \n    mat3 M = mat3(a, b, normOut);\n    \n    return normalize(M * dir);\n}\n\n//random point in sphere\nvec3 randSphere()\n{\n    float xi1 = rnd();\n    float xi2 = rnd();\n\n    float psi = xi1 * 2.0 - 1.0;\n    float theta = xi2 * 2.0 * 3.141592;\n    float sinp = sqrt(1.0 - psi*psi);\n\n    float x = sinp * cos(theta);\n    float y = sinp * sin(theta);\n    float z = psi;\n\n    return vec3(x, y, z);\n}\n\nvec3 randLambert(vec3 normal)\n{\n    float xi1 = rnd();\n    float xi2 = rnd();\n\n    float theta = xi2 * 2.0 * 3.141592;\n    float cosp = sqrt(xi1);\n    float sinp = sqrt(1.0 - cosp*cosp);\n\n    float x = sinp * cos(theta);\n    float y = sinp * sin(theta);\n    float z = cosp;\n\n    return toWorld(vec3(x, y, z), normal);\n}\n\nfloat brdfLambert(tvHit Hit, Ray rOut)\n{\n    float diffuse = dot(Hit.normal, rOut.dir) / 3.141592;\n    diffuse = clamp(diffuse, 0.0, 1.0);\n    return diffuse;\n}\n\nvec3 sampleLambert(tvHit Hit, out float pdf)\n{    \n    Ray ray;\n    ray.dir = randLambert(Hit.normal);\n    \n    pdf = brdfLambert(Hit, ray);\n    \n    return ray.dir;\n}\n\nvec3 sampleLightSingular(tvHit Hit, out float pdf, vec3 sPos, float sRad)\n{\n    pdf = 1.0;\n    \n    //selects a random point on the light to raytrace towards\n    vec3 rPos = randSphere();\n    pdf /= 2.0 * 3.141592;\n    \n    vec3 rNorm = rPos;\n    \n    rPos *= sRad;\n    pdf /= sRad*sRad;\n    \n    rPos += sPos;\n    rPos -= Hit.ray.src;\n    \n    //pdf is the probability area projected toward from point\n    float r2 = dot(rPos, rPos);\n    vec3 rOut = rPos / sqrt(r2);\n    \n    pdf /= abs(dot(rNorm, rOut)) / r2;\n    \n    return rOut;\n}\n\nvec3 raytrace2(Ray rIn, int inid)\n{\n    tvHit Hit = traverse(rIn, inid);\n    \n    if(Hit.id == 0)\n        return vec3(0,0,0);\n    \n    vec3 Out = Materials[Hit.id-1].emission;\n    \n    return Out;\n}\n\nvec3 raytrace(Ray rIn)\n{\n    tvHit Hit = traverse(rIn, 0);\n    \n    if(Hit.id == 0)\n        return vec3(0.1,0.1,0.1);\n    \n    vec3 Out = Materials[Hit.id-1].emission;\n    \n    Ray rOut = Hit.ray;\n    float pdf = 1.0;\n    float brdf = 0.0;\n    \n    //rOut.dir = sampleLambert(Hit, pdf);\n    rOut.dir = sampleLightSingular(Hit, pdf, Spheres[1].position, Spheres[1].radius);\n    \n    //non raytraced point light\n    pdf = 1.0 / (3.141592 * Spheres[1].radius*Spheres[1].radius);\n    vec3 diff = Spheres[1].position - Hit.ray.src;\n    pdf *= dot(diff, diff);\n    rOut.dir = normalize(diff);\n    \n    brdf = brdfLambert(Hit, rOut);\n    \n    pdf += 1e-10; // corrects for a division by zero error in Lambert and Phong.\n    \n    if(pdf < 2e-10)\n    {\n        brdf = 0.0;\n        pdf = 1.0;\n    }\n    //it looks like an epsilon on the pdf works. 0/0 errors aren't fun.\n    \n    brdf /= pdf;\n    \n    return Out + brdf * raytrace2(rOut, Hit.id);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    //seed = fract(iTime) + iResolution.y * uv.x + uv.y;\n    seed = iResolution.y * fragCoord.x / iResolution.x + fragCoord.y / iResolution.y;\n\t\n    vec2 xy = fragCoord.xy / iResolution.xy * 2.0 - 1.0;\n    xy.y *= iResolution.y / iResolution.x;\n    \n    //setup spheres\n    Spheres[0].radius = 1.0;\n    Spheres[0].position = vec3(0.0,3.0,0.0);\n    Spheres[1].radius = 0.025;\n    Spheres[1].position = vec3(1.0,2.0,0.0);\n    \n    float sTime = iTime + 4.41;\n    Spheres[1].position = vec3(2.0*cos(sTime), 3.0 + 2.0*sin(sTime), 0.0);\n    \n    //setup materials\n    Materials[0].emission     = vec3(1,1,1) * 0.0;\n    Materials[0].albedo       = vec3(1,1,1);\n    Materials[0].reflectivity = vec3(1,1,1) * 0.25 * 0.0;\n    Materials[0].power        =               1000.0; // 1000.0;\n    \n    Materials[1] = Materials[0];\n    Materials[1].emission     = vec3(1,1,1) / (Spheres[1].radius*Spheres[1].radius);\n    \n    // Time varying pixel color\n    vec3 col = 0.5 + 0.5*cos(iTime+uv.xyx+vec3(0,2,4));\n    \n    Ray ray;\n    col = vec3(0,0,0);\n    const int samples = 1;\n    for(int smp=0; smp<samples; ++smp)\n    {\n        seed += 1.0;\n        vec2 dxy = vec2(rnd(), rnd()) * 2.0 - 1.0;\n        \n        dxy /= iResolution.xy;\n        dxy *= 0.0;\n        dxy += xy;\n        \n        ray.src = vec3(0,0,0);\n        ray.dir = vec3(dxy.x,1,dxy.y);\n        ray.dir = normalize(ray.dir);\n        //ray.dir /= sqrt(dot(ray.dir, ray.dir));\n\n        vec3 clr = raytrace(ray);\n        col += clr / float(samples);\n    }\n    \n    // Output to screen\n    fragColor = vec4(col,1.0);\n}","name":"Buffer A","description":"","type":"buffer"}]}
{"ver":"0.1","info":{"id":"MlSBW3","date":"1517706159","viewed":251,"name":"color interpolation tests","username":"fluffycritter","description":"An experiment in interpolating between colors in RGB vs normalized YIQ (which should be equivalent to interpolating in HSV).\n","likes":4,"published":1,"flags":0,"usePreview":0,"tags":["interpolation"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n\nThis shader attempts to show what an interpolation through HSV space would look like,\nas opposed to the more typical RGB interpolation. It does this by converting the colors\nfrom RGB to YIQ, which is a \"dual\" to HSV that is still based on affine transforms from\nRGB; it is most commonly used as NTSC's color burst colorspace. You can read more about\nit at https://en.wikipedia.org/wiki/YIQ\n\nIn YIQ space, Y is equivalent to V, the length of IQ is equivalent to S,\nand the angle of IQ is equivalent to H. Thus, to interpolate in HSV, we simply interpolate\nin YIQ and then adjust the saturation to match what the expected saturation would be.\n\nNote that this is interpolating in HSV through the rainbow cylinder of HSV space, rather than\ninterpolating in an angular manner, which is somewhat poorly-defined, although in a future\nexperiment I might try it anyway.\n\nFor some reason there are sometimes visible gradients along the left and right edge of the\nimage, which should never be the case; if anyone can figure out my probably-obvious math\nerror that's causing that it would be greatly appreciated.\n\nAlso, this doesn't attempt to normalize the arc length along H; really this should be\nprojecting the interpolated YIQ color onto the unit circle within the IQ plane.\n\n*/\n    \n// Convert an RGB color to YIQ\nvec3 rgb2yiq(in vec3 rgb) {\n    return vec3(.299*rgb.r + .587*rgb.g + .114*rgb.b,\n                .596*rgb.r - .274*rgb.g - .321*rgb.b,\n                .211*rgb.r - .523*rgb.g + .311*rgb.b);\n}\n\n// Convert a YIQ color to RGB\nvec3 yiq2rgb(in vec3 yiq) {\n    return vec3(yiq.x + .956*yiq.y + .621*yiq.z,\n                yiq.x - .272*yiq.y - .647*yiq.z,\n                yiq.x - 1.107*yiq.y + 1.705*yiq.z);\n}\n\n// Convert a gamma-space color to linear\nvec3 gamma2linear(in vec3 gamma) {\n    return pow(gamma, vec3(2.2,2.2,2.2));\n}\n\n// Convert a linear color to gamma-space\nvec3 linear2gamma(in vec3 linear) {\n    return pow(linear, vec3(.454,.454,.454));\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord.xy / iResolution.xy;\n\n    // left and right colors\n    vec3 left = gamma2linear(0.5 + 0.5*cos(iTime*vec3(0.17,0.23,0.61)));\n    vec3 right = gamma2linear(0.5 + 0.5*cos(iTime*vec3(0.49,0.27,0.15)));\n    \n    // naively blended in YIQ\n    vec3 yiqBlended = mix(rgb2yiq(left), rgb2yiq(right), uv.x);\n\n    // the naively-interpolated saturation\n    float bmag = length(yiqBlended.yz);\n    // the expected saturation\n    float tmag = mix(length(left.yz), length(right.yz), uv.x);\n\n    // the interpolated color with the saturation set to the expected saturation\n    vec3 hsvBlended = (vec3(yiqBlended.x, yiqBlended.yz*tmag/bmag));\n\n    // for comparison, straight RGB interpolation\n\tvec3 rgbInterpolated = mix(left, right, uv.x);\n    \n    fragColor = vec4(linear2gamma(mix(rgbInterpolated, yiq2rgb(hsvBlended), uv.y)), 1.0);\n}\n\n","name":"Image","description":"","type":"image"}]}
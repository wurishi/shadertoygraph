{"ver":"0.1","info":{"id":"tlVSzG","date":"1583078729","viewed":122,"name":"Fog Beam Tracer","username":"spalmer","description":"fork of [url]https://shadertoy.com/view/WlySzy[/url] by [url]https://shadertoy.com/user/aethelwhat[/url]\nmouse+WASD/space/C to fly, z=debug extinction \"depths\"","likes":0,"published":1,"flags":48,"usePreview":0,"tags":["volume","lighting","fog","scattering","subsurface","atmospherics"],"hasliked":0,"parentid":"","parentname":""},"renderpass":[{"inputs":[{"id":"4sf3Rn","filepath":"/media/a/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","previewfilepath":"/media/ap/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"// I saw the vol cubes shader by aethelwhat and thought it was close enough to\n// what I had been doing with atmospheric/subsurface that I could\n// bridge into it easily enough.  I'm thinking about making this\n// into a full-blown ray tracer toy with feedback from frame to frame.\n// I'm crazy ambitious.  Maybe some day.  Adapting from various\n// platforms and rendering strategies takes lots of effort.\n// Anyway mostly retread of stuff that's been done before.\n// Trying to extend this out to fairly expansive scene has\n// sure exposed many of the limitations of this full-resolution \n// fragment shader marching approach.  I hope I can get\n// enough of it refactored that I can eventually turn it into\n// something like that anyway, even if I must eventually branch\n// of to another toy to do so to prevent continually breaking this one.\n// This one has gotten fairly cool on its own.\n\n// from 'Volumetric Cubes' https://shadertoy.com/view/WlySzy\n\n/*\n  raymarching volumes by integration of light sources \n  wrt transmission through the scene, over total distance marched.\n \n  features multiple light sources, volumetric shadows.\n  there are no hard surfaces in this scene!\n  \n  What is so interesting about the Volumetric Rendering Equation\n  is that it is essentially a generalization of the rendering equation.\n  a high density cube should be similar to a hard surface cube with a \n  good subsurface scatter approximation.\n  \n  further references in Common tab or BufferA tab\n  because that's where the code lives\n*/\n\n#define BufferA iChannel0\n#define Noise iChannel1\n#define Keyboard iChannel3\n\nbool key(int k)\n{\n    return texelFetch(Keyboard, ivec2(k,0), 0).x >= .5;\n}\n\nbool option(int k)\n{\n    return texelFetch(Keyboard, ivec2(k,2), 0).x >= .5;\n}\n\n// combined exposure, tone map, gamma correction\nvec3 toneMap(vec3 c)\n{\n    c = max(vec3(0), c); // pow won't like negatives\n    c *= 1.4; // fine exposure control\n  #if 1\n    // to sRGB gamma via filmic-like Reinhard-esque combination approximation\n    c = c / (c + .1667); // actually cancelled out the gamma correction!  Probably cheaper than even sRGB approx by itself.\n    c *= 1.17; // cheap exposure scaling to balance input 0..1 range\n \t// considering I can't tell the difference, using full ACES+sRGB together seems quite wasteful computationally.\n  #elif\n    1 // ACES+sRGB, which I approximated above - I can't tell the difference anymore in this scene\n    c = ((c*(2.51*c+.03))/(c*(2.43*c+.59)+.14)); // https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve\n    c *= 1.24; // cheap exposure correction\n    c = pow(c, vec3(.454545)); // to sRGB gamma\n  #else\n    // sRGB by itself just seems a little darker in midrange since yeah, it doesn't have the extra gamma from ACES which is really bright itself.\n    c = pow(c, vec3(1.0/2.2)); // to sRGB gamma the approximate way, not true high-quality conversion, but close enough for shaders.\n  #endif\n    // TODO if I cared enough, I could go ahead and handle variable exposure quite a lot better here\n    // but would need to compute the tonemap operator of the exposure level, which although would optimize out at compile time, \n    // still would mean I'd need to do the entire thing in vec4 and then divide by w.  I just scale here.\n    // and HACK hardcoded the exposure factor in 2 or 3 different places!  c'mon, dude!\n    return c;\n}\n\nvec3 dither(vec3 c, vec2 p)\n{\n    float x; // noise\n    x = fract(iTime*0. + 23456.7*sin(dot(p, vec2(12.93,8.57)))); // from ALU hash\n    x = 2.*x-1.; // signed\n    c += .75/256.*x;\n    return c;\n}\n//    x = .5; \n//    x = texelFetch(Noise, ivec2(mod(fragCoord, iChannelResolution[1].xy)), 0).x; // from texture\n//    c = vec3(x); // debug\n\nvoid mainImage(out vec4 o, vec2 p)\n{\n    vec4 A = texelFetch(BufferA, ivec2(p), 0);\n    float d = A.a; // depth\n    vec3 c = A.rgb;\n    if (option(90))\n    \tc = vec3(.5+.5*sin(d*1.)); // debug depths - rings\n    c = toneMap(c);\n\tc = dither(c, p);\n\to = vec4(c, 1);\n}\n\n//    c = vec3(pow(max(0.,d/50.), 3.4)); // debug depths\n\n","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[],"code":"// can trade-off samples between scene and shadow.\n// uses nStepTrace*nStepShadow shadow steps total though!  be careful.\nconst int nStepTrace = 48; //64; //96; //128; //256; //192; //\t// reduce for full-screen\nconst float nStepShadowSun = 4. //3. //5. //6. //8. //12. //2. //\n, nStepShadow = 8. //4. //3. //5. //6. //12. //2. // quality control. Bump to avoid shadow aliasing\n, shadowRangeSun = 2. //3. //2.6 //4. //6. //12. // shadow distance: tuned for self-shadows, mostly\n, shadowRange = 4. //3. //6. //12. //\n, shadowLimitSun = shadowRangeSun + 8.//6. // 12. //16. //24. //32. //64. // don't bother tracing any distant shadows\n, shadowLimit = shadowRange + 12. //8. //16. //24. //32. //64. // don't bother tracing any distant shadows\n, thruRange = 4. //6. //8. //12. //16. // // thickness of positive density region it tries to trace through\n, minD = thruRange / float(nStepTrace); //.1; // restrict max step for better scattering evaluation\n// just tanks in full-screen no matter what I do, though :(\n\n#define NUM_LIGHTS 1\n// beware comments after preprocessor!\n//0 //2 //3 //\n\n// main parallel light ('sun')\nconst vec3 sunDir = normalize(vec3(.3,.8,.5)) //-.1,.5,.8)) //\n, sunColor = vec3(1,1,1) * 1.6; //.5; //\nconst float constantFog = .1e1; // a white haze everywhere, or at least near the camera\n\n// scene-related parameters\nconst float hfpHeight = -.6\n, hfpDensity = 12. //4. //6. //8. //2. //\n, shapeDensity = 256. //64. //24. //32. //12. //1.5 //6. // when too dense it just shows the self-shadow artifacts\n, tiling = 3.;\n\n// to prevent unrolling, involve a uniform in loop index somehow\n#define IZERO min(0,iFrame)\n#define FZERO min(0.,iTime)\n\n// buffer mapping logic, could wrap to subsequent rows\nint slotid(ivec2 loc) { return loc.x; }\nivec2 slotloc(int id) { return ivec2(id, 0); }\n\nvec4 loadValue(sampler2D buf, int slot_id)\n{\n    return texelFetch(buf, slotloc(slot_id), 0);\n}\n\n// channel allocations can't be done in Common,\n// as the defines for the iChannel# samplers have not yet been set.\n// but we can allocate the slots within BufferC at least.\n\nconst int slotCameraPosition = 0;\nconst int slotCameraForward  = 1;\nconst int slotDesiredForward = 2;\nconst int slotMouseOld       = 3; // iMouse from prior frame\nconst int slotCount          = 4;\n\nconst float pi = acos(-1.); //3.141592;\n\n// TODO use it more\nvec2 cossin(float r)\n{\n    const float halfpi = .5*pi; //1.5707963;\n    return cos(vec2(r, r - halfpi));\n}\n\n// cheap rotation transform on p by s=(cos(a),sin(a))\nvoid rot(inout vec2 p, vec2 s) \n{\n\tp = p * s.x + vec2(p.y, -p.x) * s.y;\n} // then can rot(q.xz, vec2(cos(a),sin(a)))\n\n// build a 3x3 camera orientation matrix given forward direction vector, assuming up is +Y\nmat3 cameraMatrix(vec3 camFwd)\n{\n    vec3 w = normalize(camFwd)\n       , u = normalize(cross(vec3(0., 1., 0.), w))\n       , v = normalize(cross(w, u));\n    return mat3(u, v, w);\n}\n// then I just transform by pw = MC * pv;\n\nvec2 StoQ(vec2 s, vec2 r)\n{\n\treturn (s + s - r) / r.y;\n}\n\n// BufferC isn't available directly in Common!\nvec3 cameraPosition(sampler2D BufC) \n{\n    return loadValue(BufC, slotCameraPosition).xyz;\n}\n\nvec3 cameraDirection(sampler2D BufC) \n{\n    return loadValue(BufC, slotCameraForward).xyz;\n}\n\n\n\nfloat sdSph(vec3 p, float radius)\n{\n    return length(p) - radius;\n}\n\nfloat sdBox(vec3 p, vec3 halfextent)\n{\n    vec3 a = abs(p) - halfextent\n//    , n = min(a, 0.) // the negatives, or zeroes\n    ;\n//\treturn length(a - n) + max(n.x, max(n.y, n.z)); // good sdf, round corner voronoi regions; iq's box is slightly superior though\n    return max(a.x, max(a.y, a.z)); //float d = ; // removed the positive portion // imperfect sdf, still decent though\n}\n// it was this.  don't do this.  breaks everything!\n//    return min(d, 0.); // leftover from iq's sdBox most likely.\n// having all \"outside\" distances return zero really jacks up the marcher!  \n// killed total march range even far away from the boxes.\n\n\n\n// to CIE luminance Y, from linear RGB\nfloat Lumi(vec3 rgb_linear)\n{\n\tconst vec3 lum_rgb_709 = vec3(.2126, .7152, .0722); // ITU-R Rec. BT.709 computed from linear RGB\n\treturn dot(rgb_linear, lum_rgb_709);\n}\n\n// from https://shadertoy.com/view/3t3GDs\n// earliest use of this method I can find is by las in 2011:\n// http://pouet.net/topic.php?which=7920&page=29&x=14&y=9\nvec3 hue(float h)\n{\n\tvec3 h3 = fract(h + vec3(0, 2./3., 1./3.));\n\treturn clamp(abs(h3 * 6. - 3.) - 1., 0., 1.);\n}\n\n// 'mss' of different parts of air; hand tweaked, not measured, though.  base 2, not e.\nconst vec3 fogRayleigh = vec3(.8e-5, 1.9e-5, 4.7e-5) * 2.5; //vec3(5.8e-6, 13.5e-6, 33.1e-6) * 1.44; // / log(2.); // Rayleigh RGB coefficients, 1/m units, base e, also convert base e to base 2\nconst vec3 fogMie = vec3(1.1e-6, .6e-6, .3e-6) * 2.0; // Mie RGB coefficients - I just made these up, but they're basically orange\n\nfloat phaseIso()  // isotropic\n{\n    return 1. / (4.*pi);\n}\n\n// what paper did I get this from originally?  \n// \"Real Time Rendering of Atmospheric Scattering Effects for Flight Simulators\" by Ralf Stokholm Nielsen\n// can be found at http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/2554/pdf/imm2554.pdf\n// Nielsen says: (pi*(n*n - 1))^2/2/N/lambda^4 * (1 + (cos(theta))^2)\n// where n = IOR of air (about 1.003), N is molecular density of air\n// lambda the wavelength of light; I still must simplify to 3 known rgb wavelengths\n// and whole thing is to be artist-tuneable anyway, so... not caring about precise spectral quantities,\n// just overall shape.\n#if 1\nfloat phaseRayleigh(float costheta)\n{ // the original equation from Nielsen is 3/16/pi*Br*(1+costheta^2)\n    // so it appears I've messed with it some since then.  Why? I should have made a note.\n\tconst float rc = 3. / (16.*pi); // related to rcp_two_tau (* 3/4)\n    return (1. + costheta*costheta) * rc;\n\t//return (2. + .5*costheta*costheta) * rc; // a little brighter, otherwise similar\n}\n#endif\n// since it's supposed to be the same anyway, I'm just going to use phaseHG\n// may need to tune g depending on observer height and sun angle\n// g is asymmetry parameter, corresponds to amount of back- or front-scattering depending on sign\n// the Henyey-Greenstein phase function to approximate Mie scattering as an ellipse\n// with g set to 0 it should be almost identical to phaseRayleigh\n// Nielsen says hg is (1-g^2) / 4 / π / (1 + g^2 - 2*cos(θ))^(3/2)\n// I'm fairly sure that was a misprint?! which I corrected later... agh\n// pbrt and ocean optics both basically have the same correction but different sign than I use\nfloat phaseHG(float costheta, float g) // phaseHenyeyGreenstein\n{\n\tfloat p = 1. + g * (g + 2. * costheta);\n\tfloat pn32 = inversesqrt(p*p*p); //pow(p, -1.5); //\n\treturn .25/pi * (1. - g)*(1. - g) * pn32;\n} // now a bit dimmer than Rayleigh when g==0 though!\n\nfloat phaseFunction(float costheta)\n{\n    // ? is sign backward? or did I forget a factor?\n//    return phaseHG(costheta, .6); // backscatter, wrong way\n//    return phaseHG(costheta, -.6); // idk, doesn't work well with the point lights\n    return phaseHG(costheta, .0); // similar shape to phaseRayleigh\n//    return phaseRayleigh(costheta);\n    return phaseIso();\n}\n\n\n\nfloat pointLight(vec3 lpos, vec3 pos, out vec3 L)\n{\n    L = lpos - pos;\n    float ill = 1. / dot(L, L);  // d^-2 falloff\n    L = normalize(L); //L *= sqrt(ill); // normalize\n    return ill;\n}\n\n//float parallelLight(vec3 ldir, vec3 pos)\n//{\n//    return 1.;\n//}\n\n// TODO must handle all the \"in between\" areas where there's no other fog or object as \"air\"\n//    vec3 airFogVol = fogEarthRayleigh * 0. //exp2()\n//        + fogEarthMie * 0.; //phaseHG(lv, -.6);\n//        + airFogVol\n\n\n","name":"Common","description":"","type":"common"},{"inputs":[{"id":"XsX3zn","filepath":"/media/a/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","previewfilepath":"/media/ap/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png","type":"cubemap","channel":2,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4sfGRr","filepath":"/media/a/27012b4eadd0c3ce12498b867058e4f717ce79e10a99568cca461682d84a4b04.bin","previewfilepath":"/media/ap/27012b4eadd0c3ce12498b867058e4f717ce79e10a99568cca461682d84a4b04.bin","type":"volume","channel":3,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"// FIXME something goes wrong if iTime gets large enough,\n// causes black strangeness; resetting toy fixes it.\n#define USE_CUBE_MAP 0\n\n#define BufferA   iChannel0\n#define BufferC   iChannel1\n#if USE_CUBE_MAP\n#define CubeEnv   iChannel2\n//#define CubeEnvLQ iChannel3 // old\n#endif\n#define NoiseVol iChannel3\n\n\nvec3 enviroSimple(vec3 rd)\n{\n    // similar to aethelwhat's background\n    return .25 * mix(vec3(.5,.4,.3), vec3(.6,.7,.8), smoothstep(-1., .3, rd.y));\n}\n\nfloat skyDepthHack(float rdy, float focus)\n{\n    //focus = mix(focus, 1., .5);\n    focus = clamp(focus, 0., 1.);\n    rdy *= focus;\n    return 8.5e4 * 2. * (rdy < 0.\n    ? exp2(8. * rdy) //1. - .99 * sqrt(-rdy) //1. + .99 * rdy // * (1.+rdy)\n    : 1. - .55 * rdy // * (1.-rdy)\n    );\n}\n\n// TODO should probably not hack this quite so much\n// my goal is that this should use the same function the other fog lighting uses\nvec3 enviroSkyDome(vec3 rd, float focus)\n{\n    //return vec3(focus);\n    // FIXME focus ignored :( should use to blur the horizon\n    float od = skyDepthHack(rd.y, focus); // optical depth\n    // is 1. - correct? may be exp2(+x)...\n// in fact I really don't think it's right, and am about to go read some papers to refresh my memory wut should happen here\n    float lv = dot(sunDir, rd);\n    return (//0.\n        1. - exp2(-fogRayleigh * od * phaseHG(lv, 0.)) //phaseRayleigh(lv))\n       // exp2(fogRayleigh * od * phaseRayleigh(lv)) // - 1.\n        + 1. - exp2(-fogMie * od * phaseHG(lv, -.6))\n       // + exp2(fogEarthMie * od * phaseHG(lv, -.6)) // - 1.\n        ) * sunColor;\n//    return enviroSimple(rd);\n}\n\n// ro ray origin provided for future parallax use, currently ignored\n// rd is ray direction\n// focus argument is basically the cosine of the cone angle\n// somewhat akin to the \"gloss\" term for material surface reflection\n// which allows varying the blurriness of the query\n// TODO consider cosine squared also; we only need a hemisphere maybe?\n// Anyway the focus argument abstracts considerable complexity\n// involving the need to integrate incoming light over conic angles.\n// Nobody sampling the environment wishes to know the details of\n// how such integration is achieved.  So it allows to cleanly\n// separate the intent (blurred query) from the implementation\n// (some texture filtering or analytical approximation,\n// or even brute force supersampling or clever stochastic whatever)\n\n#if USE_CUBE_MAP\nvec3 texCube(vec3 rd, float lod, samplerCube envcube)\n{\n    return pow(textureLod(envcube, rd, lod).rgb, vec3(2.2)); // from srgb gamma to linear\n}\n\n// LQ focus should always be between 0 and 0.25 I guess\n//vec3 enviroCubeLQ(vec3 ro, vec3 rd, float focus)\n//{\n//    float sw = focus;\n    // HACK idk what I did to it, but it's borked and kludged now\n//    return .8 //(.05 + .75 * 4. * sw * (1.-sw))\n//        * texCube(rd, mix(3., 0., focus), CubeEnvLQ);\n//}\n    // how to phase function an environment map?  Just something for now until I can convolve it properly somehow\n    // some kludge attempting to mimic self-shadowing and inscattering of blurred envmap\n    // for an approximation to ambient lighting; it's not great, but it's a start.\n    //if (true || focus >= .25) // really HQ's mip chain is good enough, and better to keep it simple, really.\n    //else // the main problem with the LQ envmap is it's actually lower resolution than the HQ\n    //    color = enviroLQ(ro, rd, focus);\n\n// HQ focus should always be between 0.25 and 1\nvec3 enviroCubeHQ(vec3 ro, vec3 rd, float focus)\n{\n    return .8 * texCube(rd, mix(10., 0., focus), CubeEnv); // or an envmap; can be a bit intense\n}\n#endif\n\n// mostly I want to abstract the sky out so needn't deal with it in the \n// lighting and tracer functions\n\n// refactored both envmap samples into some sky/enviro function wrapper\nvec3 enviro(vec3 ro, vec3 rd, float focus)\n{\n #if USE_CUBE_MAP\n    return enviroCubeHQ(ro, rd, focus);\n #else\n    return enviroSkyDome(rd, focus);\n #endif\n}\n// need access to a \"sky\" function everywhere\n// but difficult to do anything involving maps from Common tab\n// it got so convoluted I moved it back here to BufferA.\n\n// if sample enviro \"away from higher density\" along gradient, \n// it would effectively cause some internal self-shadowing;\n// combined with focus could be fairly effective hack.\n// could use for approx to incoming ambient lighting from enviro\n// in presence of some self-occluding media of given thickness.\n\n\nfloat FogNoiseSinus(vec3 q)\n{\n\tq *= 3.; // pi? close enough\n    mat3x3 M = 2.03 * mat3x3(.866, 0, .5,  0, 1, 0,  -.5, 0, .866); // think I got the idea from iq originally long ago\n    //float M = 2.13; // cheaper but the sinewaves are still expensive,\n    // and without rotation it's not very high quality.    \n    float n = .5 + .5 * sqrt(.5) * (\n          .55*dot(vec3(1), sin(q)) // FIXME dot(1,x) = sum3(x) but not optimal\n        + .33*dot(vec3(1), sin(M * q)) // Maybe with just 2 octaves?\n        //+ .11*dot(vec3(1), sin(M * M * q)) // or try 3?\n        ); // \"fbm\" of sinewaves\n    return n;\n}\n\nfloat FogNoiseVolTex(vec3 q) // using slow sampler3D\n{\n    return texture(NoiseVol, q / 16.).x;\n}\n\n// TODO 3d or even 4d fbm simplex noise \"texture\"\n\n// TODO if we took focus as argument, could blur the query appropriately or use lower lod to save work\nfloat FogNoise(vec3 q) // given world space query point\n{ // can try different methods\n    float time = iTime, n;\n    //time = mod(time, 1024.);\n    q += time * .2 * vec3(1,0,1); // wind scroll\n    n = FogNoiseSinus(q);\n    //n = FogNoiseVolTex(q);\n    //n = FogNoisePerlin(q); // TODO try other noises\n    //n = FogNoiseSimplex(q);\n    return n; //clamp(n, 0., 1.); //\n}\n\n    // noise is cool but this volume texture is really expensive\n    // and alu perlin may be cheaper.  With wind scroll helps.\n    // But it definitely makes it look like \"fog\" and not, say,\n    // some other more material of a more consistent density.\n\n/*\n  https://shadertoy.com/view/WlySzy 'Volumetric Cubes' by aethelwhat included these references:\n  https://shadertoy.com/view/XlBSRz 'Volumetric Integration' by SebH\n  http://frostbite.com/2015/08/physically-based-unified-volumetric-rendering-in-frostbite/\n  https://graphics.pixar.com/library/ProductionVolumeRendering/paper.pdf\n*/\n\n#if NUM_LIGHTS\nvec3 lightPos[NUM_LIGHTS]\n, lightColor[NUM_LIGHTS]\n, lightDir[NUM_LIGHTS];\n// the animated point lights\nvoid InitLights()\n{\n    float time = iTime;    \n    lightPos[0] = vec3(vec2(3.5, 1.5)*cossin(time*.2) + vec2(0,.5), hfpHeight).xzy; //-.9\n    lightColor[0] = 10.0*vec3(.2,1,.2); //vec3(1); //vec3( 1., 1., .5);\n    #if NUM_LIGHTS >= 2\n    lightPos[1] = vec3(vec2(3.5, 1.5)*cossin(time*.7) + vec2(2.5,0), 1.5).xzy;\n    lightColor[1] = 1.*vec3(1); //vec3(1., .5, 1.);\n    #endif\n    #if NUM_LIGHTS >= 3\n    lightPos[2] = vec3(vec2(-1.5, 3.)*cossin(time*.5), 2.).xzy;\n    lightColor[2] = 1.*vec3(1); //vec3(.5, 1., 1.);\n    #endif\n}\n#endif\n\n// TODO include hard surfaces in the future which requires a \n// lot of changes:\n// probably a preliminary trace to get the final hit that does not integrate,\n// and then separately integrate over that distance so the integrating\n// ray march distance is not perturbed by tracing close to a surface\n// which aethelwhat saw when testing this with a fractal sdf.\n// also each light evaluation will check shadows of solids\n// eventually needs reflection and refraction at material boundaries\n\n// participatingMedia is effectively the scene function for this toy\n// as it provides a description of the fog spectral density at any world point and time\n// dist returns a signed distance to the fog volume as an isosurface, for marching\n// sigmaS here is spectral, w is for all wavelengths combined (white)\n// sigmaS means density per distance unit\n// pretty sure the units *I* use are in reciprocal meters, base 2, for efficient evaluation using exp2.\n// Frostbite also uses m^-1, but probably base e, so factor of ln(e)/ln(2) difference\n// others may use mm^-1, or base e, be careful.\n// mediaColor is for extinction purposes; FIXME rename, make into similar units\n// FIXME I'm unsure why we treat sigma spectrally here\n// if just mixing the color in otherwise later;\n// basically it's just about density, and that's not particularly hue-dependent.\n// mediaColor is at least extremely tuneable by artists, just get gamma right!\nvoid participatingMedia(out float sigma //out vec4 sigmaS\n                      , out vec3 mediaColor // just a linear rgb color, of the fog\n                      , out float dist\n                      , vec3 q, float time)\n{\n//  float shapeDensity = pow(1.5, 2.+ p.x); // vary density?\n    float fognoise = FogNoise(q);\n\tfloat dshape, dhfplane = q.y - hfpHeight;\n    ivec2 cell = ivec2(floor((q.xz+.5*tiling)/tiling));\n    vec3 p = q; // leave q arg untiled for use by fognoise; TODO maybe scale it by tiling though?\n    p.xz = mod(q.xz+.5*tiling, vec2(tiling))-.5*tiling; // repetition\n//    if (((cell.x^cell.y)&1)!=0)\n//    \tdshape = sdBox(p, vec3(1)); // boxes?\n//    else\n    \tdshape = sdSph(p, 1.); // spheres?\n    // convert sdf to a density by simply negating, scaling\n    float tiledShapeFog = max(0., dshape * -shapeDensity); //clamp(dist * -shapeDensity, 0., 1e3);\n    float heightFog = max(0., dhfplane * -hfpDensity); //clamp(dhfplane * -hfpDensity, 0., 1e3);\n    mediaColor = vec3(0); //.5); //1); //\n    vec3 hueshape = vec3(1,0,0);\n    // hue's really cheap, but evaluating at every march step\n    // even for shadows, really adds up!  This is a bit ridiculous in fact.\n    // but considering how many spheres it affects (an infinite amount)\n    // it's not *that* bad.  Some of this other mixing may could stand to be optimized.\n    // considering my framerate is currently tanked though, I can't yet afford to leave it on all the time.\n//    hueshape = mix(hue(1./6.13*float(cell.x)), vec3(1), sqrt(1./.75*fract(1./4.0*(float(cell.y))))); // desat hue of cell id?\n    mediaColor = mix(mediaColor, .7*hueshape, min(1.,tiledShapeFog)); //1.-abs(sin(.2*time)));\n    mediaColor = mix(mediaColor, vec3(.48,.49,.47), min(1.,heightFog)); // HACK mixing is wrong\n    //mediaColor = clamp(mediaColor, 0., 1.); // HACK just in case - yep, something was going awry up there\n    //sigmaS = vec4(0.\n    sigma = 0.\n        + heightFog * fognoise\n        + tiledShapeFog\n        ;\n    //    );\n    //sigma *= fognoise;\n    // one good thing about splitting this up is that the noise doesn't \n    // have to affect the sdf at all, so doesn't affect the marching.\n\n    dist = min(dshape, dhfplane);  // merge raw sdf's for use by trace stepper  \n}\n\n// FIXME I get the feeling usually caller will need to multiply mediaColor by sigmaS.w\n\n// I've usually parameterized transparent materials\n// by inscatter and extinction, but \n// apparently Frostbite prefers absorption to extinction\n// and aethelwhat and prior had transmission and mediaColor instead.\n// so I'm confused atm and trying to sort it back out.\nvoid participatingMediaB(out vec4 trans\n                       , out vec4 inscatter\n                       , out float dist // passthru sdf for use by marcher stepping\n                       , vec3 p, float time)\n{\n    float sigma; // mss * density\n    vec3 mediaColor; // spectral HACK just uses media color\n    participatingMedia(sigma, mediaColor, dist\n                      , p, time);\n   // TODO can hack these to alter the material properties\n    // at some point should just merge directly into participatingMedia instead\n    trans = sigma * vec4(1.-mediaColor, 1); //1); //\n    // FIXME isn't inscatter.a going to be equal to outscatter.a?\n    inscatter = sigma * vec4(mediaColor, 1); //.1); //1.); //0); //\n}\n                       //, vec3 priortrans // effective transmission to viewer here\n            //* vec4(priortrans, 1); // obscure by prior fog - can just do in caller\n        \t// (1. - outscatter.a) / (outscatter.a + 1e-7) * (light * sigma); // integrate along the current step segment\n\n// mat2x4 just conveniently packages multiplicative color factor with additive color term\n\n// outscatter, inscatter spectral optical depths (alpha=white) \"sigma\"s or mss * ln(e)/ln(2) * density\nvoid IntegrateParticipatingMedia(\n      vec4 mo, vec4 mi, out vec4 so, out vec4 si\n\t, float stepdist // meters\n    )\n{\n    //mo = max(mo, 0.); // ensure these positive also? wasted work in most cases also\n    //mi = max(mi, 0.);\n    stepdist = -max(0., stepdist); // max(0,) just to be safe and show what's going on better; was probably already always positive\n    so = exp2(stepdist * mo);\n    si = 1. - exp2(stepdist * mi);    \n}\n\n// TODO probably refactor atmo out somehow;\n// right now it's mostly just hacked into enviro function\n// which is just a background color, not a real light or fog, but I make do.\n/*\nvoid participatingMediaEverywhere(out vec4 inscatter\n                       , out vec4 outscatter\n                       , float time)\n{ // could take p into account for altitude fx or something but not presently\n    // noticeable lack of ambient/env lighting\n    // constantFog allows to see the moving point lights themselves, sort of undersampled and flickery though\n    //const float constantFog = .0005e-4; // a white haze everywhere\n    \n    vec4 atmoFog = vec4(fogRayleigh, Lumi(fogRayleigh));\n    \n    inscatter = vec4(0);\n    // FIXME truly should factor all this atmo and constant fog out\n    // to the very end after computing complete trace to extinction\n    // because it can all be one with one big ol' exp2!  wasting effort doing per-step\n    // sure here the \"effort\" is just a few adds\n    // I suppose if it did amount to enough to actually extinct the ray march,\n    // it may be worth considering here, but it's really not... usually!\n    // so I want to do another of these but for the entire ray\n    inscatter += atmoFog\n    //    + constantFog\n        ;\n}\n*/\n\n// FIXME there's actually two marchings going on, one in shadow, one in trace\n// could really stand to combine them\n\n// return vec3, at least; generalize to accumulating media over a ray segment\nvec3 colorTransmission(vec3 ro, vec3 rd, float time, float nsteps)\n{\n    vec3 trans = vec3(1);\n    float dd = length(rd) / nsteps;\n    for (float s=.5 + FZERO; s < nsteps-.1; s += 1.) { // start at 0.5 to sample at center of integral part\n        vec3 p = ro + s / nsteps * rd;\n        float dist;\n      #if 1\n        vec3 mediaColor = vec3(1);\n        float sigma; //vec4 sigmaS;    \n        participatingMedia(sigma, mediaColor, dist, p, time); // quite heavy but we ignore most results\n        vec3 shadowTint = vec3(1);\n        // most of the rest of the colorization\n        // happens down in lightFog\n        shadowTint = (1.-mediaColor); // tinted shadows\n        trans *= exp2(-sigma * dd * shadowTint);\n      #else  // FIXME use IntegrateParticipatingMedia or...\n        // anyway seems it should actually take inscattering into account\n        // (it's light... *seems* to be coming from light source, so... use it!)\n        // because it prevents \"shadowing\" just same as if lit directly by light source\n        // anyway here we only take into account the extinction\n        // because we don't know the actual light source or its brightness, here.\n        // TODO I think there's a better way to compute the shadows more generally, probably.\n        vec4 mo, mi;\n        participatingMediaB(mo, mi, dist, p, time); // alt\n     \ttrans *= mo.rgb;\n      #endif\n    }\n    return trans;\n}\n\n// each lit march step must check volumetric shadows, so...\n\nvec3 pointLightShadowed(vec3 lp, vec3 q, out vec3 ld)\n{\n    float time = iTime;\n    if (distance(lp, q) > shadowLimit) return vec3(0);\n    return pointLight(lp, q, ld)\n        * colorTransmission(q, lp - q, time, nStepShadow)\n        ;\n    //if (dot(from,from) > shadowLimit*shadowLimit) return 1.; // shadows only near the light sources\n}\n\n// added arg for ao term, something about depth within fog for ambient occlusion purposes\n// ao currently ignored though TODO\nvec3 lightContrib(vec3 p, vec3 ro, vec3 rd) //, float ao)\n{\n    vec3 v = -rd;\n    float time = iTime;\n    vec3 col = vec3(0.);\n    vec3 suntrans = vec3(1);\n    float sunshadow = 1.; // vec3?\n    if (distance(p, ro) < shadowLimitSun) { //*shadowLimit)\n        suntrans = colorTransmission(p, sunDir * shadowRangeSun, time, nStepShadowSun);\n    }\n    float slv = dot(sunDir, v); //1.; //dot(L,V); // TODO no vector access here\n    // ok let's do a shadow on the main (sun) parallel light too\n    col += sunColor //* parallelLight(sunDir, p)\n    //\t* sunshadow\n        * suntrans\n        * phaseFunction(slv)\n        ;\n  #if NUM_LIGHTS\n    // only checking shadow for the first light source for since it is the biggest\n    // which is visually pleasing but improper for the integral\n    // since evaluating a light source implies checking its shadow (but I'm skipping for the smaller lights)\n    // doing all lights will kill performance\n    vec3 L = normalize(lightDir[0]); //lightPos[0] - p); // HACK probably already computed inside evaluateLight\n    float dlv = dot(L, v); //1.; //dot(L,V); // TODO no vector access here\n    col += lightColor[0] * pointLightShadowed(lightPos[0], p, lightDir[0])\n    \t* phaseFunction(dlv);\n    #if NUM_LIGHTS >= 2\n    col += lightColor[1] * pointLight(lightPos[1], p, lightDir[1]);\n    #endif\n    #if NUM_LIGHTS >= 3\n    col += lightColor[2] * pointLight(lightPos[2], p, lightDir[2]);\n    #endif\n  #endif\n    \n    // TODO approximate the ambient lighting better, \n    // would use extinction as a form of self-shadowing/ambient occlusion I guess until I find something better but it's not available here yet\n    //col += .75; // HACK \"ambient\" contribution\n    return col;\n}\n\n\nvoid FogOld(float stepdist, vec3 p, vec3 ro, vec3 rd, float time\n         , out float dist\n         , inout vec3 trans, inout vec3 scatt)\n{\n\tvec3 mediaColor;\n    float sigma;\n    participatingMedia(sigma, mediaColor, dist, p, time);\n    // participatingMedia doesn't know anything about the actual step distance dd\n    // sigmaS takes the *density* into account, but not the step length. \n    // the more-or-less constant step length does prevent many issues currently.\n    float fogbias = 0.;\n   \tif (distance(p, ro) < shadowRange) {  // but only near the camera, to prevent such uneven look due to marcher\n        fogbias += constantFog;\n       \tdist = min(dist, minD * 2.); //24.); //.2); // don't step too far thru it\n    }\n    float sigmaL = sigma + 1.*fogbias;\n    if (sigmaL > 0.) {\n        float sigmaE = max(1e-9, sigmaL); //sigmaS.w); // avoid division by zero extinction - sebH\n        //float ao = 1. - Lumi(trans); // FIXME need lumi // extinction? something like that\n        // following is SebH's improved integration \n        // added an absorption color to the media\n        // See slide 28 at http://frostbite.com/2015/08/physically-based-unified-volumetric-rendering-in-frostbite/\n    \t// constantFog allows to see the moving point lights themselves, sort of undersampled and flickery though\n    \tvec3 lc = lightContrib(p, ro, rd);//, ao)\n        vec3 S = lc * sigmaL; // * sigmaS.rgb; // incoming light\n        float Sbl = exp2(-stepdist * sigmaL); //Sba; //\n        float Sba = exp2(-stepdist * sigma); //sigmaL); // can use different value for transmission; sigmaL just darkens everything :(\n        // currently mediaColor tinted shadows *only* block opposite of their own tint which seems wrong somehow\n        // my mediaColor is currently not 100% saturated, keep that in mind.\n        vec3 Sbt = vec3(1.); // full transmission\n        //Sbt = vec3(Sba); //Sbl; // monochrome transmission\n        Sbt = mix(.6*mediaColor, vec3(1.), Sba); // extinct opposite of tint only? hmm.\n        \n        vec3 Sint = (1. - Sbl) / sigmaE * S; // integrate along the current step segment\n        Sint *= trans; // obscure by prior fog\n        // fog, cloud, and mist tend to be white for specular scattering purposes, smoke is more dark.\n        // Can colorize the smoke if you like, idk what that models, maybe colored smoke?\n        // if it scatters the same color it absorbs, it's hard to tell what really happens.\n        // I've tried setting either trans or scatt to mediaColor independently and they both seem to work.\n        // if you do tint Sint here, it will probably break the constant fog shadows\n        Sint *= mediaColor; // and tint - more \"smokelike\" or glowy instead of \"foglike\" if dense enough to extinct, otherwise colorizes the glow\n        //Sint += .25*mediaColor * (1.-Sba); // emissive glow?  very bright, independent of lighting\n        // don't forget about the mediaColor coming from the shadows in colorTransmission!\n        scatt += Sint; // accumulate and also take into account the transmittance from previous steps\n        trans *= Sbt; // combined or independent transmittance to view\n    }\n}\n\n// idk, just keep on wrappering until I get a decent interface\n// then unwrapper and simplify\n// not completely broken now, but still looks a lot different than FogOld :(\nvoid Fog(float stepdist, vec3 p, vec3 ro, vec3 rd, float time\n         , out float dist, out vec4 fo, out vec4 fi)\n\n{\n    vec4 mo, mi; \n    participatingMediaB(mo, mi, dist, p, time);\n    float fogbias = 0.;\n   \tif (distance(p, ro) < shadowRange) {  // but only near the camera, to prevent such uneven look due to marcher\n     \tfogbias += constantFog;\n        dist = min(dist, minD * 2.); //24.); //.2); // don't step too far thru it\n\t}\n    float sigmaL = mi.w + 1.*fogbias;\n    if (sigmaL > 0.) { //dist <= 0.) { //dot(mi, mi) > 1e-7) { //\n\t    vec3 lc = lightContrib(p, ro, rd);//, ao)\n    //    mo.rgb *= sigmaL;\n        mi += fogbias;\n\t    //mi.rgb += 1.-sigmaL;\n\t    mi.rgb *= lc;  //  TODO maybe some emissive also\n\t\tIntegrateParticipatingMedia(mo, mi, fo, fi, stepdist);\n    } else { \n        fo = vec4(1); fi = vec4(0);\n    }\n}\n\n\n// hey at least I decoupled the lighting from the ray marcher\n// TODO consider similar mat2x3 package for 3d ray, with direction in [0] and origin in [1]\nvoid LightFog(vec3 p, vec3 ro, vec3 rd, float time, float dd\n              , out float dist, inout vec3 trans, inout vec3 scatt)\n{\n  #if 1\n    // some kind of integration\n    FogOld(dd, p, ro, rd, time, dist, trans, scatt);\n  #else\n    // alternative integration - \"new\" interfaces\n    // TODO for one thing, need trans and scatt to be vec4, so caller can easily track w instead of abusing Lumi\n    // FIXME currently somewhat dim, otherwise surprisingly not too terribly broken\n    vec4 fo, fi;\n    Fog(dd, p, ro, rd, time, dist, fo, fi);\n    trans *= fo.rgb; scatt += fi.rgb;\n  #endif\n}\n\n\nvoid trace(vec3 ro, vec3 rd, float rnd\n     , out vec3 finalPos, out vec3 normal\n     , out vec3 scatter, out vec3 transmit) // frostbite uses term absorption = what, 1-transmit? idk\n{\n    // Initialize volumetric scattering integration (to view)\n    vec3 trans = vec3(1)\n    , scatt = vec3(0)\n\t, p = vec3(0);\n\tfloat t = 0. // trace distance along ray, assuming normalized rd\n    , dd = 0. // should first step do anything?\n    , time = iTime; // FIXME hate having to pass this uniform around; was trying to code in Common tab before\n\tfor(int i=IZERO; i < nStepTrace; ++i) {\n\t\tvec3 p = ro + t*rd;\n        float dist;\n        LightFog(p, ro, rd, time, dd, dist, trans, scatt);\n        dd = dist; \n        dd = min(dd, 1e1); // HACK fixes black crud in sky due to bad exp2 somehow\n        float minstep = minD;\n        minstep = max(minstep, t * .005 + .1); // HACK just force step based on camera trace length so far - seems really banded due to lack of dither and inconsistent stepping across the \"edge\" where it's less dense\n        minstep += .4 * minD * (rnd * 2. - 1.); // jitter at every step? really does help break up stepping bands, unsure why needs so much\n    //    if (false || dd <= 1e-3)\n    //        dd = minstep; // ignore actual \"distance\" once inside non-negative density region for uniform stepping to avoid artifacts\n    //    else // well the dd there is real small or negative anyway, so this max will handle it\n            dd = max(minstep, dd * .98);\n        // TODO might as well give up when trans.w is near zero\n        // should help performance in opaque solids or thick clouds\n        // at least with constant step size the fog spheres don't cause the heightfog plane seen through them to bend/warp\n        if (Lumi(trans) < .02) break;\n\t\tt += dd;\n    }\n    finalPos = ro + t*rd;   // maybe just return trace distance t instead FIXME \n    scatter = scatt;\n    transmit = trans;\n}\n\n// FIXME all of the bigger steps it takes when it's not inside an object\n// should also accumulate sigma etc. but from the air, atmospheric fx.\n// The integration is slightly different due to varying step size, otherwise similar.\n// HOWEVER when fully \"extincted\" by atmo, we should be seeing the\n// environment and not just black.  So the lighting must agree somehow.\n// last time I tried allowing it to accumulate any constantFog,\n// it caused most of the scene to go dark.  If we want fog shadows though,\n// and we do, we must step thru the air near the camera with\n// fairly constant step size to march shadows.  Even where there isn't\n// any real fog indicated.\n\n    // take final ray direction and sample the environment map with it\n    // use that to \"light\" the fog again\n    // can use mips of hi-detail and/or the blurred lo-detail envmap, \n    // in any combination, for specular and diffuse-like lighting\n    // here we need the blurred version for a sort of ambient\n    // and the hi-detail for the background and maybe some hi-freq inscatter\n\nvec3 trace2(vec3 ro, vec3 rd, float focus, float rnd, out float depth)\n{\n\tvec3 normal, finalPos;\n    vec3 scattered, transmit;\n    trace(ro, rd, rnd\n          , finalPos, normal, scattered, transmit);\n    \n    depth = distance(finalPos, ro);\n\n    // without access to mediaColor, no way to do this correctly.  FIXME\n    // so what I really should be doing is sampling sky as we go maybe\n    // like within trace.  Currently all applied afterward for background and fake ambient\n    \n    // this is just some approximation - see enviroLQ\n    focus *= Lumi(transmit); // HACK need lumi also\n    vec3 color = vec3(0);\n//    color += enviro(finalPos, rd, focus); // I am undecided about this, anyway unsure how best to fake mixing it in\n       \n    // envmap mostly exhibits the lack of ambient occlusion/sky shadowing and ambient enviro lighting\n    vec3 bgcol = enviro(ro, rd, focus);\n    color += bgcol;\n    // background * transmittance + scattered light\n    color *= transmit;\n    color += scattered;\n//    color = transmit; // debug transmission\n//    color = bgcol; // debug background/enviroHQ\n    return color;\n}\n\n\n// debug fly camera controlled by keyboard+mouse; see Buffer C.\n\nvoid ViewRay(vec2 p, out vec3 ro, out vec3 rd, out vec3 vd)\n{\n    vec2 q = StoQ(p, iResolution.xy);\n    vec3 camera_pos = cameraPosition(BufferC);\n    vec3 camera_dir = cameraDirection(BufferC);\n    mat3 M = cameraMatrix(camera_dir);\n    const float hfovy = pi/6.;\n    vd = normalize(vec3(q, 1./sin(hfovy)));\n    ro = camera_pos, rd = normalize(M * vd);\n}\n\n\nvoid mainImage(out vec4 o, vec2 p)\n{\n    vec3 ro, rd, vd; // Camera\n\tViewRay(p, ro, rd, vd);\n  #if NUM_LIGHTS\n    InitLights();\n  #endif\n    // temporal jitter / \"temporal volumetric integration\"\n    // not having a lot of effect here due to the alignment up to the isosurface in trace\n  \tfloat rnd = fract(iTime*24. + 12345.67*sin(dot(p, vec2(12.7,8.3))));\n    ro += rd * .4 * rnd;\n    float depth; // = 1.;\n    float focus = 1.;\n    vec3 color = trace2(ro, rd, focus, rnd, depth);\n    // TODO temporal reprojection?\n    if (iFrame < 3) //2) // must fill both double buffers initially\n    \to = vec4(color, 1);\n    else {\n    \to = texelFetch(BufferA, ivec2(p), 0);\n\t    color = mix(color, o.rgb, exp2(-64.*iTimeDelta)); // temporal feedback / retinal smear fx, may help w aliasing or noise\n    }\n    //color = vec3(rnd); // HACK debug temporal jitter - yep, indeed, very jittery\n\to = vec4(color, depth);\n}\n\n\n    //color = vec3(rnd);\n\n","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"4dXGRr","filepath":"/presets/tex00.jpg","previewfilepath":"/presets/tex00.jpg","type":"keyboard","channel":3,"sampler":{"filter":"nearest","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"/media/previz/buffer02.png","previewfilepath":"/media/previz/buffer02.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"// from https://shadertoy.com/view/WlVGDh\n\n// BufferC controls the state, mostly the camera location+direction\n// but wound up needing old mouse state and, for smoothing,\n// the desired facing direction.\n\n#define BufferC   iChannel2\n#define Keyboard  iChannel3\n\nconst float moverate = 1.2;\nconst float turnratemouse = .02;\nconst float turnratekbd = 2.6;\n\n\nvec3 desiredDirection() \n{\n    return loadValue(BufferC, slotDesiredForward).xyz;\n}\n\nvec4 oldMouse() \n{\n    return loadValue(BufferC, slotMouseOld);\n}\n\nbool asleep(vec2 mouse) // in shadertoy.com shader browser thumbnail? \n{\n    return dot(mouse, mouse) <= 2.;\n}\n\n// read keyboard key, return 1.0 if down\n// ultimately want to do differencing of negatives from positives\nfloat key(int vk) // key down state value as a float fraction\n{\n    float s = loadValue(Keyboard, vk).x; // read keyboard key state from texture\n    return step(.5, s); // test if down\n}\n\nconst int\n  KEY_SPACE = 32\n, KEY_CTRL  = 17 // DO NOT use control generally as when held, bad things can happen to our window or tab\n, KEY_SHIFT = 16\n, KEY_C     = 67\n// https://wikipedia.org/wiki/Arrow_keys#WASD_keys\n, KEY_W     = 87\n, KEY_A     = 65\n, KEY_S     = 83\n, KEY_D     = 68\n// in DVORAK it's ,AOE, in AZERTY it's ZQSD\n, KEY_Z     = 90 // but Image tab is using it for showing depth FIXME\n, KEY_Q     = 81\n, KEY_O     = 79\n, KEY_E     = 69\n, KEY_COMMA = 188\n#if 0\n    // AZERTY ZQSD\n, KEY_FW    = KEY_Z\n, KEY_LF    = KEY_Q\n, KEY_BW    = KEY_S\n, KEY_RT    = KEY_D\n#elif 0\n    // DVORAK ,AOE\n, KEY_FW    = KEY_COMMA\n, KEY_LF    = KEY_A\n, KEY_BW    = KEY_O\n, KEY_RT    = KEY_E\n#else\n    // QWERTY\n, KEY_FW    = KEY_W\n, KEY_LF    = KEY_A\n, KEY_BW    = KEY_S\n, KEY_RT    = KEY_D\n#endif\n, KEY_UW    = KEY_SPACE\n, KEY_DW    = KEY_C  // anything but control!\n, KEY_LEFT  = 37 // arrow keys for lookaround\n, KEY_RIGHT = 39\n, KEY_UP    = 38\n, KEY_DOWN  = 40\n;\n\nvec3 cameraMovement(bool shift)\n{\n    vec3 campos = cameraPosition(BufferC);\n    float\n      fw = key(KEY_FW)\n    , bw = key(KEY_BW)\n    , lf = key(KEY_LF)\n    , rt = key(KEY_RT)\n    , up = key(KEY_UW)\n    , dn = key(KEY_DW);\n    if (asleep(iMouse.xy)) fw = .5; // automate forward in thumbnails\n    vec3 camfwd = cameraDirection(BufferC);\n    mat3 camori = cameraMatrix(camfwd);\n    vec3 cammove = vec3(rt-lf, up-dn, fw-bw) * iTimeDelta * moverate;\n    if (shift) cammove *= 4.0; // shift key for speed boost\n    campos += camori * cammove;\n    const float camradius = .04;\n//    campos += sdfnormal(campos) * -min(sdf(campos) - camradius, .0); // collision with sdf\n    return campos;\n}\n\nvec3 cameraSteering(bool shift)\n{\n    vec3 desiredRot = desiredDirection();\n    vec4 oMouse = oldMouse();\n    bool lmb = iMouse.z >= 0.;\n    bool olmb = oMouse.z >= 0.;\n    float shiftmod = shift ? .5 : 1.; // shift actually slows rotation down\n    vec2 orbit = vec2(0);\n    if (asleep(iMouse.xy)) {\n    \torbit = vec2(.05*iTimeDelta, 0);   // attract mode slow spin\n\t} else {\n    \tif (lmb && olmb) {\n\t        vec2 m = iMouse.xy - oMouse.xy;\n    \t    orbit += m * turnratemouse * shiftmod;\n    \t} \n    \t{\n    \t\tfloat aL = key(KEY_LEFT), aR = key(KEY_RIGHT), aU = key(KEY_UP), aD = key(KEY_DOWN);\n\t        vec2 m = vec2(aR - aL, aU - aD);\n    \t    orbit += m * iTimeDelta * turnratekbd * shiftmod;\n        }\n    }\n    if (dot(orbit,orbit) != 0.) {\n        rot(desiredRot.xz, cossin(orbit.x));\n        vec2 vr = vec2(1.,desiredRot.y);\n        rot(vr, cossin(-orbit.y));\n        desiredRot.xz *= max(1e-1f, vr.x); // do not flip signs here!\n        desiredRot.y = vr.y;\n  \t\tdesiredRot = normalize(desiredRot);\n    }\n    return desiredRot;\n}\n\n// smoothing filter\nvec3 cameraSmoothing()\n{\n    vec3 camfwd = cameraDirection(BufferC);\n    vec3 desiredFwd = desiredDirection();\n    camfwd = normalize(mix(desiredFwd, camfwd, exp2(-64.*iTimeDelta)));\n    return camfwd;\n}\n\n// implements a debugging fly camera using keyboard WASD + mouse + C/space\n// stores camera position,aim,etc. into c as a \n// color coded vector suitable for output to buffer\nvoid debugFlyCamera(out vec4 c, vec2 p)\n{    \n    ivec2 ip = ivec2(p);\n    c = loadValue(BufferC, ip.x); // passthru by default\n    float elapsed = iTimeDelta; // seconds\n    bool shift = key(KEY_SHIFT) > .5;\n    bool init = iFrame < 3; //iFrame == 0; // thumbnail issues\n    switch (slotid(ip)) {\n      case slotCameraPosition: {\n \t    c.xyz = init ? vec3(.0,1.5,-6.5) : cameraMovement(shift);            \n        break;\n      }\n      case slotCameraForward: {\n        c.xyz = init ? vec3(0.,0.,1.) : cameraSmoothing();\n        break;\n      }\n      case slotDesiredForward: {\n        c.xyz = init ? vec3(-.5,0.,.866) : cameraSteering(shift);\n        break;\n      }\n      case slotMouseOld: {\n        c = iMouse;\n        break;\n      }\n      default:\n        break;\n    }\n}\n\n// to Buffer C\nvoid mainImage(out vec4 c, vec2 p)\n{    \n    if (p.y >= 1. || int(p.x) > slotCount) discard; // ignore most pixels - otherwise using an entire buffer is really bad\n    debugFlyCamera(c, p);\n}\n\n\n// TODO since only 4 pixels are actually used of this entire buffer,\n// may as well do something useful with the rest of the pass and memory,\n// I'm leaning toward putting the ray bundle data here.\n\n// may do it separately to keep simple,\n// and try to merge in here later once it works better.\n\n// probably do this with multiple passes maybe with latency pipelining\n// from prior frames; only have so many way it can be done here,\n// and going to buffer memory at all has serious perf implications.\n// may be better to keep it all on chip as much as possible,\n// but certain operations depend on combined results of prior operations.\n// For instance can't calculate lighting until we're certain\n// which object is nearest intersection, which was my original \n// reason for buffering rays.  Honestly I'm not 100% sure I need to buffer rays at all.\n// or that buffering them will help anything in the end.\n// some folks do trace everything all in one pass!\n// I fear it'll be stochastic and have insufficient sampling anyway.\n\n// will be tricky to pack rays into pixels, since we need at least like\n// 6 floats just for the ray pos & dir, then some kind of ranges,\n// spectral attenuation/inscatter factors and like, cosine of cone angle/focus\n// not to mention so kind of linked list?  idk if I need that, might do something simpler.\n// lot of data, only 4 floats per pixel available.  I'll likely\n// either need to use *more* than a single buffer to store it all\n// or drastically reduce the payload so it can fit.  Good chance\n// that I can split between 2 pixels, reduce resolution by factor of 2 isn't\n// so bad for a shadertoy raytracer, but hmm.  Must figure out where\n// all this will go.  Can use Cubemap A in a pinch, but\n// I have designs on that for maybe other purposes for environment/sky caching.\n// of course each pass can do quite a bit of work, also;\n// the idea is that when it gives up, the remainder can be pushed off\n// to later passes, wherever convenient, or deferred to a later\n// buffer in the same pass.\n// gah what have I gotten myself into lol :)\n\n// probably in Image, but can't do feedback from there;\n// so maybe in a Buffer, will likely gather all the appropriate\n// ray fragments and add them up for final display at the eye.\n\n// bah, I prattle on too much and code too little.\n// sort of designing in commentary, considering alternatives,\n// having debates with myself where I can sort out the \n// argument later.\n\n","name":"Buffer C","description":"","type":"buffer"}]}
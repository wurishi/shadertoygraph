{"ver":"0.1","info":{"id":"clKGRV","date":"1684300954","viewed":60,"name":"3ds light field 2 pass","username":"holophone3d","description":"Synthesizes a lightfield all views between L and R given a rectified stereo pair with depth maps (designed for 3ds)\nInstructions in the shader for: loading textures, using different render modes and viewing lightfield as a hologram on a LookingGlass","likes":0,"published":1,"flags":32,"usePreview":0,"tags":["backwardmapping"],"hasliked":0,"parentid":"Dl3GDj","parentname":"3ds lightfield LKG WIP"},"renderpass":[{"inputs":[{"id":"4dXGR8","filepath":"/media/previz/buffer00.png","previewfilepath":"/media/previz/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"/*\n DETAILS:\nSynthesizes a light field between L and R given a rectified stereo pair with depth maps (designed for 3ds)\nPOC shader to enable 3DS emulator Citra to natively render into Looking Glass hologram display\nUses a depth based warping and blending approach to create virtual frames\nbackward mapping - loosely based on the paper:https://www.cc.gatech.edu/conferences/3DPVT08/Program/Papers/paper213.pdf\nUI is not warped because no depth is present at the moment.\n\nNot sure why I need to do this in two passes, but something doesn't work right if I try to do it all in one pass.\nSo for now, I'm rendering the quilt, etc to Buffer A and then building the lenticular filter on that texture\n\n\nINSTRUCTIONS:\n1. SWITCH TO 'BUFFER A' AND LOAD THE FOUR TEXTURES BELOW TO RUN THE SHADER:\n\nThe idea is to call directly the SetTexture function found in Shadertoy js code \n(https://www.shadertoy.com/view/lsGGDd)\n\nHere is how to loads the three textures needed for this shader:\n - Open the javascript console of your browser:\n\t\t\t\t   Mac      /     Windows\n\tChrome:  cmd + opt + J  /  ctrl + shift J\n\tFirefox: cmd + opt + K  /  ctrl + shift K\n    Edge:          na         /  ctrl + shift J   \n\n- Then copy the following lines in the console:\n\nSuper Mario 3D world (3DS) - RGB+D\n\ngShaderToy.SetTexture(0, {mSrc:'https://i.imgur.com/WyfxrfJ.png', mType:'texture', mID:1, mSampler:{ filter: 'linear', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\ngShaderToy.SetTexture(1, {mSrc:'https://i.imgur.com/knCRQt5.png', mType:'texture', mID:1, mSampler:{ filter: 'linear', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\ngShaderToy.SetTexture(2, {mSrc:'https://i.imgur.com/v961sp9.png', mType:'texture', mID:1, mSampler:{ filter: 'linear', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\ngShaderToy.SetTexture(3, {mSrc:'https://i.imgur.com/xcgUn8T.png', mType:'texture', mID:1, mSampler:{ filter: 'linear', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\n\n- hit return to execute and load the textures.\n\n2. SET YOUR INTERACTIVE RENDER MODE ( in mainImage method ) or CLICK AND DRAG IN from the screen corners\n    0 = render lightfield image viewer (default) - TOP RIGHT CORNER\n        - Click and drag mouse in x axis to see the lightfield\n    1 = render lightfield as quilt - - BOTTOM LEFT CORNER\n        - Click and drag mouse in x axis to change lightfield depth\n        - Click and drag mouse in y axis to change lightfield focus\n    2 = render lightfield as lenticular image for LKG - - BOTTOM RIGHT CORNER\n        - Click and drag mouse in x axis to change lightfield depth\n        - Click and drag mouse in y axis to change lightfield focus\n    3 = render stereo images (debug) - TOP LEFT CORNER\n        - Click and drag mouse in x axis to blend between stereo images\n\n3. CONFIGURE YOUR LKG CALIBRATION DATA (If using LKG Render mode with a device)\n    Set all LKG device calibration data - defaults are for my device and will show the lenticular image\n    (https://jakedowns.github.io/looking-glass-calibration.html)\n    When using lenticular image LKG rendering mode\n    Use extended mode on your desktop and have the LKG as an additional display\n    Drag the the window over to the LKG display\n    Click the 'full screen' button on the bottom right of the shader view\n    Click and drag on the LKG screen to change depth and focus\n    Hit 'Esc' key to exit full screen mode\n\n\nLookingGlass Lenticular rendering code is ported from here:\nhttps://github.com/Looking-Glass/LookingGlassCoreSDK/blob/master/HoloPlayCore/include/HoloPlayShaders.h\n\nObligatory license details for LKG lenticular code:\n\nBy using, copying, or modifying this code in any way, you agree to the terms of\nhttps://github.com/Looking-Glass/HoloPlayCoreSDK/blob/master/LICENSE.txt\n\nThe contents of this file are not open source and should not be merged into\ncodebases with licenses that conflict with the HoloPlay SDK License. In those\ncases, please include HoloPlayShadersOpen.h instead.\n\n*/\n\n\n// https://jakedowns.github.io/looking-glass-calibration.html\n// LKG calibration data  (put your LKG data here)\nconst float width = 1536.0f;\nconst float height = 2048.0f;\nconst float dpi = 324.0f;\nconst float slope = -7.198658892370121;\nconst float center = 0.5990424947346542;\nconst float pitch = 52.57350593130944;\nconst int invView = 1;\nconst float displayAspect = 0.75;\nconst int ri = 0;\nconst int bi = 2;\n\n// Quilt data (defaults)\nvec3 tile = vec3(8.0,6.0,1.0); //cols, rows, total views (will be computed)\nfloat quiltAspect = 1.0; // default - cols/rows (will be computed)\nvec2 viewPortion = vec2(1.0,1.0);\nconst int overscan = 0; \nconst int quiltInvert = 0; // this makes it look more correct, but is visually somewhat uncomfortable - I think this shouldn't be needed, but I'm not sure\n\n\n// LKG LENTICULAR SHADER FUNCTIONS\nvec2 texArr(vec3 uvz)\n{\n    // decide which section to take from based on the z.\n    float x = (mod(uvz.z, tile.x) + uvz.x) / tile.x;\n    float y = (floor(uvz.z / tile.x) + uvz.y) / tile.y;\n    return vec2(x, y) * viewPortion.xy;\n}\n// recreate CG clip function (clear pixel if any component is negative)\nvoid clip(vec3 toclip)\n{\n    if (any(lessThan(toclip, vec3(0,0,0)))) discard;\n}\nvec4 renderToLookingGlass(vec2 normalized_coords, float alpha_range_offset, float focus_val)\n{   \n    // update computed LKG values from calibration data\n    float subp = 1.0f / (3.0f * width);\n    float tilt = height / (width * slope);\n    float adjusted_pitch = pitch * (width / dpi) * sin(atan(abs(slope)));\n    // update computed quilt values\n    tile.z = tile.x*tile.y;\n    if(tile.y > tile.x)\n    {\n        quiltAspect = tile.y/tile.x;\n    }\n    else\n    {\n        quiltAspect = tile.x/tile.y;\n    }\n    \n    float invert = 1.0;\n    if (invView + quiltInvert == 1) invert = -1.0;\n    vec3 nuv = vec3(normalized_coords.xy, 0.0);\n    nuv -= 0.5;\n    float modx = clamp(step(quiltAspect, displayAspect) * step(float(overscan), 0.5) + step(displayAspect, quiltAspect) * step(0.5, float(overscan)), 0., 1.);\n    nuv.x = modx * nuv.x * displayAspect / quiltAspect + (1.0-modx) * nuv.x;\n    nuv.y = modx * nuv.y + (1.0-modx) * nuv.y * quiltAspect / displayAspect;\n    nuv += 0.5;\n    clip (nuv);\n    clip (1.0-nuv);\n    vec4 rgb[3];\n    for (int i=0; i < 3; i++)\n    {\n        nuv.z = (normalized_coords.x + float(i) * subp + normalized_coords.y * tilt) * adjusted_pitch - center;\n        nuv.z = mod(nuv.z + ceil(abs(nuv.z)), 1.0);\n        nuv.z *= invert;\n        nuv.z *= tile.z;\n        vec3 coords1 = nuv;\n        vec3 coords2 = nuv;\n        coords1.y = coords2.y = clamp(nuv.y, 0.005, 0.995);\n        coords1.z = floor(nuv.z);\n        coords2.z = ceil(nuv.z);\n        vec4 col1 = texture(iChannel0, texArr(coords1));\n        vec4 col2 = texture(iChannel0, texArr(coords2));\n        rgb[i] = mix(col1, col2, nuv.z - coords1.z);\n    }\n    return vec4(rgb[ri].r, rgb[1].g, rgb[bi].b, 1.0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{      \n    bool mouse_value_debugger_enabled = false;\n    vec2 normalized_coords = fragCoord.xy/iResolution.xy;\n    \n    render_mode = updateRenderModeFromCornerHotspots(iMouse, iResolution);\n\n    \n    if (render_mode == -1)\n    {\n        fragColor = vec4(0.0,0.0,0.0,1.0);\n    }\n    else if (render_mode == 2)\n    {\n        fragColor = renderToLookingGlass(normalized_coords, iMouse.x/iResolution.x, (iMouse.y/iResolution.y)/3.0);\n    }\n    else\n    {\n        fragColor = texture(iChannel0, normalized_coords);\n    }\n\n   if(mouse_value_debugger_enabled){\n       if(normalized_coords.x > 0.9)\n           fragColor = vec4((iMouse.x / iResolution.x), 0.0, 0.0, 1.0);\n       if(normalized_coords.x > 0.95)\n           fragColor = vec4((iMouse.y / iResolution.y), 0.0, 0.0, 1.0);\n       }\n}","name":"Image","description":"","type":"image"},{"inputs":[],"outputs":[{"id":"4dXGR8","channel":0}],"code":"/*\nThe idea is to call directly the SetTexture function found in Shadertoy js code \n(https://www.shadertoy.com/view/lsGGDd)\n\nHere is how to loads the three textures needed for this shader:\n - Open the javascript console of your browser:\n\t\t\t\t   Mac      /     Windows\n\tChrome:  cmd + opt + J  /  ctrl + shift J\n\tFirefox: cmd + opt + K  /  ctrl + shift K\n    Edge:          na         /  ctrl + shift J   \n\n- Then copy the following lines in the console:\n\nSuper Mario 3D world (3DS) - RGB+D\n\ngShaderToy.SetTexture(0, {mSrc:'https://i.imgur.com/WyfxrfJ.png', mType:'texture', mID:1, mSampler:{ filter: 'linear', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\ngShaderToy.SetTexture(1, {mSrc:'https://i.imgur.com/knCRQt5.png', mType:'texture', mID:1, mSampler:{ filter: 'linear', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\ngShaderToy.SetTexture(2, {mSrc:'https://i.imgur.com/v961sp9.png', mType:'texture', mID:1, mSampler:{ filter: 'linear', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\ngShaderToy.SetTexture(3, {mSrc:'https://i.imgur.com/xcgUn8T.png', mType:'texture', mID:1, mSampler:{ filter: 'linear', wrap: 'repeat', vflip:'true', srgb:'false', internal:'byte' }});\n\n- hit return to execute and load the textures.\n\nGo back to 'Image' tab\n*/\n\n// LIGHTFIELD AND QUILT GENERATORS\n\nvec3 tile = vec3(8.0,6.0,1.0); //cols, rows, total views (will be computed)\n\n// Determines how far to shift a pixel based on depth information\nfloat get_depth_shift(vec2 normalized_coords, float depth_value) {\n    // offset = d1(distance to central layer)/d2(distance to camera)*camera (represented by alpha)\n    // Define a reference resolution and scale factor\n    float depth_log = 0.2 + ((depth_value) * mix((depth_value), 1.0, 0.04975));\n    depth_value = depth_log;\n    \n    float central_layer =30.0/256.0; // Focal plane distance\n    float camera = 53.0/256.0;// cameral parallel shift offset\n    //central_layer = (iMouse.x / iResolution.x)/5.0;\n    //camera = (iMouse.y / iResolution.y);\n    float offset = -((central_layer-depth_value)/(depth_value)) * camera;\n    // Return the distance between the left and right pixels in pixels\n    return offset;\n}\n\n//shifts pixel color information and depth information\nvec3 get_Im(vec2 normalized_coords, float alpha)\n{\n    // default depth is inverted so fix that  \n    float depthl = 1. - texture(iChannel1, normalized_coords ).x;\n    float depthr = 1. - texture(iChannel3, normalized_coords).x;\n\n    vec2 Shift_L = vec2(get_depth_shift(normalized_coords, depthl),0.0);\n    vec2 Shift_R = vec2(get_depth_shift(normalized_coords, depthr),0.0);\n\n    float depth_l = 1. - texture(iChannel1, normalized_coords - alpha*Shift_L).x;\n    float depth_r = 1. - texture(iChannel3, normalized_coords + (1.0-alpha)*Shift_R ).x;\n    \n    // compute normalized shifted position    \n    float depth_shifted_x_l = normalized_coords.x - alpha*get_depth_shift(normalized_coords, depth_l);\n    float depth_shifted_x_r = normalized_coords.x + (1.0-alpha)*get_depth_shift(normalized_coords, depth_r);\n    \n    // Handle warping beyond known pixel data for single images and both images screen edge occlusion\n    // we've excceded pixel data for one image, so only use the data from the image still in bounds\n    if (depth_shifted_x_l < 0.0)\n    {\n        alpha = 1.0;\n    }\n    else if (depth_shifted_x_r > 1.0)\n    {\n        alpha = 0.0;\n    }\n    // we've excceed all known pixel data for both images so just extend the last values\n    if(depth_shifted_x_r < 0.0)\n    {\n        depth_shifted_x_r = 0.01;\n    }\n    if(depth_shifted_x_l > 1.0)\n    {\n        depth_shifted_x_l = 0.99;\n    }\n    \n    // clamp color_mix_alpha so as not to over saturate colors below when using extended alpha\n    float color_mix_alpha = clamp(alpha, 0.0, 1.0); \n     \n    // sample alpha mixed pixels at shifted positions \n    vec3 left_rgb = (1.0-color_mix_alpha)*texture(iChannel0, vec2(depth_shifted_x_l, normalized_coords.y)).xyz;\n    vec3 right_rgb = color_mix_alpha*texture(iChannel2, vec2(depth_shifted_x_r, normalized_coords.y)).xyz;\n    \n    return left_rgb + right_rgb;\n}\n\n// samples the image at the required shift alpha (0-1)\nvec4 sampleImage(vec2 normalized_coords, float alpha, float alpha_range_offset)\n{\n    alpha = mix(-alpha_range_offset, 1.0 + alpha_range_offset, alpha);\n    return vec4(get_Im(normalized_coords, alpha), 1.0);\n}\n\n// Get 'virtual' quilt image coordinates\nvec3 get_quilt_coords(vec2 normalized_coords, vec3 quilt_layout, float focus_val)\n{\n    // quilt config\n    float cols = quilt_layout.x;\n    float rows = quilt_layout.y;    \n    float view_count = rows*cols;\n\n    // alter virtual camera angle for each quilt image\n    float alpha_delta = 1.0/(view_count-1.0); //step per quilt view, top right needs to be at alpha 1.0 so subtract -1\n    float active_row = floor(normalized_coords.y/(1.0/rows));\n    float active_col = floor(normalized_coords.x/(1.0/cols));\n    float alpha = active_row*cols*alpha_delta + active_col*alpha_delta; // update alpha virtual camera angle based on quilt view\n\n    // EXPERIMENTAL QUILT FOCUS\n    // map the view_num to -1 to 1 (0 is leftmost n is righmost)\n    float view_num = active_row*cols + active_col;\n    float focusAdjust = view_num / view_count * 2.0f - 1.0f;\n    // multiply by the focus value (normally a user accessable slider)\n    focusAdjust *= focus_val;\n  \n    // update coordinates for quilt space\n    vec2 quilt_coords =  vec2((normalized_coords.x*cols - active_col) + focusAdjust, normalized_coords.y * rows);\n    // return the updated coord data and alpha\n    return vec3(quilt_coords, alpha);\n}\n\n// sample quilt image - supports increased alpha range and quilt focusing\nvec4 sampleQuiltImage(vec2 normalized_coords, float alpha_range_offset, float focus_val){\n    \n    vec3 quilt_data = get_quilt_coords(normalized_coords, tile, focus_val);\n    return sampleImage(quilt_data.xy, quilt_data.z, alpha_range_offset);\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 normalized_coords = fragCoord.xy/iResolution.xy;\n    render_mode = updateRenderModeFromCornerHotspots(iMouse, iResolution);\n    \n    // render lightfield panning viewer\n    if(render_mode == 0)\n    {        \n        fragColor = sampleImage(normalized_coords, iMouse.x/iResolution.x, 0.4);\n    }\n    // render stereo images\n    else if (render_mode == 3)\n    {\n        float blend_factor = iMouse.x/iResolution.x;\n        vec4 l_fragColor = sampleImage(normalized_coords, 0.0, 0.0);\n        vec4 r_fragColor = sampleImage(normalized_coords, 1.0, 0.0);\n        fragColor = (1.0-blend_factor)*l_fragColor + (blend_factor*r_fragColor);\n    }\n    // default is to render lightfield as quilt - render modes 1 and 2\n    else\n    {\n        fragColor = sampleQuiltImage(normalized_coords, 1.5*iMouse.x/iResolution.x, (iMouse.y/iResolution.y)/3.0);\n    }\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[],"outputs":[],"code":"int render_mode = 0;\n\n// Changes render mode based on mouse input\nint updateRenderModeFromCornerHotspots(vec4 iMouse, vec3 iResolution)\n{\n    //Corner based render mode swap\n    // leverages the unique property that abs(mouse.zw) returns the drag start position (persists across frames)\n    int mode = 0;\n     //top left - stereo\n    if(abs(iMouse.z)/iResolution.x < 0.1 && abs(iMouse.w)/iResolution.y > 0.9 )\n    {\n        mode=3;\n    }\n    //top right - lightfield\n    else if(abs(iMouse.z)/iResolution.x > 0.9 && abs(iMouse.w)/iResolution.y > 0.9 )\n    {\n        mode=0;\n    }\n     //bottom left - quilt\n    else if(abs(iMouse.z)/iResolution.x < 0.1 && abs(iMouse.w)/iResolution.y < 0.1 )\n    {\n        mode=1;\n    }\n    //bottom right - lenticular\n    else if(abs(iMouse.z)/iResolution.x > 0.9 && abs(iMouse.w)/iResolution.y < 0.1 )\n    {\n        mode=2;\n    }    \n    //bottom right - lenticular screen clear\n    if(mode == 2 && ((iMouse.x/iResolution.x > 0.87 && iMouse.x/iResolution.x < 0.9 && iMouse.y/iResolution.y < 0.13) || (iMouse.y/iResolution.y > 0.1 && iMouse.y/iResolution.y < 0.13 && iMouse.x/iResolution.x > 0.87)) )\n    {\n        mode=-1;\n    }\n    return mode;\n}\n\n","name":"Common","description":"","type":"common"}]}